[{"text": "hi everyone", "start": 1.8, "duration": 3.84}, {"text": "um we're going to get started now while", "start": 3.419, "duration": 4.44}, {"text": "people still filter in", "start": 5.64, "duration": 4.26}, {"text": "um I just want to introduce myself I'm", "start": 7.859, "duration": 4.381}, {"text": "Marty Candice I'm a computational and", "start": 9.9, "duration": 4.08}, {"text": "data science research specialist here in", "start": 12.24, "duration": 3.479}, {"text": "the high performance Computing user", "start": 13.98, "duration": 4.08}, {"text": "service group here at sdsc", "start": 15.719, "duration": 3.301}, {"text": "um today", "start": 18.06, "duration": 5.059}, {"text": "um we're holding this rescheduled", "start": 19.02, "duration": 7.259}, {"text": "training on the new Rapids framework", "start": 23.119, "duration": 5.801}, {"text": "from Nvidia I apologize about the", "start": 26.279, "duration": 5.82}, {"text": "rescheduling last week the SSD on my", "start": 28.92, "duration": 5.9}, {"text": "hard drive died and it created a lot of", "start": 32.099, "duration": 5.881}, {"text": "backup in my workflow for uh finishing", "start": 34.82, "duration": 5.559}, {"text": "both this talk and the grant the", "start": 37.98, "duration": 3.78}, {"text": "submission we were working on last week", "start": 40.379, "duration": 3.121}, {"text": "and a few other things so apologize for", "start": 41.76, "duration": 4.799}, {"text": "the delay in the um in the training here", "start": 43.5, "duration": 4.98}, {"text": "but hopefully you get something out of", "start": 46.559, "duration": 4.5}, {"text": "it today and thanks for joining", "start": 48.48, "duration": 6.02}, {"text": "so let's go ahead and get started", "start": 51.059, "duration": 3.441}, {"text": "so again just a quick thing about me um", "start": 55.079, "duration": 5.881}, {"text": "working in the HPC user Services Group I", "start": 58.16, "duration": 4.36}, {"text": "mostly work on comment if it's one of", "start": 60.96, "duration": 4.379}, {"text": "the exceed systems here uh running on", "start": 62.52, "duration": 3.779}, {"text": "right now", "start": 65.339, "duration": 3.301}, {"text": "um my background's actually not in data", "start": 66.299, "duration": 3.841}, {"text": "science or machine learning I'm more of", "start": 68.64, "duration": 3.42}, {"text": "a computational physicist by training a", "start": 70.14, "duration": 3.299}, {"text": "traditional HPC", "start": 72.06, "duration": 4.62}, {"text": "um uh sort of hybrid codes with NPI", "start": 73.439, "duration": 5.521}, {"text": "openmp and sort of calculations for it", "start": 76.68, "duration": 4.259}, {"text": "on a sort of computational fluid Dynamic", "start": 78.96, "duration": 4.68}, {"text": "like simulation so all the material in", "start": 80.939, "duration": 4.68}, {"text": "here uh that I'll cover in Rapids is", "start": 83.64, "duration": 4.92}, {"text": "really data science oriented so you", "start": 85.619, "duration": 4.68}, {"text": "might be more of an expert than I am on", "start": 88.56, "duration": 4.5}, {"text": "certain aspects of some of the libraries", "start": 90.299, "duration": 5.061}, {"text": "we'll talk about today like pandas or", "start": 93.06, "duration": 4.199}, {"text": "scikit-learning things like that so if", "start": 95.36, "duration": 3.82}, {"text": "you're here to really learn some", "start": 97.259, "duration": 5.0}, {"text": "intricacies of how Rapids", "start": 99.18, "duration": 6.72}, {"text": "translates over into a lot of the", "start": 102.259, "duration": 6.701}, {"text": "algorithms in those packages I'm not the", "start": 105.9, "duration": 5.64}, {"text": "expert there but we will have uh some", "start": 108.96, "duration": 6.659}, {"text": "other Talks by Nvidia next month that", "start": 111.54, "duration": 6.539}, {"text": "you can ask more in-depth questions too", "start": 115.619, "duration": 4.32}, {"text": "if you're interested so just a", "start": 118.079, "duration": 4.021}, {"text": "disclaimer that I'm actually learning", "start": 119.939, "duration": 4.86}, {"text": "how to use all the data science tools", "start": 122.1, "duration": 6.42}, {"text": "such as pandas scikit-learn and today", "start": 124.799, "duration": 7.261}, {"text": "Rapids myself so hopefully uh this will", "start": 128.52, "duration": 5.34}, {"text": "at least give you an introduction to", "start": 132.06, "duration": 4.679}, {"text": "material and get you going if you're", "start": 133.86, "duration": 6.0}, {"text": "sort of new to it all like me as well", "start": 136.739, "duration": 4.461}, {"text": "okay", "start": 139.86, "duration": 4.26}, {"text": "so just a few quick reminders before we", "start": 141.2, "duration": 4.0}, {"text": "get going", "start": 144.12, "duration": 3.839}, {"text": "um so uh just uh the exceed code of", "start": 145.2, "duration": 4.2}, {"text": "conduct here this is sort of a public", "start": 147.959, "duration": 3.42}, {"text": "forum you know you have the other", "start": 149.4, "duration": 3.6}, {"text": "participants you can communicate with", "start": 151.379, "duration": 4.021}, {"text": "them through chat or communicate with us", "start": 153.0, "duration": 3.84}, {"text": "through chat", "start": 155.4, "duration": 3.24}, {"text": "um so if uh you know just try to treat", "start": 156.84, "duration": 3.96}, {"text": "everybody with respect and um if you", "start": 158.64, "duration": 3.72}, {"text": "need to know more about the exceed code", "start": 160.8, "duration": 3.0}, {"text": "of conduct there's the uh the link", "start": 162.36, "duration": 4.2}, {"text": "available here with contact information", "start": 163.8, "duration": 5.48}, {"text": "there as well", "start": 166.56, "duration": 2.72}, {"text": "so uh like I said I work on comment", "start": 169.379, "duration": 5.701}, {"text": "mostly so uh just FYI um right comments", "start": 171.959, "duration": 5.761}, {"text": "end of service is going to be March 2021", "start": 175.08, "duration": 4.379}, {"text": "next year so if you just applied for an", "start": 177.72, "duration": 4.44}, {"text": "exceed allocation in January 15th I", "start": 179.459, "duration": 4.801}, {"text": "think was the deadline that'll be sort", "start": 182.16, "duration": 3.9}, {"text": "of the last full year of production if", "start": 184.26, "duration": 3.479}, {"text": "you get awarded so just keep that in", "start": 186.06, "duration": 2.7}, {"text": "mind", "start": 187.739, "duration": 3.801}, {"text": "and then uh we have the follow-on system", "start": 188.76, "duration": 5.58}, {"text": "expanse which is the follow-on system to", "start": 191.54, "duration": 5.38}, {"text": "uh comment coming in September 2020", "start": 194.34, "duration": 4.979}, {"text": "roughly is when", "start": 196.92, "duration": 4.26}, {"text": "it'll be online um keep if you're", "start": 199.319, "duration": 3.901}, {"text": "interested in running on expanse in the", "start": 201.18, "duration": 4.62}, {"text": "future keep an eye out for any sort of", "start": 203.22, "duration": 5.7}, {"text": "announcements about maybe early user", "start": 205.8, "duration": 5.34}, {"text": "allocations and things might be uh", "start": 208.92, "duration": 4.92}, {"text": "before September 2020 but you'll again", "start": 211.14, "duration": 4.44}, {"text": "have to apply through the exceed", "start": 213.84, "duration": 3.899}, {"text": "allocation process for those", "start": 215.58, "duration": 3.6}, {"text": "so I don't think the details are set", "start": 217.739, "duration": 3.481}, {"text": "there but uh just keep an eye out", "start": 219.18, "duration": 3.3}, {"text": "okay", "start": 221.22, "duration": 3.659}, {"text": "so let's go ahead and get started so the", "start": 222.48, "duration": 3.539}, {"text": "talk today", "start": 224.879, "duration": 2.821}, {"text": "um what I call from zero to Rapids", "start": 226.019, "duration": 3.181}, {"text": "because that's sort of How I Learned", "start": 227.7, "duration": 3.72}, {"text": "Rapids from the ground up", "start": 229.2, "duration": 3.539}, {"text": "um is just want to give you a quick high", "start": 231.42, "duration": 3.959}, {"text": "level overview of what Rapids is", "start": 232.739, "duration": 4.08}, {"text": "um sort of what some of its capabilities", "start": 235.379, "duration": 3.901}, {"text": "are and then I really just want to jump", "start": 236.819, "duration": 5.401}, {"text": "into a Jupiter notebook demo and show", "start": 239.28, "duration": 4.319}, {"text": "you", "start": 242.22, "duration": 3.84}, {"text": "um a little bit in-depth example about", "start": 243.599, "duration": 6.601}, {"text": "at least the the first core Library", "start": 246.06, "duration": 6.12}, {"text": "which is called qdf which is sort of the", "start": 250.2, "duration": 4.44}, {"text": "the pandas drop in replacement I was", "start": 252.18, "duration": 3.839}, {"text": "hoping to get to the sort of", "start": 254.64, "duration": 4.26}, {"text": "scikit-learn drop-in replacement", "start": 256.019, "duration": 4.981}, {"text": "um which is called qml but I didn't have", "start": 258.9, "duration": 3.9}, {"text": "enough time to sort of uh", "start": 261.0, "duration": 3.54}, {"text": "sort through all the data and come up", "start": 262.8, "duration": 3.54}, {"text": "with a good example there but um I'll", "start": 264.54, "duration": 3.48}, {"text": "show you some links to additional", "start": 266.34, "duration": 5.04}, {"text": "resources and references for this Fannie", "start": 268.02, "duration": 6.179}, {"text": "Mae loan performance data set that we'll", "start": 271.38, "duration": 4.92}, {"text": "look at um it has some more in-depth", "start": 274.199, "duration": 4.921}, {"text": "sort of analysis for example there's one", "start": 276.3, "duration": 6.119}, {"text": "example that's going to use the Rapids", "start": 279.12, "duration": 5.16}, {"text": "framework also with pi torch if you're", "start": 282.419, "duration": 3.72}, {"text": "familiar with pi Torch 2 to do some sort", "start": 284.28, "duration": 4.199}, {"text": "of machine learning on the on the on the", "start": 286.139, "duration": 4.081}, {"text": "data set as well", "start": 288.479, "duration": 3.78}, {"text": "okay so that's sort of the overview of", "start": 290.22, "duration": 4.56}, {"text": "today and let's just start talking about", "start": 292.259, "duration": 4.201}, {"text": "Rapids so if you're not familiar with", "start": 294.78, "duration": 4.5}, {"text": "what Rapids is it's nvidia's new suite", "start": 296.46, "duration": 5.34}, {"text": "of uh open source software libraries and", "start": 299.28, "duration": 6.18}, {"text": "apis that sort of give you access to all", "start": 301.8, "duration": 5.88}, {"text": "of the sort of classical data science", "start": 305.46, "duration": 5.22}, {"text": "analytics machine learning type", "start": 307.68, "duration": 6.299}, {"text": "algorithms that you can run you know the", "start": 310.68, "duration": 5.22}, {"text": "idea is to run them much faster on", "start": 313.979, "duration": 5.601}, {"text": "Nvidia gpus than you can on traditional", "start": 315.9, "duration": 6.66}, {"text": "CPUs so this is um", "start": 319.58, "duration": 6.459}, {"text": "sort of the main goal so it what I'll", "start": 322.56, "duration": 5.22}, {"text": "show you it's trying to really fill in I", "start": 326.039, "duration": 3.301}, {"text": "think a niche", "start": 327.78, "duration": 3.9}, {"text": "um outside of sort of all of the sort of", "start": 329.34, "duration": 4.26}, {"text": "machine learning Frameworks you kind of", "start": 331.68, "duration": 4.68}, {"text": "think of like tensorflow Pi torch mxnet", "start": 333.6, "duration": 5.22}, {"text": "all these really", "start": 336.36, "duration": 4.74}, {"text": "Frameworks that are targeted the you", "start": 338.82, "duration": 5.68}, {"text": "know very popular deep learning", "start": 341.1, "duration": 3.84}, {"text": "[Music]", "start": 344.5, "duration": 1.58}, {"text": "um", "start": 344.94, "duration": 3.9}, {"text": "sort of applications these days right so", "start": 346.08, "duration": 4.98}, {"text": "Rapids is really trying to fill in sort", "start": 348.84, "duration": 3.84}, {"text": "of all the more classical machine", "start": 351.06, "duration": 4.02}, {"text": "learning data science algorithms that", "start": 352.68, "duration": 4.26}, {"text": "you're running in pandas scikit learn", "start": 355.08, "duration": 5.04}, {"text": "and some other libraries as well", "start": 356.94, "duration": 4.44}, {"text": "um so it's not really trying to compete", "start": 360.12, "duration": 3.0}, {"text": "with those deep learning libraries it's", "start": 361.38, "duration": 5.099}, {"text": "really trying to fill in places where", "start": 363.12, "duration": 6.0}, {"text": "um sort of GPU accelerated algorithms", "start": 366.479, "duration": 4.801}, {"text": "haven't been developed yet or haven't", "start": 369.12, "duration": 4.38}, {"text": "been sort of put into a nice framework", "start": 371.28, "duration": 4.38}, {"text": "that you can use", "start": 373.5, "duration": 4.32}, {"text": "so why might you want to use Rapids", "start": 375.66, "duration": 4.8}, {"text": "right so Rapids sort of leverages the", "start": 377.82, "duration": 5.46}, {"text": "underlying Cuda programming language and", "start": 380.46, "duration": 6.079}, {"text": "Primitives to sort of get you those GPU", "start": 383.28, "duration": 5.639}, {"text": "compute optimizations without you having", "start": 386.539, "duration": 4.481}, {"text": "to do any sort of of the programming", "start": 388.919, "duration": 4.56}, {"text": "right it's also I think what you'll see", "start": 391.02, "duration": 4.86}, {"text": "is very user friendly if you're familiar", "start": 393.479, "duration": 4.761}, {"text": "with sort of the sort of standard python", "start": 395.88, "duration": 5.64}, {"text": "data science sort of ecosystem", "start": 398.24, "duration": 6.519}, {"text": "so the the they're really aiming to", "start": 401.52, "duration": 9.36}, {"text": "develop very similar apis to all of the", "start": 404.759, "duration": 8.22}, {"text": "um you know well-known", "start": 410.88, "duration": 5.3}, {"text": "data science and machine learning python", "start": 412.979, "duration": 6.481}, {"text": "pythonic sort of interfaces to a bunch", "start": 416.18, "duration": 4.54}, {"text": "of these libraries", "start": 419.46, "duration": 4.2}, {"text": "and so it'll the idea is to really get", "start": 420.72, "duration": 5.58}, {"text": "you working on gpus as fast as possible", "start": 423.66, "duration": 4.92}, {"text": "and so you'll kind of see that I think", "start": 426.3, "duration": 4.019}, {"text": "in the demo", "start": 428.58, "duration": 4.619}, {"text": "um also uh it allows you um to if you're", "start": 430.319, "duration": 4.761}, {"text": "familiar with desk which is sort of a", "start": 433.199, "duration": 5.161}, {"text": "framework to help paralyze a lot of", "start": 435.08, "duration": 6.7}, {"text": "these traditional um python-based uh", "start": 438.36, "duration": 5.16}, {"text": "data science and machine learning", "start": 441.78, "duration": 5.34}, {"text": "workflows across multiple CPUs they also", "start": 443.52, "duration": 6.239}, {"text": "integrate Rapids with desks to allow for", "start": 447.12, "duration": 4.979}, {"text": "sort of multi multi-gpu systems if you", "start": 449.759, "duration": 5.401}, {"text": "have really large data sets and it sort", "start": 452.099, "duration": 5.581}, {"text": "of allows you to scale out your analysis", "start": 455.16, "duration": 4.439}, {"text": "more quickly", "start": 457.68, "duration": 4.62}, {"text": "I was hoping to get to an example of", "start": 459.599, "duration": 4.981}, {"text": "this uh in the in the notebook we'll go", "start": 462.3, "duration": 5.16}, {"text": "through but I wasn't able to get", "start": 464.58, "duration": 4.739}, {"text": "everything set up quite so it's sort of", "start": 467.46, "duration": 3.9}, {"text": "probably on the future roadmap of this", "start": 469.319, "duration": 3.841}, {"text": "talk of having sort of a full", "start": 471.36, "duration": 4.44}, {"text": "multi-known multi-gpu example because", "start": 473.16, "duration": 4.08}, {"text": "the data simple look at is actually", "start": 475.8, "duration": 3.54}, {"text": "large enough to really take advantage of", "start": 477.24, "duration": 4.2}, {"text": "and show you the advantages of that this", "start": 479.34, "duration": 3.6}, {"text": "kind of setup", "start": 481.44, "duration": 3.9}, {"text": "and then the last point is it's uh open", "start": 482.94, "duration": 3.9}, {"text": "source so you can go see the source code", "start": 485.34, "duration": 3.06}, {"text": "and see what's going on and everything", "start": 486.84, "duration": 3.12}, {"text": "what's going on and sometimes you kind", "start": 488.4, "duration": 2.88}, {"text": "of have to do that right now I mean the", "start": 489.96, "duration": 3.78}, {"text": "the documentation is still", "start": 491.28, "duration": 4.74}, {"text": "um being formed so if you can't figure", "start": 493.74, "duration": 5.519}, {"text": "out why sort of the Rapids version of", "start": 496.02, "duration": 5.399}, {"text": "this method is not working you might", "start": 499.259, "duration": 4.62}, {"text": "have to sort of dig around in there and", "start": 501.419, "duration": 5.4}, {"text": "see how it's expecting sort of sort of", "start": 503.879, "duration": 4.38}, {"text": "in different input variables and things", "start": 506.819, "duration": 4.861}, {"text": "to be added in to uh your call to a", "start": 508.259, "duration": 6.181}, {"text": "certain method so anyway", "start": 511.68, "duration": 5.219}, {"text": "um so that's sort of a high level", "start": 514.44, "duration": 4.56}, {"text": "overview of Rapid so this is sort of the", "start": 516.899, "duration": 3.361}, {"text": "traditional", "start": 519.0, "duration": 4.08}, {"text": "um CPU based data science", "start": 520.26, "duration": 4.26}, {"text": "sort of software stack you might be", "start": 523.08, "duration": 2.64}, {"text": "familiar with this is what you've been", "start": 524.52, "duration": 3.18}, {"text": "working with for a long time", "start": 525.72, "duration": 5.22}, {"text": "so right um the two core libraries I", "start": 527.7, "duration": 4.56}, {"text": "would say Rapids is really trying to", "start": 530.94, "duration": 4.2}, {"text": "replace right now is um pandas and", "start": 532.26, "duration": 7.139}, {"text": "scikit-learn for GPU accelerate on on", "start": 535.14, "duration": 6.54}, {"text": "their GPU so they're really targeting", "start": 539.399, "duration": 4.081}, {"text": "all of the algorithms that you might be", "start": 541.68, "duration": 4.76}, {"text": "familiar with that are in those two", "start": 543.48, "duration": 4.56}, {"text": "libraries", "start": 546.44, "duration": 3.579}, {"text": "that's sort of what's been most", "start": 548.04, "duration": 4.08}, {"text": "developed so far um", "start": 550.019, "duration": 4.981}, {"text": "if you're also using network X for sort", "start": 552.12, "duration": 6.36}, {"text": "of graph analytics there is a Rapids", "start": 555.0, "duration": 5.58}, {"text": "replacement for that right now I think", "start": 558.48, "duration": 3.9}, {"text": "it's still one of the newer libraries", "start": 560.58, "duration": 4.02}, {"text": "that's being developed so", "start": 562.38, "duration": 3.959}, {"text": "I haven't played with that at all so I", "start": 564.6, "duration": 3.54}, {"text": "don't really have any uh", "start": 566.339, "duration": 5.101}, {"text": "experience with using that yet so this", "start": 568.14, "duration": 5.16}, {"text": "is sort of right your traditional CPU", "start": 571.44, "duration": 4.26}, {"text": "based status science software stack that", "start": 573.3, "duration": 3.96}, {"text": "you you're you might be you're probably", "start": 575.7, "duration": 3.06}, {"text": "familiar with if you're here in this", "start": 577.26, "duration": 2.519}, {"text": "talk right", "start": 578.76, "duration": 2.88}, {"text": "so again this is what Rapids is trying", "start": 579.779, "duration": 3.321}, {"text": "to do it's really trying to replace so", "start": 581.64, "duration": 5.04}, {"text": "your drop-in replacement for pandas is", "start": 583.1, "duration": 5.38}, {"text": "going to be kudia", "start": 586.68, "duration": 4.2}, {"text": "um this coup i o that's here on the", "start": 588.48, "duration": 3.18}, {"text": "screen", "start": 590.88, "duration": 2.82}, {"text": "um I'm not exactly sure what the", "start": 591.66, "duration": 4.02}, {"text": "difference is they might be they think", "start": 593.7, "duration": 4.259}, {"text": "trying to split these libraries into two", "start": 595.68, "duration": 4.74}, {"text": "uh When I Was preparing this talker the", "start": 597.959, "duration": 4.061}, {"text": "first time I'd seen", "start": 600.42, "duration": 4.58}, {"text": "[Music]", "start": 602.02, "duration": 5.72}, {"text": "Library show up so I'm not exactly sure", "start": 605.0, "duration": 4.18}, {"text": "what", "start": 607.74, "duration": 3.06}, {"text": "um sort of the future roadmap is here", "start": 609.18, "duration": 3.659}, {"text": "maybe they're splitting the the existing", "start": 610.8, "duration": 5.099}, {"text": "version of qdf into two this is what", "start": 612.839, "duration": 4.141}, {"text": "it's", "start": 615.899, "duration": 2.821}, {"text": "seems like from this chart", "start": 616.98, "duration": 2.34}, {"text": "um", "start": 618.72, "duration": 2.88}, {"text": "again cool ml here is going to be your", "start": 619.32, "duration": 4.92}, {"text": "scikit-learn replacement and kugraph is", "start": 621.6, "duration": 5.7}, {"text": "sort of your network X replacement so", "start": 624.24, "duration": 5.159}, {"text": "and again these are all integrated with", "start": 627.3, "duration": 4.64}, {"text": "desks to help you do sort of multi-node", "start": 629.399, "duration": 4.981}, {"text": "multi-gpu training if your data sets are", "start": 631.94, "duration": 3.339}, {"text": "that large", "start": 634.38, "duration": 2.34}, {"text": "so I'm not going to go into any details", "start": 635.279, "duration": 2.941}, {"text": "sort of the underlying architectures of", "start": 636.72, "duration": 3.299}, {"text": "the different libraries I just want to", "start": 638.22, "duration": 3.42}, {"text": "give you a high level overview if you're", "start": 640.019, "duration": 3.421}, {"text": "not familiar with these libraries of", "start": 641.64, "duration": 3.18}, {"text": "what they are", "start": 643.44, "duration": 3.3}, {"text": "um and some", "start": 644.82, "duration": 3.6}, {"text": "just some bullet points on that and then", "start": 646.74, "duration": 4.44}, {"text": "we'll jump into the Jupiter notebook", "start": 648.42, "duration": 4.919}, {"text": "demo and show you sort of get how you", "start": 651.18, "duration": 5.46}, {"text": "could get started with uh kudia", "start": 653.339, "duration": 5.701}, {"text": "okay so I think I've kind of said this", "start": 656.64, "duration": 4.56}, {"text": "so qdf is your pandas replacement right", "start": 659.04, "duration": 3.72}, {"text": "it's so they're going to provide you", "start": 661.2, "duration": 3.9}, {"text": "with your sort of GPU native data frame", "start": 662.76, "duration": 4.079}, {"text": "library for", "start": 665.1, "duration": 6.78}, {"text": "essentially filtering and sorting and", "start": 666.839, "duration": 8.641}, {"text": "sort of exploring your data sets and the", "start": 671.88, "duration": 5.639}, {"text": "idea is to really allow you to explore", "start": 675.48, "duration": 4.08}, {"text": "large data sets more quickly essentially", "start": 677.519, "duration": 4.521}, {"text": "okay", "start": 679.56, "duration": 2.48}, {"text": "as I said", "start": 682.14, "duration": 5.639}, {"text": "scikit-learn GPU accelerated version and", "start": 683.779, "duration": 5.74}, {"text": "you know it's going to have again", "start": 687.779, "duration": 4.081}, {"text": "they're trying to develop all of the", "start": 689.519, "duration": 4.681}, {"text": "similar all of the same algorithms and", "start": 691.86, "duration": 3.84}, {"text": "methods that you might be using in", "start": 694.2, "duration": 4.86}, {"text": "scikit learn in qml however with all of", "start": 695.7, "duration": 5.16}, {"text": "these libraries they're not they're", "start": 699.06, "duration": 3.6}, {"text": "they're they're they're they're still", "start": 700.86, "duration": 3.719}, {"text": "undergoing lots of development so", "start": 702.66, "duration": 3.419}, {"text": "certain algorithms may not be", "start": 704.579, "duration": 3.361}, {"text": "implemented yet", "start": 706.079, "duration": 3.901}, {"text": "um the Nvidia is pretty good I think", "start": 707.94, "duration": 4.8}, {"text": "about putting out a roadmap of what is", "start": 709.98, "duration": 4.979}, {"text": "um on the roadmap and when you might", "start": 712.74, "duration": 3.599}, {"text": "expect certain algorithms to be", "start": 714.959, "duration": 2.88}, {"text": "available if certain ones are important", "start": 716.339, "duration": 2.581}, {"text": "here", "start": 717.839, "duration": 2.761}, {"text": "to your workflow", "start": 718.92, "duration": 4.14}, {"text": "um but uh just something to keep in mind", "start": 720.6, "duration": 5.46}, {"text": "that these things these these libraries", "start": 723.06, "duration": 5.1}, {"text": "are changing quickly and new stuff is", "start": 726.06, "duration": 4.44}, {"text": "being added in and so if something", "start": 728.16, "duration": 4.44}, {"text": "doesn't exist yet in Rapids it probably", "start": 730.5, "duration": 4.2}, {"text": "will in the future if it exists in one", "start": 732.6, "duration": 3.479}, {"text": "of its sort of", "start": 734.7, "duration": 2.9}, {"text": "um CPU", "start": 736.079, "duration": 3.961}, {"text": "Brothers like brother libraries", "start": 737.6, "duration": 4.859}, {"text": "essentially", "start": 740.04, "duration": 2.419}, {"text": "um again kugraph is the if you're", "start": 742.98, "duration": 5.22}, {"text": "familiar with network X which is for", "start": 745.98, "duration": 4.68}, {"text": "graph Analytics", "start": 748.2, "duration": 4.62}, {"text": "um you know some stats that will sound", "start": 750.66, "duration": 3.54}, {"text": "kind of interesting that I was reading", "start": 752.82, "duration": 4.199}, {"text": "about you know so on a single Nvidia GPU", "start": 754.2, "duration": 6.54}, {"text": "V100 you can get fit about 500 million", "start": 757.019, "duration": 6.241}, {"text": "edges of a graph and you can scale to", "start": 760.74, "duration": 4.92}, {"text": "billions of edges uh if you go to multi", "start": 763.26, "duration": 4.139}, {"text": "GPU so it's", "start": 765.66, "duration": 4.739}, {"text": "might give you if you're this is", "start": 767.399, "duration": 3.781}, {"text": "um", "start": 770.399, "duration": 3.141}, {"text": "part of your workflow some sort of graph", "start": 771.18, "duration": 5.04}, {"text": "analytics this is", "start": 773.54, "duration": 5.38}, {"text": "seems pretty interesting how high you", "start": 776.22, "duration": 4.559}, {"text": "can go how large of graphs you could", "start": 778.92, "duration": 5.039}, {"text": "really consider analyzing", "start": 780.779, "duration": 5.701}, {"text": "where you might not even consider doing", "start": 783.959, "duration": 5.581}, {"text": "it on a CPU because I don't think as far", "start": 786.48, "duration": 4.38}, {"text": "as I understand Network X isn't", "start": 789.54, "duration": 3.06}, {"text": "integrated with desk but like it could", "start": 790.86, "duration": 3.18}, {"text": "be you know it could be wrong", "start": 792.6, "duration": 3.239}, {"text": "oh", "start": 794.04, "duration": 5.46}, {"text": "um and the latest Library that's been", "start": 795.839, "duration": 5.881}, {"text": "added into Rapids recently is Coos", "start": 799.5, "duration": 5.579}, {"text": "spatial so this is a focused specialized", "start": 801.72, "duration": 6.0}, {"text": "library and geospatial and spatio", "start": 805.079, "duration": 4.981}, {"text": "temporal sort of data processing so if", "start": 807.72, "duration": 4.98}, {"text": "you are doing sort of analyzing", "start": 810.06, "duration": 7.2}, {"text": "satellite data and have like geolocation", "start": 812.7, "duration": 6.72}, {"text": "data and things like that you know this", "start": 817.26, "duration": 5.04}, {"text": "might be one of the Rapids libraries", "start": 819.42, "duration": 4.14}, {"text": "that you might want to look at and see", "start": 822.3, "duration": 3.06}, {"text": "what's being built I think it's very new", "start": 823.56, "duration": 4.14}, {"text": "I think it's only like less", "start": 825.36, "duration": 5.34}, {"text": "few months that it came out so um I", "start": 827.7, "duration": 5.22}, {"text": "don't know exactly what", "start": 830.7, "duration": 5.579}, {"text": "um what's all in there yet but if this", "start": 832.92, "duration": 5.099}, {"text": "is part of your workflow some sort of", "start": 836.279, "duration": 5.341}, {"text": "geospatial data processing this is one", "start": 838.019, "duration": 5.521}, {"text": "of the Rapids libraries you want to look", "start": 841.62, "duration": 4.04}, {"text": "at", "start": 843.54, "duration": 2.12}, {"text": "okay so let's get to the more fun part", "start": 845.7, "duration": 6.0}, {"text": "so we're gonna so I developed a Jupiter", "start": 848.88, "duration": 5.699}, {"text": "notebook here based on one of the", "start": 851.7, "duration": 4.98}, {"text": "existing sort of demos that Nvidia has", "start": 854.579, "duration": 5.461}, {"text": "out there looking at this Fannie Mae", "start": 856.68, "duration": 6.899}, {"text": "mortgage loan data set so if", "start": 860.04, "duration": 5.52}, {"text": "yeah you don't have no reference here", "start": 863.579, "duration": 6.181}, {"text": "the big shortest movie about the 2008 uh", "start": 865.56, "duration": 6.839}, {"text": "financial crisis and particularly about", "start": 869.76, "duration": 5.22}, {"text": "the the U.S housing market and so", "start": 872.399, "duration": 4.081}, {"text": "there's a book in a movie about it it's", "start": 874.98, "duration": 3.299}, {"text": "actually yeah both are pretty good I've", "start": 876.48, "duration": 3.599}, {"text": "seen both I've seen them the movie and", "start": 878.279, "duration": 3.42}, {"text": "read the book it's pretty good", "start": 880.079, "duration": 3.0}, {"text": "um and the data set that we'll look at", "start": 881.699, "duration": 3.961}, {"text": "covers sort of before the crisis and", "start": 883.079, "duration": 3.841}, {"text": "after the crisis so it's kind of", "start": 885.66, "duration": 3.66}, {"text": "interesting from recent historical", "start": 886.92, "duration": 5.4}, {"text": "um you know economic Financial history I", "start": 889.32, "duration": 4.379}, {"text": "guess so it's sort of an interesting", "start": 892.32, "duration": 4.319}, {"text": "data set it's large enough to really", "start": 893.699, "duration": 6.901}, {"text": "um show you how much faster uh", "start": 896.639, "duration": 6.721}, {"text": "Rapids could be if you anal using Rapids", "start": 900.6, "duration": 4.679}, {"text": "could be then sticking with your sort of", "start": 903.36, "duration": 5.039}, {"text": "sort of same pandas sort of workflow or", "start": 905.279, "duration": 5.281}, {"text": "uh it's like get learn more it's big", "start": 908.399, "duration": 4.141}, {"text": "enough to give you a sense of the speed", "start": 910.56, "duration": 4.139}, {"text": "up that you'll gain running on gpus", "start": 912.54, "duration": 5.22}, {"text": "versus CPUs okay", "start": 914.699, "duration": 4.861}, {"text": "so um before I jump in the notebook I", "start": 917.76, "duration": 4.34}, {"text": "just want to give you some context here", "start": 919.56, "duration": 6.44}, {"text": "about the data sets what it means what's", "start": 922.1, "duration": 6.64}, {"text": "some links to", "start": 926.0, "duration": 5.44}, {"text": "how to explore the data set further if", "start": 928.74, "duration": 4.44}, {"text": "you want to do it later on", "start": 931.44, "duration": 2.94}, {"text": "um", "start": 933.18, "duration": 2.82}, {"text": "during your free time and get familiar", "start": 934.38, "duration": 3.06}, {"text": "with Rapids", "start": 936.0, "duration": 2.279}, {"text": "um", "start": 937.44, "duration": 2.94}, {"text": "this is the data set so it's the Fannie", "start": 938.279, "duration": 4.381}, {"text": "Mae single family loan performance data", "start": 940.38, "duration": 4.62}, {"text": "set and there's a link here to the", "start": 942.66, "duration": 3.96}, {"text": "website where you can find it and it's", "start": 945.0, "duration": 3.54}, {"text": "actually really nice in the sense that", "start": 946.62, "duration": 2.839}, {"text": "there's", "start": 948.54, "duration": 5.099}, {"text": "tutorials there's R code and SAS code to", "start": 949.459, "duration": 5.921}, {"text": "analyze the data set if you're familiar", "start": 953.639, "duration": 4.14}, {"text": "with either those languages for doing", "start": 955.38, "duration": 4.98}, {"text": "data analysis so it's it's pretty well", "start": 957.779, "duration": 4.62}, {"text": "documented it's constantly being updated", "start": 960.36, "duration": 4.14}, {"text": "that's updated every quarter", "start": 962.399, "duration": 4.921}, {"text": "um and it's", "start": 964.5, "duration": 4.86}, {"text": "I think I have some stats on the next", "start": 967.32, "duration": 3.6}, {"text": "set yeah so why why are we going to use", "start": 969.36, "duration": 2.88}, {"text": "this data set so it's large in size", "start": 970.92, "duration": 4.68}, {"text": "right so it's more than 1.9 billion", "start": 972.24, "duration": 7.38}, {"text": "records on 37 million 30 or 30-year", "start": 975.6, "duration": 6.84}, {"text": "fixed rate mortgages and uncompress the", "start": 979.62, "duration": 4.74}, {"text": "data set that we'll use today is around", "start": 982.44, "duration": 4.1}, {"text": "200 gigabytes", "start": 984.36, "duration": 4.2}, {"text": "however we're going to use a subset of", "start": 986.54, "duration": 4.359}, {"text": "that because as I said I didn't do the", "start": 988.56, "duration": 5.1}, {"text": "multi-node multi-gpu training so 200", "start": 990.899, "duration": 4.321}, {"text": "gigabytes isn't going to fit on a single", "start": 993.66, "duration": 3.72}, {"text": "GPU so", "start": 995.22, "duration": 4.02}, {"text": "um this is sort of uh why it's sort of", "start": 997.38, "duration": 3.54}, {"text": "an aspirational data set to keep", "start": 999.24, "duration": 4.14}, {"text": "developing this and this training to get", "start": 1000.92, "duration": 3.599}, {"text": "to", "start": 1003.38, "duration": 4.56}, {"text": "uh using the full full data set and all", "start": 1004.519, "duration": 5.82}, {"text": "the records in it um like I said it's a", "start": 1007.94, "duration": 4.5}, {"text": "it's data set grows so every quarter", "start": 1010.339, "duration": 4.081}, {"text": "it's updated by Fannie Mae", "start": 1012.44, "duration": 3.839}, {"text": "um you know like I said it's also well", "start": 1014.42, "duration": 3.659}, {"text": "documented on the website", "start": 1016.279, "duration": 4.141}, {"text": "um on the previous slide um Fannie Mae", "start": 1018.079, "duration": 4.62}, {"text": "you'll see links to a couple tutorials", "start": 1020.42, "duration": 4.56}, {"text": "on how to analyze the data set for um I", "start": 1022.699, "duration": 3.421}, {"text": "think they're doing some sort of credit", "start": 1024.98, "duration": 4.859}, {"text": "analysis on the um in through through", "start": 1026.12, "duration": 6.36}, {"text": "those tutorials and Nvidia also has the", "start": 1029.839, "duration": 4.141}, {"text": "data set featured in some of their", "start": 1032.48, "duration": 3.18}, {"text": "previous Rapids training so you can find", "start": 1033.98, "duration": 3.24}, {"text": "material there I think I've put some", "start": 1035.66, "duration": 4.019}, {"text": "links later on to uh one of the", "start": 1037.22, "duration": 4.14}, {"text": "notebooks I mentioned where they use", "start": 1039.679, "duration": 4.14}, {"text": "Rapids and Pi torch to analyze the data", "start": 1041.36, "duration": 3.78}, {"text": "set", "start": 1043.819, "duration": 3.24}, {"text": "um and it's easily accessible so the", "start": 1045.14, "duration": 3.299}, {"text": "data set you can get available for free", "start": 1047.059, "duration": 3.601}, {"text": "from Fannie Mae on the website you can", "start": 1048.439, "duration": 4.021}, {"text": "just you have to I think sign it get a", "start": 1050.66, "duration": 2.72}, {"text": "login", "start": 1052.46, "duration": 3.54}, {"text": "to download it and any of the updates", "start": 1053.38, "duration": 4.6}, {"text": "but some of the subsets that are are", "start": 1056.0, "duration": 4.98}, {"text": "available on the Nvidia Rapids website", "start": 1057.98, "duration": 6.68}, {"text": "so I'll just show you that here", "start": 1060.98, "duration": 3.68}, {"text": "so so on the Rapids in the Rapids", "start": 1068.0, "duration": 4.08}, {"text": "documentation under the demonstrations", "start": 1070.52, "duration": 4.62}, {"text": "you'll find the some subsets of the", "start": 1072.08, "duration": 5.94}, {"text": "mortgage data set as well okay so this", "start": 1075.14, "duration": 3.96}, {"text": "is actually where we're going to", "start": 1078.02, "duration": 2.7}, {"text": "download the data set you'll see in the", "start": 1079.1, "duration": 3.06}, {"text": "notebook but", "start": 1080.72, "duration": 4.86}, {"text": "it's available here in the uh the Rapids", "start": 1082.16, "duration": 5.16}, {"text": "documentation as well", "start": 1085.58, "duration": 3.54}, {"text": "so you don't have to actually go sign up", "start": 1087.32, "duration": 4.8}, {"text": "at the Fannie Mae website to get it", "start": 1089.12, "duration": 6.12}, {"text": "okay so just uh some additional context", "start": 1092.12, "duration": 4.799}, {"text": "so what is Fannie Mae so if you're not", "start": 1095.24, "duration": 3.24}, {"text": "familiar this is the Federal National", "start": 1096.919, "duration": 4.14}, {"text": "Mortgage Association so Fannie Mae is", "start": 1098.48, "duration": 4.38}, {"text": "sort of the", "start": 1101.059, "duration": 4.201}, {"text": "its nickname I don't know why but that's", "start": 1102.86, "duration": 5.34}, {"text": "the uh that's the uh that's the nickname", "start": 1105.26, "duration": 3.96}, {"text": "um it's what's called a", "start": 1108.2, "duration": 3.06}, {"text": "government-sponsored Enterprise so it's", "start": 1109.22, "duration": 6.0}, {"text": "essentially a private company but", "start": 1111.26, "duration": 6.419}, {"text": "with certain sponsorship by the", "start": 1115.22, "duration": 3.72}, {"text": "government which essentially in this", "start": 1117.679, "duration": 2.821}, {"text": "case really", "start": 1118.94, "duration": 5.58}, {"text": "means that the U.S government backed the", "start": 1120.5, "duration": 7.32}, {"text": "debt of the company essentially so it's", "start": 1124.52, "duration": 5.519}, {"text": "sort of uh one of these off-balance", "start": 1127.82, "duration": 3.96}, {"text": "sheet items in the U.S government", "start": 1130.039, "duration": 5.041}, {"text": "national debt it was founded in the 1938", "start": 1131.78, "duration": 5.7}, {"text": "sort of at the sort of late stages of", "start": 1135.08, "duration": 3.959}, {"text": "the Great Depression to sort of get the", "start": 1137.48, "duration": 3.6}, {"text": "mortgage Market moving again in the US", "start": 1139.039, "duration": 4.081}, {"text": "so it created what's called a secondary", "start": 1141.08, "duration": 3.36}, {"text": "mortgage Market which I'll talk about", "start": 1143.12, "duration": 4.439}, {"text": "here uh briefly on the next slide and", "start": 1144.44, "duration": 5.099}, {"text": "some other history became publicly", "start": 1147.559, "duration": 4.801}, {"text": "traded in 68 and", "start": 1149.539, "duration": 5.701}, {"text": "um during the financial crisis I was", "start": 1152.36, "duration": 4.92}, {"text": "taken over by the federal government and", "start": 1155.24, "duration": 4.26}, {"text": "along with its sort of for other company", "start": 1157.28, "duration": 3.899}, {"text": "Freddie Mac", "start": 1159.5, "duration": 4.559}, {"text": "um and in recent news I guess they're", "start": 1161.179, "duration": 4.5}, {"text": "actually talking about making them go", "start": 1164.059, "duration": 4.141}, {"text": "private again so so it's kind of like I", "start": 1165.679, "duration": 4.081}, {"text": "said an interesting data set with", "start": 1168.2, "duration": 4.92}, {"text": "historical context and even uh for", "start": 1169.76, "duration": 6.12}, {"text": "current events I guess", "start": 1173.12, "duration": 4.919}, {"text": "so just to give you a sense of what the", "start": 1175.88, "duration": 4.26}, {"text": "data set is and why it exists and what", "start": 1178.039, "duration": 4.561}, {"text": "Fannie Mae does what they do essentially", "start": 1180.14, "duration": 4.919}, {"text": "is if you go get a mortgage at a bank", "start": 1182.6, "duration": 5.28}, {"text": "for your house that you want to buy", "start": 1185.059, "duration": 5.941}, {"text": "um you know the bank will lend you or", "start": 1187.88, "duration": 6.539}, {"text": "give you the mortgage you get the house", "start": 1191.0, "duration": 6.179}, {"text": "um when the bank takes on the mortgage", "start": 1194.419, "duration": 4.441}, {"text": "right it's a debt that you have to pay", "start": 1197.179, "duration": 3.721}, {"text": "back to the bank what usually happens is", "start": 1198.86, "duration": 5.58}, {"text": "in most cases or at least I think half", "start": 1200.9, "duration": 6.139}, {"text": "of the cases of all U.S housing loans", "start": 1204.44, "duration": 6.66}, {"text": "is the the banks then sell the loan to", "start": 1207.039, "duration": 6.821}, {"text": "Fannie Mae okay so if anime buys", "start": 1211.1, "duration": 6.42}, {"text": "mortgages from Banks to get them off the", "start": 1213.86, "duration": 6.0}, {"text": "bank's balance sheets essentially", "start": 1217.52, "duration": 4.019}, {"text": "what Fannie Mae does is then package", "start": 1219.86, "duration": 2.66}, {"text": "those", "start": 1221.539, "duration": 3.961}, {"text": "mortgages which are talked about talked", "start": 1222.52, "duration": 5.8}, {"text": "about a lot in the uh uh The Big Short", "start": 1225.5, "duration": 5.64}, {"text": "movie I mentioned in the book they'd", "start": 1228.32, "duration": 6.12}, {"text": "package them into sort of larger bonds", "start": 1231.14, "duration": 5.399}, {"text": "essentially that they sell as you know", "start": 1234.44, "duration": 4.56}, {"text": "packages you know a whole Suite of", "start": 1236.539, "duration": 4.561}, {"text": "mortgages contained in a single Bond and", "start": 1239.0, "duration": 5.28}, {"text": "they sell those bonds or what they call", "start": 1241.1, "duration": 5.819}, {"text": "mortgage-backed Securities to investors", "start": 1244.28, "duration": 5.1}, {"text": "and they get the money back right so", "start": 1246.919, "duration": 4.38}, {"text": "basically Fannie Mae", "start": 1249.38, "duration": 3.9}, {"text": "says okay we'll sell you this", "start": 1251.299, "duration": 4.681}, {"text": "mortgage-backed security and by the way", "start": 1253.28, "duration": 3.72}, {"text": "it's guaranteed by the federal", "start": 1255.98, "duration": 2.939}, {"text": "government so it's pretty safe bet that", "start": 1257.0, "duration": 2.88}, {"text": "you're going to get your money back", "start": 1258.919, "duration": 2.941}, {"text": "that's why the investors buy these", "start": 1259.88, "duration": 3.12}, {"text": "mortgages", "start": 1261.86, "duration": 1.98}, {"text": "um", "start": 1263.0, "duration": 3.24}, {"text": "so that's sort of the the overview of", "start": 1263.84, "duration": 4.38}, {"text": "how Fannie Mae fits into sort of the", "start": 1266.24, "duration": 3.059}, {"text": "financial", "start": 1268.22, "duration": 4.199}, {"text": "um system and where why this data set", "start": 1269.299, "duration": 4.62}, {"text": "exists and", "start": 1272.419, "duration": 3.361}, {"text": "sort of you know because of the housing", "start": 1273.919, "duration": 4.26}, {"text": "crisis this data set is now public", "start": 1275.78, "duration": 5.279}, {"text": "because they want to try to provide more", "start": 1278.179, "duration": 5.161}, {"text": "transparency of how many loans are being", "start": 1281.059, "duration": 5.161}, {"text": "made what sort of debt is being backed", "start": 1283.34, "duration": 4.56}, {"text": "and things like that", "start": 1286.22, "duration": 6.66}, {"text": "okay so how big is how how much money is", "start": 1287.9, "duration": 7.8}, {"text": "do Freddie and Fannie Mae actually also", "start": 1292.88, "duration": 7.46}, {"text": "this is I think a chart I found from a", "start": 1295.7, "duration": 4.64}, {"text": "2016 article and so then it was about", "start": 1300.52, "duration": 7.6}, {"text": "5.7 trillion dollars is uh guaranteed", "start": 1303.98, "duration": 6.179}, {"text": "through Freddy and Fanny I'm not sure", "start": 1308.12, "duration": 3.539}, {"text": "how it breaks down percentage-wise but", "start": 1310.159, "duration": 4.081}, {"text": "this is sort of the best sort of size of", "start": 1311.659, "duration": 5.461}, {"text": "the what the data set sort of is a", "start": 1314.24, "duration": 5.939}, {"text": "subset of representing how much debt and", "start": 1317.12, "duration": 4.799}, {"text": "mortgages are backed by these two", "start": 1320.179, "duration": 4.261}, {"text": "companies and I think the recent article", "start": 1321.919, "duration": 4.801}, {"text": "I saw in 2019 was it's up to seven", "start": 1324.44, "duration": 5.04}, {"text": "trillion so so this keeps going up and", "start": 1326.72, "duration": 4.26}, {"text": "up and up and", "start": 1329.48, "duration": 4.199}, {"text": "so so lots of the mortgages so your", "start": 1330.98, "duration": 5.699}, {"text": "mortgage if it fits in certain terms", "start": 1333.679, "duration": 7.161}, {"text": "um might be owned by Freddie or Fanny", "start": 1336.679, "duration": 4.161}, {"text": "um and so yeah this is the the last", "start": 1340.94, "duration": 3.359}, {"text": "slide just sort of to give the context", "start": 1342.799, "duration": 3.24}, {"text": "so all the mortgage that we'll see in", "start": 1344.299, "duration": 4.081}, {"text": "the data set are what they're called", "start": 1346.039, "duration": 4.321}, {"text": "um conforming mortgage loans and so", "start": 1348.38, "duration": 3.9}, {"text": "essentially it's the primary type of", "start": 1350.36, "duration": 4.679}, {"text": "loans that um the Fannie Mae and these", "start": 1352.28, "duration": 4.86}, {"text": "other government sponsored entities can", "start": 1355.039, "duration": 3.721}, {"text": "purchase", "start": 1357.14, "duration": 3.96}, {"text": "um so so this is to give you context", "start": 1358.76, "duration": 4.98}, {"text": "like one of the main limits", "start": 1361.1, "duration": 5.52}, {"text": "um that creates a conforming loan is", "start": 1363.74, "duration": 4.98}, {"text": "really how much the loan can be what's", "start": 1366.62, "duration": 3.9}, {"text": "the maximum amount a loan can be right", "start": 1368.72, "duration": 3.9}, {"text": "so that'll that'll show up in the data", "start": 1370.52, "duration": 4.98}, {"text": "set of like how many loans are at a", "start": 1372.62, "duration": 4.679}, {"text": "certain price essentially right so this", "start": 1375.5, "duration": 4.799}, {"text": "is uh some important context to have", "start": 1377.299, "duration": 4.981}, {"text": "um and so in 2019 and it changes over", "start": 1380.299, "duration": 3.841}, {"text": "time so that you'll have to look if you", "start": 1382.28, "duration": 3.3}, {"text": "really want to do some in-depth analysis", "start": 1384.14, "duration": 3.6}, {"text": "you have to look up sort of what the", "start": 1385.58, "duration": 4.32}, {"text": "conforming loan limit was in a certain", "start": 1387.74, "duration": 6.12}, {"text": "year like in 2019 so any mortgage under", "start": 1389.9, "duration": 7.5}, {"text": "fourth for 400 000 uh", "start": 1393.86, "duration": 5.46}, {"text": "four hundred and eighty four thousand", "start": 1397.4, "duration": 3.779}, {"text": "three hundred fifty dollars well as a", "start": 1399.32, "duration": 3.54}, {"text": "conforming loan and so if any May", "start": 1401.179, "duration": 4.38}, {"text": "probably bought that kind of loan right", "start": 1402.86, "duration": 6.0}, {"text": "um obviously so I'm I live in California", "start": 1405.559, "duration": 4.5}, {"text": "um some of you probably live in the", "start": 1408.86, "duration": 4.559}, {"text": "higher cost areas there are some", "start": 1410.059, "duration": 5.941}, {"text": "higher limit loans you'll see in the the", "start": 1413.419, "duration": 3.721}, {"text": "data set", "start": 1416.0, "duration": 3.78}, {"text": "um in high cost areas so in 2008 from", "start": 1417.14, "duration": 5.94}, {"text": "the financial crisis there was a", "start": 1419.78, "duration": 5.22}, {"text": "bill that was passed that allowed them", "start": 1423.08, "duration": 4.14}, {"text": "to raise sort of these sort of jumbo", "start": 1425.0, "duration": 4.86}, {"text": "conforming loan limits to", "start": 1427.22, "duration": 6.54}, {"text": "um you know 730 000 dollars and again", "start": 1429.86, "duration": 6.0}, {"text": "also increasing over time", "start": 1433.76, "duration": 4.919}, {"text": "so you'll see some larger loans but just", "start": 1435.86, "duration": 4.5}, {"text": "to give you context in like how much", "start": 1438.679, "duration": 5.88}, {"text": "money is in the data set this is a good", "start": 1440.36, "duration": 6.0}, {"text": "an important definition I think to show", "start": 1444.559, "duration": 4.201}, {"text": "okay", "start": 1446.36, "duration": 4.74}, {"text": "oh yeah so let's jump into the notebook", "start": 1448.76, "duration": 4.62}, {"text": "so I've actually posted this um to my", "start": 1451.1, "duration": 5.939}, {"text": "GitHub so if you want to download now", "start": 1453.38, "duration": 5.279}, {"text": "and follow along you can just go to my", "start": 1457.039, "duration": 2.88}, {"text": "GitHub", "start": 1458.659, "duration": 3.02}, {"text": "at mkendus", "start": 1459.919, "duration": 3.841}, {"text": "presentations and it's the only thing in", "start": 1461.679, "duration": 3.761}, {"text": "there sort of one of my New Year's", "start": 1463.76, "duration": 3.659}, {"text": "resolutions to start tracking all my", "start": 1465.44, "duration": 4.8}, {"text": "presentations in GitHub so", "start": 1467.419, "duration": 4.861}, {"text": "The Notebook will be there if you want", "start": 1470.24, "duration": 3.66}, {"text": "to follow along", "start": 1472.28, "duration": 5.279}, {"text": "um and I will jump into the notebook on", "start": 1473.9, "duration": 6.779}, {"text": "one of comets uh", "start": 1477.559, "duration": 5.641}, {"text": "test nodes we have which is actually", "start": 1480.679, "duration": 5.641}, {"text": "Nvidia V100 node", "start": 1483.2, "duration": 5.12}, {"text": "um", "start": 1486.32, "duration": 2.0}, {"text": "so let me just close the chat here", "start": 1490.159, "duration": 7.461}, {"text": "the increase", "start": 1494.84, "duration": 2.78}, {"text": "probably the", "start": 1497.72, "duration": 3.199}, {"text": "increase the font size for the demo as", "start": 1505.94, "duration": 6.5}, {"text": "well in the terminal", "start": 1509.299, "duration": 3.141}, {"text": "seeing", "start": 1512.659, "duration": 2.661}, {"text": "I think I have to reset it", "start": 1519.38, "duration": 3.56}, {"text": "okay that's probably a little bit better", "start": 1527.059, "duration": 3.681}, {"text": "okay so I'm not going through", "start": 1541.039, "duration": 4.921}, {"text": "um the comet queue right now just", "start": 1543.5, "duration": 4.32}, {"text": "because usually our GPU nodes are pretty", "start": 1545.96, "duration": 4.079}, {"text": "busy and we didn't set up a reservation", "start": 1547.82, "duration": 5.28}, {"text": "for this and I knew we had this sort of", "start": 1550.039, "duration": 4.441}, {"text": "V100", "start": 1553.1, "duration": 4.52}, {"text": "test node here", "start": 1554.48, "duration": 3.14}, {"text": "that we have laying around and no one's", "start": 1557.84, "duration": 3.18}, {"text": "using so", "start": 1559.46, "duration": 2.88}, {"text": "um", "start": 1561.02, "duration": 5.039}, {"text": "uh one of the things that I do in my day", "start": 1562.34, "duration": 6.24}, {"text": "job is help support on a lot of the", "start": 1566.059, "duration": 5.041}, {"text": "singularity containers that we um", "start": 1568.58, "duration": 5.28}, {"text": "support on Comet and so I did build a", "start": 1571.1, "duration": 5.78}, {"text": "new version of the Rapids uh container", "start": 1573.86, "duration": 5.46}, {"text": "distributed by well sort of a custom", "start": 1576.88, "duration": 5.38}, {"text": "version of the one distributed by Nvidia", "start": 1579.32, "duration": 5.82}, {"text": "so any if you if you haven't used a", "start": 1582.26, "duration": 5.1}, {"text": "singularity container we won't when you", "start": 1585.14, "duration": 4.38}, {"text": "talk about that it's basically just a", "start": 1587.36, "duration": 5.699}, {"text": "pre-packaged uh mini operating system", "start": 1589.52, "duration": 5.22}, {"text": "with all the software I needed to run", "start": 1593.059, "duration": 4.201}, {"text": "this demo and if you are familiar with", "start": 1594.74, "duration": 5.16}, {"text": "Singularity we do keep all of our sort", "start": 1597.26, "duration": 4.44}, {"text": "of supported Singularity containers in", "start": 1599.9, "duration": 4.08}, {"text": "sort of these paths so share apps GPU", "start": 1601.7, "duration": 5.099}, {"text": "Singularity if it's a CPU only code", "start": 1603.98, "duration": 6.059}, {"text": "it'll be apps compute Singularity so if", "start": 1606.799, "duration": 5.041}, {"text": "you want to check out any of our other", "start": 1610.039, "duration": 3.421}, {"text": "Singularity images you can check them", "start": 1611.84, "duration": 3.6}, {"text": "out there as well", "start": 1613.46, "duration": 4.319}, {"text": "um okay so I'm going to start up this", "start": 1615.44, "duration": 4.2}, {"text": "Singularity container", "start": 1617.779, "duration": 4.14}, {"text": "with Rapids inside so the latest version", "start": 1619.64, "duration": 5.659}, {"text": "of Rapids I think is the", "start": 1621.919, "duration": 6.601}, {"text": "0.11.0 so like I said it's really early", "start": 1625.299, "duration": 5.74}, {"text": "on in the Rapids uh history they're not", "start": 1628.52, "duration": 5.1}, {"text": "at 1.0 yet so", "start": 1631.039, "duration": 4.201}, {"text": "um things are changing and not", "start": 1633.62, "duration": 4.08}, {"text": "everything works as you might expect", "start": 1635.24, "duration": 3.66}, {"text": "so I'm just going to start up this", "start": 1637.7, "duration": 4.099}, {"text": "Jupiter notebook", "start": 1638.9, "duration": 2.899}, {"text": "okay close that window", "start": 1654.98, "duration": 3.559}, {"text": "oh I forgot", "start": 1663.62, "duration": 6.2}, {"text": "one mistake I apologize", "start": 1665.5, "duration": 4.32}, {"text": "I forgot to change my working directory", "start": 1670.7, "duration": 4.68}, {"text": "so I've pre-downloaded the data sets", "start": 1673.039, "duration": 5.64}, {"text": "onto comets scratch file system as well", "start": 1675.38, "duration": 6.24}, {"text": "so if you do have access to comment", "start": 1678.679, "duration": 4.261}, {"text": "um", "start": 1681.62, "duration": 5.22}, {"text": "the data sets are available already here", "start": 1682.94, "duration": 6.599}, {"text": "in this data folder you'll see in The", "start": 1686.84, "duration": 3.8}, {"text": "Notebook", "start": 1689.539, "duration": 3.12}, {"text": "and the reason I had to change", "start": 1690.64, "duration": 3.46}, {"text": "directories here is if you've ever", "start": 1692.659, "duration": 3.12}, {"text": "worked with Jupiter notebooks usually by", "start": 1694.1, "duration": 4.26}, {"text": "default it assumes that it you can only", "start": 1695.779, "duration": 4.38}, {"text": "see the directory structure under the", "start": 1698.36, "duration": 4.14}, {"text": "top level directory so I just since the", "start": 1700.159, "duration": 4.081}, {"text": "data is here in this directory I needed", "start": 1702.5, "duration": 2.76}, {"text": "to go here", "start": 1704.24, "duration": 3.799}, {"text": "foreign", "start": 1705.26, "duration": 2.779}, {"text": "all right so now we're in the right", "start": 1718.039, "duration": 4.861}, {"text": "directory so yeah like I said the uh", "start": 1719.48, "duration": 5.939}, {"text": "the data is here a single family mem", "start": 1722.9, "duration": 3.899}, {"text": "forces and I've downloaded all the", "start": 1725.419, "duration": 2.941}, {"text": "different subsets so if you do have", "start": 1726.799, "duration": 2.821}, {"text": "access to comment you don't have to", "start": 1728.36, "duration": 3.12}, {"text": "download the data yourself you can", "start": 1729.62, "duration": 5.039}, {"text": "actually point to uh my scratch", "start": 1731.48, "duration": 5.699}, {"text": "directory on Comet it's publicly", "start": 1734.659, "duration": 5.341}, {"text": "accessible to all the users there but if", "start": 1737.179, "duration": 3.901}, {"text": "you need to download the data set", "start": 1740.0, "duration": 2.64}, {"text": "somewhere else the code is available", "start": 1741.08, "duration": 5.459}, {"text": "here in the um in the notebook as well", "start": 1742.64, "duration": 9.539}, {"text": "let me just close that and open this up", "start": 1746.539, "duration": 7.441}, {"text": "so um", "start": 1752.179, "duration": 4.561}, {"text": "a few things to note about the data sets", "start": 1753.98, "duration": 5.4}, {"text": "and Rapids in general when you start", "start": 1756.74, "duration": 5.46}, {"text": "working with it is right you do need to", "start": 1759.38, "duration": 5.82}, {"text": "be mindful again of your data set size", "start": 1762.2, "duration": 6.42}, {"text": "so I sort of copied this um", "start": 1765.2, "duration": 7.079}, {"text": "table out of here just as a reference", "start": 1768.62, "duration": 5.7}, {"text": "so I'm going to use the the largest data", "start": 1772.279, "duration": 3.601}, {"text": "set that's available on the Rapids", "start": 1774.32, "duration": 3.719}, {"text": "website which is the this mortgage 2000", "start": 1775.88, "duration": 6.06}, {"text": "to 2016 so the sort of 17-year", "start": 1778.039, "duration": 5.941}, {"text": "uh version", "start": 1781.94, "duration": 4.88}, {"text": "and the data set actually consists of", "start": 1783.98, "duration": 6.9}, {"text": "two subsets as we walk through the um", "start": 1786.82, "duration": 4.959}, {"text": "the", "start": 1790.88, "duration": 3.36}, {"text": "The Notebook here you'll see so and I'm", "start": 1791.779, "duration": 4.081}, {"text": "only going to use one of them so the the", "start": 1794.24, "duration": 3.539}, {"text": "one I'm going to use today for sort of a", "start": 1795.86, "duration": 4.319}, {"text": "single GPU demonstration", "start": 1797.779, "duration": 5.221}, {"text": "is this acquisition data set so this", "start": 1800.179, "duration": 4.641}, {"text": "acquisition data set is basically", "start": 1803.0, "duration": 4.98}, {"text": "records about all of the loans that have", "start": 1804.82, "duration": 6.12}, {"text": "been acquired by Fannie Mae from 2000 to", "start": 1807.98, "duration": 5.64}, {"text": "2016. or at least the the conforming", "start": 1810.94, "duration": 5.56}, {"text": "30-year fixed rate mortgages that are in", "start": 1813.62, "duration": 6.12}, {"text": "this step set the other half of the data", "start": 1816.5, "duration": 6.38}, {"text": "set or I mean not half much much the", "start": 1819.74, "duration": 5.819}, {"text": "vast majority of the data set in terms", "start": 1822.88, "duration": 5.26}, {"text": "of size is the performance that is set", "start": 1825.559, "duration": 5.22}, {"text": "and so this performance data set is", "start": 1828.14, "duration": 5.159}, {"text": "um basically records on all the payments", "start": 1830.779, "duration": 5.221}, {"text": "on the acquired loans okay so if you", "start": 1833.299, "duration": 4.201}, {"text": "look at the number of loans so", "start": 1836.0, "duration": 2.94}, {"text": "essentially the acquisition data set", "start": 1837.5, "duration": 4.74}, {"text": "really has records of 37 million uh", "start": 1838.94, "duration": 5.88}, {"text": "loans essentially or is this is this", "start": 1842.24, "duration": 5.7}, {"text": "four gigabyte number here um the", "start": 1844.82, "duration": 5.28}, {"text": "performance records are on all the", "start": 1847.94, "duration": 4.38}, {"text": "payments on those 37 million loans and", "start": 1850.1, "duration": 5.16}, {"text": "so that's where you add a sort of 1.9", "start": 1852.32, "duration": 6.359}, {"text": "billion records or available in the data", "start": 1855.26, "duration": 4.5}, {"text": "set so", "start": 1858.679, "duration": 3.541}, {"text": "however like I said the performance has", "start": 1859.76, "duration": 5.039}, {"text": "huge if you use the full range", "start": 1862.22, "duration": 6.179}, {"text": "um so you could use a smaller subset to", "start": 1864.799, "duration": 5.221}, {"text": "do some development work on the", "start": 1868.399, "duration": 3.601}, {"text": "performance data set I didn't really", "start": 1870.02, "duration": 4.5}, {"text": "have time to do that myself but um the", "start": 1872.0, "duration": 4.32}, {"text": "idea is like this data set really does", "start": 1874.52, "duration": 4.86}, {"text": "force you to go to multiple gpus at some", "start": 1876.32, "duration": 4.44}, {"text": "point if you really want to analyze well", "start": 1879.38, "duration": 3.539}, {"text": "so that's sort of the it's sort of a", "start": 1880.76, "duration": 4.38}, {"text": "non-trivial data set that it'll sort of", "start": 1882.919, "duration": 4.62}, {"text": "really you know if you need an example", "start": 1885.14, "duration": 4.44}, {"text": "to use to get started with Rapids and", "start": 1887.539, "duration": 4.081}, {"text": "learning how to really scale something", "start": 1889.58, "duration": 4.74}, {"text": "like this up this that's why this I", "start": 1891.62, "duration": 5.9}, {"text": "think this is a good example", "start": 1894.32, "duration": 3.2}, {"text": "so let's start walking through uh The", "start": 1897.559, "duration": 5.761}, {"text": "Notebook here so I just start off with", "start": 1900.26, "duration": 6.539}, {"text": "you know simple stuff uh just import the", "start": 1903.32, "duration": 5.82}, {"text": "python modules that we need", "start": 1906.799, "duration": 5.0}, {"text": "um so these are sort of the first", "start": 1909.14, "duration": 5.58}, {"text": "elements here are the uh just from the", "start": 1911.799, "duration": 5.74}, {"text": "standard Library the next are sort of", "start": 1914.72, "duration": 5.64}, {"text": "the standard data science machine", "start": 1917.539, "duration": 5.221}, {"text": "learning modules you you use on CPUs", "start": 1920.36, "duration": 3.539}, {"text": "essentially", "start": 1922.76, "duration": 2.399}, {"text": "um so I mean like I said I'm going to", "start": 1923.899, "duration": 1.981}, {"text": "use", "start": 1925.159, "duration": 4.74}, {"text": "I didn't develop a multi GPU integration", "start": 1925.88, "duration": 6.96}, {"text": "uh example here with with Basque but I", "start": 1929.899, "duration": 4.561}, {"text": "am going to use Das to read in the data", "start": 1932.84, "duration": 3.24}, {"text": "set because it takes a long time to do", "start": 1934.46, "duration": 4.38}, {"text": "it if you don't so uh if you're not", "start": 1936.08, "duration": 4.079}, {"text": "familiar with desk there's at least one", "start": 1938.84, "duration": 3.719}, {"text": "example here of like how to read in", "start": 1940.159, "duration": 4.561}, {"text": "um a data set pretty quickly and then", "start": 1942.559, "duration": 4.801}, {"text": "again I'm going to use pandas only in", "start": 1944.72, "duration": 4.92}, {"text": "this example um my goal was to get to", "start": 1947.36, "duration": 4.799}, {"text": "scikit learn in qml but um", "start": 1949.64, "duration": 4.86}, {"text": "I didn't have quite the time to develop", "start": 1952.159, "duration": 3.961}, {"text": "it so all the examples here really are", "start": 1954.5, "duration": 5.22}, {"text": "comparing pandas to cudia at this point", "start": 1956.12, "duration": 6.72}, {"text": "right and so we import the Rapids", "start": 1959.72, "duration": 6.5}, {"text": "modules we'll need", "start": 1962.84, "duration": 3.38}, {"text": "the next part of the notebook is just to", "start": 1966.5, "duration": 6.539}, {"text": "do some setup so uh I just create a", "start": 1968.899, "duration": 6.181}, {"text": "section if you need to find some system", "start": 1973.039, "duration": 3.721}, {"text": "environment variables so here I'm just", "start": 1975.08, "duration": 4.74}, {"text": "going to use the username", "start": 1976.76, "duration": 6.72}, {"text": "as part of the um the configuration and", "start": 1979.82, "duration": 5.88}, {"text": "like I said the the top level directory", "start": 1983.48, "duration": 3.84}, {"text": "um sort of where you want to do all the", "start": 1985.7, "duration": 3.199}, {"text": "working so essentially", "start": 1987.32, "duration": 4.56}, {"text": "wherever you started your Jupiter", "start": 1988.899, "duration": 5.02}, {"text": "notebook this is essentially where you'd", "start": 1991.88, "duration": 3.659}, {"text": "want to start um", "start": 1993.919, "duration": 4.26}, {"text": "like I said I've pre-downloaded the data", "start": 1995.539, "duration": 5.281}, {"text": "to this directory already on the scratch", "start": 1998.179, "duration": 4.801}, {"text": "file system so if you were going to use", "start": 2000.82, "duration": 3.599}, {"text": "my", "start": 2002.98, "duration": 2.16}, {"text": "um", "start": 2004.419, "duration": 2.821}, {"text": "my version of the data set you on", "start": 2005.14, "duration": 4.5}, {"text": "comment you would actually edit this and", "start": 2007.24, "duration": 5.46}, {"text": "put in my username right because the", "start": 2009.64, "duration": 5.18}, {"text": "environment variable here is", "start": 2012.7, "duration": 4.859}, {"text": "your username so if you actually wanted", "start": 2014.82, "duration": 4.3}, {"text": "to point to my version of the data set", "start": 2017.559, "duration": 2.701}, {"text": "that would be the change that you could", "start": 2019.12, "duration": 4.02}, {"text": "make to The Notebook", "start": 2020.26, "duration": 5.1}, {"text": "um if you're following along at home on", "start": 2023.14, "duration": 3.779}, {"text": "your laptop or something", "start": 2025.36, "duration": 2.78}, {"text": "um", "start": 2026.919, "duration": 4.5}, {"text": "don't use this status and this is going", "start": 2028.14, "duration": 4.659}, {"text": "to be the large ones it'll take a while", "start": 2031.419, "duration": 4.321}, {"text": "to download and it'll probably be too", "start": 2032.799, "duration": 4.88}, {"text": "large to get you going", "start": 2035.74, "duration": 4.74}, {"text": "if you want to follow along on say your", "start": 2037.679, "duration": 4.901}, {"text": "laptop if you're if you're using I would", "start": 2040.48, "duration": 6.72}, {"text": "use maybe just the mortgage 2000 or 2001", "start": 2042.58, "duration": 8.819}, {"text": "version but for the GPU example I mean", "start": 2047.2, "duration": 6.6}, {"text": "to really show you that the how how much", "start": 2051.399, "duration": 5.7}, {"text": "faster the gpus can be than CPU analysis", "start": 2053.8, "duration": 6.18}, {"text": "you really do need larger data sets so", "start": 2057.099, "duration": 4.381}, {"text": "if you have really small data sets", "start": 2059.98, "duration": 4.26}, {"text": "Rapids might not be for you you can just", "start": 2061.48, "duration": 4.8}, {"text": "keep doing what you're doing um it's a", "start": 2064.24, "duration": 3.96}, {"text": "pandas psychic learn", "start": 2066.28, "duration": 3.48}, {"text": "the other", "start": 2068.2, "duration": 4.56}, {"text": "equivalent libraries it's really", "start": 2069.76, "duration": 4.379}, {"text": "um you're really only going to see the", "start": 2072.76, "duration": 2.7}, {"text": "advantages once you go to large datasets", "start": 2074.139, "duration": 3.72}, {"text": "that's why I'm going to analyze uh the", "start": 2075.46, "duration": 4.439}, {"text": "largest one we have right now", "start": 2077.859, "duration": 4.101}, {"text": "um", "start": 2079.899, "duration": 2.061}, {"text": "sorry Jeff did was there a question oh", "start": 2082.78, "duration": 3.839}, {"text": "okay", "start": 2085.119, "duration": 2.22}, {"text": "um", "start": 2086.619, "duration": 3.06}, {"text": "so again just some setup to the where", "start": 2087.339, "duration": 5.941}, {"text": "the directory the the data data set", "start": 2089.679, "duration": 5.041}, {"text": "directory is located", "start": 2093.28, "duration": 4.559}, {"text": "uh the next few elements there", "start": 2094.72, "duration": 5.94}, {"text": "um now this is one question yes how", "start": 2097.839, "duration": 5.841}, {"text": "large do you think is the threshold", "start": 2100.66, "duration": 5.64}, {"text": "you know I really wanted to do some", "start": 2103.68, "duration": 4.9}, {"text": "extensive but yeah so the question was", "start": 2106.3, "duration": 5.64}, {"text": "um how large of a data set do you really", "start": 2108.58, "duration": 6.96}, {"text": "need to use to see a significant", "start": 2111.94, "duration": 6.659}, {"text": "um speed up so I mean it's a complicated", "start": 2115.54, "duration": 4.2}, {"text": "question", "start": 2118.599, "duration": 2.641}, {"text": "um you'll see in the example here", "start": 2119.74, "duration": 3.3}, {"text": "there's actually you know some", "start": 2121.24, "duration": 3.66}, {"text": "algorithms even though they're available", "start": 2123.04, "duration": 3.66}, {"text": "or you know or some methods are", "start": 2124.9, "duration": 4.56}, {"text": "available in kdf that are you know the", "start": 2126.7, "duration": 4.2}, {"text": "same ones as a pandas they actually run", "start": 2129.46, "duration": 3.72}, {"text": "the same just because you might not be", "start": 2130.9, "duration": 4.439}, {"text": "able to do that type of transformation", "start": 2133.18, "duration": 5.939}, {"text": "or task on the GPU you actually probably", "start": 2135.339, "duration": 5.641}, {"text": "um you know there's some fundamental", "start": 2139.119, "duration": 3.96}, {"text": "issues like certain things you can't do", "start": 2140.98, "duration": 4.619}, {"text": "faster on the GPU I think is what you'll", "start": 2143.079, "duration": 5.341}, {"text": "see in some later example so that'll be", "start": 2145.599, "duration": 6.121}, {"text": "sort of be data set size independent", "start": 2148.42, "duration": 5.58}, {"text": "um for the ones that do get speed up", "start": 2151.72, "duration": 4.379}, {"text": "um it's really you think you'll really", "start": 2154.0, "duration": 3.48}, {"text": "have to play around with it a bit I", "start": 2156.099, "duration": 2.701}, {"text": "would say like", "start": 2157.48, "duration": 3.18}, {"text": "you know the data set we'll use today", "start": 2158.8, "duration": 4.559}, {"text": "um we'll see you know speed UPS of you", "start": 2160.66, "duration": 6.24}, {"text": "know three four five x I think is is or", "start": 2163.359, "duration": 5.581}, {"text": "even 10x I think in some some cases", "start": 2166.9, "duration": 5.04}, {"text": "really depends on the actual method um", "start": 2168.94, "duration": 5.46}, {"text": "you're calling what's what the what the", "start": 2171.94, "duration": 4.62}, {"text": "task is doing", "start": 2174.4, "duration": 4.62}, {"text": "um but uh right so the data set size", "start": 2176.56, "duration": 4.32}, {"text": "we'll use today is around four gigabyte", "start": 2179.02, "duration": 3.18}, {"text": "so", "start": 2180.88, "duration": 4.62}, {"text": "several gigabytes you know some some a", "start": 2182.2, "duration": 5.52}, {"text": "few gigabytes is where you'll start to", "start": 2185.5, "duration": 4.44}, {"text": "see um significant performance increases", "start": 2187.72, "duration": 4.98}, {"text": "all right um but with the times that", "start": 2189.94, "duration": 4.74}, {"text": "we'll see you know how much", "start": 2192.7, "duration": 5.34}, {"text": "more are you waiting around yeah it's", "start": 2194.68, "duration": 5.82}, {"text": "it'll still be pretty small you know", "start": 2198.04, "duration": 5.9}, {"text": "absolute times that we'll see today but", "start": 2200.5, "duration": 6.06}, {"text": "you know the speed up is you can start", "start": 2203.94, "duration": 4.54}, {"text": "really seeing it here at this should be", "start": 2206.56, "duration": 3.9}, {"text": "a goodbye level", "start": 2208.48, "duration": 5.46}, {"text": "okay so back to the notebook um so the", "start": 2210.46, "duration": 5.82}, {"text": "next section here is just to download", "start": 2213.94, "duration": 4.2}, {"text": "and extract the data set if you don't", "start": 2216.28, "duration": 3.54}, {"text": "have it so this will download and", "start": 2218.14, "duration": 3.3}, {"text": "extract the data set for you um", "start": 2219.82, "duration": 3.6}, {"text": "whichever one you've chosen up here", "start": 2221.44, "duration": 3.48}, {"text": "like I said if you're doing this on your", "start": 2223.42, "duration": 2.939}, {"text": "laptop you probably don't want to use", "start": 2224.92, "duration": 3.419}, {"text": "this version", "start": 2226.359, "duration": 3.0}, {"text": "um but that's the version I'm going to", "start": 2228.339, "duration": 2.821}, {"text": "use today and it'll check if it might", "start": 2229.359, "duration": 4.5}, {"text": "already be available so all right so", "start": 2231.16, "duration": 4.679}, {"text": "since I already have it downloaded", "start": 2233.859, "duration": 4.201}, {"text": "um to the directories I defined above", "start": 2235.839, "duration": 4.74}, {"text": "I can see here in that directory I have", "start": 2238.06, "duration": 4.68}, {"text": "the original tarball that was downloaded", "start": 2240.579, "duration": 4.681}, {"text": "and the two subset directories the", "start": 2242.74, "duration": 3.74}, {"text": "acquisition", "start": 2245.26, "duration": 4.26}, {"text": "subset of the of the data and the", "start": 2246.48, "duration": 5.08}, {"text": "performance subset of the data so again", "start": 2249.52, "duration": 3.42}, {"text": "we're just going to use the acquisition", "start": 2251.56, "duration": 5.039}, {"text": "data set for the examples below", "start": 2252.94, "duration": 4.74}, {"text": "um", "start": 2256.599, "duration": 3.181}, {"text": "so in the next section we do some uh", "start": 2257.68, "duration": 4.8}, {"text": "preparation just to uh", "start": 2259.78, "duration": 4.92}, {"text": "figure out how much of the data you want", "start": 2262.48, "duration": 4.02}, {"text": "to analyze so basically you can choose", "start": 2264.7, "duration": 4.02}, {"text": "here the starting year you want to start", "start": 2266.5, "duration": 3.839}, {"text": "the analysis on so it will sort of", "start": 2268.72, "duration": 4.32}, {"text": "ignore all the other files if you say", "start": 2270.339, "duration": 6.421}, {"text": "sit we only want to look from 2015 2005", "start": 2273.04, "duration": 7.92}, {"text": "to 2016 from quarter one in 2005 to", "start": 2276.76, "duration": 7.5}, {"text": "quarter four in 2016. you can change how", "start": 2280.96, "duration": 5.1}, {"text": "many um of the files you want to sort of", "start": 2284.26, "duration": 3.24}, {"text": "import and start looking at I'm just", "start": 2286.06, "duration": 3.779}, {"text": "going to use the full data set", "start": 2287.5, "duration": 5.76}, {"text": "um and", "start": 2289.839, "duration": 3.421}, {"text": "yeah and so the next section just", "start": 2294.339, "duration": 4.02}, {"text": "creates some lists of all the files in", "start": 2296.44, "duration": 4.139}, {"text": "there between those that time interval", "start": 2298.359, "duration": 4.98}, {"text": "that we want to look at okay so the", "start": 2300.579, "duration": 5.241}, {"text": "question does", "start": 2303.339, "duration": 2.481}, {"text": "Ah that's", "start": 2307.68, "duration": 5.14}, {"text": "an interesting question I don't know", "start": 2309.82, "duration": 5.7}, {"text": "I uh yeah I would have to look that up", "start": 2312.82, "duration": 5.039}, {"text": "for you um like I said I'm sort of new", "start": 2315.52, "duration": 4.2}, {"text": "to the whole Rapids framework as well", "start": 2317.859, "duration": 3.301}, {"text": "and so I'm not sure what the Windows", "start": 2319.72, "duration": 3.48}, {"text": "support is like so", "start": 2321.16, "duration": 2.82}, {"text": "um", "start": 2323.2, "duration": 3.139}, {"text": "it definitely works on Linux I know that", "start": 2323.98, "duration": 5.58}, {"text": "so so yeah that's a good question um", "start": 2326.339, "duration": 4.721}, {"text": "like I said we're going to have Nvidia", "start": 2329.56, "duration": 3.72}, {"text": "talking about this again next month as", "start": 2331.06, "duration": 4.74}, {"text": "well with some other topics so", "start": 2333.28, "duration": 3.96}, {"text": "um if you're really interested in sort", "start": 2335.8, "duration": 2.46}, {"text": "of more", "start": 2337.24, "duration": 3.599}, {"text": "underlying details and support and", "start": 2338.26, "duration": 4.859}, {"text": "what's coming they'll know a lot more", "start": 2340.839, "duration": 5.581}, {"text": "about about that", "start": 2343.119, "duration": 6.181}, {"text": "Okay so we've got about 20 minutes left", "start": 2346.42, "duration": 4.199}, {"text": "so now that we're going to really start", "start": 2349.3, "duration": 2.76}, {"text": "building up", "start": 2350.619, "duration": 3.901}, {"text": "um the acquisition data set so we're", "start": 2352.06, "duration": 3.299}, {"text": "gonna", "start": 2354.52, "duration": 4.2}, {"text": "basically import it the the strategy", "start": 2355.359, "duration": 6.121}, {"text": "here is what I'm going to do is actually", "start": 2358.72, "duration": 5.28}, {"text": "take the data set so these are all the", "start": 2361.48, "duration": 7.26}, {"text": "files that are in the 2016 and the 2000", "start": 2364.0, "duration": 7.859}, {"text": "and 2016 data sets so you see each file", "start": 2368.74, "duration": 6.0}, {"text": "is by quarter you can kind of see the", "start": 2371.859, "duration": 5.581}, {"text": "sizes here they're all you know between", "start": 2374.74, "duration": 4.379}, {"text": "one and", "start": 2377.44, "duration": 4.74}, {"text": "I guess another half a gig and two two", "start": 2379.119, "duration": 4.201}, {"text": "gigs", "start": 2382.18, "duration": 3.0}, {"text": "um", "start": 2383.32, "duration": 3.48}, {"text": "um on the Nvidia web page they actually", "start": 2385.18, "duration": 2.939}, {"text": "have", "start": 2386.8, "duration": 4.2}, {"text": "um two versions of each data set so they", "start": 2388.119, "duration": 3.96}, {"text": "break", "start": 2391.0, "duration": 4.38}, {"text": "um some of these data sets up into one", "start": 2392.079, "duration": 6.421}, {"text": "gigabyte size files so so if you look", "start": 2395.38, "duration": 4.8}, {"text": "here there's like a two gigabyte version", "start": 2398.5, "duration": 3.72}, {"text": "here they would split this into two", "start": 2400.18, "duration": 4.5}, {"text": "essentially I guess on the gpus with", "start": 2402.22, "duration": 4.2}, {"text": "certain methods when importing the data", "start": 2404.68, "duration": 3.54}, {"text": "you can get faster results by having", "start": 2406.42, "duration": 3.659}, {"text": "sort of more uniform", "start": 2408.22, "duration": 4.859}, {"text": "smaller file sizes", "start": 2410.079, "duration": 5.401}, {"text": "so that's just a note here I'm not going", "start": 2413.079, "duration": 3.661}, {"text": "to do that I'm just using the the", "start": 2415.48, "duration": 4.4}, {"text": "regular data set files", "start": 2416.74, "duration": 6.359}, {"text": "and I'm going to import it into pandas", "start": 2419.88, "duration": 5.199}, {"text": "first actually and then convert it over", "start": 2423.099, "duration": 4.801}, {"text": "to a qdf data frame so that's one way to", "start": 2425.079, "duration": 4.26}, {"text": "do it and I'll explain why I'm doing", "start": 2427.9, "duration": 3.719}, {"text": "that eventually", "start": 2429.339, "duration": 3.661}, {"text": "so", "start": 2431.619, "duration": 3.121}, {"text": "um I guess one thing I didn't do in the", "start": 2433.0, "duration": 3.06}, {"text": "slides which I probably should have done", "start": 2434.74, "duration": 4.08}, {"text": "is talk a little bit about what's so", "start": 2436.06, "duration": 4.14}, {"text": "what's in each data set so we're just", "start": 2438.82, "duration": 3.779}, {"text": "looking at the acquisition data set", "start": 2440.2, "duration": 3.899}, {"text": "so", "start": 2442.599, "duration": 5.461}, {"text": "um I don't in the next um", "start": 2444.099, "duration": 5.881}, {"text": "part of the Jupiter notebook here below", "start": 2448.06, "duration": 4.44}, {"text": "you'll see I'm going to define a", "start": 2449.98, "duration": 4.859}, {"text": "dictionary that Define all the column", "start": 2452.5, "duration": 5.22}, {"text": "labels and what their data types are so", "start": 2454.839, "duration": 4.621}, {"text": "if you want to know what each column is", "start": 2457.72, "duration": 3.18}, {"text": "in the data set", "start": 2459.46, "duration": 2.159}, {"text": "um", "start": 2460.9, "duration": 4.439}, {"text": "this is what each of those variables are", "start": 2461.619, "duration": 6.541}, {"text": "and what they uh what their data type is", "start": 2465.339, "duration": 5.221}, {"text": "okay so exactly so if we look at the top", "start": 2468.16, "duration": 4.5}, {"text": "here the First Column is some alone", "start": 2470.56, "duration": 4.08}, {"text": "identifier so it's just some ID for the", "start": 2472.66, "duration": 3.6}, {"text": "loan itself", "start": 2474.64, "duration": 3.9}, {"text": "um you know who did it the seller name", "start": 2476.26, "duration": 5.22}, {"text": "you know so JP so Fannie Mae bought the", "start": 2478.54, "duration": 6.0}, {"text": "first loan here from uh JPMorgan", "start": 2481.48, "duration": 6.06}, {"text": "um this seven five thousand is probably", "start": 2484.54, "duration": 6.059}, {"text": "the size right so this unpaid principal", "start": 2487.54, "duration": 5.52}, {"text": "balance so like how much does the loan", "start": 2490.599, "duration": 4.561}, {"text": "should be repaid", "start": 2493.06, "duration": 4.86}, {"text": "um you know when it was made so in 1999", "start": 2495.16, "duration": 5.52}, {"text": "and so on so there's all these other um", "start": 2497.92, "duration": 4.5}, {"text": "you know one I think this code here at", "start": 2500.68, "duration": 3.84}, {"text": "the end is the zip code", "start": 2502.42, "duration": 3.36}, {"text": "um", "start": 2504.52, "duration": 3.48}, {"text": "so", "start": 2505.78, "duration": 4.14}, {"text": "you know how are you supposed to figure", "start": 2508.0, "duration": 3.96}, {"text": "this all out so again like I said if you", "start": 2509.92, "duration": 5.52}, {"text": "go to the um the the the web page for", "start": 2511.96, "duration": 6.0}, {"text": "the data set there's actually", "start": 2515.44, "duration": 4.62}, {"text": "um some PDFs that just list and tell you", "start": 2517.96, "duration": 4.8}, {"text": "what each of these definitions are and", "start": 2520.06, "duration": 4.92}, {"text": "what this column is essentially so it's", "start": 2522.76, "duration": 4.319}, {"text": "really well documented I think if I", "start": 2524.98, "duration": 3.06}, {"text": "remember they even have like little", "start": 2527.079, "duration": 3.661}, {"text": "blurbs of like what it means if if one", "start": 2528.04, "duration": 4.68}, {"text": "in the column doesn't make sense", "start": 2530.74, "duration": 3.3}, {"text": "um so", "start": 2532.72, "duration": 3.42}, {"text": "we're not going to go in any details of", "start": 2534.04, "duration": 5.16}, {"text": "a lot of the different things but later", "start": 2536.14, "duration": 4.26}, {"text": "on you'll see I'm making some", "start": 2539.2, "duration": 4.26}, {"text": "calculations to answer certain questions", "start": 2540.4, "duration": 5.28}, {"text": "um on different columns here essentially", "start": 2543.46, "duration": 4.379}, {"text": "and so if you need more context of the", "start": 2545.68, "duration": 3.72}, {"text": "different definitions for each column", "start": 2547.839, "duration": 3.541}, {"text": "they're definitely available on the", "start": 2549.4, "duration": 5.179}, {"text": "datasets website", "start": 2551.38, "duration": 3.199}, {"text": "so I'm going to Define this dictionary", "start": 2555.099, "duration": 5.341}, {"text": "to", "start": 2559.3, "duration": 3.12}, {"text": "um right the the printed out the first", "start": 2560.44, "duration": 3.84}, {"text": "few lines of the data file right it", "start": 2562.42, "duration": 4.14}, {"text": "doesn't have any column labels right so", "start": 2564.28, "duration": 4.079}, {"text": "we're going to want to add column labels", "start": 2566.56, "duration": 5.6}, {"text": "to our data frame", "start": 2568.359, "duration": 3.801}, {"text": "and I'm predefining this this dictionary", "start": 2572.88, "duration": 7.78}, {"text": "here really because I ran into a lot of", "start": 2578.079, "duration": 5.101}, {"text": "problems with when I read in the data", "start": 2580.66, "duration": 3.8}, {"text": "certain", "start": 2583.18, "duration": 4.2}, {"text": "data types aren't recognized both by", "start": 2584.46, "duration": 6.04}, {"text": "pandas that aren't correctly recognized", "start": 2587.38, "duration": 5.219}, {"text": "by pandas", "start": 2590.5, "duration": 4.98}, {"text": "um from like the read CS3 method and the", "start": 2592.599, "duration": 5.881}, {"text": "same is true with using kudif which also", "start": 2595.48, "duration": 6.78}, {"text": "has a read seat read CSV file method as", "start": 2598.48, "duration": 6.42}, {"text": "well so what I try to do is try to I", "start": 2602.26, "duration": 5.64}, {"text": "knew what the data types are I wanted in", "start": 2604.9, "duration": 4.679}, {"text": "each column and so I'm trying to really", "start": 2607.9, "duration": 4.56}, {"text": "Force those data types on the read so", "start": 2609.579, "duration": 6.0}, {"text": "they don't change the two that I", "start": 2612.46, "duration": 5.159}, {"text": "probably just because my pen is", "start": 2615.579, "duration": 5.701}, {"text": "ignorance oh someone drawn", "start": 2617.619, "duration": 6.181}, {"text": "yes yeah", "start": 2621.28, "duration": 5.339}, {"text": "um is this uh or", "start": 2623.8, "duration": 5.94}, {"text": "uh these two date", "start": 2626.619, "duration": 6.24}, {"text": "um object uh date columns um it could be", "start": 2629.74, "duration": 4.56}, {"text": "just my penis ignorance I wasn't able to", "start": 2632.859, "duration": 3.181}, {"text": "figure out a good way to force these two", "start": 2634.3, "duration": 3.24}, {"text": "so I'm just labeling them as objects", "start": 2636.04, "duration": 3.96}, {"text": "we're going to correct that later", "start": 2637.54, "duration": 3.72}, {"text": "okay", "start": 2640.0, "duration": 2.579}, {"text": "um", "start": 2641.26, "duration": 3.42}, {"text": "so uh if you're not familiar with that", "start": 2642.579, "duration": 4.74}, {"text": "so to ask is this um library that will", "start": 2644.68, "duration": 5.179}, {"text": "allow you to uh", "start": 2647.319, "duration": 7.321}, {"text": "uh parallelize your um sort of data", "start": 2649.859, "duration": 5.801}, {"text": "science", "start": 2654.64, "duration": 3.679}, {"text": "uh", "start": 2655.66, "duration": 2.659}, {"text": "workflows with pandas and scikit-learn", "start": 2659.56, "duration": 6.36}, {"text": "and I'm learning how to use it myself", "start": 2663.0, "duration": 4.54}, {"text": "um I", "start": 2665.92, "duration": 2.939}, {"text": "the only thing I was able to really", "start": 2667.54, "duration": 3.12}, {"text": "accomplish with that so far", "start": 2668.859, "duration": 3.121}, {"text": "um getting familiar with it was to", "start": 2670.66, "duration": 4.02}, {"text": "really speed up the uh read time to get", "start": 2671.98, "duration": 4.92}, {"text": "the data set into uh", "start": 2674.68, "duration": 5.939}, {"text": "uh a reasonable time to actually", "start": 2676.9, "duration": 5.34}, {"text": "uh", "start": 2680.619, "duration": 4.561}, {"text": "import the the full data set for us to", "start": 2682.24, "duration": 5.28}, {"text": "analyze here in this example", "start": 2685.18, "duration": 4.02}, {"text": "um because otherwise it takes 10 minutes", "start": 2687.52, "duration": 3.72}, {"text": "if you just do sort of a regular pandas", "start": 2689.2, "duration": 4.619}, {"text": "read CSV and that's basically because", "start": 2691.24, "duration": 4.619}, {"text": "pandas is really using only a single", "start": 2693.819, "duration": 5.401}, {"text": "thread or a single core to read in the", "start": 2695.859, "duration": 5.041}, {"text": "data set so", "start": 2699.22, "duration": 5.94}, {"text": "in this example here on the uh on the", "start": 2700.9, "duration": 6.719}, {"text": "this V100 test node that we have there's", "start": 2705.16, "duration": 4.32}, {"text": "actually 32 cores and it actually has", "start": 2707.619, "duration": 4.141}, {"text": "hyper threading turned on so that's why", "start": 2709.48, "duration": 5.52}, {"text": "the setup here is 32 workers with two", "start": 2711.76, "duration": 4.98}, {"text": "threads per core so if you're running", "start": 2715.0, "duration": 3.06}, {"text": "this on your laptop and you only have", "start": 2716.74, "duration": 4.14}, {"text": "like two cores you know you should", "start": 2718.06, "duration": 5.039}, {"text": "change this to two and maybe got this", "start": 2720.88, "duration": 3.84}, {"text": "down to one", "start": 2723.099, "duration": 4.381}, {"text": "um but an uncomment rate this would be", "start": 2724.72, "duration": 5.099}, {"text": "24 and we don't have hyper threading on", "start": 2727.48, "duration": 5.52}, {"text": "so it would be one so it's yeah you got", "start": 2729.819, "duration": 4.26}, {"text": "to play around with this if you're going", "start": 2733.0, "duration": 3.18}, {"text": "to run this yourself this is just what", "start": 2734.079, "duration": 4.26}, {"text": "I'm going to use and I'm going to start", "start": 2736.18, "duration": 3.96}, {"text": "it up and what you'll see here I have", "start": 2738.339, "duration": 3.721}, {"text": "top running which will show you all the", "start": 2740.14, "duration": 3.84}, {"text": "processes that start you'll just see", "start": 2742.06, "duration": 3.96}, {"text": "a bunch of python processes to start", "start": 2743.98, "duration": 3.839}, {"text": "right so I'm using all the cores to", "start": 2746.02, "duration": 4.92}, {"text": "really read in all of these CSV files", "start": 2747.819, "duration": 6.721}, {"text": "and again I'm using this um", "start": 2750.94, "duration": 7.62}, {"text": "there's columns uh dictionary to force", "start": 2754.54, "duration": 7.5}, {"text": "both the label onto the data frame and", "start": 2758.56, "duration": 6.18}, {"text": "the type okay", "start": 2762.04, "duration": 3.96}, {"text": "and this is the only thing I'm going to", "start": 2764.74, "duration": 3.859}, {"text": "use stats for today so it'll be done in", "start": 2766.0, "duration": 7.74}, {"text": "it takes about 56 50 60 Seconds", "start": 2768.599, "duration": 8.141}, {"text": "um with the full data set so it takes 10", "start": 2773.74, "duration": 4.92}, {"text": "minutes with pandas by itself so don't", "start": 2776.74, "duration": 4.5}, {"text": "don't do that if you don't have to", "start": 2778.66, "duration": 4.439}, {"text": "but you can play around with it this is", "start": 2781.24, "duration": 3.48}, {"text": "something again you can Benchmark all", "start": 2783.099, "duration": 3.661}, {"text": "the methods which is what I played", "start": 2784.72, "duration": 4.16}, {"text": "around with a lot was pandas itself", "start": 2786.76, "duration": 5.94}, {"text": "tasks non-distributed read CSV the", "start": 2788.88, "duration": 6.52}, {"text": "distributor USB and also qdf has its own", "start": 2792.7, "duration": 6.84}, {"text": "read CSV which I said again I didn't use", "start": 2795.4, "duration": 6.48}, {"text": "um mainly because of this type", "start": 2799.54, "duration": 4.26}, {"text": "enforcement that I wanted", "start": 2801.88, "duration": 3.66}, {"text": "um it was a much cleaner to First import", "start": 2803.8, "duration": 3.44}, {"text": "it into", "start": 2805.54, "duration": 4.319}, {"text": "pandas and then transfer it over to the", "start": 2807.24, "duration": 4.3}, {"text": "GPU which I'll show you", "start": 2809.859, "duration": 3.901}, {"text": "quick question yes reading in multiple", "start": 2811.54, "duration": 3.6}, {"text": "csvs", "start": 2813.76, "duration": 4.02}, {"text": "no so there's multiple csvs so if you go", "start": 2815.14, "duration": 4.08}, {"text": "back up in the notebook at the start of", "start": 2817.78, "duration": 4.319}, {"text": "this acquisition data section so here", "start": 2819.22, "duration": 5.7}, {"text": "I'm literally listing all of the files", "start": 2822.099, "duration": 5.821}, {"text": "that are in the data set so there's four", "start": 2824.92, "duration": 6.78}, {"text": "per year for 17 years so that's so it's", "start": 2827.92, "duration": 6.36}, {"text": "reading in multiple csvs what's going on", "start": 2831.7, "duration": 4.919}, {"text": "under the hood in all these read CSV", "start": 2834.28, "duration": 4.74}, {"text": "methods I don't know exactly so um are", "start": 2836.619, "duration": 5.761}, {"text": "they chunking it in each CSV in some way", "start": 2839.02, "duration": 5.76}, {"text": "Distributing it across the processes I I", "start": 2842.38, "duration": 4.5}, {"text": "don't know the details", "start": 2844.78, "duration": 4.98}, {"text": "um but that's that'd be a smart thing to", "start": 2846.88, "duration": 4.439}, {"text": "do I guess", "start": 2849.76, "duration": 3.54}, {"text": "um so hopefully that answers uh so I'm", "start": 2851.319, "duration": 3.481}, {"text": "definitely reading in multiple csvs but", "start": 2853.3, "duration": 2.76}, {"text": "how that's actually happening under the", "start": 2854.8, "duration": 3.0}, {"text": "hood if it's sort of breaking each CSV", "start": 2856.06, "duration": 5.22}, {"text": "up into smaller chunks uh I don't know", "start": 2857.8, "duration": 6.0}, {"text": "um at the end of the day I end up with", "start": 2861.28, "duration": 4.86}, {"text": "um a single data frame right so I take", "start": 2863.8, "duration": 5.22}, {"text": "the dasc data frame that was that was", "start": 2866.14, "duration": 5.16}, {"text": "imported into and just immediately dump", "start": 2869.02, "duration": 3.54}, {"text": "it to pandas", "start": 2871.3, "duration": 3.96}, {"text": "it's really I'm really only using it to", "start": 2872.56, "duration": 4.98}, {"text": "read things in quickly", "start": 2875.26, "duration": 4.5}, {"text": "so uh I'm showing here the dad types", "start": 2877.54, "duration": 3.96}, {"text": "again just to show that", "start": 2879.76, "duration": 5.22}, {"text": "um the the types were enforced when I", "start": 2881.5, "duration": 5.22}, {"text": "read in the data sets", "start": 2884.98, "duration": 3.839}, {"text": "and again like I mentioned earlier these", "start": 2886.72, "duration": 5.099}, {"text": "dates uh I want to force into date time", "start": 2888.819, "duration": 4.8}, {"text": "objects so that's", "start": 2891.819, "duration": 2.581}, {"text": "um", "start": 2893.619, "duration": 2.761}, {"text": "what we're going to do here in this next", "start": 2894.4, "duration": 4.199}, {"text": "section", "start": 2896.38, "duration": 3.6}, {"text": "so again if you haven't played around", "start": 2898.599, "duration": 4.081}, {"text": "with uh pandas data types or not", "start": 2899.98, "duration": 5.359}, {"text": "checking that your data types or", "start": 2902.68, "duration": 5.58}, {"text": "correct when you read in your data um I", "start": 2905.339, "duration": 5.861}, {"text": "would definitely make sure I ran into", "start": 2908.26, "duration": 5.04}, {"text": "lots of problems with um when I was", "start": 2911.2, "duration": 4.2}, {"text": "first started developing this and just", "start": 2913.3, "duration": 4.62}, {"text": "some of the methods aren't you know good", "start": 2915.4, "duration": 4.08}, {"text": "automatically recognizing certain", "start": 2917.92, "duration": 3.3}, {"text": "certain types of data and maybe how", "start": 2919.48, "duration": 3.96}, {"text": "they're formatted so", "start": 2921.22, "duration": 3.84}, {"text": "um so this takes a little bit of time to", "start": 2923.44, "duration": 4.26}, {"text": "reformat those objects into date time", "start": 2925.06, "duration": 4.759}, {"text": "objects the reason you want to get um", "start": 2927.7, "duration": 6.36}, {"text": "some of the data types um", "start": 2929.819, "duration": 6.581}, {"text": "to be a certain type for example these", "start": 2934.06, "duration": 4.38}, {"text": "category types", "start": 2936.4, "duration": 4.74}, {"text": "if you read these in naively some of", "start": 2938.44, "duration": 4.919}, {"text": "these category data types are actually", "start": 2941.14, "duration": 4.74}, {"text": "read in usually as objects which are", "start": 2943.359, "duration": 4.801}, {"text": "sort of more open-ended if they're", "start": 2945.88, "duration": 4.08}, {"text": "actually categories right it limits sort", "start": 2948.16, "duration": 4.56}, {"text": "of the the memory footprint that needs", "start": 2949.96, "duration": 5.46}, {"text": "to you know there's only certain a fixed", "start": 2952.72, "duration": 4.74}, {"text": "finite number of things that that object", "start": 2955.42, "duration": 4.32}, {"text": "can be so it's more efficient to have", "start": 2957.46, "duration": 4.379}, {"text": "your data types set in category then say", "start": 2959.74, "duration": 5.0}, {"text": "object for some of these", "start": 2961.839, "duration": 7.401}, {"text": "some of these Columns of the data set", "start": 2964.74, "duration": 4.5}, {"text": "and so the next section after this", "start": 2970.48, "duration": 4.92}, {"text": "finish is loading or reformatting those", "start": 2972.819, "duration": 4.26}, {"text": "columns um", "start": 2975.4, "duration": 3.419}, {"text": "again this could probably be quicker and", "start": 2977.079, "duration": 4.201}, {"text": "done in a certain way maybe you can", "start": 2978.819, "duration": 5.221}, {"text": "figure out how to how to do it on the", "start": 2981.28, "duration": 5.76}, {"text": "read for me and let me know if you're", "start": 2984.04, "duration": 6.12}, {"text": "more Panda savvy than I am um", "start": 2987.04, "duration": 6.66}, {"text": "but yeah again this is really just to", "start": 2990.16, "duration": 4.98}, {"text": "enforce that we have the correct data", "start": 2993.7, "duration": 4.68}, {"text": "types once we throw it over to um", "start": 2995.14, "duration": 5.4}, {"text": "the GPU", "start": 2998.38, "duration": 3.959}, {"text": "because again I had similar problems", "start": 3000.54, "duration": 3.9}, {"text": "there where certain even more problems", "start": 3002.339, "duration": 3.421}, {"text": "there where like things were just", "start": 3004.44, "duration": 3.179}, {"text": "basically thrown into his objects and", "start": 3005.76, "duration": 4.14}, {"text": "not really um well formatted in terms of", "start": 3007.619, "duration": 4.621}, {"text": "data type so you can see now that I've", "start": 3009.9, "duration": 4.32}, {"text": "changed these the the dates to date time", "start": 3012.24, "duration": 3.24}, {"text": "objects", "start": 3014.22, "duration": 3.0}, {"text": "I'm going to start speeding up all right", "start": 3015.48, "duration": 5.28}, {"text": "so lots of background and context and", "start": 3017.22, "duration": 5.34}, {"text": "now we're finally at our first call to", "start": 3020.76, "duration": 4.98}, {"text": "uh kudia which is to basically transfer", "start": 3022.56, "duration": 7.62}, {"text": "over our pandas data frame to uh", "start": 3025.74, "duration": 6.119}, {"text": "the GPU", "start": 3030.18, "duration": 3.54}, {"text": "all right so I'm going to show you here", "start": 3031.859, "duration": 5.161}, {"text": "just on repeat so I have my empty gpus", "start": 3033.72, "duration": 6.72}, {"text": "again if you call kudi F data frame from", "start": 3037.02, "duration": 5.4}, {"text": "pandas it'll convert your pandas data", "start": 3040.44, "duration": 3.54}, {"text": "frame into a qdf data frame so", "start": 3042.42, "duration": 4.98}, {"text": "essentially offloading the data frame", "start": 3043.98, "duration": 6.54}, {"text": "to the GPU so we should see", "start": 3047.4, "duration": 5.76}, {"text": "there's my python process pop-up so this", "start": 3050.52, "duration": 5.28}, {"text": "is the Rapids process from qdf popping", "start": 3053.16, "duration": 5.58}, {"text": "up and importing uh the data set so I", "start": 3055.8, "duration": 4.759}, {"text": "think it'll get to about", "start": 3058.74, "duration": 5.339}, {"text": "six gigabytes I think", "start": 3060.559, "duration": 6.701}, {"text": "sorry as I mentioned uh at the top the", "start": 3064.079, "duration": 4.681}, {"text": "the raw does it's about four gigabytes", "start": 3067.26, "duration": 2.7}, {"text": "so there's always some overhead rate", "start": 3068.76, "duration": 4.2}, {"text": "associated with all these", "start": 3069.96, "duration": 5.28}, {"text": "data structures so you'll have to keep", "start": 3072.96, "duration": 4.56}, {"text": "in that keep that in mind too is you", "start": 3075.24, "duration": 4.079}, {"text": "know reading in a four gigabyte", "start": 3077.52, "duration": 5.4}, {"text": "um uncompressed you know data sets into", "start": 3079.319, "duration": 5.3}, {"text": "a different", "start": 3082.92, "duration": 4.08}, {"text": "data structure um you know it'll create", "start": 3084.619, "duration": 3.641}, {"text": "some overhead so you won't be able to", "start": 3087.0, "duration": 3.98}, {"text": "read in you know", "start": 3088.26, "duration": 2.72}, {"text": "I think on this on these on each GPU", "start": 3091.26, "duration": 4.2}, {"text": "here it's like 32 gigabytes available", "start": 3093.72, "duration": 3.74}, {"text": "per", "start": 3095.46, "duration": 5.04}, {"text": "GPU so you know you have to", "start": 3097.46, "duration": 5.34}, {"text": "leave some overhead for the", "start": 3100.5, "duration": 5.96}, {"text": "data structure as well", "start": 3102.8, "duration": 3.66}, {"text": "okay", "start": 3107.28, "duration": 3.66}, {"text": "so again it took about another minute to", "start": 3108.96, "duration": 4.98}, {"text": "load that from CPU memory to GPU memory", "start": 3110.94, "duration": 5.82}, {"text": "but now we have our both our pandas data", "start": 3113.94, "duration": 5.28}, {"text": "frame and our cudia data frame and now", "start": 3116.76, "duration": 4.62}, {"text": "we can start comparing them and so again", "start": 3119.22, "duration": 3.839}, {"text": "I just do some type checking just to", "start": 3121.38, "duration": 4.08}, {"text": "make sure everything was thrown over", "start": 3123.059, "duration": 4.861}, {"text": "correctly and now we can start using", "start": 3125.46, "duration": 4.92}, {"text": "both our pandas data frames and our qdf", "start": 3127.92, "duration": 4.439}, {"text": "data frame and comparing things so one", "start": 3130.38, "duration": 3.92}, {"text": "of the methods that you know", "start": 3132.359, "duration": 5.341}, {"text": "you might be familiar with early on when", "start": 3134.3, "duration": 4.96}, {"text": "you start using pandas is just to look", "start": 3137.7, "duration": 4.68}, {"text": "at say the top few rows of the file qdf", "start": 3139.26, "duration": 5.22}, {"text": "has the same", "start": 3142.38, "duration": 4.26}, {"text": "the same set", "start": 3144.48, "duration": 4.56}, {"text": "one thing that's nice is in the latest", "start": 3146.64, "duration": 3.719}, {"text": "version of Rapids you used to have to", "start": 3149.04, "duration": 3.059}, {"text": "actually print", "start": 3150.359, "duration": 4.381}, {"text": "each of these calls out I guess they", "start": 3152.099, "duration": 4.201}, {"text": "fixed some of the", "start": 3154.74, "duration": 2.4}, {"text": "um", "start": 3156.3, "duration": 5.22}, {"text": "string support from kudia since I last", "start": 3157.14, "duration": 6.54}, {"text": "played around with it in the summer", "start": 3161.52, "duration": 4.2}, {"text": "but yeah so there's different methods", "start": 3163.68, "duration": 3.54}, {"text": "you know you're going to see things", "start": 3165.72, "duration": 4.44}, {"text": "exactly the same from pandas to cudif is", "start": 3167.22, "duration": 4.08}, {"text": "just going to give you the same exact", "start": 3170.16, "duration": 4.8}, {"text": "results again performance data that'll", "start": 3171.3, "duration": 6.299}, {"text": "be for a future version of this talk", "start": 3174.96, "duration": 5.34}, {"text": "or an extended version of this talk and", "start": 3177.599, "duration": 5.281}, {"text": "let's just jump into actually exploring", "start": 3180.3, "duration": 3.96}, {"text": "the data a bit in the last few minutes", "start": 3182.88, "duration": 2.64}, {"text": "that we have", "start": 3184.26, "duration": 1.92}, {"text": "um", "start": 3185.52, "duration": 2.22}, {"text": "so one of the things you want to start", "start": 3186.18, "duration": 3.84}, {"text": "doing right uh when you once you have", "start": 3187.74, "duration": 3.78}, {"text": "your data set loaded is you want to", "start": 3190.02, "duration": 3.78}, {"text": "start querying around maybe you know", "start": 3191.52, "duration": 4.079}, {"text": "answering some simple questions about", "start": 3193.8, "duration": 3.72}, {"text": "the data right so the first question", "start": 3195.599, "duration": 3.841}, {"text": "here is how many loans were made for", "start": 3197.52, "duration": 3.78}, {"text": "more than four hundred thousand dollars", "start": 3199.44, "duration": 4.619}, {"text": "right remember I mentioned in the slides", "start": 3201.3, "duration": 4.319}, {"text": "right there's this conforming loan limit", "start": 3204.059, "duration": 3.971}, {"text": "right which was about 485", "start": 3205.619, "duration": 3.781}, {"text": "[Music]", "start": 3208.03, "duration": 5.69}, {"text": "000 in 2019 right so from 20 2000 to", "start": 3209.4, "duration": 8.04}, {"text": "2016 how many loans were in the data set", "start": 3213.72, "duration": 5.399}, {"text": "with more than four hundred thousand", "start": 3217.44, "duration": 4.86}, {"text": "dollars right so I mean pandas is pretty", "start": 3219.119, "duration": 7.921}, {"text": "fast right it only took 1.3 seconds so", "start": 3222.3, "duration": 9.12}, {"text": "it's not you know gonna kill like you", "start": 3227.04, "duration": 6.0}, {"text": "know your research if you wait around", "start": 3231.42, "duration": 4.02}, {"text": "for a second but if we run the same", "start": 3233.04, "duration": 5.279}, {"text": "question on the qdf data frame", "start": 3235.44, "duration": 6.659}, {"text": "you know it's what four times faster so", "start": 3238.319, "duration": 6.601}, {"text": "if you then scale that out and if this", "start": 3242.099, "duration": 4.98}, {"text": "speed up", "start": 3244.92, "duration": 4.8}, {"text": "um improves even more with larger data", "start": 3247.079, "duration": 4.141}, {"text": "sets you can kind of see the advantages", "start": 3249.72, "duration": 4.08}, {"text": "right so this is again a few gigabytes", "start": 3251.22, "duration": 6.44}, {"text": "of data right so you get about a 4X", "start": 3253.8, "duration": 6.6}, {"text": "speed up on this type of query right", "start": 3257.66, "duration": 4.959}, {"text": "it's going to matter what type of query", "start": 3260.4, "duration": 4.699}, {"text": "you're making", "start": 3262.619, "duration": 2.48}, {"text": "um and also right so I go through some", "start": 3265.2, "duration": 4.98}, {"text": "sort of additional sort of more", "start": 3267.66, "duration": 6.659}, {"text": "complicated queries uh going down here I", "start": 3270.18, "duration": 7.32}, {"text": "do and but yeah the the speed up will", "start": 3274.319, "duration": 4.981}, {"text": "depend on also the method that you're", "start": 3277.5, "duration": 4.5}, {"text": "calling and sort of also on", "start": 3279.3, "duration": 4.92}, {"text": "um the data types of the columns that", "start": 3282.0, "duration": 3.54}, {"text": "you're actually performing the queries", "start": 3284.22, "duration": 3.3}, {"text": "on or the Transformations on so this", "start": 3285.54, "duration": 3.6}, {"text": "you'll see this in some of these", "start": 3287.52, "duration": 3.599}, {"text": "examples so I'll just try to run these", "start": 3289.14, "duration": 3.54}, {"text": "off they're they're pretty quick so", "start": 3291.119, "duration": 4.621}, {"text": "again so you can start nesting um your", "start": 3292.68, "duration": 4.8}, {"text": "questions together so how many you know", "start": 3295.74, "duration": 3.18}, {"text": "loans were made in California for more", "start": 3297.48, "duration": 4.139}, {"text": "than four hundred thousand dollars", "start": 3298.92, "duration": 6.54}, {"text": "um so that only took about half a second", "start": 3301.619, "duration": 7.561}, {"text": "do it with qdf oh this is uh one of the", "start": 3305.46, "duration": 6.3}, {"text": "first examples where it's like okay not", "start": 3309.18, "duration": 4.379}, {"text": "everything is going to be exactly the", "start": 3311.76, "duration": 4.02}, {"text": "same so I ran into this uh the first", "start": 3313.559, "duration": 4.861}, {"text": "time I did the stock back in the summer", "start": 3315.78, "duration": 3.48}, {"text": "um", "start": 3318.42, "duration": 2.88}, {"text": "uh for whatever reason uh kdf doesn't", "start": 3319.26, "duration": 6.66}, {"text": "quite have support for like string uh", "start": 3321.3, "duration": 6.12}, {"text": "literals", "start": 3325.92, "duration": 4.919}, {"text": "um uh so or comparisons at least so what", "start": 3327.42, "duration": 5.52}, {"text": "you actually have to do in this case is", "start": 3330.839, "duration": 6.601}, {"text": "you know I go to my property State", "start": 3332.94, "duration": 8.159}, {"text": "column it's actually a category and so", "start": 3337.44, "duration": 5.34}, {"text": "you actually have to input here the", "start": 3341.099, "duration": 2.841}, {"text": "integer", "start": 3342.78, "duration": 3.72}, {"text": "of the category like what what's its", "start": 3343.94, "duration": 4.78}, {"text": "index essentially in that in that column", "start": 3346.5, "duration": 3.9}, {"text": "or in that", "start": 3348.72, "duration": 4.619}, {"text": "category data type so you see it starts", "start": 3350.4, "duration": 6.0}, {"text": "from zero so zero is Arkansas one is", "start": 3353.339, "duration": 5.461}, {"text": "Alaska so so California is number four", "start": 3356.4, "duration": 5.58}, {"text": "so to actually perform this", "start": 3358.8, "duration": 8.58}, {"text": "um this uh this query on the qdf data", "start": 3361.98, "duration": 6.839}, {"text": "frame you actually have to put in the", "start": 3367.38, "duration": 3.6}, {"text": "integer and it works fine and again it's", "start": 3368.819, "duration": 3.901}, {"text": "faster right this is about a half a", "start": 3370.98, "duration": 5.099}, {"text": "second this is uh so it's about two and", "start": 3372.72, "duration": 8.339}, {"text": "a half times I mean faster on the GPU", "start": 3376.079, "duration": 7.141}, {"text": "and you can get more and more", "start": 3381.059, "duration": 4.681}, {"text": "complicated queries going you're not", "start": 3383.22, "duration": 3.98}, {"text": "going to see a whole lot of difference", "start": 3385.74, "duration": 4.5}, {"text": "again about twice as fast for this more", "start": 3387.2, "duration": 4.84}, {"text": "complicated query but again you have", "start": 3390.24, "duration": 3.72}, {"text": "these limitations like your code isn't", "start": 3392.04, "duration": 3.84}, {"text": "exactly the same you have to make some", "start": 3393.96, "duration": 4.56}, {"text": "modifications as well all right so", "start": 3395.88, "duration": 4.679}, {"text": "that's like the aquarium method", "start": 3398.52, "duration": 3.48}, {"text": "um and you know some of the pitfalls you", "start": 3400.559, "duration": 4.081}, {"text": "might run into there the grouping data", "start": 3402.0, "duration": 4.5}, {"text": "examples here are pretty interesting", "start": 3404.64, "duration": 3.6}, {"text": "because you'll actually see the the", "start": 3406.5, "duration": 4.14}, {"text": "reason I put these uh the the data types", "start": 3408.24, "duration": 3.72}, {"text": "here", "start": 3410.64, "duration": 4.199}, {"text": "um is you'll see the some of the", "start": 3411.96, "duration": 5.84}, {"text": "variability in the speed up between", "start": 3414.839, "duration": 7.101}, {"text": "doing these uh Group by", "start": 3417.8, "duration": 7.18}, {"text": "functions depending on both the type of", "start": 3421.94, "duration": 6.1}, {"text": "the data and also on the the function", "start": 3424.98, "duration": 4.56}, {"text": "that you're doing in the group by so", "start": 3428.04, "duration": 3.9}, {"text": "here I'm actually just counting I'm", "start": 3429.54, "duration": 5.64}, {"text": "creating a essentially a small data", "start": 3431.94, "duration": 6.24}, {"text": "frame of the total loans per month", "start": 3435.18, "duration": 5.54}, {"text": "essentially that were originated", "start": 3438.18, "duration": 5.58}, {"text": "essentially how many loans that Fannie", "start": 3440.72, "duration": 5.44}, {"text": "Mae bought were made by banks in that", "start": 3443.76, "duration": 4.319}, {"text": "month right so this is a little bit more", "start": 3446.16, "duration": 3.899}, {"text": "complicated calculation right it's going", "start": 3448.079, "duration": 4.621}, {"text": "to take about two and a half seconds if", "start": 3450.059, "duration": 5.04}, {"text": "you go to the qdf data frame it's way", "start": 3452.7, "duration": 4.56}, {"text": "faster right", "start": 3455.099, "duration": 4.02}, {"text": "so", "start": 3457.26, "duration": 4.68}, {"text": "it's you know if there's some sort of", "start": 3459.119, "duration": 5.581}, {"text": "group by function with like counts this", "start": 3461.94, "duration": 4.679}, {"text": "is a significant speed up that you'll", "start": 3464.7, "duration": 4.98}, {"text": "see in this example right and so I walk", "start": 3466.619, "duration": 4.801}, {"text": "through a few more examples", "start": 3469.68, "duration": 3.419}, {"text": "um where uh", "start": 3471.42, "duration": 4.98}, {"text": "you can use different", "start": 3473.099, "duration": 4.321}, {"text": "um", "start": 3476.4, "duration": 3.6}, {"text": "different functions and different data", "start": 3477.42, "duration": 4.679}, {"text": "types so I tried to label those here", "start": 3480.0, "duration": 6.0}, {"text": "so this is another example here where", "start": 3482.099, "duration": 5.881}, {"text": "um again you're going to run into", "start": 3486.0, "duration": 5.22}, {"text": "problems using qdf where ever not", "start": 3487.98, "duration": 5.639}, {"text": "everything works so in this case the div", "start": 3491.22, "duration": 5.899}, {"text": "method here so basically I tried to", "start": 3493.619, "duration": 6.361}, {"text": "reformat the data I wanted to calculate", "start": 3497.119, "duration": 4.72}, {"text": "the sum and then just you know just", "start": 3499.98, "duration": 3.78}, {"text": "output the data in billions of dollars", "start": 3501.839, "duration": 5.28}, {"text": "well you can't use the div function in", "start": 3503.76, "duration": 7.38}, {"text": "cudif yet so I just had to go back and", "start": 3507.119, "duration": 7.381}, {"text": "leave it all in dollars yeah so there's", "start": 3511.14, "duration": 4.38}, {"text": "like I said there's going to be", "start": 3514.5, "duration": 2.4}, {"text": "limitations", "start": 3515.52, "duration": 3.059}, {"text": "uh", "start": 3516.9, "duration": 4.88}, {"text": "that you're going to come across", "start": 3518.579, "duration": 5.881}, {"text": "skip them", "start": 3521.78, "duration": 5.92}, {"text": "yeah so yeah so you're gonna run into", "start": 3524.46, "duration": 3.899}, {"text": "um", "start": 3527.7, "duration": 3.599}, {"text": "these issues but again if you sort of", "start": 3528.359, "duration": 5.641}, {"text": "work around some of the um", "start": 3531.299, "duration": 4.741}, {"text": "issues with cudif as it's still being", "start": 3534.0, "duration": 3.66}, {"text": "developed right you're going to see", "start": 3536.04, "duration": 3.539}, {"text": "significant speed UPS right this", "start": 3537.66, "duration": 4.8}, {"text": "calculating the total balance originated", "start": 3539.579, "duration": 5.401}, {"text": "per month again significant speed up in", "start": 3542.46, "duration": 4.44}, {"text": "calculations", "start": 3544.98, "duration": 5.18}, {"text": "all right so I'm going to just", "start": 3546.9, "duration": 3.26}, {"text": "go through and", "start": 3550.38, "duration": 6.12}, {"text": "there's not a whole lot more other than", "start": 3553.4, "duration": 5.5}, {"text": "just playing around with some of the", "start": 3556.5, "duration": 5.4}, {"text": "other examples so what I'm doing here in", "start": 3558.9, "duration": 4.5}, {"text": "this group by section I'm just going to", "start": 3561.9, "duration": 2.76}, {"text": "sort of run these off since we're", "start": 3563.4, "duration": 3.899}, {"text": "running out of time the idea here is I'm", "start": 3564.66, "duration": 5.04}, {"text": "just building up a bunch of series that", "start": 3567.299, "duration": 4.081}, {"text": "I'm going to then concatenate together", "start": 3569.7, "duration": 4.26}, {"text": "to maybe do some more data exploration", "start": 3571.38, "duration": 4.08}, {"text": "in the next section", "start": 3573.96, "duration": 3.24}, {"text": "Okay so", "start": 3575.46, "duration": 4.68}, {"text": "again you'll see these times vary right", "start": 3577.2, "duration": 5.7}, {"text": "now at the beginning there was", "start": 3580.14, "duration": 5.459}, {"text": "um you know up to two seconds for the", "start": 3582.9, "duration": 5.399}, {"text": "pan disc calculation uh or the group by", "start": 3585.599, "duration": 6.601}, {"text": "Method versus uh down to uh hundreds of", "start": 3588.299, "duration": 6.121}, {"text": "milliseconds in these later ones when", "start": 3592.2, "duration": 6.359}, {"text": "I'm doing say a mean on a floating Point", "start": 3594.42, "duration": 6.06}, {"text": "number the speed up isn't as much so", "start": 3598.559, "duration": 3.181}, {"text": "you're really going to see variability", "start": 3600.48, "duration": 2.7}, {"text": "depending on what the method is you're", "start": 3601.74, "duration": 4.44}, {"text": "using uh what your method you're calling", "start": 3603.18, "duration": 6.6}, {"text": "and some of the other uh sub functions", "start": 3606.18, "duration": 5.7}, {"text": "that might be there and and what type of", "start": 3609.78, "duration": 3.66}, {"text": "data types you're dealing with right so", "start": 3611.88, "duration": 4.14}, {"text": "it'd be really nice to have some time to", "start": 3613.44, "duration": 4.8}, {"text": "go through and sort of Benchmark", "start": 3616.02, "duration": 4.079}, {"text": "um this stuff in a little bit more", "start": 3618.24, "duration": 4.02}, {"text": "detail which it's sort of set up to", "start": 3620.099, "duration": 4.74}, {"text": "start doing uh with these examples um", "start": 3622.26, "duration": 3.9}, {"text": "but I just didn't have time to sort of", "start": 3624.839, "duration": 3.181}, {"text": "put that all together for you", "start": 3626.16, "duration": 4.62}, {"text": "um the last section here is", "start": 3628.02, "duration": 6.059}, {"text": "um just the concatenation method so", "start": 3630.78, "duration": 4.86}, {"text": "again in pandas", "start": 3634.079, "duration": 4.5}, {"text": "um what I did is with all those", "start": 3635.64, "duration": 5.719}, {"text": "small summary", "start": 3638.579, "duration": 5.101}, {"text": "pandas data frames just concatenate", "start": 3641.359, "duration": 4.901}, {"text": "those together into a single data frame", "start": 3643.68, "duration": 4.2}, {"text": "and", "start": 3646.26, "duration": 4.44}, {"text": "again you can do the same on 2df and", "start": 3647.88, "duration": 4.02}, {"text": "this is one of those examples where I", "start": 3650.7, "duration": 2.159}, {"text": "said", "start": 3651.9, "duration": 2.58}, {"text": "for whatever reason", "start": 3652.859, "duration": 3.901}, {"text": "um kudi f does not have any advantages", "start": 3654.48, "duration": 4.8}, {"text": "to say for concatenation right so you", "start": 3656.76, "duration": 5.16}, {"text": "see pandas is actually faster right so", "start": 3659.28, "duration": 4.92}, {"text": "it really is the advantages you're going", "start": 3661.92, "duration": 5.34}, {"text": "to see with qdf and any of the Rapids", "start": 3664.2, "duration": 4.74}, {"text": "um", "start": 3667.26, "duration": 4.14}, {"text": "based algorithms available in the other", "start": 3668.94, "duration": 4.139}, {"text": "libraries Rapids you're really just", "start": 3671.4, "duration": 2.88}, {"text": "going to have to explore whether or not", "start": 3673.079, "duration": 3.421}, {"text": "it's worth your time if you rely on a", "start": 3674.28, "duration": 5.94}, {"text": "Signet one type of algorithm or um", "start": 3676.5, "duration": 6.54}, {"text": "certain methods for your workflow", "start": 3680.22, "duration": 4.079}, {"text": "whether or not it's going to be worth it", "start": 3683.04, "duration": 2.059}, {"text": "to", "start": 3684.299, "duration": 5.461}, {"text": "go explore Rapids kdf cool ML and the", "start": 3685.099, "duration": 6.581}, {"text": "other libraries", "start": 3689.76, "duration": 4.44}, {"text": "so that's sort of the summary and", "start": 3691.68, "duration": 5.28}, {"text": "hopefully uh sort of you know how far", "start": 3694.2, "duration": 4.5}, {"text": "I've gotten I guess using Rapids and", "start": 3696.96, "duration": 3.3}, {"text": "pandas and things like that and", "start": 3698.7, "duration": 4.44}, {"text": "comparing the two as well", "start": 3700.26, "duration": 4.079}, {"text": "um hopefully the next version of this", "start": 3703.14, "duration": 4.919}, {"text": "talk we'll have some sort of qml scikit", "start": 3704.339, "duration": 6.061}, {"text": "learning comparisons looking at sort of", "start": 3708.059, "duration": 4.5}, {"text": "my first goal is to do some cluster sort", "start": 3710.4, "duration": 4.199}, {"text": "of analysis if I can you know find", "start": 3712.559, "duration": 4.201}, {"text": "someone some subset of data here that", "start": 3714.599, "duration": 4.02}, {"text": "makes sense to do that on I just haven't", "start": 3716.76, "duration": 4.38}, {"text": "figured that out yet", "start": 3718.619, "duration": 5.041}, {"text": "um so hopefully uh you enjoyed uh the", "start": 3721.14, "duration": 4.5}, {"text": "talk and it gives you some context for", "start": 3723.66, "duration": 4.8}, {"text": "this data sets and obviously you have a", "start": 3725.64, "duration": 4.14}, {"text": "notebook here that you can start playing", "start": 3728.46, "duration": 4.46}, {"text": "around with modifying and", "start": 3729.78, "duration": 5.94}, {"text": "exploring the comparisons at least", "start": 3732.92, "duration": 5.8}, {"text": "between pandas and kudi F in the Rapids", "start": 3735.72, "duration": 4.139}, {"text": "framework", "start": 3738.72, "duration": 4.68}, {"text": "so uh with that I will stop here I'm", "start": 3739.859, "duration": 5.641}, {"text": "going to throw the slides back on at the", "start": 3743.4, "duration": 3.419}, {"text": "end of the slides which will eventually", "start": 3745.5, "duration": 3.96}, {"text": "be posted there are some additional", "start": 3746.819, "duration": 5.341}, {"text": "links and resources and references so", "start": 3749.46, "duration": 5.099}, {"text": "again the Rapids website's pretty nice", "start": 3752.16, "duration": 4.5}, {"text": "it has links to all these other sort of", "start": 3754.559, "duration": 4.621}, {"text": "sublinks that you should go to the", "start": 3756.66, "duration": 4.08}, {"text": "Rapids blog", "start": 3759.18, "duration": 3.84}, {"text": "has a lot of cool examples so if you're", "start": 3760.74, "duration": 5.76}, {"text": "curious whether or not your science uh", "start": 3763.02, "duration": 6.36}, {"text": "or workflow might be similar to", "start": 3766.5, "duration": 4.14}, {"text": "something that they've been able to do", "start": 3769.38, "duration": 2.82}, {"text": "and show significant results that's", "start": 3770.64, "duration": 3.419}, {"text": "where you might want to start to sort of", "start": 3772.2, "duration": 4.26}, {"text": "summary articles on what what else is", "start": 3774.059, "duration": 4.621}, {"text": "available and what's possible", "start": 3776.46, "duration": 5.339}, {"text": "um again uh there's some documentation", "start": 3778.68, "duration": 6.0}, {"text": "on how to get started so there's if my", "start": 3781.799, "duration": 4.441}, {"text": "example is a little bit too complicated", "start": 3784.68, "duration": 3.06}, {"text": "with this data set if you just want to", "start": 3786.24, "duration": 3.599}, {"text": "get started with just sort of a syntax", "start": 3787.74, "duration": 4.5}, {"text": "and a few simple things", "start": 3789.839, "duration": 4.5}, {"text": "um this uh part of the documentation the", "start": 3792.24, "duration": 3.96}, {"text": "Rapids documentation this start link", "start": 3794.339, "duration": 4.681}, {"text": "there's a few very simple tutorials just", "start": 3796.2, "duration": 5.359}, {"text": "to familiarize yourself with", "start": 3799.02, "duration": 4.74}, {"text": "the different methods that are available", "start": 3801.559, "duration": 5.26}, {"text": "say from kdf or from pandas that are", "start": 3803.76, "duration": 7.02}, {"text": "available on qdf and some some simple", "start": 3806.819, "duration": 7.02}, {"text": "desk stuff too allegedly I wasn't able", "start": 3810.78, "duration": 4.98}, {"text": "to get to work myself but", "start": 3813.839, "duration": 2.821}, {"text": "um", "start": 3815.76, "duration": 3.0}, {"text": "uh so that's that's another good place", "start": 3816.66, "duration": 3.48}, {"text": "to start if you want to start a little", "start": 3818.76, "duration": 4.319}, {"text": "bit simpler then once you get a little", "start": 3820.14, "duration": 4.979}, {"text": "bit more uh adventurous I would", "start": 3823.079, "duration": 4.02}, {"text": "definitely recommend going to the GitHub", "start": 3825.119, "duration": 4.261}, {"text": "site especially um", "start": 3827.099, "duration": 3.96}, {"text": "they have a bunch of their notebooks", "start": 3829.38, "duration": 4.02}, {"text": "there and the more complicated version", "start": 3831.059, "duration": 5.341}, {"text": "that of the notebook that I created here", "start": 3833.4, "duration": 5.52}, {"text": "where it sort of I started was sort of a", "start": 3836.4, "duration": 5.699}, {"text": "distillation of this deep learning", "start": 3838.92, "duration": 6.6}, {"text": "hybrid one where basically they use as I", "start": 3842.099, "duration": 5.881}, {"text": "mentioned Rapids and Pie torch to", "start": 3845.52, "duration": 4.98}, {"text": "analyze this data set I don't", "start": 3847.98, "duration": 4.619}, {"text": "I don't know how well maintained this", "start": 3850.5, "duration": 5.46}, {"text": "notebook is because I", "start": 3852.599, "duration": 4.921}, {"text": "I saw things in there when I was looking", "start": 3855.96, "duration": 4.2}, {"text": "at it again this this last week I don't", "start": 3857.52, "duration": 5.76}, {"text": "think will work in Rapids anymore so so", "start": 3860.16, "duration": 4.439}, {"text": "I mean but it'll give you some", "start": 3863.28, "duration": 2.76}, {"text": "additional context of things you can do", "start": 3864.599, "duration": 3.901}, {"text": "with data sets and maybe how to go about", "start": 3866.04, "duration": 5.279}, {"text": "it there as well and then the last bit", "start": 3868.5, "duration": 4.319}, {"text": "of documentation that's really helpful", "start": 3871.319, "duration": 4.701}, {"text": "is the the API documentation", "start": 3872.819, "duration": 7.381}, {"text": "so definitely uh use that no okay I'll", "start": 3876.02, "duration": 6.039}, {"text": "fix those links here they're supposed to", "start": 3880.2, "duration": 4.26}, {"text": "be split across two pages", "start": 3882.059, "duration": 3.121}, {"text": "um", "start": 3884.46, "duration": 2.7}, {"text": "and the last thing before if there's any", "start": 3885.18, "duration": 5.46}, {"text": "last minute questions is just we have uh", "start": 3887.16, "duration": 5.22}, {"text": "recent and upcoming Rapids training", "start": 3890.64, "duration": 3.12}, {"text": "events so", "start": 3892.38, "duration": 3.78}, {"text": "um Abe Stern who's from Nvidia our sort", "start": 3893.76, "duration": 4.38}, {"text": "of Nvidia contact here at sdsc he", "start": 3896.16, "duration": 5.659}, {"text": "recently gave a talk to me exceed", "start": 3898.14, "duration": 3.679}, {"text": "e-c-s-e-e-c-s Symposium I think actually", "start": 3901.94, "duration": 5.2}, {"text": "on Tuesday so there's a link to his", "start": 3904.92, "duration": 4.439}, {"text": "YouTube video already available there I", "start": 3907.14, "duration": 3.36}, {"text": "think he does cover a little bit of", "start": 3909.359, "duration": 3.301}, {"text": "Rapids but I heard it was a little bit", "start": 3910.5, "duration": 4.88}, {"text": "more in depth on a different part of", "start": 3912.66, "duration": 6.72}, {"text": "uh sort of nvidia's python", "start": 3915.38, "duration": 7.419}, {"text": "pythonic ecosystem that's developing", "start": 3919.38, "duration": 6.0}, {"text": "um and then uh he'll be I think giving a", "start": 3922.799, "duration": 4.921}, {"text": "very similar talk next month on February", "start": 3925.38, "duration": 6.66}, {"text": "20th uh for the exceed webinar here so", "start": 3927.72, "duration": 8.639}, {"text": "with that I will stop and take questions", "start": 3932.04, "duration": 7.14}, {"text": "if there are any left or if anybody's", "start": 3936.359, "duration": 4.321}, {"text": "still around I guess we still have 33", "start": 3939.18, "duration": 4.26}, {"text": "participants okay great", "start": 3940.68, "duration": 5.34}, {"text": "so that's it for the talk if you have", "start": 3943.44, "duration": 4.44}, {"text": "questions we'll stick around for I don't", "start": 3946.02, "duration": 3.539}, {"text": "know next five minutes or so to see if", "start": 3947.88, "duration": 2.82}, {"text": "there's anything", "start": 3949.559, "duration": 3.06}, {"text": "anybody's curious abouts or has", "start": 3950.7, "duration": 4.2}, {"text": "additional questions you can always um", "start": 3952.619, "duration": 5.46}, {"text": "shoot me an email if you want if you", "start": 3954.9, "duration": 5.58}, {"text": "have problems on comments", "start": 3958.079, "duration": 3.72}, {"text": "um", "start": 3960.48, "duration": 3.24}, {"text": "I would ask you to go through the exceed", "start": 3961.799, "duration": 3.78}, {"text": "ticketing system but uh if you have", "start": 3963.72, "duration": 3.72}, {"text": "specific things about this talk", "start": 3965.579, "duration": 3.78}, {"text": "um with Rapids and", "start": 3967.44, "duration": 4.02}, {"text": "or the notebook to even just email me", "start": 3969.359, "duration": 3.601}, {"text": "directly you can find my email on the", "start": 3971.46, "duration": 5.06}, {"text": "sdsc directory", "start": 3972.96, "duration": 3.56}, {"text": "one question you just used one V100 card", "start": 3977.64, "duration": 6.719}, {"text": "yeah so that's what I did here so the", "start": 3981.299, "duration": 5.701}, {"text": "notebook is set up for", "start": 3984.359, "duration": 5.46}, {"text": "um uh where is the chat sorry I'm trying", "start": 3987.0, "duration": 4.02}, {"text": "to open the chat so I can see the", "start": 3989.819, "duration": 2.52}, {"text": "questions", "start": 3991.02, "duration": 3.42}, {"text": "oh there it is", "start": 3992.339, "duration": 3.661}, {"text": "um yeah so", "start": 3994.44, "duration": 5.7}, {"text": "The Notebook is set up only to do", "start": 3996.0, "duration": 7.98}, {"text": "um single GPU at this time", "start": 4000.14, "duration": 4.86}, {"text": "um", "start": 4003.98, "duration": 4.079}, {"text": "so to do to do the multi-gpu", "start": 4005.0, "duration": 5.819}, {"text": "um things with cudif and qml and could", "start": 4008.059, "duration": 4.98}, {"text": "graph you have to use sort of the task", "start": 4010.819, "duration": 3.421}, {"text": "integration", "start": 4013.039, "duration": 3.181}, {"text": "um and since I'm still new to desk", "start": 4014.24, "duration": 4.5}, {"text": "myself I was only able to sort of use", "start": 4016.22, "duration": 5.879}, {"text": "plain desk just for the to read into", "start": 4018.74, "duration": 4.68}, {"text": "um", "start": 4022.099, "duration": 3.361}, {"text": "the dash data frame and transfer it into", "start": 4023.42, "duration": 4.86}, {"text": "a pandas data frame just to get the data", "start": 4025.46, "duration": 5.099}, {"text": "set in quickly to do multi-gp you really", "start": 4028.28, "duration": 4.44}, {"text": "have to do Straight you have to do the", "start": 4030.559, "duration": 4.8}, {"text": "task Cuda", "start": 4032.72, "duration": 3.26}, {"text": "um", "start": 4035.359, "duration": 3.48}, {"text": "is is the module you'd load in your", "start": 4035.98, "duration": 5.68}, {"text": "python script so there is support to do", "start": 4038.839, "duration": 4.681}, {"text": "the multi-gpu but yeah it's not done", "start": 4041.66, "duration": 5.459}, {"text": "here yet in the uh in The Notebook", "start": 4043.52, "duration": 8.4}, {"text": "um so one comment here is well uh in", "start": 4047.119, "duration": 8.101}, {"text": "terms of desk and cudia so in the", "start": 4051.92, "duration": 5.58}, {"text": "notebook I did go through and I read", "start": 4055.22, "duration": 4.74}, {"text": "into pandas first and so I do want to", "start": 4057.5, "duration": 4.079}, {"text": "point out again that you can read", "start": 4059.96, "duration": 5.52}, {"text": "directly in from disk to the GPU through", "start": 4061.579, "duration": 7.881}, {"text": "say cudif and with Basque", "start": 4065.48, "duration": 7.619}, {"text": "integration with qdf as well I just", "start": 4069.46, "duration": 6.82}, {"text": "really had trouble with", "start": 4073.099, "duration": 7.02}, {"text": "keeping or enforcing the", "start": 4076.28, "duration": 5.519}, {"text": "um the data types on the different", "start": 4080.119, "duration": 3.901}, {"text": "columns so that that's the main reason I", "start": 4081.799, "duration": 3.54}, {"text": "did", "start": 4084.02, "duration": 3.66}, {"text": "um I did it this way sort of preload", "start": 4085.339, "duration": 4.98}, {"text": "everything into pandas through desks and", "start": 4087.68, "duration": 6.0}, {"text": "then shove it over to the single GPU so", "start": 4090.319, "duration": 7.321}, {"text": "how you how how would I actually do this", "start": 4093.68, "duration": 7.579}, {"text": "for a multi-gpu", "start": 4097.64, "duration": 6.42}, {"text": "example I don't know yet I guess because", "start": 4101.259, "duration": 5.861}, {"text": "I still need those data types to be", "start": 4104.06, "duration": 5.639}, {"text": "properly defined once they're on GPU and", "start": 4107.12, "duration": 4.079}, {"text": "I just don't know the workflow yet of", "start": 4109.699, "duration": 4.741}, {"text": "how to use desk on the GPU to make sure", "start": 4111.199, "duration": 5.341}, {"text": "it gets transferred over properly across", "start": 4114.44, "duration": 3.419}, {"text": "multiple GPS", "start": 4116.54, "duration": 2.94}, {"text": "so that's sort of like one thing on my", "start": 4117.859, "duration": 2.82}, {"text": "list of things to do before I get this", "start": 4119.48, "duration": 3.56}, {"text": "talk again", "start": 4120.679, "duration": 2.361}, {"text": "all right", "start": 4126.62, "duration": 3.109}, {"text": "if there's any other questions", "start": 4127.819, "duration": 2.4}, {"text": "[Music]", "start": 4129.729, "duration": 2.49}, {"text": "um", "start": 4130.219, "duration": 2.0}, {"text": "let us know", "start": 4133.4, "duration": 2.959}, {"text": "if not thank you", "start": 4136.58, "duration": 3.259}]