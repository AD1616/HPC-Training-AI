[{"text": "when okay all right thank you Susan um", "start": 4.4, "duration": 6.359}, {"text": "yeah welcome everybody to uh the session", "start": 7.919, "duration": 4.281}, {"text": "my name is Andy gz I'm a research", "start": 10.759, "duration": 3.361}, {"text": "scientist at San Diego supercomputer", "start": 12.2, "duration": 4.6}, {"text": "Center I'm a computational chemist by", "start": 14.12, "duration": 5.52}, {"text": "training and we have computationally", "start": 16.8, "duration": 5.479}, {"text": "intensive codes um that we've been", "start": 19.64, "duration": 4.479}, {"text": "porting to gpus in order to take", "start": 22.279, "duration": 4.801}, {"text": "advantage of GPU um performance and and", "start": 24.119, "duration": 4.681}, {"text": "computational power and so I'm going to", "start": 27.08, "duration": 3.519}, {"text": "talk a little bit about that", "start": 28.8, "duration": 4.279}, {"text": "trying to give you a brief", "start": 30.599, "duration": 6.8}, {"text": "overview um here looking at", "start": 33.079, "duration": 7.281}, {"text": "the uh topics that we're going to cover", "start": 37.399, "duration": 4.281}, {"text": "um starting with a little bit about", "start": 40.36, "duration": 3.44}, {"text": "Hardware overview", "start": 41.68, "duration": 6.0}, {"text": "background uh just a few um accelerated", "start": 43.8, "duration": 6.56}, {"text": "software examples um based on the codes", "start": 47.68, "duration": 5.0}, {"text": "that I've been developing um and then I", "start": 50.36, "duration": 5.16}, {"text": "will go into programming gpus um", "start": 52.68, "duration": 4.719}, {"text": "focusing on Nvidia gpus those are the", "start": 55.52, "duration": 3.999}, {"text": "gpus that we have here in expans at the", "start": 57.399, "duration": 4.96}, {"text": "San Diego superc computer center um I'll", "start": 59.519, "duration": 4.6}, {"text": "talk about GPU enabled", "start": 62.359, "duration": 4.44}, {"text": "libraries and give you a really a brief", "start": 64.119, "duration": 5.881}, {"text": "introduction to QC programming Basics um", "start": 66.799, "duration": 4.721}, {"text": "in these slides I have much more", "start": 70.0, "duration": 4.6}, {"text": "material than I'm going to be able to go", "start": 71.52, "duration": 5.04}, {"text": "through with you but I decided to leave", "start": 74.6, "duration": 5.159}, {"text": "this in so we have this as a reference", "start": 76.56, "duration": 6.0}, {"text": "um and we'll skip over that and and and", "start": 79.759, "duration": 4.481}, {"text": "and you'll see that so there are also", "start": 82.56, "duration": 4.28}, {"text": "some code examples that I have um for", "start": 84.24, "duration": 5.839}, {"text": "some of those um sections that we just", "start": 86.84, "duration": 6.8}, {"text": "going to gloss over and after this um", "start": 90.079, "duration": 6.08}, {"text": "we'll have a break so let me think about", "start": 93.64, "duration": 5.96}, {"text": "this it's 10 if we make a halftime break", "start": 96.159, "duration": 4.561}, {"text": "that would", "start": 99.6, "duration": 3.0}, {"text": "be", "start": 100.72, "duration": 6.48}, {"text": "um about let's see so until", "start": 102.6, "duration": 4.6}, {"text": "130 1115 or something like that no no no", "start": 107.64, "duration": 7.92}, {"text": "wait it's 10:45 around noon or so we", "start": 112.119, "duration": 5.28}, {"text": "should try to get get a little bit of a", "start": 115.56, "duration": 4.36}, {"text": "of a break let's see how far we get um", "start": 117.399, "duration": 5.561}, {"text": "until then and then we'll access um GPU", "start": 119.92, "duration": 8.08}, {"text": "notes um so the slides and as well the", "start": 122.96, "duration": 6.84}, {"text": "source code we're going to use and look", "start": 128.0, "duration": 3.56}, {"text": "at and information on how to log in and", "start": 129.8, "duration": 4.64}, {"text": "so on is in the GitHub repository so if", "start": 131.56, "duration": 4.48}, {"text": "you will pull that up I'll show that", "start": 134.44, "duration": 3.72}, {"text": "later to you but there is in the read me", "start": 136.04, "duration": 4.199}, {"text": "there's instructions on that that you", "start": 138.16, "duration": 3.56}, {"text": "can literally go through and that you", "start": 140.239, "duration": 3.961}, {"text": "can follow to do some Hands-On exercises", "start": 141.72, "duration": 5.96}, {"text": "on expans with cuter code compile it", "start": 144.2, "duration": 6.08}, {"text": "yourself and run it and then we'll talk", "start": 147.68, "duration": 5.08}, {"text": "about open ACC and do some Hands-On", "start": 150.28, "duration": 6.64}, {"text": "exercises uh again with open ACC and", "start": 152.76, "duration": 7.32}, {"text": "hopefully um I can spit this all in", "start": 156.92, "duration": 6.12}, {"text": "until 1:30 p.m. all right so with that", "start": 160.08, "duration": 5.68}, {"text": "said let's start with a GPU Hardware", "start": 163.04, "duration": 5.919}, {"text": "overview and I like to start with very", "start": 165.76, "duration": 6.04}, {"text": "Basics um you know GPU basically if you", "start": 168.959, "duration": 4.121}, {"text": "ask what is what is it it's an", "start": 171.8, "duration": 2.88}, {"text": "accelerator specialized Hardware", "start": 173.08, "duration": 4.079}, {"text": "component to speed up some aspect of a", "start": 174.68, "duration": 6.08}, {"text": "Computing workload and not unlike some", "start": 177.159, "duration": 5.521}, {"text": "other co-processors um that you would", "start": 180.76, "duration": 3.88}, {"text": "find in older PCS or also Modern", "start": 182.68, "duration": 4.119}, {"text": "Hardware um for instance you know to", "start": 184.64, "duration": 3.879}, {"text": "speed up floating Point operations or", "start": 186.799, "duration": 3.401}, {"text": "nowadays you have fpgas or you have", "start": 188.519, "duration": 3.36}, {"text": "dedicated processors you know for all", "start": 190.2, "duration": 4.16}, {"text": "sorts of operations um in the last few", "start": 191.879, "duration": 5.241}, {"text": "years in particular for machine learning", "start": 194.36, "duration": 3.599}, {"text": "uh", "start": 197.12, "duration": 4.0}, {"text": "applications um so this was really", "start": 197.959, "duration": 5.321}, {"text": "developed for computer Graphics which is", "start": 201.12, "duration": 5.88}, {"text": "um been driven by a huge huge um gaming", "start": 203.28, "duration": 6.599}, {"text": "industry um so a lot of money went into", "start": 207.0, "duration": 4.159}, {"text": "mment of this Hardware that's why it's", "start": 209.879, "duration": 4.161}, {"text": "so powerful uh today um originally had", "start": 211.159, "duration": 4.64}, {"text": "only fixed function pipelines and then", "start": 214.04, "duration": 4.52}, {"text": "about like 15 years ago or so um you", "start": 215.799, "duration": 5.481}, {"text": "know you know um Frameworks were", "start": 218.56, "duration": 4.28}, {"text": "developed and the hardware was changed", "start": 221.28, "duration": 3.44}, {"text": "in such a way that you can actually", "start": 222.84, "duration": 3.8}, {"text": "program these pasts with a general", "start": 224.72, "duration": 4.879}, {"text": "purpose um Pro programming languages", "start": 226.64, "duration": 4.959}, {"text": "with some extensions um that's basically", "start": 229.599, "duration": 3.161}, {"text": "pter for", "start": 231.599, "duration": 3.441}, {"text": "cc++ uh and now there are other ways as", "start": 232.76, "duration": 5.52}, {"text": "well um so really accessible for general", "start": 235.04, "duration": 5.68}, {"text": "purpose computations um some limitations", "start": 238.28, "duration": 4.0}, {"text": "because of the simplified core design", "start": 240.72, "duration": 3.799}, {"text": "that they have in in in comparison to a", "start": 242.28, "duration": 7.08}, {"text": "CPU so you know Branch caches not not as", "start": 244.519, "duration": 6.36}, {"text": "big and so on partially exposed memory", "start": 249.36, "duration": 3.04}, {"text": "hierarchy and of course the parallelism", "start": 250.879, "duration": 3.2}, {"text": "that you really have to take into", "start": 252.4, "duration": 5.0}, {"text": "account um now the question is why is", "start": 254.079, "duration": 4.961}, {"text": "there a big interest in gpus so if you", "start": 257.4, "duration": 3.399}, {"text": "look at you know all the big", "start": 259.04, "duration": 3.879}, {"text": "supercomputers basically everybody has", "start": 260.799, "duration": 4.641}, {"text": "nodes with gpus in them the big exess", "start": 262.919, "duration": 4.201}, {"text": "scale computers by Doe the biggest", "start": 265.44, "duration": 4.52}, {"text": "machines they all are get get you know", "start": 267.12, "duration": 4.519}, {"text": "the majority of the raw compute power", "start": 269.96, "duration": 6.32}, {"text": "from gpus um used to be all Nvidia and", "start": 271.639, "duration": 8.0}, {"text": "now there's Nvidia there's a AMD um at", "start": 276.28, "duration": 4.6}, {"text": "argon there's going to be a machine", "start": 279.639, "duration": 3.081}, {"text": "that's going to have Intel gpus actually", "start": 280.88, "duration": 6.0}, {"text": "so Intel is also getting into the game", "start": 282.72, "duration": 6.6}, {"text": "and if we look at M's law if you're", "start": 286.88, "duration": 3.84}, {"text": "familiar with that it's basically the", "start": 289.32, "duration": 3.159}, {"text": "transistor count in integrated circuits", "start": 290.72, "duration": 4.08}, {"text": "doubles about every two years so that's", "start": 292.479, "duration": 4.44}, {"text": "an exponential growth right and that", "start": 294.8, "duration": 4.2}, {"text": "still holds so if you look at that that", "start": 296.919, "duration": 4.28}, {"text": "plot here it's not completely up to date", "start": 299.0, "duration": 3.88}, {"text": "but", "start": 301.199, "duration": 4.84}, {"text": "um what what you see on here still holds", "start": 302.88, "duration": 5.4}, {"text": "um effectively so the number of", "start": 306.039, "duration": 5.561}, {"text": "transistors um is is still growing", "start": 308.28, "duration": 5.479}, {"text": "exponentially um however if you look at", "start": 311.6, "duration": 3.36}, {"text": "what happened about here in the mid", "start": 313.759, "duration": 4.481}, {"text": "2000s is um several things you know", "start": 314.96, "duration": 5.239}, {"text": "first of all the clock frequency um", "start": 318.24, "duration": 3.76}, {"text": "wasn't increased anymore so if you if", "start": 320.199, "duration": 4.72}, {"text": "you're a little bit older like myself um", "start": 322.0, "duration": 5.88}, {"text": "you know you remember megaherz 100 mahz", "start": 324.919, "duration": 4.601}, {"text": "processors and then at some point gahz", "start": 327.88, "duration": 3.28}, {"text": "processors and that's why we stuck so", "start": 329.52, "duration": 3.959}, {"text": "you can't really up the clock", "start": 331.16, "duration": 6.84}, {"text": "frequency um so", "start": 333.479, "duration": 7.361}, {"text": "um the the the single threat performance", "start": 338.0, "duration": 4.44}, {"text": "is slightly increasing because you know", "start": 340.84, "duration": 3.04}, {"text": "there's still Innovations happening but", "start": 342.44, "duration": 3.479}, {"text": "it's basically leveling as off as well", "start": 343.88, "duration": 3.4}, {"text": "that means you know serial code just", "start": 345.919, "duration": 3.081}, {"text": "doesn't run faster anymore just because", "start": 347.28, "duration": 3.759}, {"text": "you wait for a new generation of a", "start": 349.0, "duration": 4.759}, {"text": "processor at least not much um so what", "start": 351.039, "duration": 6.44}, {"text": "instead happened is you know um was that", "start": 353.759, "duration": 5.44}, {"text": "we went into this multicore regime so", "start": 357.479, "duration": 3.041}, {"text": "now we we have all these multicore", "start": 359.199, "duration": 3.161}, {"text": "processors and if you look at sdsd", "start": 360.52, "duration": 5.119}, {"text": "expans you know we have um two AMD CPUs", "start": 362.36, "duration": 5.76}, {"text": "in there each CPU has 64 cor so total", "start": 365.639, "duration": 5.481}, {"text": "128 cores in a single compute note right", "start": 368.12, "duration": 6.12}, {"text": "and um so the number of logical core", "start": 371.12, "duration": 6.0}, {"text": "increases and so what you have to do is", "start": 374.24, "duration": 5.16}, {"text": "you must write parallel code and gpus", "start": 377.12, "duration": 3.84}, {"text": "take this in some sense to an extreme", "start": 379.4, "duration": 3.16}, {"text": "because you have thousands of um", "start": 380.96, "duration": 4.639}, {"text": "processing units um compute course", "start": 382.56, "duration": 6.639}, {"text": "equivalence effectively on each GPU um", "start": 385.599, "duration": 6.201}, {"text": "and you need to be able to program that", "start": 389.199, "duration": 4.961}, {"text": "um if you're able to do that now what", "start": 391.8, "duration": 4.04}, {"text": "you see here on the left and on the", "start": 394.16, "duration": 6.0}, {"text": "right is um the peak floating Point", "start": 395.84, "duration": 6.96}, {"text": "performance of gpus those are older gpus", "start": 400.16, "duration": 4.68}, {"text": "so um I've taken this from this website", "start": 402.8, "duration": 5.04}, {"text": "here that not been updated recently but", "start": 404.84, "duration": 6.72}, {"text": "the those Trends are still valid as well", "start": 407.84, "duration": 6.799}, {"text": "and the left is um single Precision so", "start": 411.56, "duration": 4.88}, {"text": "32 bit floating Point numbers and here", "start": 414.639, "duration": 3.761}, {"text": "double Precision 64 bit floating Point", "start": 416.44, "duration": 4.52}, {"text": "numbers and what you can see is of", "start": 418.4, "duration": 3.68}, {"text": "course the floating Point performance", "start": 420.96, "duration": 4.28}, {"text": "has been increasing for CPUs um but gpus", "start": 422.08, "duration": 5.28}, {"text": "have you know orders of magnitude larger", "start": 425.24, "duration": 3.799}, {"text": "floating Point performance so if you do", "start": 427.36, "duration": 3.92}, {"text": "number crunching um you can do and you", "start": 429.039, "duration": 4.241}, {"text": "can parallelize it efficiently um you", "start": 431.28, "duration": 4.44}, {"text": "can do that quite effectively on on", "start": 433.28, "duration": 4.68}, {"text": "Modern gpus so you get a lot of uh", "start": 435.72, "duration": 4.72}, {"text": "compute power here right so we here in", "start": 437.96, "duration": 6.44}, {"text": "the tens of teraflops uh", "start": 440.44, "duration": 6.56}, {"text": "regime um one thing to keep in mind is", "start": 444.4, "duration": 4.44}, {"text": "you know on the left you see these are", "start": 447.0, "duration": 5.599}, {"text": "all like consumer gaming type gpus um", "start": 448.84, "duration": 6.32}, {"text": "and you won't see them on here because", "start": 452.599, "duration": 4.561}, {"text": "uh they", "start": 455.16, "duration": 4.479}, {"text": "typically are handicapped in some sense", "start": 457.16, "duration": 4.64}, {"text": "you know the chips are manufactured in", "start": 459.639, "duration": 4.161}, {"text": "such a way that they can't do the same", "start": 461.8, "duration": 3.92}, {"text": "even if it's the same type of processor", "start": 463.8, "duration": 4.88}, {"text": "the same generation in architecture um", "start": 465.72, "duration": 5.36}, {"text": "they will not have the same double", "start": 468.68, "duration": 4.799}, {"text": "Precision so fp64 floating Point perform", "start": 471.08, "duration": 3.76}, {"text": "so if that's important for your codes", "start": 473.479, "duration": 2.801}, {"text": "it's important to get this data center", "start": 474.84, "duration": 3.799}, {"text": "gpus so these are the really expensive", "start": 476.28, "duration": 4.16}, {"text": "data center GP use of the tpe that we", "start": 478.639, "duration": 4.84}, {"text": "have at stfc so this is a Tesla p100 an", "start": 480.44, "duration": 5.159}, {"text": "accelerator that was in Comet the", "start": 483.479, "duration": 4.601}, {"text": "prevor expans and expounds basically", "start": 485.599, "duration": 5.921}, {"text": "somewhere up here is you know the wter", "start": 488.08, "duration": 5.28}, {"text": "architectures", "start": 491.52, "duration": 4.32}, {"text": "um another thing that's very important", "start": 493.36, "duration": 7.0}, {"text": "is look at the left graph here um is the", "start": 495.84, "duration": 10.319}, {"text": "memory bandwidth so many codes nowadays", "start": 500.36, "duration": 8.36}, {"text": "um because we have such a high floating", "start": 506.159, "duration": 4.401}, {"text": "Point performance the memory bandit has", "start": 508.72, "duration": 4.679}, {"text": "not been keeping up with um so meaning", "start": 510.56, "duration": 5.279}, {"text": "how much data you can move in a given", "start": 513.399, "duration": 6.481}, {"text": "amount of time um from memory from the", "start": 515.839, "duration": 7.281}, {"text": "ram to the processor in back right and", "start": 519.88, "duration": 4.92}, {"text": "that is very important because if you", "start": 523.12, "duration": 3.48}, {"text": "don't have the data on the processor to", "start": 524.8, "duration": 4.0}, {"text": "do the computations you know the", "start": 526.6, "duration": 3.64}, {"text": "processor is just sitting there idle not", "start": 528.8, "duration": 5.12}, {"text": "doing anything and many uh algorithms", "start": 530.24, "duration": 5.719}, {"text": "and you know problems are memory band", "start": 533.92, "duration": 3.479}, {"text": "that's limited so you actually don't use", "start": 535.959, "duration": 2.88}, {"text": "the full floating Point performance it's", "start": 537.399, "duration": 2.921}, {"text": "hard to get the full floating Point", "start": 538.839, "duration": 4.0}, {"text": "performance um out of a GPU unless you", "start": 540.32, "duration": 6.84}, {"text": "have a problem that really uh is is is", "start": 542.839, "duration": 5.961}, {"text": "ideally amable like you know dense", "start": 547.16, "duration": 4.359}, {"text": "linear algebra typ you can get very high", "start": 548.8, "duration": 5.68}, {"text": "um um Peak floating close to the peak", "start": 551.519, "duration": 5.0}, {"text": "floating Point performance in any case", "start": 554.48, "duration": 4.32}, {"text": "what you see is that", "start": 556.519, "duration": 5.641}, {"text": "um uh gpus have a very high altitude of", "start": 558.8, "duration": 5.12}, {"text": "memory they're employing and the the", "start": 562.16, "duration": 3.56}, {"text": "memory bus and so on the architectures", "start": 563.92, "duration": 4.2}, {"text": "they have a much higher floating U", "start": 565.72, "duration": 5.559}, {"text": "memory B bandwidth than CPUs and so", "start": 568.12, "duration": 5.159}, {"text": "that's a significant Advantage is", "start": 571.279, "duration": 4.361}, {"text": "then and then you need to look at the", "start": 573.279, "duration": 3.161}, {"text": "power", "start": 575.64, "duration": 3.72}, {"text": "consumption um modern gpus can draw a", "start": 576.44, "duration": 5.68}, {"text": "significant amount of power um so some", "start": 579.36, "duration": 5.24}, {"text": "of the gpus you know are up at 300 I", "start": 582.12, "duration": 6.76}, {"text": "think I think the v100s in in expanse", "start": 584.6, "duration": 6.84}, {"text": "they can draw up to 350 watch and you", "start": 588.88, "duration": 6.04}, {"text": "know GP CPU typically draws around 150", "start": 591.44, "duration": 5.92}, {"text": "water 200 so it depends so you consume", "start": 594.92, "duration": 4.039}, {"text": "more power so you need to take that into", "start": 597.36, "duration": 3.12}, {"text": "account to be fair you know to have a", "start": 598.959, "duration": 4.041}, {"text": "comparison about uh running costs", "start": 600.48, "duration": 5.039}, {"text": "operation costs right", "start": 603.0, "duration": 5.36}, {"text": "um and so here's a summary that was from", "start": 605.519, "duration": 5.281}, {"text": "2018 that's basically state-of-the-art", "start": 608.36, "duration": 5.599}, {"text": "when you know Comet was um about to be", "start": 610.8, "duration": 5.12}, {"text": "installed so these were state-ofthe-art", "start": 613.959, "duration": 6.44}, {"text": "U sorry expans um state-ofthe-art CPUs", "start": 615.92, "duration": 7.64}, {"text": "back then uh from Intel um they have a", "start": 620.399, "duration": 5.241}, {"text": "lower core count than AMD", "start": 623.56, "duration": 4.2}, {"text": "equivalent um but in any case you know", "start": 625.64, "duration": 4.04}, {"text": "56 course per node and here you'd have", "start": 627.76, "duration": 5.12}, {"text": "you know the Tesla v00 accelerators so", "start": 629.68, "duration": 6.2}, {"text": "GPU that sticks into PCI Express Bus on", "start": 632.88, "duration": 7.519}, {"text": "on on on the on the server and a", "start": 635.88, "duration": 7.28}, {"text": "comparison of the peak uh floating Point", "start": 640.399, "duration": 4.041}, {"text": "performance that you can get so these", "start": 643.16, "duration": 3.2}, {"text": "numbers are approximate because you know", "start": 644.44, "duration": 3.56}, {"text": "it's hard to really", "start": 646.36, "duration": 5.56}, {"text": "measure um what what what consist you", "start": 648.0, "duration": 6.76}, {"text": "know Peak roading Point performance um", "start": 651.92, "duration": 4.28}, {"text": "depends on the operations that you do", "start": 654.76, "duration": 2.96}, {"text": "and so on but you can see that you know", "start": 656.2, "duration": 5.12}, {"text": "you get much more out of uh the gpus for", "start": 657.72, "duration": 6.239}, {"text": "the same amount of uh dollars that you", "start": 661.32, "duration": 6.24}, {"text": "spend and for a comparable sort of like", "start": 663.959, "duration": 5.641}, {"text": "um power consumption a little bit more", "start": 667.56, "duration": 4.839}, {"text": "right so to be fair there's one more and", "start": 669.6, "duration": 4.2}, {"text": "and the memory bandwidth of course is", "start": 672.399, "duration": 5.201}, {"text": "very very very high um this is half", "start": 673.8, "duration": 6.44}, {"text": "Precision so gpus actually Support also", "start": 677.6, "duration": 4.44}, {"text": "you know different types of precision", "start": 680.24, "duration": 4.32}, {"text": "model models um that have been developed", "start": 682.04, "duration": 3.919}, {"text": "in particular for deep learning", "start": 684.56, "duration": 3.6}, {"text": "applications so that's important that", "start": 685.959, "duration": 4.601}, {"text": "often you don't have the CPUs and you", "start": 688.16, "duration": 4.16}, {"text": "see the the memory band with so it's", "start": 690.56, "duration": 4.36}, {"text": "much much higher on the gpus right", "start": 692.32, "duration": 5.079}, {"text": "almost a factor of 10 in this case U", "start": 694.92, "duration": 3.8}, {"text": "there's another thing though of course", "start": 697.399, "duration": 2.841}, {"text": "because these guys are actually sitting", "start": 698.72, "duration": 4.6}, {"text": "on a PCI Express bus um and and we'll", "start": 700.24, "duration": 5.279}, {"text": "get back to that you know when you when", "start": 703.32, "duration": 5.16}, {"text": "you have data you load it into memory", "start": 705.519, "duration": 4.401}, {"text": "and that memory is the memory that's", "start": 708.48, "duration": 3.72}, {"text": "attached to the CPU and then you have to", "start": 709.92, "duration": 4.12}, {"text": "send it to the GPU to do some processing", "start": 712.2, "duration": 4.36}, {"text": "on the GPU so if you have to move a lot", "start": 714.04, "duration": 4.08}, {"text": "of data forth and back to the GPU that's", "start": 716.56, "duration": 3.279}, {"text": "a bottleneck because because the PCI", "start": 718.12, "duration": 5.68}, {"text": "Express bus is just much slower right um", "start": 719.839, "duration": 6.161}, {"text": "and then the question is you know you", "start": 723.8, "duration": 3.8}, {"text": "write code you want that the code still", "start": 726.0, "duration": 4.519}, {"text": "works next year on the on you know maybe", "start": 727.6, "duration": 4.64}, {"text": "a different vendor and so on and the", "start": 730.519, "duration": 4.041}, {"text": "question is is the code portable and I", "start": 732.24, "duration": 4.599}, {"text": "would say that nowadays also GPU code is", "start": 734.56, "duration": 5.24}, {"text": "portable um Cuda is really specific", "start": 736.839, "duration": 6.281}, {"text": "for um Nidia gpus but you have other you", "start": 739.8, "duration": 5.92}, {"text": "know these are so open Cale first of all", "start": 743.12, "duration": 6.399}, {"text": "you know is is works on on any type um", "start": 745.72, "duration": 6.96}, {"text": "of architectures also for you know CPUs", "start": 749.519, "duration": 6.481}, {"text": "Arm based systems and so on um and then", "start": 752.68, "duration": 8.24}, {"text": "uh pragma based um um methods like like", "start": 756.0, "duration": 8.68}, {"text": "open ACC and and open MP um they can be", "start": 760.92, "duration": 6.32}, {"text": "used to upload um B to gpus we'll look", "start": 764.68, "duration": 6.2}, {"text": "at open ACC later uh Cuda is in some", "start": 767.24, "duration": 5.8}, {"text": "sense was not portable but nowadays", "start": 770.88, "duration": 3.88}, {"text": "there are code translators that you can", "start": 773.04, "duration": 3.919}, {"text": "use to translate the code to um", "start": 774.76, "duration": 3.84}, {"text": "different Frameworks because Kudo runs", "start": 776.959, "duration": 5.641}, {"text": "on on on video", "start": 778.6, "duration": 4.0}, {"text": "gpus then right so been talking about", "start": 783.56, "duration": 4.719}, {"text": "the performance and just to put this a", "start": 786.519, "duration": 3.641}, {"text": "little bit in perspective I like to do", "start": 788.279, "duration": 4.8}, {"text": "this um this is now already over 20", "start": 790.16, "duration": 7.0}, {"text": "years ago but uh that was the um asky V", "start": 793.079, "duration": 6.401}, {"text": "supercomputer at Lawrence Livermore lab", "start": 797.16, "duration": 4.32}, {"text": "that had a peak floating performance", "start": 799.48, "duration": 4.599}, {"text": "floating Point performance of 12 terlop", "start": 801.48, "duration": 4.08}, {"text": "that was the number one the fastest", "start": 804.079, "duration": 4.32}, {"text": "superc computer in the world right then", "start": 805.56, "duration": 5.6}, {"text": "it C $10 million us it fill an entire", "start": 808.399, "duration": 6.68}, {"text": "Data Center and if you compare this to", "start": 811.16, "duration": 7.08}, {"text": "expans um so you know we have the CPU", "start": 815.079, "duration": 4.721}, {"text": "noes", "start": 818.24, "duration": 3.839}, {"text": "and", "start": 819.8, "duration": 5.279}, {"text": "um we have an aggregate so let me I", "start": 822.079, "duration": 4.44}, {"text": "think I don't want to get this wrong so", "start": 825.079, "duration": 4.081}, {"text": "each each each node gets already 4.6 ter", "start": 826.519, "duration": 5.44}, {"text": "flops on floating P performance but then", "start": 829.16, "duration": 4.76}, {"text": "adding the gpus we don't have that many", "start": 831.959, "duration": 4.041}, {"text": "GPU nodes I think there's another rack", "start": 833.92, "duration": 5.12}, {"text": "now that's uh available that has been", "start": 836.0, "duration": 4.44}, {"text": "installed a short while ago so these", "start": 839.04, "duration": 4.239}, {"text": "numbers might not be exact about the", "start": 840.44, "duration": 6.0}, {"text": "total um compute power but so we from", "start": 843.279, "duration": 5.641}, {"text": "those rews alone we also get us 1.6 ped", "start": 846.44, "duration": 5.36}, {"text": "flops right um so that's you", "start": 848.92, "duration": 6.64}, {"text": "know um three orders of magnitude fast", "start": 851.8, "duration": 5.399}, {"text": "right so that that's super powerful if", "start": 855.56, "duration": 3.199}, {"text": "you think about it and the whole", "start": 857.199, "duration": 3.0}, {"text": "Hardware cost here was just about10", "start": 858.759, "duration": 4.041}, {"text": "million us right and and and that that", "start": 860.199, "duration": 6.841}, {"text": "was 2001 right so 110 us million US", "start": 862.8, "duration": 6.52}, {"text": "Dollars nowadays um", "start": 867.04, "duration": 4.88}, {"text": "would be much less back then so much", "start": 869.32, "duration": 4.04}, {"text": "cheaper much more compute power", "start": 871.92, "duration": 2.96}, {"text": "obviously and you know you can build", "start": 873.36, "duration": 3.44}, {"text": "your own box that's basically a super", "start": 874.88, "duration": 3.56}, {"text": "computer compared to what we had 20", "start": 876.8, "duration": 4.399}, {"text": "years ago um so these are the Nvidia", "start": 878.44, "duration": 4.68}, {"text": "gaming gpus", "start": 881.199, "duration": 4.921}, {"text": "and um the double Precision performance", "start": 883.12, "duration": 4.639}, {"text": "like I told you is not that great but", "start": 886.12, "duration": 4.48}, {"text": "still you know it's 10% of the entire uh", "start": 887.759, "duration": 4.361}, {"text": "machine here but if you can get away", "start": 890.6, "duration": 3.479}, {"text": "with a single Precision is you know you", "start": 892.12, "duration": 4.88}, {"text": "have 4 gpus you spend about $4,000 maybe", "start": 894.079, "duration": 4.281}, {"text": "a little bit more for all the you know", "start": 897.0, "duration": 3.839}, {"text": "mother and so on but let's say you have", "start": 898.36, "duration": 4.68}, {"text": "you know5 $6,000 you can build a machine", "start": 900.839, "duration": 5.641}, {"text": "that has 10 times the compute power of", "start": 903.04, "duration": 6.52}, {"text": "the fastest computer in the world and 20", "start": 906.48, "duration": 6.64}, {"text": "years ago so all you um scientists", "start": 909.56, "duration": 6.24}, {"text": "researchers you have a lot of compute", "start": 913.12, "duration": 4.6}, {"text": "power at your fingertips and so do", "start": 915.8, "duration": 5.36}, {"text": "something great with that", "start": 917.72, "duration": 3.44}, {"text": "um", "start": 921.36, "duration": 4.8}, {"text": "so we have all this compute power right", "start": 923.0, "duration": 4.56}, {"text": "so your manager comes to and says well", "start": 926.16, "duration": 2.599}, {"text": "our servers are using too much", "start": 927.56, "duration": 3.8}, {"text": "electricity we need to use gpus because", "start": 928.759, "duration": 4.52}, {"text": "you know then we need less gpus they're", "start": 931.36, "duration": 4.36}, {"text": "more powerful and he says I did my part", "start": 933.279, "duration": 5.881}, {"text": "by reading about gpus in a trade", "start": 935.72, "duration": 3.44}, {"text": "Journal hour later you can part taking", "start": 941.959, "duration": 5.0}, {"text": "so long so we need to Port our codes and", "start": 944.36, "duration": 5.719}, {"text": "that's not always trivial um sometimes", "start": 946.959, "duration": 6.481}, {"text": "you get very very quickly um um very", "start": 950.079, "duration": 4.841}, {"text": "easy you can speed up your codes very", "start": 953.44, "duration": 3.319}, {"text": "quickly open ACC or just with python", "start": 954.92, "duration": 3.359}, {"text": "dropping in libraries and so on but you", "start": 956.759, "duration": 4.601}, {"text": "know if to rewrite your code using Cuda", "start": 958.279, "duration": 7.281}, {"text": "um that can be significant effort um and", "start": 961.36, "duration": 5.52}, {"text": "one thing you have to keep in mind if", "start": 965.56, "duration": 3.719}, {"text": "you think about the real estate that you", "start": 966.88, "duration": 5.0}, {"text": "have on the chip so the Silicon that is", "start": 969.279, "duration": 4.401}, {"text": "available you know on a CPU you have a", "start": 971.88, "duration": 4.439}, {"text": "lot of like uh um you know control", "start": 973.68, "duration": 6.079}, {"text": "hardware and caches for um you know", "start": 976.319, "duration": 5.161}, {"text": "prefetching Branch prediction and all", "start": 979.759, "duration": 4.121}, {"text": "sorts of stuff and then we have a few of", "start": 981.48, "duration": 4.839}, {"text": "the processing units arithmetic logical", "start": 983.88, "duration": 5.28}, {"text": "units right comparatively on GPU you", "start": 986.319, "duration": 4.841}, {"text": "have thousands of simplistic compute", "start": 989.16, "duration": 5.799}, {"text": "cores right and you have much less cach", "start": 991.16, "duration": 6.799}, {"text": "in control units um", "start": 994.959, "duration": 6.721}, {"text": "so these these GP the the GPU compute", "start": 997.959, "duration": 5.401}, {"text": "cores they operate in lock step so you", "start": 1001.68, "duration": 3.519}, {"text": "have to write code in such a way that", "start": 1003.36, "duration": 3.719}, {"text": "you know you can do the same operation", "start": 1005.199, "duration": 3.56}, {"text": "like like on a vector processor in a", "start": 1007.079, "duration": 3.601}, {"text": "vector units right Vector processing", "start": 1008.759, "duration": 4.2}, {"text": "units uh you do vectorized loads and", "start": 1010.68, "duration": 4.56}, {"text": "stores and and you need to think about", "start": 1012.959, "duration": 4.24}, {"text": "these things and you need partially to", "start": 1015.24, "duration": 3.76}, {"text": "manage the memory hierarchy so this this", "start": 1017.199, "duration": 4.161}, {"text": "has been gotten better um you don't have", "start": 1019.0, "duration": 4.56}, {"text": "to think about everything but you still", "start": 1021.36, "duration": 4.8}, {"text": "even some of the directive based", "start": 1023.56, "duration": 4.279}, {"text": "programming approaches if you don't know", "start": 1026.16, "duration": 3.399}, {"text": "how the underlying architecture works", "start": 1027.839, "duration": 2.72}, {"text": "you know", "start": 1029.559, "duration": 3.76}, {"text": "you it's not automatic that your code", "start": 1030.559, "duration": 5.161}, {"text": "runs will run very very efficiently on", "start": 1033.319, "duration": 7.441}, {"text": "the GPU so takes some work um then if we", "start": 1035.72, "duration": 8.8}, {"text": "look at the GPU architecture this is an", "start": 1040.76, "duration": 7.279}, {"text": "old old old Nvidia slide from 2008 right", "start": 1044.52, "duration": 5.399}, {"text": "and I just was an architecture that", "start": 1048.039, "duration": 5.441}, {"text": "actually was sold then in 2008 2009 um", "start": 1049.919, "duration": 6.201}, {"text": "this was the I believe the First Data", "start": 1053.48, "duration": 5.84}, {"text": "Center GPU server that was sold right um", "start": 1056.12, "duration": 5.48}, {"text": "and I'm showing this because the basics", "start": 1059.32, "duration": 4.92}, {"text": "of how our GPU processor looks like and", "start": 1061.6, "duration": 4.0}, {"text": "what you have to keep in your mind", "start": 1064.24, "duration": 4.16}, {"text": "doesn't didn't really change so back", "start": 1065.6, "duration": 6.4}, {"text": "then um basically what we have is we", "start": 1068.4, "duration": 6.88}, {"text": "have several of these called so-called", "start": 1072.0, "duration": 4.96}, {"text": "multiprocessors so you see them here", "start": 1075.28, "duration": 5.16}, {"text": "there one two three four five six seven", "start": 1076.96, "duration": 7.199}, {"text": "8 n 10 in this G SCH magic", "start": 1080.44, "duration": 6.4}, {"text": "here each of those multiprocessors so", "start": 1084.159, "duration": 6.4}, {"text": "think of those as different", "start": 1086.84, "duration": 7.6}, {"text": "um CPUs if you want so and that you have", "start": 1090.559, "duration": 5.921}, {"text": "like different sockets right sort", "start": 1094.44, "duration": 3.719}, {"text": "of", "start": 1096.48, "duration": 4.36}, {"text": "um and each of those has multiple", "start": 1098.159, "duration": 4.681}, {"text": "compute cores like s single precision", "start": 1100.84, "duration": 3.839}, {"text": "and double Precision compute units", "start": 1102.84, "duration": 6.68}, {"text": "special function units and so on so um", "start": 1104.679, "duration": 7.24}, {"text": "and its own you know cache and and", "start": 1109.52, "duration": 3.92}, {"text": "shared memory so the cach on this", "start": 1111.919, "duration": 3.281}, {"text": "processor doesn't know anything about", "start": 1113.44, "duration": 3.28}, {"text": "the cach in this processor right so", "start": 1115.2, "duration": 3.959}, {"text": "these are independent but all these", "start": 1116.72, "duration": 4.439}, {"text": "processes in here they they operate in", "start": 1119.159, "duration": 3.721}, {"text": "lock steps so you have to paral", "start": 1121.159, "duration": 4.281}, {"text": "parallelize the code to utilize all", "start": 1122.88, "duration": 3.799}, {"text": "those compute cores and all those", "start": 1125.44, "duration": 3.04}, {"text": "different multiprocessors and you have", "start": 1126.679, "duration": 4.961}, {"text": "to write the code in such a way that um", "start": 1128.48, "duration": 6.04}, {"text": "it it does the same operation in all of", "start": 1131.64, "duration": 5.56}, {"text": "those um um compute cores at the same", "start": 1134.52, "duration": 4.639}, {"text": "time right", "start": 1137.2, "duration": 4.16}, {"text": "um yeah so the other thing that to keep", "start": 1139.159, "duration": 5.561}, {"text": "in mind is that there is this um", "start": 1141.36, "duration": 6.559}, {"text": "multi-threading uh uh instruction issue", "start": 1144.72, "duration": 4.8}, {"text": "that handles many more threats and", "start": 1147.919, "duration": 4.081}, {"text": "processing course and um so when you", "start": 1149.52, "duration": 6.039}, {"text": "launch compter kernels soal kernels", "start": 1152.0, "duration": 5.679}, {"text": "those are the the compu units the", "start": 1155.559, "duration": 5.921}, {"text": "functions that do computation on the GPU", "start": 1157.679, "duration": 5.36}, {"text": "you want to launch them with many more", "start": 1161.48, "duration": 3.12}, {"text": "threats than you have actually compute", "start": 1163.039, "duration": 2.481}, {"text": "cores", "start": 1164.6, "duration": 4.48}, {"text": "available um and you know cter handles", "start": 1165.52, "duration": 5.12}, {"text": "that you know the GPU architecture", "start": 1169.08, "duration": 3.68}, {"text": "handles it automatically to schedule", "start": 1170.64, "duration": 4.039}, {"text": "them at the right point in time and that", "start": 1172.76, "duration": 4.32}, {"text": "helps uh mitigate memory band with", "start": 1174.679, "duration": 4.601}, {"text": "issues because you know while data is", "start": 1177.08, "duration": 3.16}, {"text": "being", "start": 1179.28, "duration": 4.44}, {"text": "requested um you know some other um", "start": 1180.24, "duration": 5.84}, {"text": "threats that you have launched may have", "start": 1183.72, "duration": 3.92}, {"text": "the data already and they can do some", "start": 1186.08, "duration": 2.8}, {"text": "compute while the other threats are", "start": 1187.64, "duration": 3.48}, {"text": "waiting and that that hasn't changed so", "start": 1188.88, "duration": 6.0}, {"text": "this is all still the same um there's", "start": 1191.12, "duration": 5.919}, {"text": "many more features now that that the", "start": 1194.88, "duration": 4.6}, {"text": "gpus have so", "start": 1197.039, "duration": 7.12}, {"text": "we have a tzor course for instance and", "start": 1199.48, "duration": 8.199}, {"text": "um they accelerate so-call like uh", "start": 1204.159, "duration": 6.161}, {"text": "matrix multiplication and accumulation", "start": 1207.679, "duration": 6.48}, {"text": "operations and they can do this for", "start": 1210.32, "duration": 6.239}, {"text": "fp64 um so different data types like", "start": 1214.159, "duration": 4.841}, {"text": "seef this tenser float um", "start": 1216.559, "duration": 6.881}, {"text": "32 B float 15 and", "start": 1219.0, "duration": 4.44}, {"text": "fp16 um so that's specialized Hardware", "start": 1223.679, "duration": 4.521}, {"text": "that basically does this sort of", "start": 1226.36, "duration": 3.559}, {"text": "operation right so you you you can do", "start": 1228.2, "duration": 4.88}, {"text": "something like also mixed um precisions", "start": 1229.919, "duration": 6.441}, {"text": "right where you have say 16 bit floats", "start": 1233.08, "duration": 5.2}, {"text": "where you do a matrix multiplication and", "start": 1236.36, "duration": 4.96}, {"text": "you add that into either 16 bit or 32bit", "start": 1238.28, "duration": 6.879}, {"text": "float um for accumulation uh uh results", "start": 1241.32, "duration": 5.239}, {"text": "output so that's schematically", "start": 1245.159, "duration": 2.841}, {"text": "represented here right so you have the", "start": 1246.559, "duration": 4.041}, {"text": "input of", "start": 1248.0, "duration": 2.6}, {"text": "the matrix multiplication and add that", "start": 1250.919, "duration": 3.88}, {"text": "onto your", "start": 1253.48, "duration": 3.12}, {"text": "corresponding", "start": 1254.799, "duration": 4.601}, {"text": "um um output Matrix and you know that", "start": 1256.6, "duration": 4.52}, {"text": "those are basically tensor operations", "start": 1259.4, "duration": 5.88}, {"text": "that uh are used in in in deep learning", "start": 1261.12, "duration": 5.84}, {"text": "neural networks right so that's why they", "start": 1265.28, "duration": 3.6}, {"text": "have been implemented specifically in", "start": 1266.96, "duration": 4.92}, {"text": "Hardware uh it runs extremely fast so if", "start": 1268.88, "duration": 5.679}, {"text": "you have these sorts of like um machine", "start": 1271.88, "duration": 5.799}, {"text": "learning deep learning applications", "start": 1274.559, "duration": 5.161}, {"text": "um um so you have like this fully", "start": 1277.679, "duration": 3.921}, {"text": "connected linear and dense layers", "start": 1279.72, "duration": 3.319}, {"text": "convolutional layers and the current", "start": 1281.6, "duration": 2.959}, {"text": "layers they all benefit from these", "start": 1283.039, "duration": 4.561}, {"text": "tensor cores um and you can use those", "start": 1284.559, "duration": 5.081}, {"text": "also for mix Precision Matrix operation", "start": 1287.6, "duration": 4.88}, {"text": "so there's a qast library that um", "start": 1289.64, "duration": 4.6}, {"text": "supports", "start": 1292.48, "duration": 3.92}, {"text": "that", "start": 1294.24, "duration": 4.72}, {"text": "then the hardware characteristics change", "start": 1296.4, "duration": 4.36}, {"text": "across GPU models and generations but in", "start": 1298.96, "duration": 4.76}, {"text": "some sense you know it's not different", "start": 1300.76, "duration": 6.519}, {"text": "than then using different gpus uh CPUs", "start": 1303.72, "duration": 6.199}, {"text": "right um so you write code that should", "start": 1307.279, "duration": 5.081}, {"text": "run independently on which generation of", "start": 1309.919, "duration": 4.12}, {"text": "GPU you use I mean it's not entirely", "start": 1312.36, "duration": 3.84}, {"text": "true you know instructions set", "start": 1314.039, "duration": 5.24}, {"text": "architectures change but um for you know", "start": 1316.2, "duration": 4.56}, {"text": "if you recompile the code it should it", "start": 1319.279, "duration": 5.76}, {"text": "should run um and what changes typically", "start": 1320.76, "duration": 6.36}, {"text": "the ratio of the floating Point", "start": 1325.039, "duration": 5.201}, {"text": "performance fp32 to", "start": 1327.12, "duration": 5.48}, {"text": "fp64 you know memory bandwidth number of", "start": 1330.24, "duration": 3.84}, {"text": "compute cores and", "start": 1332.6, "duration": 3.16}, {"text": "multiprocessors the number of threats", "start": 1334.08, "duration": 3.839}, {"text": "that the hardware can execute um the", "start": 1335.76, "duration": 3.84}, {"text": "number of registers and C sites you have", "start": 1337.919, "duration": 3.24}, {"text": "so you might have to optimize Colonels", "start": 1339.6, "duration": 3.72}, {"text": "for that um that's not different than", "start": 1341.159, "duration": 5.88}, {"text": "optimizing code you know for cach um um", "start": 1343.32, "duration": 6.88}, {"text": "optimization proced use for instance um", "start": 1347.039, "duration": 5.12}, {"text": "and of course the available GPU memory", "start": 1350.2, "duration": 5.16}, {"text": "that you have um so so so if you look", "start": 1352.159, "duration": 4.481}, {"text": "here you know those are different", "start": 1355.36, "duration": 3.88}, {"text": "Generations so the p100 was in Comet", "start": 1356.64, "duration": 5.12}, {"text": "V100 that's the WTA architecture that we", "start": 1359.24, "duration": 6.4}, {"text": "have in in in xon and that's the impair", "start": 1361.76, "duration": 5.919}, {"text": "architecture and there's actually new", "start": 1365.64, "duration": 4.84}, {"text": "architecture now after that that's been", "start": 1367.679, "duration": 3.88}, {"text": "coming out that's the hopper", "start": 1370.48, "duration": 2.84}, {"text": "architecture don't have data for this on", "start": 1371.559, "duration": 5.881}, {"text": "here but um you see the single Precision", "start": 1373.32, "duration": 5.92}, {"text": "course per per multiprocessor didn't", "start": 1377.44, "duration": 4.839}, {"text": "change you still have 64 so there 64", "start": 1379.24, "duration": 6.16}, {"text": "cores on each um", "start": 1382.279, "duration": 6.161}, {"text": "multiprocessor and the P 100 has 56", "start": 1385.4, "duration": 6.32}, {"text": "multi processors the v00 at a", "start": 1388.44, "duration": 5.44}, {"text": "100 has", "start": 1391.72, "duration": 5.319}, {"text": "108 um so you see you have", "start": 1393.88, "duration": 5.399}, {"text": "like you know it's been increasing but", "start": 1397.039, "duration": 5.921}, {"text": "so in the order of like 5,000 6,000 um", "start": 1399.279, "duration": 7.76}, {"text": "cores and um correspondingly the the the", "start": 1402.96, "duration": 5.839}, {"text": "floating Point performance has increased", "start": 1407.039, "duration": 4.481}, {"text": "so we have you know about seven terap", "start": 1408.799, "duration": 5.601}, {"text": "flops of of fp64 floating Point", "start": 1411.52, "duration": 6.44}, {"text": "performance on there V 100s each V 100", "start": 1414.4, "duration": 6.2}, {"text": "um the warp size that's the size that's", "start": 1417.96, "duration": 5.24}, {"text": "the number of cores that", "start": 1420.6, "duration": 4.92}, {"text": "actually um you know instructions that", "start": 1423.2, "duration": 5.959}, {"text": "issue in lock step um so you that's 32", "start": 1425.52, "duration": 5.639}, {"text": "that didn't change but it's not gu", "start": 1429.159, "duration": 3.361}, {"text": "guaranteed to stay the same it's just", "start": 1431.159, "duration": 3.161}, {"text": "something to keep in mind so you", "start": 1432.52, "duration": 4.12}, {"text": "shouldn't shouldn't write code in such a", "start": 1434.32, "duration": 5.32}, {"text": "way that this is an assumption that it's", "start": 1436.64, "duration": 4.36}, {"text": "it is exactly", "start": 1439.64, "duration": 3.08}, {"text": "32", "start": 1441.0, "duration": 4.159}, {"text": "um then you know I already mentioned", "start": 1442.72, "duration": 5.36}, {"text": "that you have to explicitly manage the", "start": 1445.159, "duration": 5.361}, {"text": "memory Hier key so think about the CPU", "start": 1448.08, "duration": 5.32}, {"text": "memory the GPU memory um and then you", "start": 1450.52, "duration": 6.159}, {"text": "have shared memory on the GPU texture", "start": 1453.4, "duration": 4.84}, {"text": "memory constant", "start": 1456.679, "duration": 3.401}, {"text": "memory there's something that's called", "start": 1458.24, "duration": 3.319}, {"text": "unified memory where you don't have to", "start": 1460.08, "duration": 4.68}, {"text": "think about you know CPU and GPU", "start": 1461.559, "duration": 6.48}, {"text": "memory um and Q will handle that autom", "start": 1464.76, "duration": 5.159}, {"text": "Ally for you but you know the memory har", "start": 1468.039, "duration": 3.681}, {"text": "still exists um so this helps you to", "start": 1469.919, "duration": 4.841}, {"text": "prototype code quickly um but usually", "start": 1471.72, "duration": 4.72}, {"text": "people will handle that explicitly when", "start": 1474.76, "duration": 4.68}, {"text": "once they get to Performance Tuning and", "start": 1476.44, "duration": 4.959}, {"text": "then Nvidia and AMD work a little bit", "start": 1479.44, "duration": 4.8}, {"text": "differently although you know basically", "start": 1481.399, "duration": 5.441}, {"text": "if you look at it you know a lot of the", "start": 1484.24, "duration": 5.52}, {"text": "nen clature is the same they work very", "start": 1486.84, "duration": 5.48}, {"text": "similar with", "start": 1489.76, "duration": 2.56}, {"text": "GPS um there's something called compute", "start": 1492.76, "duration": 6.039}, {"text": "capability that you can look at um", "start": 1495.799, "duration": 5.801}, {"text": "and that basically um is based on the", "start": 1498.799, "duration": 4.801}, {"text": "hardware version you know so from Pascal", "start": 1501.6, "duration": 5.12}, {"text": "to Walter andair and there was touring", "start": 1503.6, "duration": 5.319}, {"text": "and um then there's the hopper", "start": 1506.72, "duration": 4.959}, {"text": "architecture now and depending on the", "start": 1508.919, "duration": 5.841}, {"text": "you know there's different types of gpus", "start": 1511.679, "duration": 6.48}, {"text": "always like gaming gpus uh workstation", "start": 1514.76, "duration": 5.48}, {"text": "gpus and then the data center gpus which", "start": 1518.159, "duration": 6.201}, {"text": "are you know cheap to very expensive and", "start": 1520.24, "duration": 6.4}, {"text": "features that being switched off the", "start": 1524.36, "duration": 3.72}, {"text": "more you go to the cheaper cheaper", "start": 1526.64, "duration": 6.399}, {"text": "Hardware um yeah but if you check what", "start": 1528.08, "duration": 8.56}, {"text": "compute capability you have um you know", "start": 1533.039, "duration": 5.441}, {"text": "you will see what what features of CUA", "start": 1536.64, "duration": 3.88}, {"text": "are supported um it's not something that", "start": 1538.48, "duration": 4.079}, {"text": "you typically have to take care of um", "start": 1540.52, "duration": 4.0}, {"text": "but something to keep in", "start": 1542.559, "duration": 7.48}, {"text": "mind um overall um you know these", "start": 1544.52, "duration": 7.08}, {"text": "changes from architecture to", "start": 1550.039, "duration": 2.961}, {"text": "architecture what that means for your", "start": 1551.6, "duration": 3.439}, {"text": "program really there's there's one two", "start": 1553.0, "duration": 4.96}, {"text": "things that you have to keep in mind uh", "start": 1555.039, "duration": 4.921}, {"text": "threads so you should never write code", "start": 1557.96, "duration": 3.88}, {"text": "that has an assumption for how many", "start": 1559.96, "duration": 3.48}, {"text": "threads it will use it's a little bit", "start": 1561.84, "duration": 4.6}, {"text": "you know like an MPI code or opening P", "start": 1563.44, "duration": 5.44}, {"text": "code you know when at runtime at launch", "start": 1566.44, "duration": 4.959}, {"text": "time you'll determine the type of", "start": 1568.88, "duration": 4.0}, {"text": "Hardware that you have how many courses", "start": 1571.399, "duration": 4.801}, {"text": "they have and then you launch so use", "start": 1572.88, "duration": 4.84}, {"text": "compter calls in this case you know you", "start": 1576.2, "duration": 3.12}, {"text": "can query the hardware configuration", "start": 1577.72, "duration": 3.839}, {"text": "with the GPU and then you", "start": 1579.32, "duration": 4.88}, {"text": "launch a certain number of threats and", "start": 1581.559, "duration": 4.441}, {"text": "that typically needs to be many more", "start": 1584.2, "duration": 4.04}, {"text": "than the processing course to help", "start": 1586.0, "duration": 5.08}, {"text": "avoid uh or hide memory latency memory", "start": 1588.24, "duration": 4.12}, {"text": "access", "start": 1591.08, "duration": 5.28}, {"text": "latency and data types um in particular", "start": 1592.36, "duration": 5.559}, {"text": "if you want to use the cheap gaming chip", "start": 1596.36, "duration": 3.48}, {"text": "use you know you have to avoid using", "start": 1597.919, "duration": 4.521}, {"text": "double Precision um and then you can get", "start": 1599.84, "duration": 4.079}, {"text": "very high performance I'll show you an", "start": 1602.44, "duration": 4.359}, {"text": "example about that um but you have to", "start": 1603.919, "duration": 5.441}, {"text": "keep in mind that of course if you need", "start": 1606.799, "duration": 5.041}, {"text": "that Precision to maintain numerical", "start": 1609.36, "duration": 4.08}, {"text": "accuracy then there's no way around that", "start": 1611.84, "duration": 3.559}, {"text": "so you need to be careful with", "start": 1613.44, "duration": 4.76}, {"text": "this um", "start": 1615.399, "duration": 5.201}, {"text": "then you've heard already a lot about", "start": 1618.2, "duration": 4.8}, {"text": "expans I'll just go briefly over that", "start": 1620.6, "duration": 5.4}, {"text": "again um you know so we have", "start": 1623.0, "duration": 6.84}, {"text": "these um scal compute units and then you", "start": 1626.0, "duration": 6.0}, {"text": "know each of the scalable compute units", "start": 1629.84, "duration": 3.68}, {"text": "has", "start": 1632.0, "duration": 6.76}, {"text": "four uh um times four GPU nodes and so", "start": 1633.52, "duration": 8.12}, {"text": "each GPU note has um so we have a total", "start": 1638.76, "duration": 3.919}, {"text": "of", "start": 1641.64, "duration": 6.0}, {"text": "208 uh uh v00 gpus so we have 52 forway", "start": 1642.679, "duration": 7.36}, {"text": "GPU noes so there spe2 noes each each", "start": 1647.64, "duration": 4.279}, {"text": "note has four four", "start": 1650.039, "duration": 3.52}, {"text": "gpus", "start": 1651.919, "duration": 4.76}, {"text": "um yeah so so later you'll get access to", "start": 1653.559, "duration": 5.761}, {"text": "one of those GPU notes and with one GPU", "start": 1656.679, "duration": 4.641}, {"text": "assign to", "start": 1659.32, "duration": 5.599}, {"text": "you um now if you look at this so this", "start": 1661.32, "duration": 5.28}, {"text": "is not a picture from expans I just", "start": 1664.919, "duration": 3.521}, {"text": "grabbed this from somewhere but", "start": 1666.6, "duration": 5.0}, {"text": "effectively you know sort of looks like", "start": 1668.44, "duration": 5.16}, {"text": "that so in expans we have this GPU", "start": 1671.6, "duration": 5.24}, {"text": "sitting on the PCI Express um um bus the", "start": 1673.6, "duration": 5.919}, {"text": "V 100 but you know here you'd see a", "start": 1676.84, "duration": 5.88}, {"text": "server that has basically four gpus um", "start": 1679.519, "duration": 4.681}, {"text": "that's how the GPU looks like so you", "start": 1682.72, "duration": 3.439}, {"text": "have the processor here you see the", "start": 1684.2, "duration": 4.719}, {"text": "memory banks um that's the ram of the of", "start": 1686.159, "duration": 6.64}, {"text": "the GPU um if you you can buy those gpus", "start": 1688.919, "duration": 6.561}, {"text": "that that go into a PCI Express slot", "start": 1692.799, "duration": 4.48}, {"text": "they look like a gaming GPU that you", "start": 1695.48, "duration": 4.799}, {"text": "would buy for a you know it's basically", "start": 1697.279, "duration": 5.321}, {"text": "a brick and you stick it into the PCI", "start": 1700.279, "duration": 4.921}, {"text": "Express um slots like like if you were", "start": 1702.6, "duration": 6.84}, {"text": "to build a a desktop um", "start": 1705.2, "duration": 8.88}, {"text": "workstation um here here are the CPUs", "start": 1709.44, "duration": 7.4}, {"text": "you know processor to processors and you", "start": 1714.08, "duration": 5.76}, {"text": "know the memory for the CPUs and yeah", "start": 1716.84, "duration": 4.719}, {"text": "the gpus they just have the memory right", "start": 1719.84, "duration": 3.679}, {"text": "on them but because you buy the GPU you", "start": 1721.559, "duration": 4.0}, {"text": "can't add or", "start": 1723.519, "duration": 5.4}, {"text": "remove um so in our case the GPU nodes", "start": 1725.559, "duration": 5.561}, {"text": "they don't have AMD processors we have", "start": 1728.919, "duration": 5.161}, {"text": "Intel processors there are two 20 core", "start": 1731.12, "duration": 6.32}, {"text": "Intel processors um there's 384", "start": 1734.08, "duration": 5.719}, {"text": "gigabytes of RAM so that's the CPU", "start": 1737.44, "duration": 4.88}, {"text": "memory and then there are four Nvidia", "start": 1739.799, "duration": 4.921}, {"text": "V100 S6 and 2 gpus and each of those", "start": 1742.32, "duration": 5.0}, {"text": "gpus has its own memory and there's 32", "start": 1744.72, "duration": 4.88}, {"text": "gigabyt of this so-called", "start": 1747.32, "duration": 5.719}, {"text": "hbm2 uh memory that has you know quite", "start": 1749.6, "duration": 5.16}, {"text": "quite High memory bandwidth So speaking", "start": 1753.039, "duration": 3.24}, {"text": "about how quickly can you get the data", "start": 1754.76, "duration": 3.159}, {"text": "that's stored in here with the processor", "start": 1756.279, "duration": 2.64}, {"text": "and", "start": 1757.919, "duration": 5.161}, {"text": "back um and then we have also you know", "start": 1758.919, "duration": 7.521}, {"text": "scratch discs on on each note 1.6 terab", "start": 1763.08, "duration": 7.68}, {"text": "and BM per note um so there are other", "start": 1766.44, "duration": 7.4}, {"text": "things that if you were to um if you", "start": 1770.76, "duration": 5.399}, {"text": "want to use multiple gpus I write code", "start": 1773.84, "duration": 3.4}, {"text": "that", "start": 1776.159, "duration": 3.841}, {"text": "basically runs across multiple gpus and", "start": 1777.24, "duration": 5.76}, {"text": "and communicates between the gpus then", "start": 1780.0, "duration": 6.24}, {"text": "the other things you know we have um", "start": 1783.0, "duration": 5.159}, {"text": "higher speed interconnects between the", "start": 1786.24, "duration": 3.6}, {"text": "gpus", "start": 1788.159, "duration": 6.88}, {"text": "um and but you have to be careful so", "start": 1789.84, "duration": 8.64}, {"text": "there's a CPU zero and CPU 1 and you", "start": 1795.039, "duration": 5.601}, {"text": "know there's like two um gpus that are", "start": 1798.48, "duration": 6.079}, {"text": "effectively closer to cpu0 than to", "start": 1800.64, "duration": 7.24}, {"text": "cpu1 and", "start": 1804.559, "duration": 6.921}, {"text": "um the the the memory Bandit on the PCI", "start": 1807.88, "duration": 6.08}, {"text": "uh switches of course um um slower than", "start": 1811.48, "duration": 3.799}, {"text": "you know the communication that you can", "start": 1813.96, "duration": 3.16}, {"text": "have between the", "start": 1815.279, "duration": 4.041}, {"text": "GPS uh there's some information here in", "start": 1817.12, "duration": 4.84}, {"text": "that user guide um if you want to know", "start": 1819.32, "duration": 5.599}, {"text": "more um please take a look look there", "start": 1821.96, "duration": 4.28}, {"text": "and or ask", "start": 1824.919, "duration": 2.841}, {"text": "questions", "start": 1826.24, "duration": 4.439}, {"text": "um so this is an information so Nvidia", "start": 1827.76, "duration": 6.84}, {"text": "SMI Nvidia system management interface", "start": 1830.679, "duration": 5.761}, {"text": "can give you information about the gpus", "start": 1834.6, "duration": 4.48}, {"text": "you'll try this as well it has an option", "start": 1836.44, "duration": 4.88}, {"text": "Topo and so if you type Topo minus M", "start": 1839.08, "duration": 5.24}, {"text": "it's going to tell you basically how the", "start": 1841.32, "duration": 5.68}, {"text": "gpus are interconnected right", "start": 1844.32, "duration": 6.52}, {"text": "so I mentioned briefly this um you know", "start": 1847.0, "duration": 6.72}, {"text": "faster interconnects these Envy links so", "start": 1850.84, "duration": 4.28}, {"text": "you see", "start": 1853.72, "duration": 4.079}, {"text": "um they're running at 50 g gab per", "start": 1855.12, "duration": 5.88}, {"text": "second as opposed to PCI Express Bus you", "start": 1857.799, "duration": 4.641}, {"text": "know which is slower so if you wanted to", "start": 1861.0, "duration": 3.76}, {"text": "send data from gpu1 to", "start": 1862.44, "duration": 5.28}, {"text": "gpu2 um in a traditional system you'd go", "start": 1864.76, "duration": 5.879}, {"text": "through the PCI switch um you don't have", "start": 1867.72, "duration": 5.679}, {"text": "to do that you can see actually that you", "start": 1870.639, "duration": 5.561}, {"text": "know uh gpu0 and gpu1 they're", "start": 1873.399, "duration": 7.201}, {"text": "interconnected by this nv2 um", "start": 1876.2, "duration": 7.8}, {"text": "um uh interconnect so they can talk", "start": 1880.6, "duration": 5.799}, {"text": "faster to each other than in a system", "start": 1884.0, "duration": 3.799}, {"text": "where you have to go through a PCI", "start": 1886.399, "duration": 4.361}, {"text": "Express bu so that's special Hardware um", "start": 1887.799, "duration": 4.961}, {"text": "and the CPU Affinity is basically you", "start": 1890.76, "duration": 5.48}, {"text": "know um which which CPU they are", "start": 1892.76, "duration": 5.96}, {"text": "connected to on the on the PCI Express", "start": 1896.24, "duration": 6.6}, {"text": "um switch right and you some information", "start": 1898.72, "duration": 5.48}, {"text": "here basically", "start": 1902.84, "duration": 5.679}, {"text": "about um if you send data between gpus", "start": 1904.2, "duration": 6.839}, {"text": "how it would how it would travel it and", "start": 1908.519, "duration": 6.04}, {"text": "this this is the um Network interconnect", "start": 1911.039, "duration": 6.681}, {"text": "that's sitting on the PCR Express bu", "start": 1914.559, "duration": 4.96}, {"text": "so that you know what you have to use if", "start": 1917.72, "duration": 4.52}, {"text": "you if you if you need to communicate", "start": 1919.519, "duration": 6.241}, {"text": "between gpus between different compute", "start": 1922.24, "duration": 5.799}, {"text": "modes um yeah I talked about this this", "start": 1925.76, "duration": 7.48}, {"text": "is how the GPU looks like um this is a a", "start": 1928.039, "duration": 8.161}, {"text": "diagram you've seen before the one from", "start": 1933.24, "duration": 7.0}, {"text": "the Tesla the early Tesla um the first", "start": 1936.2, "duration": 6.68}, {"text": "c160 card you know it looks the same", "start": 1940.24, "duration": 6.12}, {"text": "only you know now it's different um so", "start": 1942.88, "duration": 5.639}, {"text": "you have all these these M", "start": 1946.36, "duration": 4.36}, {"text": "multiprocessors each of those has 64", "start": 1948.519, "duration": 3.841}, {"text": "cores and you have many of them right", "start": 1950.72, "duration": 4.52}, {"text": "and then you have an L2 cache actually", "start": 1952.36, "duration": 7.08}, {"text": "that is accessible by all of the um", "start": 1955.24, "duration": 6.559}, {"text": "multiprocessors each multiprocessor has", "start": 1959.44, "duration": 5.119}, {"text": "its own shared and cach L1 cache memory", "start": 1961.799, "duration": 4.24}, {"text": "and shared memory is basically user", "start": 1964.559, "duration": 2.801}, {"text": "managed cach", "start": 1966.039, "duration": 3.12}, {"text": "memory um you have the memory", "start": 1967.36, "duration": 3.12}, {"text": "controllers and then you know this is", "start": 1969.159, "duration": 4.161}, {"text": "the memory that you know see sitting", "start": 1970.48, "duration": 6.159}, {"text": "here on the side um this hbm2 memory", "start": 1973.32, "duration": 5.959}, {"text": "which is it's is very fast mending and", "start": 1976.639, "duration": 4.321}, {"text": "then you also have the highspeed Hub", "start": 1979.279, "duration": 4.441}, {"text": "with these NV link interconnects um when", "start": 1980.96, "duration": 5.12}, {"text": "you want to send data to another GPU", "start": 1983.72, "duration": 5.079}, {"text": "communicate with another", "start": 1986.08, "duration": 7.839}, {"text": "GPU um right so 32 GB of RAM", "start": 1988.799, "duration": 9.921}, {"text": "atsm um 64 fp32 course perm 32 fp64", "start": 1993.919, "duration": 7.36}, {"text": "course perm a TENS are", "start": 1998.72, "duration": 6.4}, {"text": "course um 300 watt so not 350 so 300", "start": 2001.279, "duration": 5.481}, {"text": "watt they draw and then that's a peak", "start": 2005.12, "duration": 5.72}, {"text": "per performance that you get um about 7", "start": 2006.76, "duration": 8.279}, {"text": "to eight Tera flops double Precision", "start": 2010.84, "duration": 7.04}, {"text": "fp64 twice that", "start": 2015.039, "duration": 7.321}, {"text": "fp32 four times that approximately um", "start": 2017.88, "duration": 7.12}, {"text": "fp16 uh if you can do away with that", "start": 2022.36, "duration": 5.6}, {"text": "usually for numerical applications fp16", "start": 2025.0, "duration": 6.36}, {"text": "is not very helpful but it can and then", "start": 2027.96, "duration": 6.76}, {"text": "there are these tensor flops um um um", "start": 2031.36, "duration": 6.199}, {"text": "cores that give you an insanely High um", "start": 2034.72, "duration": 6.28}, {"text": "um uh performance so so if you do", "start": 2037.559, "duration": 5.321}, {"text": "machine learning that that will work", "start": 2041.0, "duration": 3.559}, {"text": "very well on those deep learning will", "start": 2042.88, "duration": 4.92}, {"text": "work very well on those Street vies as", "start": 2044.559, "duration": 7.04}, {"text": "well any questions so", "start": 2047.8, "duration": 3.799}, {"text": "far no questions okay one question in", "start": 2053.04, "duration": 7.76}, {"text": "the main um you let them know what is", "start": 2057.24, "duration": 6.679}, {"text": "the difference between GPU core and CPU", "start": 2060.8, "duration": 7.319}, {"text": "core oh okay um", "start": 2063.919, "duration": 8.121}, {"text": "well I mean a a a CPU core is basically", "start": 2068.119, "duration": 5.48}, {"text": "an independent", "start": 2072.04, "duration": 3.24}, {"text": "processor", "start": 2073.599, "duration": 4.48}, {"text": "and you know if you have two cores they", "start": 2075.28, "duration": 6.0}, {"text": "can can work completely in a completely", "start": 2078.079, "duration": 8.641}, {"text": "independent task of each other on a on a", "start": 2081.28, "duration": 9.879}, {"text": "GPU um so you have this", "start": 2086.72, "duration": 8.72}, {"text": "processor in in in some sense you can", "start": 2091.159, "duration": 7.041}, {"text": "think of this process as a core and each", "start": 2095.44, "duration": 5.12}, {"text": "of those it's not true usually people", "start": 2098.2, "duration": 4.32}, {"text": "talk about these individual cores here", "start": 2100.56, "duration": 4.88}, {"text": "as a core a compute core but they cannot", "start": 2102.52, "duration": 4.48}, {"text": "operate", "start": 2105.44, "duration": 4.32}, {"text": "independently um all of those have to do", "start": 2107.0, "duration": 5.4}, {"text": "the same operation at the same time so", "start": 2109.76, "duration": 4.319}, {"text": "they work a little bit like the vector", "start": 2112.4, "duration": 3.6}, {"text": "units on a CPU", "start": 2114.079, "duration": 5.561}, {"text": "core so like the AVX 512", "start": 2116.0, "duration": 8.44}, {"text": "instruction units on a on a on a CPU", "start": 2119.64, "duration": 9.04}, {"text": "core um in PR simple the different", "start": 2124.44, "duration": 5.639}, {"text": "multiprocessors that's why they're", "start": 2128.68, "duration": 2.919}, {"text": "called multiprocessors because they have", "start": 2130.079, "duration": 3.841}, {"text": "multiple cores", "start": 2131.599, "duration": 5.321}, {"text": "um can do different operations um but", "start": 2133.92, "duration": 5.88}, {"text": "usually you launch code that will run", "start": 2136.92, "duration": 3.84}, {"text": "the", "start": 2139.8, "duration": 4.96}, {"text": "same task on all of the mile processors", "start": 2140.76, "duration": 6.839}, {"text": "um in some sense you often do that also", "start": 2144.76, "duration": 4.96}, {"text": "when you parallelize a code on a CPU", "start": 2147.599, "duration": 5.601}, {"text": "right when you use open MP or MPI", "start": 2149.72, "duration": 5.72}, {"text": "usually you do the same task on all this", "start": 2153.2, "duration": 3.84}, {"text": "uh course only you know they they don't", "start": 2155.44, "duration": 3.32}, {"text": "have to operate in lock", "start": 2157.04, "duration": 4.36}, {"text": "step and yeah and the other difference", "start": 2158.76, "duration": 4.92}, {"text": "is of course you know the CPU course", "start": 2161.4, "duration": 4.679}, {"text": "that's a CPU and the GPU is just", "start": 2163.68, "duration": 3.639}, {"text": "physically", "start": 2166.079, "duration": 5.24}, {"text": "different I hope that answers the", "start": 2167.319, "duration": 4.0}, {"text": "question okay", "start": 2172.64, "duration": 6.52}, {"text": "um I might be going too slow or I'm", "start": 2176.04, "duration": 5.559}, {"text": "talking too much let's look at some", "start": 2179.16, "duration": 4.0}, {"text": "software examples so we will go quickly", "start": 2181.599, "duration": 4.641}, {"text": "through that um there are examples now", "start": 2183.16, "duration": 4.76}, {"text": "from virtual any field so there's not", "start": 2186.24, "duration": 4.16}, {"text": "much to talk about um lately it's become", "start": 2187.92, "duration": 4.08}, {"text": "very popular to do machine learning on", "start": 2190.4, "duration": 4.28}, {"text": "gpus but you know you have any other", "start": 2192.0, "duration": 4.92}, {"text": "applications any other field um", "start": 2194.68, "duration": 4.52}, {"text": "numerically intensive data intensive", "start": 2196.92, "duration": 5.72}, {"text": "that runs and has some codes part gpus", "start": 2199.2, "duration": 7.159}, {"text": "so um quickly just you know I I", "start": 2202.64, "duration": 5.88}, {"text": "mentioned this before I I don't want to", "start": 2206.359, "duration": 3.561}, {"text": "talk much about machine learning because", "start": 2208.52, "duration": 4.12}, {"text": "we have all these machine learning uh uh", "start": 2209.92, "duration": 5.199}, {"text": "tutorials there there's different types", "start": 2212.64, "duration": 4.08}, {"text": "of machine learning the thing that", "start": 2215.119, "duration": 3.521}, {"text": "particularly works well on gpus like I", "start": 2216.72, "duration": 3.16}, {"text": "mentioned is these deep learning", "start": 2218.64, "duration": 2.719}, {"text": "workflows right so if you do something", "start": 2219.88, "duration": 3.08}, {"text": "else like support Vector machines or", "start": 2221.359, "duration": 4.361}, {"text": "classification models and so on you know", "start": 2222.96, "duration": 4.28}, {"text": "they don't necessarily take good", "start": 2225.72, "duration": 4.72}, {"text": "advantage of of gpus um they can but not", "start": 2227.24, "duration": 4.4}, {"text": "necessarily but it's really the Deep", "start": 2230.44, "duration": 4.56}, {"text": "learning field and the reason is you", "start": 2231.64, "duration": 4.959}, {"text": "know you have the neural networks with", "start": 2235.0, "duration": 4.839}, {"text": "many hidden layers and like I alluded", "start": 2236.599, "duration": 6.921}, {"text": "before is um you know you have to do", "start": 2239.839, "duration": 5.28}, {"text": "these Matrix multiplications that's", "start": 2243.52, "duration": 3.64}, {"text": "basically these tensor operations when", "start": 2245.119, "duration": 4.761}, {"text": "when you know you you compute the you", "start": 2247.16, "duration": 6.159}, {"text": "know the the um when you Traverse the", "start": 2249.88, "duration": 5.04}, {"text": "neural network from you know your your", "start": 2253.319, "duration": 3.28}, {"text": "feature vectors from the input towards", "start": 2254.92, "duration": 4.04}, {"text": "the output um there's all these magic", "start": 2256.599, "duration": 5.24}, {"text": "multiplications H happening from uh", "start": 2258.96, "duration": 5.399}, {"text": "input to output and the gpus are really", "start": 2261.839, "duration": 4.801}, {"text": "efficient at doing these um and if you", "start": 2264.359, "duration": 5.121}, {"text": "think about the history um a 4x4 Matrix", "start": 2266.64, "duration": 5.439}, {"text": "algebra is used in 3D graphics and so", "start": 2269.48, "duration": 4.32}, {"text": "that's just naturally how the how the", "start": 2272.079, "duration": 4.161}, {"text": "hardware has evolved and then this half", "start": 2273.8, "duration": 4.4}, {"text": "precision AR mattics can be used for", "start": 2276.24, "duration": 4.28}, {"text": "many machine learning applications right", "start": 2278.2, "duration": 4.119}, {"text": "so that's why half Precision was", "start": 2280.52, "duration": 4.2}, {"text": "implemented and then now we have the", "start": 2282.319, "duration": 5.321}, {"text": "specific tensor course that literally in", "start": 2284.72, "duration": 6.359}, {"text": "Hardware speed up those um uh tensor", "start": 2287.64, "duration": 5.24}, {"text": "operations and the Machine learning", "start": 2291.079, "duration": 3.641}, {"text": "Frameworks they provide GPU support out", "start": 2292.88, "duration": 4.439}, {"text": "of the box um uh so you just have to", "start": 2294.72, "duration": 4.44}, {"text": "tell p to tensive flow that you want to", "start": 2297.319, "duration": 4.921}, {"text": "use the GPU and they will compile your", "start": 2299.16, "duration": 5.08}, {"text": "Ural Network that you're requesting um", "start": 2302.24, "duration": 5.2}, {"text": "for execution on the GPU um and and you", "start": 2304.24, "duration": 5.8}, {"text": "don't really need to know much about", "start": 2307.44, "duration": 4.28}, {"text": "gpus of course there are profilers and", "start": 2310.04, "duration": 4.079}, {"text": "things like that um where you can", "start": 2311.72, "duration": 5.32}, {"text": "actually profile the machine learning", "start": 2314.119, "duration": 4.96}, {"text": "you know their profilers for py in terms", "start": 2317.04, "duration": 4.0}, {"text": "of FL and you can look you know can you", "start": 2319.079, "duration": 4.641}, {"text": "change something in in the ways you set", "start": 2321.04, "duration": 5.24}, {"text": "up the new network and and and similar", "start": 2323.72, "duration": 4.68}, {"text": "things that can improve the performance", "start": 2326.28, "duration": 4.72}, {"text": "so you can do some some tuning as", "start": 2328.4, "duration": 5.16}, {"text": "well um now let's let's just briefly", "start": 2331.0, "duration": 4.52}, {"text": "look at benchmarks", "start": 2333.56, "duration": 3.68}, {"text": "um", "start": 2335.52, "duration": 4.16}, {"text": "and so you have to take those overs with", "start": 2337.24, "duration": 4.879}, {"text": "a grain of salt because um you got to be", "start": 2339.68, "duration": 4.36}, {"text": "very careful how people present the data", "start": 2342.119, "duration": 3.96}, {"text": "right um", "start": 2344.04, "duration": 4.44}, {"text": "so if you're in sales people sales", "start": 2346.079, "duration": 4.321}, {"text": "people like that very much and but", "start": 2348.48, "duration": 3.24}, {"text": "sometimes if you look closely it does", "start": 2350.4, "duration": 2.919}, {"text": "the benk doesn't tell much so we really", "start": 2351.72, "duration": 4.16}, {"text": "need to be", "start": 2353.319, "duration": 6.04}, {"text": "careful um here here's an example of a", "start": 2355.88, "duration": 4.84}, {"text": "quantum chemistry code that you we", "start": 2359.359, "duration": 3.881}, {"text": "developed um it's called quick it's open", "start": 2360.72, "duration": 4.44}, {"text": "source if you're a Quantum chemist or", "start": 2363.24, "duration": 3.359}, {"text": "interested in that you can actually we", "start": 2365.16, "duration": 4.36}, {"text": "downloaded for pre a bunch of years ago", "start": 2366.599, "duration": 4.681}, {"text": "we edited a book about electronic", "start": 2369.52, "duration": 3.24}, {"text": "structure calculations on Graphics", "start": 2371.28, "duration": 3.839}, {"text": "processing units so you know there bunch", "start": 2372.76, "duration": 3.92}, {"text": "of different codes that have been ported", "start": 2375.119, "duration": 3.841}, {"text": "that explain what they've been", "start": 2376.68, "duration": 5.28}, {"text": "doing um so for quick itself you see you", "start": 2378.96, "duration": 4.879}, {"text": "know for different pieces of the", "start": 2381.96, "duration": 3.72}, {"text": "calculation that we need to", "start": 2383.839, "duration": 4.201}, {"text": "do um you know we get", "start": 2385.68, "duration": 5.0}, {"text": "us quite a quite quite a de speed up so", "start": 2388.04, "duration": 4.279}, {"text": "let a speed up with respect to single", "start": 2390.68, "duration": 5.399}, {"text": "core right so it's not like our code", "start": 2392.319, "duration": 7.8}, {"text": "runs 200 times faster than a calculation", "start": 2396.079, "duration": 5.481}, {"text": "that you would be doing because usually", "start": 2400.119, "duration": 3.72}, {"text": "you don't run on a single core right but", "start": 2401.56, "duration": 5.279}, {"text": "maybe you run on 32 cores or 64 cores", "start": 2403.839, "duration": 5.201}, {"text": "and then you know you get on a single", "start": 2406.839, "duration": 4.921}, {"text": "GPU um at least the same performance or", "start": 2409.04, "duration": 4.92}, {"text": "better performance and that's what you", "start": 2411.76, "duration": 4.72}, {"text": "see here so that's a scaling plot where", "start": 2413.96, "duration": 3.52}, {"text": "you", "start": 2416.48, "duration": 3.92}, {"text": "see um ideal scaling and then those data", "start": 2417.48, "duration": 4.839}, {"text": "points is the measured scaling of our", "start": 2420.4, "duration": 4.199}, {"text": "code um for two different", "start": 2422.319, "duration": 5.0}, {"text": "operations um for Computing the forces", "start": 2424.599, "duration": 5.681}, {"text": "you know on on on atoms in a", "start": 2427.319, "duration": 5.561}, {"text": "molecule and this is the time on a", "start": 2430.28, "duration": 4.92}, {"text": "logarithmic scale right so you used", "start": 2432.88, "duration": 4.52}, {"text": "start with one core two 4 18 this was", "start": 2435.2, "duration": 3.8}, {"text": "going up to 40", "start": 2437.4, "duration": 4.36}, {"text": "cores um that we had available on on on", "start": 2439.0, "duration": 5.2}, {"text": "on those compute notes and a single v00", "start": 2441.76, "duration": 4.88}, {"text": "is significantly faster right so that's", "start": 2444.2, "duration": 3.919}, {"text": "basically the time that's taken by a", "start": 2446.64, "duration": 3.28}, {"text": "single V100 GPU so it's pretty", "start": 2448.119, "duration": 4.72}, {"text": "impressive and you know the expensive", "start": 2449.92, "duration": 5.08}, {"text": "pieces that we do in these types of", "start": 2452.839, "duration": 4.321}, {"text": "calculations um you know where we have", "start": 2455.0, "duration": 3.88}, {"text": "to compute an energy functional of the", "start": 2457.16, "duration": 3.679}, {"text": "electron density and there's a piece in", "start": 2458.88, "duration": 5.4}, {"text": "here that is you know kind of resoled um", "start": 2460.839, "duration": 5.76}, {"text": "analytically so we do a numerical", "start": 2464.28, "duration": 4.319}, {"text": "quadrature over you know where we have", "start": 2466.599, "duration": 3.881}, {"text": "to evaluate this function here at the", "start": 2468.599, "duration": 4.161}, {"text": "grid points and we have many grid points", "start": 2470.48, "duration": 4.839}, {"text": "so just even for a small water molecule", "start": 2472.76, "duration": 4.96}, {"text": "with three atoms you know there is", "start": 2475.319, "duration": 4.961}, {"text": "basically um at the end there's some", "start": 2477.72, "duration": 4.2}, {"text": "grid pruning going on you know there's", "start": 2480.28, "duration": 5.28}, {"text": "like about 8,000 grid points right and", "start": 2481.92, "duration": 5.52}, {"text": "um then each grid point we have to", "start": 2485.56, "duration": 4.559}, {"text": "evaluate you know many many many of", "start": 2487.44, "duration": 5.2}, {"text": "these basis function soal basis function", "start": 2490.119, "duration": 5.561}, {"text": "values and so on so what we implemented", "start": 2492.64, "duration": 4.56}, {"text": "is basically parallel numerical", "start": 2495.68, "duration": 3.399}, {"text": "quadrature that uses a o three based", "start": 2497.2, "duration": 4.6}, {"text": "partitioning of 3D grid points so you", "start": 2499.079, "duration": 4.921}, {"text": "you you have your grip points and you", "start": 2501.8, "duration": 4.0}, {"text": "start partitioning them into cubes and", "start": 2504.0, "duration": 5.96}, {"text": "so on so you go through these op Tre and", "start": 2505.8, "duration": 5.559}, {"text": "and then we can do some pre-screening", "start": 2509.96, "duration": 2.96}, {"text": "you have these data points basically", "start": 2511.359, "duration": 3.441}, {"text": "that belong to region of space and now", "start": 2512.92, "duration": 4.48}, {"text": "you can think about we have all these", "start": 2514.8, "duration": 4.92}, {"text": "individual compute cores of course we", "start": 2517.4, "duration": 3.8}, {"text": "have these grid points we need to do", "start": 2519.72, "duration": 3.0}, {"text": "this same operation here with", "start": 2521.2, "duration": 3.44}, {"text": "multiplications and function evaluation", "start": 2522.72, "duration": 3.32}, {"text": "at each grip Point well we can do this", "start": 2524.64, "duration": 3.64}, {"text": "super in parallel right so this is", "start": 2526.04, "duration": 3.6}, {"text": "perfectly to be", "start": 2528.28, "duration": 3.64}, {"text": "parallelized and so we do these", "start": 2529.64, "duration": 5.92}, {"text": "operations on different compute um um", "start": 2531.92, "duration": 6.6}, {"text": "course right so this is ideal um grid", "start": 2535.56, "duration": 5.039}, {"text": "Point batches that are being processed", "start": 2538.52, "duration": 5.72}, {"text": "in parallel on different CPU course or", "start": 2540.599, "duration": 6.441}, {"text": "um if we have um", "start": 2544.24, "duration": 6.16}, {"text": "um gpus bya cute on on the different um", "start": 2547.04, "duration": 5.76}, {"text": "GPU", "start": 2550.4, "duration": 2.4}, {"text": "course and then we have also", "start": 2553.8, "duration": 5.039}, {"text": "parallelized the code across multiple", "start": 2556.28, "duration": 5.96}, {"text": "gpus and if the computational problem", "start": 2558.839, "duration": 5.561}, {"text": "that you have um is large enough so here", "start": 2562.24, "duration": 4.359}, {"text": "is a small molecule larger molecules and", "start": 2564.4, "duration": 4.0}, {"text": "so on with many many more atoms and", "start": 2566.599, "duration": 5.121}, {"text": "basis functions then you can see that", "start": 2568.4, "duration": 5.8}, {"text": "then we have sufficient work that we can", "start": 2571.72, "duration": 5.16}, {"text": "actually make use of of of more than a", "start": 2574.2, "duration": 4.84}, {"text": "single GQ right and so the speed up is", "start": 2576.88, "duration": 4.36}, {"text": "almost perfect um depending on the", "start": 2579.04, "duration": 5.68}, {"text": "underlying size of the problem right so", "start": 2581.24, "duration": 5.839}, {"text": "can use multiple gpus another example is", "start": 2584.72, "duration": 7.359}, {"text": "molecular Dynamics where um you", "start": 2587.079, "duration": 7.361}, {"text": "know I've been working on a code and I'm", "start": 2592.079, "duration": 3.921}, {"text": "still working on a code that does also", "start": 2594.44, "duration": 3.159}, {"text": "classical molecular Dynamics not with", "start": 2596.0, "duration": 4.24}, {"text": "quantum mechanics but simple interaction", "start": 2597.599, "duration": 5.48}, {"text": "potentials they are simple but you see", "start": 2600.24, "duration": 5.52}, {"text": "here atoms moving and the whole enzyme", "start": 2603.079, "duration": 4.561}, {"text": "here in this case it's an enzyme and you", "start": 2605.76, "duration": 3.839}, {"text": "see water where we have determine a", "start": 2607.64, "duration": 4.4}, {"text": "water Channel exit channel in this um", "start": 2609.599, "duration": 4.361}, {"text": "from this reaction Center in this", "start": 2612.04, "duration": 3.76}, {"text": "enzyme you know we have tens of", "start": 2613.96, "duration": 3.28}, {"text": "thousands hundreds of thousands of atoms", "start": 2615.8, "duration": 2.72}, {"text": "and we need to compute all those", "start": 2617.24, "duration": 4.4}, {"text": "interactions between all those atoms and", "start": 2618.52, "duration": 5.76}, {"text": "the time steps that we are interested in", "start": 2621.64, "duration": 4.6}, {"text": "you know they are on the nanom micro", "start": 2624.28, "duration": 3.52}, {"text": "millisecond time", "start": 2626.24, "duration": 4.76}, {"text": "scale um but each time that that we do", "start": 2627.8, "duration": 4.96}, {"text": "in these molecular Dynamic simulations", "start": 2631.0, "duration": 4.44}, {"text": "right so in this movie you've seen just", "start": 2632.76, "duration": 4.24}, {"text": "a very short time time but those are", "start": 2635.44, "duration": 5.48}, {"text": "many many time steps because um the", "start": 2637.0, "duration": 5.28}, {"text": "these you know interactions between the", "start": 2640.92, "duration": 4.159}, {"text": "atoms we have to um do the computation", "start": 2642.28, "duration": 5.039}, {"text": "and the time steps numerical time steps", "start": 2645.079, "duration": 4.04}, {"text": "to integration the equation of motions", "start": 2647.319, "duration": 3.921}, {"text": "is is on the order of temp seconds so we", "start": 2649.119, "duration": 3.641}, {"text": "have to do millions of time steps and in", "start": 2651.24, "duration": 2.96}, {"text": "each time step we have to compute all", "start": 2652.76, "duration": 4.48}, {"text": "those interactions and um you know", "start": 2654.2, "duration": 4.879}, {"text": "people don't want to wait years for the", "start": 2657.24, "duration": 3.879}, {"text": "simulation to finish we need to do these", "start": 2659.079, "duration": 5.081}, {"text": "computations very fast", "start": 2661.119, "duration": 5.681}, {"text": "and we can do this very efficiently and", "start": 2664.16, "duration": 4.76}, {"text": "if you if you if you look at so we had a", "start": 2666.8, "duration": 4.4}, {"text": "code that's pretty well optimized for", "start": 2668.92, "duration": 4.04}, {"text": "CPUs you probably you know could", "start": 2671.2, "duration": 4.359}, {"text": "optimize it more but to get the gist of", "start": 2672.96, "duration": 4.84}, {"text": "the essence here is the essence of um", "start": 2675.559, "duration": 6.201}, {"text": "yeah is basically here um 36 cores you", "start": 2677.8, "duration": 5.84}, {"text": "know single node you get a throughput a", "start": 2681.76, "duration": 3.24}, {"text": "computational throughput so you can", "start": 2683.64, "duration": 3.64}, {"text": "simulate about like two or three nanocs", "start": 2685.0, "duration": 5.599}, {"text": "in the uh life of a molecule that like", "start": 2687.28, "duration": 5.039}, {"text": "your cellulose in water that has about", "start": 2690.599, "duration": 5.401}, {"text": "half a million atoms and on a single GPU", "start": 2692.319, "duration": 7.481}, {"text": "this is the v00 here you can do about 20", "start": 2696.0, "duration": 6.559}, {"text": "times as much right so that's that's", "start": 2699.8, "duration": 4.759}, {"text": "really really very powerful enables a", "start": 2702.559, "duration": 5.601}, {"text": "lot of new science and the way we", "start": 2704.559, "duration": 7.641}, {"text": "managed to do this um is to implement a", "start": 2708.16, "duration": 5.679}, {"text": "Precision model so this has different", "start": 2712.2, "duration": 3.8}, {"text": "Precision models in there we not now", "start": 2713.839, "duration": 4.881}, {"text": "using this to make that does most of the", "start": 2716.0, "duration": 4.359}, {"text": "computations in single", "start": 2718.72, "duration": 4.08}, {"text": "precision and the accumulations in", "start": 2720.359, "duration": 5.0}, {"text": "double Precision actually use fix", "start": 2722.8, "duration": 6.319}, {"text": "Precision but that's just a detail and", "start": 2725.359, "duration": 6.121}, {"text": "it's important I talk to you about", "start": 2729.119, "duration": 3.681}, {"text": "precision and", "start": 2731.48, "duration": 4.24}, {"text": "numerical uh accuracy right and", "start": 2732.8, "duration": 6.0}, {"text": "numerical stability um what you see here", "start": 2735.72, "duration": 6.48}, {"text": "is is a simulation time and the energy", "start": 2738.8, "duration": 6.68}, {"text": "and um energy must be conserved due to", "start": 2742.2, "duration": 5.8}, {"text": "Newton's Laws right energy is not", "start": 2745.48, "duration": 5.52}, {"text": "conserved something is wrong and if you", "start": 2748.0, "duration": 5.119}, {"text": "use single Precision for", "start": 2751.0, "duration": 4.96}, {"text": "everything um it's just numerically not", "start": 2753.119, "duration": 4.44}, {"text": "stable right so you might look at the", "start": 2755.96, "duration": 3.52}, {"text": "first few steps and your forces look", "start": 2757.559, "duration": 4.52}, {"text": "okay but then it starts to drift and", "start": 2759.48, "duration": 4.119}, {"text": "eventually your whole system heats up", "start": 2762.079, "duration": 3.801}, {"text": "and close up and simulation breaks down", "start": 2763.599, "duration": 5.96}, {"text": "is not not not valid um so you can do", "start": 2765.88, "duration": 5.32}, {"text": "many things in single Precision but not", "start": 2769.559, "duration": 2.8}, {"text": "everything and you have to be very", "start": 2771.2, "duration": 4.44}, {"text": "careful with that when when you um", "start": 2772.359, "duration": 5.361}, {"text": "decide to do something like", "start": 2775.64, "duration": 4.28}, {"text": "this but because we have single", "start": 2777.72, "duration": 5.68}, {"text": "Precision we can run on gaming gpus uh", "start": 2779.92, "duration": 4.439}, {"text": "very", "start": 2783.4, "duration": 2.919}, {"text": "efficiently and of course also in the", "start": 2784.359, "duration": 5.321}, {"text": "data center GP as", "start": 2786.319, "duration": 3.361}, {"text": "well right any questions so", "start": 2791.0, "duration": 4.24}, {"text": "far we don't have anything in the chat", "start": 2797.48, "duration": 3.28}, {"text": "at the", "start": 2799.8, "duration": 5.68}, {"text": "moment okay so you know I have a little", "start": 2800.76, "duration": 8.599}, {"text": "bit of an you know overview now of DP", "start": 2805.48, "duration": 6.52}, {"text": "architecture you know how we can speed", "start": 2809.359, "duration": 6.24}, {"text": "up certain codes um examples that we", "start": 2812.0, "duration": 5.559}, {"text": "very", "start": 2815.599, "duration": 4.281}, {"text": "successful and so what what we're going", "start": 2817.559, "duration": 3.56}, {"text": "to do now is we're going to start", "start": 2819.88, "duration": 6.04}, {"text": "looking at how can we actually program", "start": 2821.119, "duration": 4.801}, {"text": "gpus", "start": 2830.88, "duration": 5.52}, {"text": "so if you program gpus directly there", "start": 2832.68, "duration": 5.48}, {"text": "are different programming languages so", "start": 2836.4, "duration": 4.56}, {"text": "that assumes now you have a compiled", "start": 2838.16, "duration": 6.6}, {"text": "programming language or you could also", "start": 2840.96, "duration": 5.44}, {"text": "have um", "start": 2844.76, "duration": 3.319}, {"text": "interpreted languages you know you can", "start": 2846.4, "duration": 4.48}, {"text": "have um P", "start": 2848.079, "duration": 6.401}, {"text": "instance we will focus now on C++ and", "start": 2850.88, "duration": 5.32}, {"text": "cc++ and", "start": 2854.48, "duration": 4.4}, {"text": "fortun um but there are different ways", "start": 2856.2, "duration": 5.24}, {"text": "um there's open CL that you can use um", "start": 2858.88, "duration": 4.679}, {"text": "I'm not going to talk about it but this", "start": 2861.44, "duration": 5.2}, {"text": "works for NVIDIA and AMD gpus and other", "start": 2863.559, "duration": 7.0}, {"text": "devices Cuda that's nvidia's solution um", "start": 2866.64, "duration": 6.84}, {"text": "it works only for NVIDIA gpus the factor", "start": 2870.559, "duration": 6.161}, {"text": "standard for high performance code still", "start": 2873.48, "duration": 6.639}, {"text": "um it at least on Nvidia gpus and it", "start": 2876.72, "duration": 6.32}, {"text": "probably will remain like that for a", "start": 2880.119, "duration": 5.561}, {"text": "while um there's something called hip", "start": 2883.04, "duration": 4.68}, {"text": "hip um I keep forgetting what it stands", "start": 2885.68, "duration": 3.8}, {"text": "for hetrogeneous", "start": 2887.72, "duration": 4.32}, {"text": "I don't remember interoperable", "start": 2889.48, "duration": 4.24}, {"text": "performance I don't I don't remember", "start": 2892.04, "duration": 4.96}, {"text": "something like that this is um amd's", "start": 2893.72, "duration": 6.119}, {"text": "answer top that's an open source C++", "start": 2897.0, "duration": 5.839}, {"text": "runtime API and kernel language that is", "start": 2899.839, "duration": 4.841}, {"text": "very similar to Cuda so if you look at", "start": 2902.839, "duration": 4.961}, {"text": "it you literally okay you have all the", "start": 2904.68, "duration": 5.24}, {"text": "same like of like instructions I mean", "start": 2907.8, "duration": 4.72}, {"text": "the same um nomenclature just a little", "start": 2909.92, "duration": 4.32}, {"text": "bit different and then there are few", "start": 2912.52, "duration": 3.24}, {"text": "things that are slightly different right", "start": 2914.24, "duration": 3.359}, {"text": "so there's actually code translator", "start": 2915.76, "duration": 4.559}, {"text": "where you can take your uter code you do", "start": 2917.599, "duration": 6.201}, {"text": "it basically does grap replace on your", "start": 2920.319, "duration": 6.24}, {"text": "um function calls and definitions and so", "start": 2923.8, "duration": 4.68}, {"text": "on and generates this hip code and then", "start": 2926.559, "duration": 4.161}, {"text": "you can use that hip code or you could", "start": 2928.48, "duration": 6.079}, {"text": "write it directly in Hip um and then you", "start": 2930.72, "duration": 7.52}, {"text": "can actually use that to generate back", "start": 2934.559, "duration": 6.881}, {"text": "cter code or code for amd's rocken so", "start": 2938.24, "duration": 6.559}, {"text": "that's the radium open compute structure", "start": 2941.44, "duration": 5.639}, {"text": "so hip code in principle can get", "start": 2944.799, "duration": 5.961}, {"text": "compiled for both um Nvidia and and dqs", "start": 2947.079, "duration": 5.24}, {"text": "but you will not get the same", "start": 2950.76, "duration": 4.48}, {"text": "performances if you use pter directly at", "start": 2952.319, "duration": 6.161}, {"text": "least yeah that's probably so it's it's", "start": 2955.24, "duration": 6.0}, {"text": "a nice solution but of course um not", "start": 2958.48, "duration": 6.44}, {"text": "perfect um we will focus on Cuda and", "start": 2961.24, "duration": 5.52}, {"text": "then there's opening ACC which is", "start": 2964.92, "duration": 5.24}, {"text": "accelerator directives for NVA and", "start": 2966.76, "duration": 7.16}, {"text": "AMD um there's not as much support for", "start": 2970.16, "duration": 7.52}, {"text": "AMD simply because um when this was", "start": 2973.92, "duration": 6.8}, {"text": "developed it was developed by the", "start": 2977.68, "duration": 6.119}, {"text": "Portland Group Portland group was", "start": 2980.72, "duration": 5.76}, {"text": "purchased by Nvidia and they dropped the", "start": 2983.799, "duration": 6.201}, {"text": "AMD support um but you know it's a", "start": 2986.48, "duration": 6.639}, {"text": "standard being implemented also in other", "start": 2990.0, "duration": 7.119}, {"text": "compilers now there's also P um you know", "start": 2993.119, "duration": 7.401}, {"text": "that came from parallelization for you", "start": 2997.119, "duration": 6.281}, {"text": "know threading for CPUs but it's not", "start": 3000.52, "duration": 5.319}, {"text": "only for CPUs um since version four it", "start": 3003.4, "duration": 4.32}, {"text": "includes accelerating vectorization", "start": 3005.839, "duration": 3.641}, {"text": "directive so these things are sort of", "start": 3007.72, "duration": 2.639}, {"text": "like", "start": 3009.48, "duration": 4.24}, {"text": "similar um I would say open andp is not", "start": 3010.359, "duration": 5.601}, {"text": "yet as mature for gpus as open", "start": 3013.72, "duration": 4.76}, {"text": "ACC but um we'll see how these things", "start": 3015.96, "duration": 4.8}, {"text": "develop over next few years certainly", "start": 3018.48, "duration": 4.8}, {"text": "interesting to look at all of those um", "start": 3020.76, "duration": 6.599}, {"text": "we will look at open ACC and Cuda", "start": 3023.28, "duration": 5.88}, {"text": "so that's is an an overview of the", "start": 3027.359, "duration": 4.041}, {"text": "Nvidia GPU Computing Universe if you", "start": 3029.16, "duration": 3.679}, {"text": "think about it", "start": 3031.4, "duration": 4.12}, {"text": "so you know you have your GPU Computing", "start": 3032.839, "duration": 5.121}, {"text": "application it it uses libraries and", "start": 3035.52, "duration": 3.92}, {"text": "middleware and so there are many", "start": 3037.96, "duration": 3.32}, {"text": "different libraries that are available", "start": 3039.44, "duration": 6.0}, {"text": "like qnn the Deep neural network library", "start": 3041.28, "duration": 8.64}, {"text": "um qft and Library blast linear algebra", "start": 3045.44, "duration": 7.08}, {"text": "libraries um Spar algebra libraries and", "start": 3049.92, "duration": 5.12}, {"text": "so on there lots of stuff available it's", "start": 3052.52, "duration": 4.96}, {"text": "also available through much love and", "start": 3055.04, "duration": 8.4}, {"text": "M Andy Mary here I posted um a link to", "start": 3057.48, "duration": 9.68}, {"text": "the uh hip which is heterogeneous", "start": 3063.44, "duration": 6.359}, {"text": "interface for portability by AMD and I", "start": 3067.16, "duration": 5.84}, {"text": "posted a link to one of their articles", "start": 3069.799, "duration": 6.721}, {"text": "about it in the slack Channel thank you", "start": 3073.0, "duration": 5.44}, {"text": "thank you yeah welcome yeah it's it's", "start": 3076.52, "duration": 3.839}, {"text": "interesting to look at that", "start": 3078.44, "duration": 5.919}, {"text": "um um I'm not an expert with it but you", "start": 3080.359, "duration": 7.48}, {"text": "know that code quick code that we wrote", "start": 3084.359, "duration": 6.521}, {"text": "in Cuda so we have actually code", "start": 3087.839, "duration": 5.081}, {"text": "generator that automatically generates", "start": 3090.88, "duration": 5.88}, {"text": "code um and the complicated story", "start": 3092.92, "duration": 5.199}, {"text": "because the code is so complex and", "start": 3096.76, "duration": 4.2}, {"text": "complicated um you have python code that", "start": 3098.119, "duration": 6.321}, {"text": "generates C++ code um with Cuda and we", "start": 3100.96, "duration": 5.56}, {"text": "have a hippi version of that so people", "start": 3104.44, "duration": 4.6}, {"text": "call it hipping so you take CA code and", "start": 3106.52, "duration": 3.72}, {"text": "you turn", "start": 3109.04, "duration": 2.799}, {"text": "into", "start": 3110.24, "duration": 4.4}, {"text": "um but you know it's just a lot of work", "start": 3111.839, "duration": 4.641}, {"text": "so your cuter code works out of the box", "start": 3114.64, "duration": 5.52}, {"text": "the hip code doesn't um yeah AMD has a", "start": 3116.48, "duration": 5.359}, {"text": "lot of catching up to do I would say", "start": 3120.16, "duration": 4.56}, {"text": "with with respect to they have done lots", "start": 3121.839, "duration": 4.321}, {"text": "of work but they still have a lot of", "start": 3124.72, "duration": 3.48}, {"text": "catching up to do but of course if you", "start": 3126.16, "duration": 5.72}, {"text": "have AMD gpus um hip is the way to go", "start": 3128.2, "duration": 6.04}, {"text": "and or you can use uh try and see how", "start": 3131.88, "duration": 4.719}, {"text": "well open MP Works um I I I don't have", "start": 3134.24, "duration": 3.8}, {"text": "experience with that so can't really", "start": 3136.599, "duration": 4.281}, {"text": "tell you much about", "start": 3138.04, "duration": 2.84}, {"text": "it um yeah so program languages C C++", "start": 3142.799, "duration": 7.481}, {"text": "for turn supported Java python rappers", "start": 3146.96, "duration": 5.68}, {"text": "as well", "start": 3150.28, "duration": 6.12}, {"text": "um and direct comput that's for graphics", "start": 3152.64, "duration": 6.36}, {"text": "obviously and then directives right you", "start": 3156.4, "duration": 6.28}, {"text": "can use um basically your your your you", "start": 3159.0, "duration": 6.88}, {"text": "have CPU code C or foron that still", "start": 3162.68, "duration": 7.639}, {"text": "works um both for CPUs in serial and and", "start": 3165.88, "duration": 6.08}, {"text": "in parallel on gpus with those", "start": 3170.319, "duration": 3.841}, {"text": "directives and then you know all of the", "start": 3171.96, "duration": 4.44}, {"text": "all of the gpus are based basically C", "start": 3174.16, "duration": 3.84}, {"text": "and aook nowadays you know that's", "start": 3176.4, "duration": 5.52}, {"text": "embedded Hardware um the gaming gpus the", "start": 3178.0, "duration": 6.24}, {"text": "workstation gpus on the data cent of GPS", "start": 3181.92, "duration": 5.04}, {"text": "so you know if you have a a laptop that", "start": 3184.24, "duration": 4.839}, {"text": "has some sort of like uh or consumer", "start": 3186.96, "duration": 4.159}, {"text": "desktop you can you can write code there", "start": 3189.079, "duration": 4.04}, {"text": "right and Cuda is free you can download", "start": 3191.119, "duration": 3.401}, {"text": "it all for free you can just work on", "start": 3193.119, "duration": 4.281}, {"text": "your laptop and play around with", "start": 3194.52, "duration": 6.48}, {"text": "it um so the cuer SDK and the toolkit", "start": 3197.4, "duration": 6.76}, {"text": "are free it contains the", "start": 3201.0, "duration": 6.68}, {"text": "um C and C++", "start": 3204.16, "duration": 6.12}, {"text": "compiler well really it contains the", "start": 3207.68, "duration": 4.72}, {"text": "cuter C compiler so it's nbcc it's the", "start": 3210.28, "duration": 4.6}, {"text": "cter compiler and it uses the underlying", "start": 3212.4, "duration": 6.919}, {"text": "um system C and C++ compiling okay um to", "start": 3214.88, "duration": 7.36}, {"text": "to to compile this the CPU portion of", "start": 3219.319, "duration": 5.04}, {"text": "the code then it comes with all sorts of", "start": 3222.24, "duration": 4.04}, {"text": "libraries it comes with debugging tools", "start": 3224.359, "duration": 6.72}, {"text": "so C GDB UD M Che um there's profiling", "start": 3226.28, "duration": 8.36}, {"text": "tools um so nvpr and envy VP that's a", "start": 3231.079, "duration": 5.801}, {"text": "visual Prof profiler they're still in", "start": 3234.64, "duration": 4.28}, {"text": "there but they're being deprecated so", "start": 3236.88, "duration": 3.76}, {"text": "Nvidia is really pushing their inside", "start": 3238.92, "duration": 4.8}, {"text": "systems and inside compute to get an", "start": 3240.64, "duration": 6.08}, {"text": "overview of the um inside systems gives", "start": 3243.72, "duration": 5.2}, {"text": "you an overview so I'm not going into", "start": 3246.72, "duration": 5.52}, {"text": "that but it gives you an overview", "start": 3248.92, "duration": 5.96}, {"text": "of the entire runtime of your code you", "start": 3252.24, "duration": 4.68}, {"text": "know how much time is spent on the CPU", "start": 3254.88, "duration": 3.84}, {"text": "where when are your KS launched when are", "start": 3256.92, "duration": 3.48}, {"text": "you running on the GPU how much data", "start": 3258.72, "duration": 3.599}, {"text": "transfer and so on and then inside", "start": 3260.4, "duration": 3.679}, {"text": "compute is for each function for each", "start": 3262.319, "duration": 3.641}, {"text": "kernel it's called a kernel it's", "start": 3264.079, "duration": 3.28}, {"text": "basically a function that executes on", "start": 3265.96, "duration": 4.32}, {"text": "the GP a function that you wrote and you", "start": 3267.359, "duration": 5.44}, {"text": "can analyze that in detail about you", "start": 3270.28, "duration": 5.039}, {"text": "know the the the you know memory", "start": 3272.799, "duration": 4.721}, {"text": "bandwidth the data transfers all the", "start": 3275.319, "duration": 3.8}, {"text": "everything that's happening literally in", "start": 3277.52, "duration": 5.799}, {"text": "that um function so that you have a an", "start": 3279.119, "duration": 6.561}, {"text": "idea how to optimize your", "start": 3283.319, "duration": 5.721}, {"text": "code um then there's lots of cod samples", "start": 3285.68, "duration": 6.439}, {"text": "that used to be in the Cuda SDK they are", "start": 3289.04, "duration": 7.079}, {"text": "still in the Cuda SDK but um they're", "start": 3292.119, "duration": 7.881}, {"text": "um there's also nvh the Nvidia HPC SDK", "start": 3296.119, "duration": 5.641}, {"text": "that doesn't have code samples anymore", "start": 3300.0, "duration": 3.319}, {"text": "instead they are just on GitHub you can", "start": 3301.76, "duration": 4.12}, {"text": "just download them from this", "start": 3303.319, "duration": 5.201}, {"text": "link um there lots of information here", "start": 3305.88, "duration": 5.16}, {"text": "on this link here is where you can get", "start": 3308.52, "duration": 5.039}, {"text": "it and then if you want to use q and", "start": 3311.04, "duration": 5.68}, {"text": "expans is pretty simple you get onto GPU", "start": 3313.559, "duration": 6.28}, {"text": "node what I like to do is to do a module", "start": 3316.72, "duration": 4.76}, {"text": "Purge and a module", "start": 3319.839, "duration": 4.041}, {"text": "reset you don't have to do that but this", "start": 3321.48, "duration": 4.359}, {"text": "is just in case you know you have set", "start": 3323.88, "duration": 5.919}, {"text": "module and it remained loaded so", "start": 3325.839, "duration": 5.72}, {"text": "something that might be CPU specific or", "start": 3329.799, "duration": 4.361}, {"text": "different compiler and so on and that", "start": 3331.559, "duration": 5.0}, {"text": "interfers so often it's good to do a", "start": 3334.16, "duration": 4.56}, {"text": "purge start with a clean slate basically", "start": 3336.559, "duration": 4.48}, {"text": "module reset that will load the default", "start": 3338.72, "duration": 5.839}, {"text": "um modules for the GPU nodes which are", "start": 3341.039, "duration": 5.08}, {"text": "different so in the GPU noes you have", "start": 3344.559, "duration": 4.361}, {"text": "different um software available specific", "start": 3346.119, "duration": 5.041}, {"text": "to the GPU nodes than on the on the GPU", "start": 3348.92, "duration": 4.96}, {"text": "on the CPU nodes and then you say module", "start": 3351.16, "duration": 4.36}, {"text": "Lo tter", "start": 3353.88, "duration": 3.52}, {"text": "and it defaults to cter version 11", "start": 3355.52, "duration": 3.24}, {"text": "there's also an older version there's", "start": 3357.4, "duration": 3.639}, {"text": "different versions available if you need", "start": 3358.76, "duration": 5.88}, {"text": "that then we also have the HPC SDK which", "start": 3361.039, "duration": 5.56}, {"text": "basically replaces the cuter", "start": 3364.64, "duration": 4.719}, {"text": "toolkit um it contains most of the", "start": 3366.599, "duration": 4.0}, {"text": "toolkit", "start": 3369.359, "duration": 4.841}, {"text": "including you know the libraries um the", "start": 3370.599, "duration": 7.041}, {"text": "nvcc compiler debugger profiler it also", "start": 3374.2, "duration": 6.0}, {"text": "contains the Nvidia C and C++ and", "start": 3377.64, "duration": 5.0}, {"text": "fortron compilers they're called NV", "start": 3380.2, "duration": 5.639}, {"text": "fortron NVC and NV C++", "start": 3382.64, "duration": 5.04}, {"text": "uh and those are basically the compilers", "start": 3385.839, "duration": 4.041}, {"text": "that used to be PGI compilers so those", "start": 3387.68, "duration": 4.639}, {"text": "are those are those are good compilers", "start": 3389.88, "duration": 4.88}, {"text": "um and you can get that for free from", "start": 3392.319, "duration": 7.201}, {"text": "here if you want to load the NV HPC SDK", "start": 3394.76, "duration": 9.2}, {"text": "you just say modu load n HBC and", "start": 3399.52, "duration": 4.44}, {"text": "stuff", "start": 3404.16, "duration": 5.28}, {"text": "so you know if you have a c or C++ for", "start": 3406.079, "duration": 5.641}, {"text": "code", "start": 3409.44, "duration": 5.44}, {"text": "um you know there are three ways to use", "start": 3411.72, "duration": 6.76}, {"text": "to use gpus is use a library um if you", "start": 3414.88, "duration": 5.04}, {"text": "already use a library you just use the", "start": 3418.48, "duration": 3.48}, {"text": "GPU accelerated version it's basically", "start": 3419.92, "duration": 4.32}, {"text": "perfect you don't have to do", "start": 3421.96, "duration": 5.079}, {"text": "much um you can use directive", "start": 3424.24, "duration": 6.64}, {"text": "programming bya open ACD um that's an", "start": 3427.039, "duration": 6.401}, {"text": "easy way to accelerate applications that", "start": 3430.88, "duration": 4.159}, {"text": "are not too complex and of course you", "start": 3433.44, "duration": 4.24}, {"text": "can do that also for very complex", "start": 3435.039, "duration": 4.481}, {"text": "applications U but of course it will", "start": 3437.68, "duration": 4.76}, {"text": "take more time or you use explicitly Q", "start": 3439.52, "duration": 5.36}, {"text": "do as a programming language with", "start": 3442.44, "duration": 4.879}, {"text": "maximum F ability to get you know the", "start": 3444.88, "duration": 5.36}, {"text": "highest performance out of the", "start": 3447.319, "duration": 5.401}, {"text": "gpus um like I mentioned before tensor", "start": 3450.24, "duration": 4.24}, {"text": "FL and Pyro come with buil in GPU", "start": 3452.72, "duration": 4.0}, {"text": "support so you don't really need to know", "start": 3454.48, "duration": 4.119}, {"text": "anything about that", "start": 3456.72, "duration": 3.8}, {"text": "right", "start": 3458.599, "duration": 4.48}, {"text": "um", "start": 3460.52, "duration": 7.039}, {"text": "so here's an example basically", "start": 3463.079, "duration": 7.24}, {"text": "um there's actually additional ways", "start": 3467.559, "duration": 4.081}, {"text": "there there's new things as well", "start": 3470.319, "duration": 3.321}, {"text": "accelerated standard languages that's", "start": 3471.64, "duration": 6.56}, {"text": "you know very recent ISO C++ and ISO for", "start": 3473.64, "duration": 9.0}, {"text": "standards um where nvs compilers can", "start": 3478.2, "duration": 7.44}, {"text": "actually um you know if you if you", "start": 3482.64, "duration": 4.36}, {"text": "mention that you want to do something in", "start": 3485.64, "duration": 2.8}, {"text": "parallel for instance here you have a", "start": 3487.0, "duration": 3.2}, {"text": "loop you can say do concurrent instead", "start": 3488.44, "duration": 3.52}, {"text": "of just doing end do", "start": 3490.2, "duration": 6.08}, {"text": "right um and the compiler will basically", "start": 3491.96, "duration": 6.879}, {"text": "um compile that code offloaded to the", "start": 3496.28, "duration": 4.96}, {"text": "GPU and do that in parallel for", "start": 3498.839, "duration": 6.2}, {"text": "you um that's pretty fancy that's some", "start": 3501.24, "duration": 5.44}, {"text": "very new", "start": 3505.039, "duration": 3.841}, {"text": "um if you", "start": 3506.68, "duration": 6.32}, {"text": "have um something like Pyon you can use", "start": 3508.88, "duration": 8.76}, {"text": "Q numeric and it will do the the the the", "start": 3513.0, "duration": 6.24}, {"text": "um it will parallelize basically", "start": 3517.64, "duration": 4.679}, {"text": "automatically similar to numai you know", "start": 3519.24, "duration": 6.0}, {"text": "it will use automatically fast libraries", "start": 3522.319, "duration": 4.441}, {"text": "and it will use automatically fast", "start": 3525.24, "duration": 3.119}, {"text": "libraries on the", "start": 3526.76, "duration": 4.559}, {"text": "gpus um that's incremental portable", "start": 3528.359, "duration": 4.601}, {"text": "optimization so we'll look into more", "start": 3531.319, "duration": 3.401}, {"text": "detail into that it's you know opening", "start": 3532.96, "duration": 3.599}, {"text": "ACC you have these", "start": 3534.72, "duration": 3.8}, {"text": "pragmas", "start": 3536.559, "duration": 4.361}, {"text": "and that you insert into your code and", "start": 3538.52, "duration": 4.599}, {"text": "then that compiler will basically you", "start": 3540.92, "duration": 3.8}, {"text": "know in this section here says okay from", "start": 3543.119, "duration": 4.161}, {"text": "here to here um I'm doing some", "start": 3544.72, "duration": 5.56}, {"text": "optimizations and um we upload it to the", "start": 3547.28, "duration": 5.68}, {"text": "GPU or you write the code yourself you", "start": 3550.28, "duration": 5.36}, {"text": "have these you know keywords", "start": 3552.96, "duration": 6.119}, {"text": "and um predefined variables that you use", "start": 3555.64, "duration": 5.8}, {"text": "and you manage the memory with memory", "start": 3559.079, "duration": 4.161}, {"text": "copies and then you launch the kernels", "start": 3561.44, "duration": 3.879}, {"text": "with some sort of exess appication here", "start": 3563.24, "duration": 3.839}, {"text": "on the cor is dis thing and this will", "start": 3565.319, "duration": 4.24}, {"text": "then run in parallel on the GQ and I", "start": 3567.079, "duration": 3.96}, {"text": "will try", "start": 3569.559, "duration": 6.321}, {"text": "to to tell you how this works", "start": 3571.039, "duration": 4.841}, {"text": "um so we'll briefly walk through GPU", "start": 3576.64, "duration": 5.12}, {"text": "enabled libraries", "start": 3579.119, "duration": 5.321}, {"text": "and then we'll look at q c program", "start": 3581.76, "duration": 4.76}, {"text": "Basics", "start": 3584.44, "duration": 6.0}, {"text": "okay so those are easy to use you don't", "start": 3586.52, "duration": 6.92}, {"text": "know need to know much about GPU", "start": 3590.44, "duration": 5.0}, {"text": "programming um it's a drop in", "start": 3593.44, "duration": 4.08}, {"text": "acceleration basically the libraries", "start": 3595.44, "duration": 4.359}, {"text": "follow standard apis they minimal code", "start": 3597.52, "duration": 4.559}, {"text": "changes required and they are high", "start": 3599.799, "duration": 5.28}, {"text": "quality are in tuned by experts so uh", "start": 3602.079, "duration": 5.52}, {"text": "use those if you can um you know you", "start": 3605.079, "duration": 4.361}, {"text": "don't want to write your own matrix", "start": 3607.599, "duration": 3.921}, {"text": "multiplication um because you won't get", "start": 3609.44, "duration": 4.119}, {"text": "the same performance of course than", "start": 3611.52, "duration": 3.48}, {"text": "something that has been optimized over", "start": 3613.559, "duration": 3.48}, {"text": "the years by people who don't do", "start": 3615.0, "duration": 3.76}, {"text": "anything", "start": 3617.039, "duration": 3.8}, {"text": "else so there's a wide range of", "start": 3618.76, "duration": 4.76}, {"text": "libraries here's a link um just take a", "start": 3620.839, "duration": 5.52}, {"text": "look at them is something for every", "start": 3623.52, "duration": 4.599}, {"text": "flavor of science to", "start": 3626.359, "duration": 5.281}, {"text": "do and here's an example where we're", "start": 3628.119, "duration": 6.521}, {"text": "going to use um the", "start": 3631.64, "duration": 6.52}, {"text": "Saxy blast function as an example so", "start": 3634.64, "duration": 5.0}, {"text": "that's a single", "start": 3638.16, "duration": 5.12}, {"text": "Precision a * x + y so this is basically", "start": 3639.64, "duration": 6.479}, {"text": "a vector addition operation if you want", "start": 3643.28, "duration": 5.079}, {"text": "to use CU you just call the CU SXP", "start": 3646.119, "duration": 4.2}, {"text": "function instead and then you have to do", "start": 3648.359, "duration": 4.401}, {"text": "something else where you have to manage", "start": 3650.319, "duration": 4.52}, {"text": "the data locality you can use computer", "start": 3652.76, "duration": 4.2}, {"text": "functions for that to allocate the", "start": 3654.839, "duration": 5.801}, {"text": "memory and copy data from the CPU to the", "start": 3656.96, "duration": 6.599}, {"text": "GPU and back or there are Q blast", "start": 3660.64, "duration": 4.28}, {"text": "functions for that you know if you", "start": 3663.559, "duration": 2.961}, {"text": "operate with vectors you know just", "start": 3664.92, "duration": 4.32}, {"text": "there's a function for this that might", "start": 3666.52, "duration": 6.2}, {"text": "make it easier for you um to understand", "start": 3669.24, "duration": 5.68}, {"text": "and once you've done that you just use", "start": 3672.72, "duration": 3.92}, {"text": "the nvcc", "start": 3674.92, "duration": 4.159}, {"text": "compiler and you link against the Q", "start": 3676.64, "duration": 4.719}, {"text": "blast Library", "start": 3679.079, "duration": 5.76}, {"text": "okay and that's basically it so here's", "start": 3681.359, "duration": 7.76}, {"text": "this example of this um a * x + y and", "start": 3684.839, "duration": 6.72}, {"text": "store it back into y so that's the sa", "start": 3689.119, "duration": 5.401}, {"text": "xpy function in the glass", "start": 3691.559, "duration": 5.361}, {"text": "library and so here's an", "start": 3694.52, "duration": 6.039}, {"text": "example where um you have n data", "start": 3696.92, "duration": 6.36}, {"text": "elements this is a so two * so what", "start": 3700.559, "duration": 5.681}, {"text": "we're doing is basically y", "start": 3703.28, "duration": 7.72}, {"text": "equals uh 2 * x + y and and and these", "start": 3706.24, "duration": 8.039}, {"text": "are just the pointers to my arrays X and", "start": 3711.0, "duration": 4.4}, {"text": "Y", "start": 3714.279, "duration": 3.681}, {"text": "I prefix them here with d", "start": 3715.4, "duration": 5.28}, {"text": "because they wouldn't be prefixed but", "start": 3717.96, "duration": 4.399}, {"text": "usually", "start": 3720.68, "duration": 4.96}, {"text": "um when we write compter code you know", "start": 3722.359, "duration": 4.841}, {"text": "sometimes it's helpful to say okay this", "start": 3725.64, "duration": 4.88}, {"text": "is a pointer to device memory so we call", "start": 3727.2, "duration": 6.52}, {"text": "device memory means the GPU memory um so", "start": 3730.52, "duration": 5.2}, {"text": "we prefix it with a d to", "start": 3733.72, "duration": 4.0}, {"text": "distinguish um but other than that you", "start": 3735.72, "duration": 6.16}, {"text": "know we just instead of sxy we call Q", "start": 3737.72, "duration": 7.24}, {"text": "Plus sa xpy um", "start": 3741.88, "duration": 5.919}, {"text": "we have to initialize um the Q Plus", "start": 3744.96, "duration": 5.839}, {"text": "Library create a handle here um destroy", "start": 3747.799, "duration": 4.161}, {"text": "it", "start": 3750.799, "duration": 3.921}, {"text": "again then we have to allocate memory so", "start": 3751.96, "duration": 4.44}, {"text": "we have to allocate", "start": 3754.72, "duration": 4.119}, {"text": "here on these pointers so you want to", "start": 3756.4, "duration": 3.679}, {"text": "have", "start": 3758.839, "duration": 5.52}, {"text": "now X and Y those arrays we want to", "start": 3760.079, "duration": 7.24}, {"text": "have um you know storage space on the", "start": 3764.359, "duration": 5.24}, {"text": "GPU for those so we allocate", "start": 3767.319, "duration": 5.0}, {"text": "memory and you know we have n elements", "start": 3769.599, "duration": 4.921}, {"text": "so n times the size of a floating point", "start": 3772.319, "duration": 4.52}, {"text": "number so we allocate basically n", "start": 3774.52, "duration": 5.4}, {"text": "elements in those at this at this memory", "start": 3776.839, "duration": 5.48}, {"text": "location and then we use this CU set", "start": 3779.92, "duration": 4.159}, {"text": "Vector function which does nothing else", "start": 3782.319, "duration": 5.52}, {"text": "than basically copying the content of X", "start": 3784.079, "duration": 6.28}, {"text": "so X wee I assume here that we have X", "start": 3787.839, "duration": 6.48}, {"text": "and Y on the CPU in the CPU memory and", "start": 3790.359, "duration": 7.2}, {"text": "this just tells it well copy in of these", "start": 3794.319, "duration": 5.04}, {"text": "elements", "start": 3797.559, "duration": 5.04}, {"text": "um from the CPU to the GPU right and", "start": 3799.359, "duration": 5.92}, {"text": "then when we done we want to copy the", "start": 3802.599, "duration": 5.081}, {"text": "result back as a CU plus get Vector", "start": 3805.279, "duration": 4.601}, {"text": "function and now we want to copy the", "start": 3807.68, "duration": 6.159}, {"text": "result back from D so our device to our", "start": 3809.88, "duration": 6.64}, {"text": "CPU right so we read the data back and", "start": 3813.839, "duration": 5.361}, {"text": "that's all that you need to do and", "start": 3816.52, "duration": 5.079}, {"text": "instead of doing that", "start": 3819.2, "duration": 4.96}, {"text": "sxy operation on the", "start": 3821.599, "duration": 6.361}, {"text": "CPU it will copy the input data to the", "start": 3824.16, "duration": 6.679}, {"text": "GPU you run it on the GPU and then you", "start": 3827.96, "duration": 5.2}, {"text": "copy the output data back and then you", "start": 3830.839, "duration": 4.72}, {"text": "you know release the memory again so", "start": 3833.16, "duration": 7.399}, {"text": "that's what you have to do and um yeah", "start": 3835.559, "duration": 7.401}, {"text": "that's basically all right so in a", "start": 3840.559, "duration": 4.961}, {"text": "similar way you can use other other", "start": 3842.96, "duration": 4.879}, {"text": "libraries and and and you know those", "start": 3845.52, "duration": 5.2}, {"text": "will then effectively run on your", "start": 3847.839, "duration": 5.44}, {"text": "GP um the only thing you have to keep in", "start": 3850.72, "duration": 4.28}, {"text": "mind", "start": 3853.279, "duration": 4.56}, {"text": "is as a xpy you probably won't see a", "start": 3855.0, "duration": 5.0}, {"text": "great speed up because this is actually", "start": 3857.839, "duration": 3.561}, {"text": "doing many operations but if you do a", "start": 3860.0, "duration": 3.559}, {"text": "matrix multiplication that's a lot of", "start": 3861.4, "duration": 4.879}, {"text": "computation is being done in comparison", "start": 3863.559, "duration": 4.921}, {"text": "to the data that you have to transfer", "start": 3866.279, "duration": 5.441}, {"text": "from the CPU to the GPU so you will see", "start": 3868.48, "duration": 5.879}, {"text": "big speed ups at least once the size of", "start": 3871.72, "duration": 4.599}, {"text": "the Matrix becomes sufficiently large", "start": 3874.359, "duration": 4.081}, {"text": "right in this case you'll spend probably", "start": 3876.319, "duration": 3.641}, {"text": "more time allocating memory and", "start": 3878.44, "duration": 3.24}, {"text": "transferring the data from the CPU to", "start": 3879.96, "duration": 6.72}, {"text": "the GPU then doing this sa xpy", "start": 3881.68, "duration": 5.0}, {"text": "function", "start": 3887.52, "duration": 3.0}, {"text": "um just talking about numerical", "start": 3891.559, "duration": 4.76}, {"text": "Computing in Pon I just want to mention", "start": 3894.319, "duration": 4.121}, {"text": "that um you know if you're familiar for", "start": 3896.319, "duration": 4.321}, {"text": "instance with numpy uh there's something", "start": 3898.44, "duration": 6.52}, {"text": "called qy um and it has an ire like", "start": 3900.64, "duration": 6.959}, {"text": "interface and it's trivial to Port the", "start": 3904.96, "duration": 5.319}, {"text": "code to the GPU in this case", "start": 3907.599, "duration": 5.081}, {"text": "um so you know you", "start": 3910.279, "duration": 5.161}, {"text": "have this is highly tuned for CPUs and", "start": 3912.68, "duration": 5.679}, {"text": "so if you have code you have n code it's", "start": 3915.44, "duration": 6.639}, {"text": "very very easy to to get that over", "start": 3918.359, "duration": 7.361}, {"text": "to gpus um have the number crunching", "start": 3922.079, "duration": 5.681}, {"text": "done on the gpus and there's data", "start": 3925.72, "duration": 3.599}, {"text": "interoperability with deep learning", "start": 3927.76, "duration": 3.599}, {"text": "Frameworks as well there Rapids", "start": 3929.319, "duration": 3.72}, {"text": "framework", "start": 3931.359, "duration": 4.76}, {"text": "number and it uses these highly ched", "start": 3933.039, "duration": 4.881}, {"text": "invid libraries you can also write", "start": 3936.119, "duration": 3.521}, {"text": "custom cuter functions I've never done", "start": 3937.92, "duration": 5.439}, {"text": "that so um but if you know cter then", "start": 3939.64, "duration": 7.88}, {"text": "can't be very hard but here's an example", "start": 3943.359, "duration": 6.48}, {"text": "where you know this is running say um", "start": 3947.52, "duration": 5.0}, {"text": "serially on a on a", "start": 3949.839, "duration": 5.361}, {"text": "CPU and", "start": 3952.52, "duration": 6.599}, {"text": "this is just doing a a a um QR", "start": 3955.2, "duration": 6.839}, {"text": "factorization I guess of the you know a", "start": 3959.119, "duration": 6.24}, {"text": "linear algebra basically um package in", "start": 3962.039, "duration": 6.8}, {"text": "numpy and I I suppose QR is just doing a", "start": 3965.359, "duration": 6.68}, {"text": "QR factorization of this Matrix a um", "start": 3968.839, "duration": 4.801}, {"text": "that we have initialized here so", "start": 3972.039, "duration": 4.441}, {"text": "Dimension 496 by", "start": 3973.64, "duration": 5.36}, {"text": "496 and you see how easy it is right you", "start": 3976.48, "duration": 5.359}, {"text": "just say instead of npy you use", "start": 3979.0, "duration": 6.52}, {"text": "QP and that's it you know it will", "start": 3981.839, "duration": 6.0}, {"text": "automatically basically run on the GPU", "start": 3985.52, "duration": 4.48}, {"text": "for you and in this case you know for", "start": 3987.839, "duration": 4.28}, {"text": "this example you get well it says for", "start": 3990.0, "duration": 4.599}, {"text": "52x speed up so I got that slide from", "start": 3992.119, "duration": 4.761}, {"text": "Nvidia um and you'll notice you know", "start": 3994.599, "duration": 3.76}, {"text": "this is like with this benchmarks well", "start": 3996.88, "duration": 3.199}, {"text": "what does that mean right I mean What", "start": 3998.359, "duration": 3.72}, {"text": "GPU were you running on what CPU were", "start": 4000.079, "duration": 3.801}, {"text": "you running on so I don't know you know", "start": 4002.079, "duration": 3.76}, {"text": "could could be anything anywhere between", "start": 4003.88, "duration": 5.8}, {"text": "20 to 100x I don't know but it's going", "start": 4005.839, "duration": 9.121}, {"text": "to run very eff the G okay", "start": 4009.68, "duration": 7.96}, {"text": "so that's what I wanted to tell you", "start": 4014.96, "duration": 5.879}, {"text": "about libraries and now QC QC", "start": 4017.64, "duration": 4.88}, {"text": "programming basically let me look at the", "start": 4020.839, "duration": 6.881}, {"text": "time it's almost noon um it will take me", "start": 4022.52, "duration": 7.0}, {"text": "quite some time to go through those", "start": 4027.72, "duration": 3.68}, {"text": "programming Basics", "start": 4029.52, "duration": 6.039}, {"text": "so we have one and a half hours", "start": 4031.4, "duration": 8.76}, {"text": "left um and so we spent basically half", "start": 4035.559, "duration": 6.8}, {"text": "of the time until here I was hoping we", "start": 4040.16, "duration": 4.439}, {"text": "could we were a little bit further", "start": 4042.359, "duration": 3.841}, {"text": "but let me get started with PC", "start": 4044.599, "duration": 3.801}, {"text": "programming", "start": 4046.2, "duration": 4.68}, {"text": "Basics", "start": 4048.4, "duration": 6.199}, {"text": "um yeah then let's take a a brief brief", "start": 4050.88, "duration": 5.32}, {"text": "Break", "start": 4054.599, "duration": 4.601}, {"text": "um let's go until let's go for a few", "start": 4056.2, "duration": 4.919}, {"text": "minutes and then when I find a good spot", "start": 4059.2, "duration": 5.04}, {"text": "I will take a a brief break so everybody", "start": 4061.119, "duration": 4.841}, {"text": "can catch their breath okay we might", "start": 4064.24, "duration": 4.96}, {"text": "just make maybe a 10 minutes", "start": 4065.96, "duration": 3.24}, {"text": "break so you can get cuter from and you", "start": 4069.68, "duration": 6.08}, {"text": "know get information", "start": 4073.72, "duration": 7.16}, {"text": "here so there's q c and Q foron and Q C", "start": 4075.76, "duration": 7.16}, {"text": "and or C++ is basically a solution to", "start": 4080.88, "duration": 4.88}, {"text": "run CN or C++ seamlessly in", "start": 4082.92, "duration": 7.84}, {"text": "gpus and um it has modest extensions so", "start": 4085.76, "duration": 6.48}, {"text": "it's not that hard to learn in some", "start": 4090.76, "duration": 4.799}, {"text": "sense there's not many things to learn", "start": 4092.24, "duration": 5.28}, {"text": "but there's much to learn about how the", "start": 4095.559, "duration": 3.64}, {"text": "road code needs to be structured and you", "start": 4097.52, "duration": 3.279}, {"text": "need to think in you know this parallel", "start": 4099.199, "duration": 3.361}, {"text": "thinking this data parallel thinking and", "start": 4100.799, "duration": 5.681}, {"text": "needs often major writing of code um and", "start": 4102.56, "duration": 6.799}, {"text": "and there are cter extensions in Porton", "start": 4106.48, "duration": 5.04}, {"text": "that were developed by Portland group", "start": 4109.359, "duration": 5.281}, {"text": "and they are available in the med F and", "start": 4111.52, "duration": 5.08}, {"text": "compiler", "start": 4114.64, "duration": 4.559}, {"text": "um here's some recommended reading if", "start": 4116.6, "duration": 4.199}, {"text": "you want to know more these are older", "start": 4119.199, "duration": 3.241}, {"text": "books already but still good or you just", "start": 4120.799, "duration": 3.92}, {"text": "Google there's many many resources", "start": 4122.44, "duration": 6.719}, {"text": "here the um GPU hackathon uh they're", "start": 4124.719, "duration": 10.48}, {"text": "organized by um open ACC and Nvidia um", "start": 4129.159, "duration": 7.52}, {"text": "there's a lot of Technical Resources a", "start": 4135.199, "duration": 4.52}, {"text": "lot of information um you know the QC", "start": 4136.679, "duration": 4.56}, {"text": "and forun programming guides are", "start": 4139.719, "duration": 3.44}, {"text": "actually not not too hard to read quite", "start": 4141.239, "duration": 4.08}, {"text": "interesting so lots of information out", "start": 4143.159, "duration": 5.16}, {"text": "there", "start": 4145.319, "duration": 3.0}, {"text": "so I you know we talking about the CPU", "start": 4148.4, "duration": 5.439}, {"text": "and the GPU and so on a lot so often", "start": 4152.08, "duration": 4.56}, {"text": "you'll hear host and device and what", "start": 4153.839, "duration": 5.721}, {"text": "people mean is host is that's the CPU", "start": 4156.64, "duration": 4.0}, {"text": "and its", "start": 4159.56, "duration": 3.759}, {"text": "memory um you know that is hosting that", "start": 4160.64, "duration": 4.28}, {"text": "device and the device is basically the", "start": 4163.319, "duration": 4.92}, {"text": "GQ right in its memory and so you write", "start": 4164.92, "duration": 7.52}, {"text": "code that starts to execute on the CPU", "start": 4168.239, "duration": 6.201}, {"text": "so on the host code and then it's", "start": 4172.44, "duration": 4.04}, {"text": "launched from the host code so how this", "start": 4174.44, "duration": 3.359}, {"text": "looks like is you know you have your", "start": 4176.48, "duration": 3.0}, {"text": "serial CPU", "start": 4177.799, "duration": 3.56}, {"text": "code", "start": 4179.48, "duration": 4.719}, {"text": "um of course it can be NPI or open and P", "start": 4181.359, "duration": 5.201}, {"text": "parallel as well but you know in general", "start": 4184.199, "duration": 4.48}, {"text": "it's like serial code and then you", "start": 4186.56, "duration": 5.159}, {"text": "launch a kernel that runs on a GPU with", "start": 4188.679, "duration": 5.16}, {"text": "many threads and the threads they group", "start": 4191.719, "duration": 3.801}, {"text": "into blocks and those blocks are grouped", "start": 4193.839, "duration": 3.801}, {"text": "into grid and that maps onto the", "start": 4195.52, "duration": 4.44}, {"text": "multiprocessors of the GPU right and", "start": 4197.64, "duration": 6.0}, {"text": "then so you have this kernel launch here", "start": 4199.96, "duration": 6.16}, {"text": "so serial code parallel code and then", "start": 4203.64, "duration": 4.36}, {"text": "you can do something serial again and", "start": 4206.12, "duration": 3.44}, {"text": "then parallel and so that's typically", "start": 4208.0, "duration": 4.44}, {"text": "how it looks like so you have your host", "start": 4209.56, "duration": 5.92}, {"text": "the CPU and its memory um sitting on a", "start": 4212.44, "duration": 6.64}, {"text": "PCI Express bus um connected to the", "start": 4215.48, "duration": 5.96}, {"text": "device you copy your input data from the", "start": 4219.08, "duration": 5.4}, {"text": "CPU to the GPU memories so that's a GPU", "start": 4221.44, "duration": 5.12}, {"text": "which with its own memory and you know", "start": 4224.48, "duration": 4.32}, {"text": "you see here these multiprocessors each", "start": 4226.56, "duration": 5.119}, {"text": "multiprocessor has many compute cores", "start": 4228.8, "duration": 4.84}, {"text": "has his own uh cache memory and then", "start": 4231.679, "duration": 4.0}, {"text": "there's this this level two cache that", "start": 4233.64, "duration": 4.16}, {"text": "that caches data and and instructions", "start": 4235.679, "duration": 4.601}, {"text": "for all the U", "start": 4237.8, "duration": 4.48}, {"text": "multiprocessors so after you've loaded", "start": 4240.28, "duration": 4.76}, {"text": "the data you know then you you you load", "start": 4242.28, "duration": 5.6}, {"text": "the GPU program so you run launch your", "start": 4245.04, "duration": 5.28}, {"text": "kernels right um or a function Library", "start": 4247.88, "duration": 4.76}, {"text": "call right like the CU s", "start": 4250.32, "duration": 5.96}, {"text": "speed and it executes on the on the GPU", "start": 4252.64, "duration": 5.64}, {"text": "so you issue an instruction from the CPU", "start": 4256.28, "duration": 4.2}, {"text": "that tells the you know I video is", "start": 4258.28, "duration": 3.879}, {"text": "called Giga thread engine but basically", "start": 4260.48, "duration": 4.32}, {"text": "the scheduler on the device okay now", "start": 4262.159, "duration": 4.441}, {"text": "launch all these threats and operate on", "start": 4264.8, "duration": 3.56}, {"text": "that data in the way that I've", "start": 4266.6, "duration": 4.48}, {"text": "programmed in the corresponding function", "start": 4268.36, "duration": 3.92}, {"text": "and when you're done you copy your", "start": 4271.08, "duration": 4.76}, {"text": "results back and so that's the", "start": 4272.28, "duration": 6.959}, {"text": "workflow um I mentioned this unified", "start": 4275.84, "duration": 6.0}, {"text": "memory um that you can use", "start": 4279.239, "duration": 5.281}, {"text": "um and that's a pool memory that's", "start": 4281.84, "duration": 4.359}, {"text": "shared between host and device so that's", "start": 4284.52, "duration": 4.48}, {"text": "a productivity feature um the memory", "start": 4286.199, "duration": 5.0}, {"text": "copies you know you don't see that you", "start": 4289.0, "duration": 4.92}, {"text": "just say oh here's my unified memory and", "start": 4291.199, "duration": 5.0}, {"text": "then you pass that memory to the CPU", "start": 4293.92, "duration": 5.16}, {"text": "functions and to the GPU functions and", "start": 4296.199, "duration": 4.161}, {"text": "but under the hood of course you know", "start": 4299.08, "duration": 2.76}, {"text": "you still have the same Hardware so", "start": 4300.36, "duration": 3.2}, {"text": "there the data copy still happen so you", "start": 4301.84, "duration": 4.52}, {"text": "need to be aware of that but", "start": 4303.56, "duration": 7.04}, {"text": "um and yeah so how does does does does", "start": 4306.36, "duration": 7.96}, {"text": "GP code look like in pter um", "start": 4310.6, "duration": 6.32}, {"text": "here a very very simple Hello World um", "start": 4314.32, "duration": 5.28}, {"text": "on the left hand side that's just C so", "start": 4316.92, "duration": 4.4}, {"text": "I'm I'm I'm working with C now here in", "start": 4319.6, "duration": 4.119}, {"text": "the slides um I hope you know some of", "start": 4321.32, "duration": 5.16}, {"text": "you may not know see if you know see", "start": 4323.719, "duration": 5.881}, {"text": "then that will be trivial um this just", "start": 4326.48, "duration": 5.239}, {"text": "prints hello world", "start": 4329.6, "duration": 6.28}, {"text": "right um and you can actually compile", "start": 4331.719, "duration": 8.881}, {"text": "this if you store this in in a docu file", "start": 4335.88, "duration": 7.64}, {"text": "um that's typically the ex um the", "start": 4340.6, "duration": 5.72}, {"text": "extension that you use for Cuda file um", "start": 4343.52, "duration": 4.32}, {"text": "you can compile this with the Nvidia", "start": 4346.32, "duration": 3.68}, {"text": "Cuda compiler what the cuder compiler", "start": 4347.84, "duration": 4.399}, {"text": "basically does it separates the source", "start": 4350.0, "duration": 5.4}, {"text": "code into host and device code and", "start": 4352.239, "duration": 8.201}, {"text": "invokes the host um compiler that can be", "start": 4355.4, "duration": 6.72}, {"text": "uh you know the glue compiler for", "start": 4360.44, "duration": 4.84}, {"text": "instance or the Intel compiler so GCC or", "start": 4362.12, "duration": 7.2}, {"text": "um um ipcc or corresponding foron", "start": 4365.28, "duration": 7.16}, {"text": "compilers if you have foron code right", "start": 4369.32, "duration": 6.16}, {"text": "um and then links everything together", "start": 4372.44, "duration": 4.32}, {"text": "and if you run that you know you'll see", "start": 4375.48, "duration": 5.08}, {"text": "Hello word world and now if you do that", "start": 4376.76, "duration": 5.879}, {"text": "want to do that from the", "start": 4380.56, "duration": 5.119}, {"text": "GPU um now you do these funky things you", "start": 4382.639, "duration": 5.441}, {"text": "have a global underscore uncore Global", "start": 4385.679, "duration": 6.081}, {"text": "uncore uncore keyword that indicates a", "start": 4388.08, "duration": 5.8}, {"text": "function that should run on the GPU but", "start": 4391.76, "duration": 6.879}, {"text": "can be called from the CPU okay uh this", "start": 4393.88, "duration": 6.4}, {"text": "function doesn't do anything it", "start": 4398.639, "duration": 3.08}, {"text": "literally doesn't do anything you can", "start": 4400.28, "duration": 3.68}, {"text": "actually print from kernel um that was", "start": 4401.719, "duration": 3.92}, {"text": "not the case in the past but you can do", "start": 4403.96, "duration": 4.32}, {"text": "that now um this is a kernel that's", "start": 4405.639, "duration": 4.241}, {"text": "empty so it really doesn't do anything", "start": 4408.28, "duration": 4.56}, {"text": "but you can compile it and so you have", "start": 4409.88, "duration": 6.0}, {"text": "this function my kernel and now in your", "start": 4412.84, "duration": 6.24}, {"text": "host source code um You can call that", "start": 4415.88, "duration": 5.52}, {"text": "function with this funky nomenclature", "start": 4419.08, "duration": 4.2}, {"text": "here and that basically tells how many", "start": 4421.4, "duration": 2.96}, {"text": "threats you're", "start": 4423.28, "duration": 3.28}, {"text": "launching so this is really not doing", "start": 4424.36, "duration": 4.24}, {"text": "anything but we've seen the syntactic", "start": 4426.56, "duration": 4.8}, {"text": "elements about that function that runs", "start": 4428.6, "duration": 4.4}, {"text": "on the device but can be called from The", "start": 4431.36, "duration": 2.96}, {"text": "Host", "start": 4433.0, "duration": 4.88}, {"text": "code and nvcc separates like I said the", "start": 4434.32, "duration": 5.0}, {"text": "source code into host and device", "start": 4437.88, "duration": 3.759}, {"text": "components and then you know the device", "start": 4439.32, "duration": 3.879}, {"text": "functions are processed internally by", "start": 4441.639, "duration": 3.841}, {"text": "MCC and the host functions are processed", "start": 4443.199, "duration": 6.561}, {"text": "for instance by GCC right", "start": 4445.48, "duration": 7.159}, {"text": "um the triple angle brackets Mark a call", "start": 4449.76, "duration": 4.56}, {"text": "from the host code to the device code", "start": 4452.639, "duration": 3.241}, {"text": "that's called the kernel", "start": 4454.32, "duration": 4.399}, {"text": "launch and you know those numbers are", "start": 4455.88, "duration": 4.24}, {"text": "the kernel launch configuration that", "start": 4458.719, "duration": 3.841}, {"text": "basically say how many threats I'm", "start": 4460.12, "duration": 5.519}, {"text": "launching okay so this colel doesn't do", "start": 4462.56, "duration": 4.88}, {"text": "anything", "start": 4465.639, "duration": 4.0}, {"text": "um", "start": 4467.44, "duration": 4.68}, {"text": "but let's try and do an addition on the", "start": 4469.639, "duration": 4.801}, {"text": "device so how would we do that so now", "start": 4472.12, "duration": 4.0}, {"text": "you see this is the", "start": 4474.44, "duration": 4.68}, {"text": "function our kernel we call it add and", "start": 4476.12, "duration": 5.039}, {"text": "now we are passing pointers to memory a", "start": 4479.12, "duration": 4.44}, {"text": "b and c or we just do an addition right", "start": 4481.159, "duration": 4.281}, {"text": "so Cals a plus", "start": 4483.56, "duration": 3.56}, {"text": "b", "start": 4485.44, "duration": 8.6}, {"text": "um so because this is a CU word keyword", "start": 4487.12, "duration": 9.96}, {"text": "um add will execute on the device and it", "start": 4494.04, "duration": 4.48}, {"text": "can be called from the", "start": 4497.08, "duration": 3.76}, {"text": "host it executes on this device", "start": 4498.52, "duration": 4.159}, {"text": "obviously adnc must point to device", "start": 4500.84, "duration": 4.44}, {"text": "memory right so how do we do", "start": 4502.679, "duration": 5.641}, {"text": "this um you know we have host pointers", "start": 4505.28, "duration": 4.8}, {"text": "that point to CPU memory just in your", "start": 4508.32, "duration": 5.8}, {"text": "normal C code and but we can we can pass", "start": 4510.08, "duration": 6.4}, {"text": "them to the device code so we can pass", "start": 4514.12, "duration": 5.24}, {"text": "the pointer address right we cannot D", "start": 4516.48, "duration": 5.239}, {"text": "reference them we cannot use them but", "start": 4519.36, "duration": 3.92}, {"text": "then we have device pointers so", "start": 4521.719, "duration": 3.161}, {"text": "basically Point as the point to memory", "start": 4523.28, "duration": 3.879}, {"text": "locations on the GPU and again those", "start": 4524.88, "duration": 4.92}, {"text": "cannot be reference in the host code and", "start": 4527.159, "duration": 4.641}, {"text": "then we use the cuter API to handle", "start": 4529.8, "duration": 4.839}, {"text": "device memory so we can allocate memory", "start": 4531.8, "duration": 5.0}, {"text": "Cuda Malo that's equivalent to Malo on", "start": 4534.639, "duration": 5.721}, {"text": "the CPU Huda free and qm copy that", "start": 4536.8, "duration": 5.12}, {"text": "handles the transfer of data from the", "start": 4540.36, "duration": 4.319}, {"text": "CPU to the GPU and back like you know", "start": 4541.92, "duration": 4.48}, {"text": "you've seen that already in", "start": 4544.679, "duration": 6.761}, {"text": "the um SX py example and then you know", "start": 4546.4, "duration": 7.239}, {"text": "this that's the equivalent to the", "start": 4551.44, "duration": 6.199}, {"text": "corresponding um C", "start": 4553.639, "duration": 4.0}, {"text": "functions so we have this", "start": 4558.76, "duration": 7.479}, {"text": "addition and so now here's a lot of code", "start": 4561.56, "duration": 8.2}, {"text": "um but don't", "start": 4566.239, "duration": 3.521}, {"text": "worry this is data that we have on the", "start": 4571.04, "duration": 5.4}, {"text": "this just just so I prefix it with h to", "start": 4574.04, "duration": 5.8}, {"text": "say host and D for device so we have a b", "start": 4576.44, "duration": 5.56}, {"text": "and c those are three integers they", "start": 4579.84, "duration": 4.12}, {"text": "exist on the", "start": 4582.0, "duration": 4.48}, {"text": "CPU and these are", "start": 4583.96, "duration": 8.56}, {"text": "Pointers right and what I do now is well", "start": 4586.48, "duration": 7.96}, {"text": "I want to have integers so I Define the", "start": 4592.52, "duration": 5.56}, {"text": "size here um a size of int I allocate", "start": 4594.44, "duration": 5.84}, {"text": "memory on the device right so I use the", "start": 4598.08, "duration": 3.44}, {"text": "talo", "start": 4600.28, "duration": 4.6}, {"text": "function and I get back a pointer to", "start": 4601.52, "duration": 4.96}, {"text": "memory that has been allocated on the", "start": 4604.88, "duration": 4.359}, {"text": "GPU and there certain amount in this", "start": 4606.48, "duration": 4.239}, {"text": "case you know just a single integer", "start": 4609.239, "duration": 2.841}, {"text": "that's", "start": 4610.719, "duration": 3.0}, {"text": "allocated", "start": 4612.08, "duration": 4.92}, {"text": "so now I have da and so on DB and", "start": 4613.719, "duration": 7.801}, {"text": "DC point to the memory address of of of", "start": 4617.0, "duration": 8.96}, {"text": "of an integer in the on the GPU right so", "start": 4621.52, "duration": 6.52}, {"text": "let's assume we have some input values", "start": 4625.96, "duration": 5.239}, {"text": "so this is St on the CPU now I can copy", "start": 4628.04, "duration": 6.199}, {"text": "the input data to the device I use the C", "start": 4631.199, "duration": 6.201}, {"text": "M Copy function uh with with this option", "start": 4634.239, "duration": 5.761}, {"text": "here Q copy host to device so I want to", "start": 4637.4, "duration": 4.16}, {"text": "copy from", "start": 4640.0, "duration": 4.36}, {"text": "host from host to the device so this the", "start": 4641.56, "duration": 5.679}, {"text": "Target and this is the source right I do", "start": 4644.36, "duration": 4.16}, {"text": "this for a and", "start": 4647.239, "duration": 4.241}, {"text": "b and now I have a and b on the GP now I", "start": 4648.52, "duration": 5.04}, {"text": "can launch my K so I call this add", "start": 4651.48, "duration": 4.36}, {"text": "function and I just launch a single", "start": 4653.56, "duration": 5.44}, {"text": "thread because I have only single number", "start": 4655.84, "duration": 5.48}, {"text": "right and when I'm done I copy the", "start": 4659.0, "duration": 5.52}, {"text": "results back so now I do a copy device", "start": 4661.32, "duration": 6.48}, {"text": "to host so from this device pointer back", "start": 4664.52, "duration": 6.52}, {"text": "to the host and I can I can free free", "start": 4667.8, "duration": 5.439}, {"text": "the memory and print the result so this", "start": 4671.04, "duration": 3.28}, {"text": "way we've", "start": 4673.239, "duration": 4.121}, {"text": "done something very convoluted to add", "start": 4674.32, "duration": 4.919}, {"text": "two numbers but the addition actually", "start": 4677.36, "duration": 3.0}, {"text": "happened on the", "start": 4679.239, "duration": 4.321}, {"text": "GPU right so that's the basic cuter", "start": 4680.36, "duration": 4.68}, {"text": "workflow you allocate memory on the", "start": 4683.56, "duration": 4.36}, {"text": "device copy input data to the device", "start": 4685.04, "duration": 4.84}, {"text": "launch a cuter kernel on the device and", "start": 4687.92, "duration": 4.16}, {"text": "then when you're done you copy results", "start": 4689.88, "duration": 4.759}, {"text": "back to the host and then you deallocate", "start": 4692.08, "duration": 5.0}, {"text": "memory on the device", "start": 4694.639, "duration": 4.481}, {"text": "okay", "start": 4697.08, "duration": 6.72}, {"text": "um let me see let me check my", "start": 4699.12, "duration": 7.039}, {"text": "briefly to", "start": 4703.8, "duration": 5.359}, {"text": "see what's", "start": 4706.159, "duration": 5.761}, {"text": "coming tradition yeah I we've been going", "start": 4709.159, "duration": 4.761}, {"text": "for a while let let's take a brief break", "start": 4711.92, "duration": 4.04}, {"text": "now and then and then I'll walk you", "start": 4713.92, "duration": 5.08}, {"text": "through let's let's meet back at", "start": 4715.96, "duration": 7.16}, {"text": "12 15 okay and then I'll show you", "start": 4719.0, "duration": 7.239}, {"text": "basically on Parallel Computing and the", "start": 4723.12, "duration": 5.2}, {"text": "GPU using", "start": 4726.239, "duration": 5.681}, {"text": "computer and if there's questions in the", "start": 4728.32, "duration": 7.56}, {"text": "meantime um feel free to", "start": 4731.92, "duration": 3.96}, {"text": "ask are we recording or is", "start": 4744.239, "duration": 7.801}, {"text": "it yes okay oh yeah I can no yeah I", "start": 4747.12, "duration": 7.64}, {"text": "thought I'd see some some notification", "start": 4752.04, "duration": 5.199}, {"text": "all right well welcome back everybody", "start": 4754.76, "duration": 5.2}, {"text": "hope everybody could take a brief Break", "start": 4757.239, "duration": 6.521}, {"text": "um so you know we've learned on you know", "start": 4759.96, "duration": 6.679}, {"text": "how we can load data onto the GPU and do", "start": 4763.76, "duration": 5.0}, {"text": "a computation on the GPU that was just a", "start": 4766.639, "duration": 5.321}, {"text": "single addition um but of course we want", "start": 4768.76, "duration": 7.399}, {"text": "to do this in parallel um so let's move", "start": 4771.96, "duration": 6.16}, {"text": "on to parallel", "start": 4776.159, "duration": 4.281}, {"text": "Computing how do we run our code in", "start": 4778.12, "duration": 4.24}, {"text": "parallel using cuter right so it's all", "start": 4780.44, "duration": 4.44}, {"text": "about massive parallelism and massive", "start": 4782.36, "duration": 4.24}, {"text": "parallelism because you know we have", "start": 4784.88, "duration": 3.759}, {"text": "thousands of threats that we need to", "start": 4786.6, "duration": 5.16}, {"text": "launch so much more than on on on what", "start": 4788.639, "duration": 5.52}, {"text": "we used to from CP", "start": 4791.76, "duration": 5.2}, {"text": "um well instead of executing the kernel", "start": 4794.159, "duration": 5.281}, {"text": "at once we just execute it end times in", "start": 4796.96, "duration": 5.679}, {"text": "parallel so if we have a problem that is", "start": 4799.44, "duration": 5.12}, {"text": "data parallel in a sense that we need to", "start": 4802.639, "duration": 4.681}, {"text": "do the same type of operation that is an", "start": 4804.56, "duration": 5.04}, {"text": "addition multiple times on different", "start": 4807.32, "duration": 4.68}, {"text": "data elements then we can parallelize", "start": 4809.6, "duration": 4.4}, {"text": "okay and so that's the central idea that", "start": 4812.0, "duration": 4.48}, {"text": "defines Computing so um the kernels", "start": 4814.0, "duration": 4.56}, {"text": "effectively look like serial", "start": 4816.48, "duration": 4.88}, {"text": "programs um we write the programs as if", "start": 4818.56, "duration": 5.079}, {"text": "they run on a single thread", "start": 4821.36, "duration": 4.16}, {"text": "um but we keep in mind that it's being", "start": 4823.639, "duration": 4.08}, {"text": "executed by many threats on different", "start": 4825.52, "duration": 7.0}, {"text": "data right the GP will do that for us so", "start": 4827.719, "duration": 6.361}, {"text": "and that we do with a kind of launch", "start": 4832.52, "duration": 3.24}, {"text": "configuration instead of launching one", "start": 4834.08, "duration": 4.159}, {"text": "copy we just launch end copies so these", "start": 4835.76, "duration": 5.399}, {"text": "are actually um the number of", "start": 4838.239, "duration": 5.201}, {"text": "blocks um there's a reason for so number", "start": 4841.159, "duration": 4.04}, {"text": "of blocks and these are thre for blocks", "start": 4843.44, "duration": 3.4}, {"text": "I get back to that", "start": 4845.199, "duration": 4.241}, {"text": "but um the GPU is good at affectionately", "start": 4846.84, "duration": 4.12}, {"text": "launching many", "start": 4849.44, "duration": 4.52}, {"text": "threats um many more than processes on", "start": 4850.96, "duration": 8.32}, {"text": "the device yeah so again why n identical", "start": 4853.96, "duration": 6.92}, {"text": "copies of the kernel doing the same", "start": 4859.28, "duration": 3.52}, {"text": "operation right that's if you have", "start": 4860.88, "duration": 4.96}, {"text": "something that is basically inherently", "start": 4862.8, "duration": 5.8}, {"text": "parallel like a vector addition for", "start": 4865.84, "duration": 5.12}, {"text": "instance as the most simple example you", "start": 4868.6, "duration": 4.88}, {"text": "know you see in a CPU J in serial", "start": 4870.96, "duration": 5.759}, {"text": "basically you go from element to element", "start": 4873.48, "duration": 4.88}, {"text": "and do the addition so you have a for", "start": 4876.719, "duration": 3.52}, {"text": "Loop in there so that for Loop you know", "start": 4878.36, "duration": 3.68}, {"text": "ideally you could parallelize it where", "start": 4880.239, "duration": 4.96}, {"text": "you know you just to each compute core", "start": 4882.04, "duration": 6.639}, {"text": "will operate in a different data uh uh", "start": 4885.199, "duration": 6.04}, {"text": "data and you know there's an addition of", "start": 4888.679, "duration": 5.161}, {"text": "the first element the next the other", "start": 4891.239, "duration": 4.521}, {"text": "while the other chord is on the second", "start": 4893.84, "duration": 4.2}, {"text": "element and so", "start": 4895.76, "duration": 6.64}, {"text": "on um so this is how our first version", "start": 4898.04, "duration": 6.199}, {"text": "of a parallelized ad kernel would look", "start": 4902.4, "duration": 4.36}, {"text": "like so there's a builtin variable", "start": 4904.239, "duration": 5.561}, {"text": "includer that's called block idx dox and", "start": 4906.76, "duration": 5.6}, {"text": "you know there's an X here because you", "start": 4909.8, "duration": 5.16}, {"text": "know can have multiple Dimensions so if", "start": 4912.36, "duration": 5.76}, {"text": "you say have a two-dimensional problem", "start": 4914.96, "duration": 4.8}, {"text": "like a matrix or three-dimensional", "start": 4918.12, "duration": 3.92}, {"text": "problem like a um Grid in three", "start": 4919.76, "duration": 5.04}, {"text": "dimensions you know or say I don't know", "start": 4922.04, "duration": 4.36}, {"text": "like we had in the quantum chemistry", "start": 4924.8, "duration": 6.16}, {"text": "example or say WEA WEA simulation um", "start": 4926.4, "duration": 6.239}, {"text": "then then it might be helpful to have a", "start": 4930.96, "duration": 6.199}, {"text": "threedimensional index thing and so", "start": 4932.639, "duration": 7.201}, {"text": "when this kernel", "start": 4937.159, "duration": 6.601}, {"text": "launches you know it knows its ID", "start": 4939.84, "duration": 7.04}, {"text": "it knows whether it's ID zero or one and", "start": 4943.76, "duration": 5.28}, {"text": "so on and so we can define a variable", "start": 4946.88, "duration": 4.759}, {"text": "where we assign the ID and then we just", "start": 4949.04, "duration": 5.08}, {"text": "let that thread with this ID being", "start": 4951.639, "duration": 4.481}, {"text": "operated on that corresponding element", "start": 4954.12, "duration": 7.28}, {"text": "in the array a b and c okay so by know", "start": 4956.12, "duration": 7.0}, {"text": "using its index each block operates in a", "start": 4961.4, "duration": 2.799}, {"text": "different", "start": 4963.12, "duration": 3.92}, {"text": "way and so we basically launch and", "start": 4964.199, "duration": 4.44}, {"text": "copies right so this is literally how it", "start": 4967.04, "duration": 3.24}, {"text": "looks like so block zero operates on", "start": 4968.639, "duration": 3.481}, {"text": "element zero block one operates on", "start": 4970.28, "duration": 5.12}, {"text": "element one at the same time and so on", "start": 4972.12, "duration": 5.44}, {"text": "um now this is not very convenient", "start": 4975.4, "duration": 3.96}, {"text": "because the colel call I mean first of", "start": 4977.56, "duration": 3.96}, {"text": "all this is always true the kernel call", "start": 4979.36, "duration": 3.64}, {"text": "needs to be consistent with the kernel", "start": 4981.52, "duration": 5.88}, {"text": "implementation right if I put an N here", "start": 4983.0, "duration": 7.6}, {"text": "um the colel itself must be written such", "start": 4987.4, "duration": 5.04}, {"text": "that you know I have n beta elements", "start": 4990.6, "duration": 3.639}, {"text": "that that I'm operating", "start": 4992.44, "duration": 3.88}, {"text": "on", "start": 4994.239, "duration": 4.041}, {"text": "um", "start": 4996.32, "duration": 4.68}, {"text": "so this is how the entire code looks", "start": 4998.28, "duration": 5.48}, {"text": "like so this was the I just show", "start": 5001.0, "duration": 5.239}, {"text": "you and now instead of doing an addition", "start": 5003.76, "duration": 4.28}, {"text": "I do a vector addition this is the the", "start": 5006.239, "duration": 3.4}, {"text": "same as I showed you before but instead", "start": 5008.04, "duration": 4.24}, {"text": "of a b and c as numbers I just have an", "start": 5009.639, "duration": 5.201}, {"text": "array here right with n numbers in", "start": 5012.28, "duration": 7.52}, {"text": "it and um now icate basically a pointer", "start": 5014.84, "duration": 7.52}, {"text": "to the device memory that has n you know", "start": 5019.8, "duration": 4.56}, {"text": "for for n", "start": 5022.36, "duration": 5.16}, {"text": "numbers um and let's assume I get my", "start": 5024.36, "duration": 5.16}, {"text": "input data from somewhere that's you", "start": 5027.52, "duration": 3.76}, {"text": "know my input vectors A and B and now I", "start": 5029.52, "duration": 3.76}, {"text": "want to do the vector Edition I do the", "start": 5031.28, "duration": 5.0}, {"text": "same thing I copy the the vectors now", "start": 5033.28, "duration": 6.04}, {"text": "from the host to the device with qm copy", "start": 5036.28, "duration": 4.879}, {"text": "and then I launch n blocks instead of", "start": 5039.32, "duration": 4.56}, {"text": "just a single block right so this way I", "start": 5041.159, "duration": 5.761}, {"text": "can do 512 for instance um like in this", "start": 5043.88, "duration": 7.2}, {"text": "example I have set n to 5002 hardcoded", "start": 5046.92, "duration": 7.6}, {"text": "right uh vector addition on the device", "start": 5051.08, "duration": 6.24}, {"text": "on on on the GPU and parallel um this is", "start": 5054.52, "duration": 5.84}, {"text": "still not great right this is", "start": 5057.32, "duration": 6.919}, {"text": "um um weird but I can also use threads", "start": 5060.36, "duration": 5.24}, {"text": "that's a different variable that's", "start": 5064.239, "duration": 2.4}, {"text": "called thread", "start": 5065.6, "duration": 4.28}, {"text": "ID and that basically indices indexes", "start": 5066.639, "duration": 5.441}, {"text": "that that second uh number here in the", "start": 5069.88, "duration": 4.6}, {"text": "kernel launch right so again you know I", "start": 5072.08, "duration": 4.24}, {"text": "I this implementation needs to be", "start": 5074.48, "duration": 3.8}, {"text": "consistent with how call the", "start": 5076.32, "duration": 5.64}, {"text": "kernel um I can do the same thing um and", "start": 5078.28, "duration": 5.68}, {"text": "then I can combine blocks and threads", "start": 5081.96, "duration": 3.36}, {"text": "right so I need to take care of the", "start": 5083.96, "duration": 3.199}, {"text": "indexing that's the important piece", "start": 5085.32, "duration": 4.96}, {"text": "right so um tter supports", "start": 5087.159, "duration": 5.96}, {"text": "threedimensional blocks and threads", "start": 5090.28, "duration": 5.439}, {"text": "the number of threats per block and the", "start": 5093.119, "duration": 5.281}, {"text": "number of concurrent blocks that you can", "start": 5095.719, "duration": 5.601}, {"text": "run is limited by the hardware right so", "start": 5098.4, "duration": 5.48}, {"text": "there are up to 248 threats per block on", "start": 5101.32, "duration": 5.319}, {"text": "c gpus", "start": 5103.88, "duration": 5.72}, {"text": "um why threats and blocks um so the", "start": 5106.639, "duration": 4.6}, {"text": "threads and the blocks they map to the", "start": 5109.6, "duration": 5.0}, {"text": "underlying Hardware okay so you've seen", "start": 5111.239, "duration": 5.081}, {"text": "you've seen the multiprocessors before", "start": 5114.6, "duration": 4.119}, {"text": "so all the threats in a block so if I", "start": 5116.32, "duration": 4.16}, {"text": "have n threats", "start": 5118.719, "duration": 5.721}, {"text": "here um in a given block they all are", "start": 5120.48, "duration": 6.6}, {"text": "guaranteed to execute on the same", "start": 5124.44, "duration": 4.4}, {"text": "multiprocessor the same streaming", "start": 5127.08, "duration": 4.039}, {"text": "multiprocessor so they share resources", "start": 5128.84, "duration": 4.0}, {"text": "they can actually communicate to each", "start": 5131.119, "duration": 4.881}, {"text": "other via that shared memory right um", "start": 5132.84, "duration": 5.04}, {"text": "threads in different blocks can not", "start": 5136.0, "duration": 3.92}, {"text": "communicate with each other", "start": 5137.88, "duration": 4.68}, {"text": "right um one thing you have to keep in", "start": 5139.92, "duration": 4.4}, {"text": "mind even if you see these examples now", "start": 5142.56, "duration": 4.24}, {"text": "with less than 32 but I talked about", "start": 5144.32, "duration": 5.919}, {"text": "this warp size and because the schedular", "start": 5146.8, "duration": 6.76}, {"text": "issues instructions in mul multiples of", "start": 5150.239, "duration": 6.041}, {"text": "warps you must have a multiple you", "start": 5153.56, "duration": 5.36}, {"text": "should have a multiple of 32 here as as", "start": 5156.28, "duration": 4.6}, {"text": "as a threat size otherwise you're going", "start": 5158.92, "duration": 6.08}, {"text": "to waste resources because you know say", "start": 5160.88, "duration": 8.48}, {"text": "if you have um 33 here then you would", "start": 5165.0, "duration": 8.199}, {"text": "have 32 cores doing an operation and", "start": 5169.36, "duration": 8.44}, {"text": "then you have one one more thread but it", "start": 5173.199, "duration": 6.44}, {"text": "still would issue the instructions of 32", "start": 5177.8, "duration": 3.8}, {"text": "cores that means that 31 cores would do", "start": 5179.639, "duration": 5.201}, {"text": "nothing they basically um are just", "start": 5181.6, "duration": 5.88}, {"text": "occupied doing nothing so you need to", "start": 5184.84, "duration": 5.56}, {"text": "use a a multiple of 32", "start": 5187.48, "duration": 6.52}, {"text": "here so you know let's assume we have an", "start": 5190.4, "duration": 5.36}, {"text": "array and then we have multiple blocks", "start": 5194.0, "duration": 4.36}, {"text": "so this is an example where I would", "start": 5195.76, "duration": 5.959}, {"text": "launch um eight threads per block and", "start": 5198.36, "duration": 6.4}, {"text": "now I have an array that has a length of", "start": 5201.719, "duration": 6.4}, {"text": "32 just St being able to explain this on", "start": 5204.76, "duration": 5.919}, {"text": "a slide um then you know what I would do", "start": 5208.119, "duration": 3.881}, {"text": "is I would launch four kernels for", "start": 5210.679, "duration": 2.921}, {"text": "instance instance um sorry a colel with", "start": 5212.0, "duration": 3.92}, {"text": "four blocks and you see the threats in", "start": 5213.6, "duration": 4.039}, {"text": "the first block they should operate on", "start": 5215.92, "duration": 4.4}, {"text": "the first um eight data elements the", "start": 5217.639, "duration": 4.681}, {"text": "threats in the second block they should", "start": 5220.32, "duration": 4.28}, {"text": "operate on the second um eight data", "start": 5222.32, "duration": 5.399}, {"text": "elements and so on right so there's a", "start": 5224.6, "duration": 5.28}, {"text": "buing variable block", "start": 5227.719, "duration": 4.561}, {"text": "dim that contains the number of threads", "start": 5229.88, "duration": 4.48}, {"text": "per block so that's the block Dimension", "start": 5232.28, "duration": 4.16}, {"text": "right so I know the number of blocks I", "start": 5234.36, "duration": 4.12}, {"text": "know my block ID I know the block", "start": 5236.44, "duration": 4.32}, {"text": "Dimension I know my thread ID and with", "start": 5238.48, "duration": 5.239}, {"text": "that I can calculate a unique Index", "start": 5240.76, "duration": 5.24}, {"text": "right so for instance if I want to", "start": 5243.719, "duration": 5.601}, {"text": "know which of those individual threads", "start": 5246.0, "duration": 4.96}, {"text": "that has been launched that's running", "start": 5249.32, "duration": 4.2}, {"text": "this colel should do the addition of or", "start": 5250.96, "duration": 5.8}, {"text": "operate on this data element there well", "start": 5253.52, "duration": 6.08}, {"text": "I want to be in block number two and", "start": 5256.76, "duration": 6.04}, {"text": "thread number three should do that right", "start": 5259.6, "duration": 5.44}, {"text": "so I just say well my my my Global", "start": 5262.8, "duration": 5.64}, {"text": "thread ID is just my thread ID plus my", "start": 5265.04, "duration": 5.639}, {"text": "block ID times the block Dimension right", "start": 5268.44, "duration": 6.08}, {"text": "so 2 * 8 so I'm I'm block", "start": 5270.679, "duration": 6.801}, {"text": "two right each block has eight threads", "start": 5274.52, "duration": 5.8}, {"text": "so the offset is basically 16 so those", "start": 5277.48, "duration": 5.639}, {"text": "are the first 16 elements plus three", "start": 5280.32, "duration": 4.399}, {"text": "because I'm thread number three so I", "start": 5283.119, "duration": 3.961}, {"text": "should operate on this data element 19", "start": 5284.719, "duration": 6.281}, {"text": "right so this is basically 8 16 17 18 19", "start": 5287.08, "duration": 5.599}, {"text": "that's correct right and so that's how", "start": 5291.0, "duration": 2.44}, {"text": "you", "start": 5292.679, "duration": 2.96}, {"text": "index", "start": 5293.44, "duration": 5.6}, {"text": "um compute the index and and you can", "start": 5295.639, "duration": 4.921}, {"text": "know what you should operate on so you", "start": 5299.04, "duration": 3.72}, {"text": "say my thread ID is now", "start": 5300.56, "duration": 5.28}, {"text": "thread idxx plus block time x times", "start": 5302.76, "duration": 5.0}, {"text": "block ID", "start": 5305.84, "duration": 7.279}, {"text": "x.x and now you have a a a a now you can", "start": 5307.76, "duration": 7.2}, {"text": "launch a kernel and all you have to make", "start": 5313.119, "duration": 4.921}, {"text": "sure is that you launch a certain", "start": 5314.96, "duration": 5.4}, {"text": "threats per block and then you use a", "start": 5318.04, "duration": 6.119}, {"text": "number of blocks that is basically um um", "start": 5320.36, "duration": 6.04}, {"text": "such that you know threads per blocks", "start": 5324.159, "duration": 3.401}, {"text": "times", "start": 5326.4, "duration": 2.759}, {"text": "the", "start": 5327.56, "duration": 6.2}, {"text": "um block number uh sums up to n right so", "start": 5329.159, "duration": 7.0}, {"text": "this is of course a limitation so what", "start": 5333.76, "duration": 5.6}, {"text": "you want to do is actually launch at", "start": 5336.159, "duration": 6.96}, {"text": "least as many blocks as are required to", "start": 5339.36, "duration": 7.279}, {"text": "operate on all elements of our Vector n", "start": 5343.119, "duration": 5.0}, {"text": "and then we need to pass that", "start": 5346.639, "duration": 4.56}, {"text": "information to our addition function to", "start": 5348.119, "duration": 4.641}, {"text": "our add function and then we just put an", "start": 5351.199, "duration": 2.92}, {"text": "if statement in there and they say well", "start": 5352.76, "duration": 3.879}, {"text": "if my thread ID is less than n then do", "start": 5354.119, "duration": 4.241}, {"text": "this operation otherwise don't do it", "start": 5356.639, "duration": 6.52}, {"text": "right so this way I can have a a uh size", "start": 5358.36, "duration": 6.6}, {"text": "of a vector that's not a multiple of our", "start": 5363.159, "duration": 3.241}, {"text": "chosen block", "start": 5364.96, "duration": 4.88}, {"text": "Dimension um you know few threats will", "start": 5366.4, "duration": 6.239}, {"text": "do no operations at the end you know at", "start": 5369.84, "duration": 4.24}, {"text": "the end of the vector but that's fine", "start": 5372.639, "duration": 2.52}, {"text": "you know it's just a little bit of", "start": 5374.08, "duration": 3.44}, {"text": "resources that are being wasted but not", "start": 5375.159, "duration": 4.121}, {"text": "much", "start": 5377.52, "duration": 4.32}, {"text": "um so we write a kernel that looks like", "start": 5379.28, "duration": 5.28}, {"text": "it runs on one thread and but we", "start": 5381.84, "duration": 4.839}, {"text": "launched that multiple times you know", "start": 5384.56, "duration": 3.8}, {"text": "multiple threads per blocks multiple", "start": 5386.679, "duration": 3.721}, {"text": "blocks and then each thread knows it", "start": 5388.36, "duration": 4.279}, {"text": "index in the block and the grid", "start": 5390.4, "duration": 4.279}, {"text": "and we can use that to computer unique", "start": 5392.639, "duration": 5.6}, {"text": "thread ID and now we want to do that to", "start": 5394.679, "duration": 5.321}, {"text": "handle arbitrary Vector", "start": 5398.239, "duration": 3.281}, {"text": "sizes", "start": 5400.0, "duration": 3.719}, {"text": "and uh because the maximum grid and", "start": 5401.52, "duration": 3.679}, {"text": "block size is limited by the hardware", "start": 5403.719, "duration": 3.241}, {"text": "now if you have a you know vector", "start": 5405.199, "duration": 3.281}, {"text": "addition of I don't know a billion", "start": 5406.96, "duration": 4.6}, {"text": "elements how do you do that right um so", "start": 5408.48, "duration": 4.96}, {"text": "what we always want to do is we launch a", "start": 5411.56, "duration": 4.04}, {"text": "fixed number of blocks and threads and", "start": 5413.44, "duration": 4.279}, {"text": "that fixed number just depends on the", "start": 5415.6, "duration": 3.84}, {"text": "hardware you're running on you know", "start": 5417.719, "duration": 3.561}, {"text": "depends on how many multiprocessors you", "start": 5419.44, "duration": 3.4}, {"text": "have and so on", "start": 5421.28, "duration": 3.68}, {"text": "and so we rewrite our kernel for fixed", "start": 5422.84, "duration": 5.56}, {"text": "grid and block size and we can do that", "start": 5424.96, "duration": 5.32}, {"text": "by using another buil-in variable that", "start": 5428.4, "duration": 3.48}, {"text": "knows the number of blocks in the grid", "start": 5430.28, "duration": 3.879}, {"text": "so we can know how many threats in total", "start": 5431.88, "duration": 3.2}, {"text": "we have", "start": 5434.159, "duration": 3.721}, {"text": "running um and with that we can compute", "start": 5435.08, "duration": 7.159}, {"text": "strides so you know um our threats they", "start": 5437.88, "duration": 6.88}, {"text": "operates imagine you have n threats so", "start": 5442.239, "duration": 5.44}, {"text": "they do the addition on N data elements", "start": 5444.76, "duration": 4.64}, {"text": "and then they skip the first end data", "start": 5447.679, "duration": 3.361}, {"text": "elements operate on the next end data", "start": 5449.4, "duration": 2.839}, {"text": "elements and they keep doing doing this", "start": 5451.04, "duration": 4.599}, {"text": "until they reach the end of the vector", "start": 5452.239, "duration": 6.721}, {"text": "okay um and yeah so for M kernel the", "start": 5455.639, "duration": 6.08}, {"text": "performance is optimal for certain GPU", "start": 5458.96, "duration": 4.32}, {"text": "Hardware dependent combination of grid", "start": 5461.719, "duration": 2.96}, {"text": "and block size and that's just something", "start": 5463.28, "duration": 3.919}, {"text": "you might have to experiment", "start": 5464.679, "duration": 5.241}, {"text": "with and so you query the hardware at", "start": 5467.199, "duration": 5.52}, {"text": "runtime um to for an optimal kernel", "start": 5469.92, "duration": 5.16}, {"text": "launch", "start": 5472.719, "duration": 2.361}, {"text": "configuration", "start": 5475.44, "duration": 3.44}, {"text": "so", "start": 5477.28, "duration": 5.48}, {"text": "yeah I I don't think need to go a lot", "start": 5478.88, "duration": 7.239}, {"text": "into details but basically um you know", "start": 5482.76, "duration": 4.959}, {"text": "the grid Dimension is you know if you", "start": 5486.119, "duration": 3.52}, {"text": "had only this is the example where you", "start": 5487.719, "duration": 3.681}, {"text": "know I have the stud2 data elements but", "start": 5489.639, "duration": 3.921}, {"text": "instead of using four blocks I only", "start": 5491.4, "duration": 5.48}, {"text": "launch two blocks right the orange one", "start": 5493.56, "duration": 7.92}, {"text": "and the and the blue blocks zero and one", "start": 5496.88, "duration": 7.2}, {"text": "you know so the first block operates on", "start": 5501.48, "duration": 4.56}, {"text": "first eight element data elements the", "start": 5504.08, "duration": 3.84}, {"text": "next block and the next eight data", "start": 5506.04, "duration": 4.72}, {"text": "elements when they are done well the", "start": 5507.92, "duration": 7.279}, {"text": "first block goes to the next and and and", "start": 5510.76, "duration": 7.12}, {"text": "the Press block here on to the next dat", "start": 5515.199, "duration": 5.04}, {"text": "elements and then they're going to check", "start": 5517.88, "duration": 4.04}, {"text": "is there anything else to do nothing is", "start": 5520.239, "duration": 3.721}, {"text": "to do and then they'll stop right and I", "start": 5521.92, "duration": 3.6}, {"text": "just do this with an if", "start": 5523.96, "duration": 4.52}, {"text": "statement so I need to know the stride I", "start": 5525.52, "duration": 4.52}, {"text": "call it the stride that's", "start": 5528.48, "duration": 3.639}, {"text": "basically how many threads I have in", "start": 5530.04, "duration": 4.76}, {"text": "total right it's the block Dimension", "start": 5532.119, "duration": 4.881}, {"text": "times the grid", "start": 5534.8, "duration": 4.68}, {"text": "Dimension and then I just do a loop here", "start": 5537.0, "duration": 6.0}, {"text": "and I say well uh why my thread ID is", "start": 5539.48, "duration": 6.52}, {"text": "less than the size of the vector which", "start": 5543.0, "duration": 5.239}, {"text": "I'm passing through my addition function", "start": 5546.0, "duration": 5.119}, {"text": "here I'll do this vector addition I do", "start": 5548.239, "duration": 7.44}, {"text": "this addition and then I I I I increment", "start": 5551.119, "duration": 6.401}, {"text": "my thread ID by the stri so I'm looking", "start": 5555.679, "duration": 3.56}, {"text": "for instance if I'm I'm thread zero and", "start": 5557.52, "duration": 3.52}, {"text": "block zero I'm looking at this data", "start": 5559.239, "duration": 4.721}, {"text": "element then I skip I'm operating on", "start": 5561.04, "duration": 5.079}, {"text": "this data element then I skip well and", "start": 5563.96, "duration": 4.92}, {"text": "now my thread ID is larger than n so I'm", "start": 5566.119, "duration": 5.52}, {"text": "going to stop right this way we can", "start": 5568.88, "duration": 4.72}, {"text": "launch a fixed number of", "start": 5571.639, "duration": 4.721}, {"text": "kernels um this shouldn't say fixed", "start": 5573.6, "duration": 4.0}, {"text": "number of kernels a fixed number of", "start": 5576.36, "duration": 5.52}, {"text": "threats per kernel", "start": 5577.6, "duration": 4.28}, {"text": "okay um yes threedimensional indexing I", "start": 5582.6, "duration": 5.24}, {"text": "mentioned that so you have this them", "start": 5585.719, "duration": 2.96}, {"text": "three", "start": 5587.84, "duration": 3.48}, {"text": "variables not much to talk", "start": 5588.679, "duration": 4.401}, {"text": "about", "start": 5591.32, "duration": 3.919}, {"text": "um", "start": 5593.08, "duration": 5.36}, {"text": "and you know those are the variables", "start": 5595.239, "duration": 5.281}, {"text": "that you have available for indexing in", "start": 5598.44, "duration": 4.199}, {"text": "in in in", "start": 5600.52, "duration": 4.159}, {"text": "and so now there's lots of material in", "start": 5602.639, "duration": 4.361}, {"text": "the slides and we're going to skip that", "start": 5604.679, "duration": 4.0}, {"text": "because we don't have time to talk about", "start": 5607.0, "duration": 4.119}, {"text": "this but I think we don't need this it's", "start": 5608.679, "duration": 7.401}, {"text": "just some you know more information um", "start": 5611.119, "duration": 8.481}, {"text": "and let me find the slides where I", "start": 5616.08, "duration": 5.84}, {"text": "wanted to", "start": 5619.6, "duration": 5.96}, {"text": "continue where's my", "start": 5621.92, "duration": 3.64}, {"text": "pointer here it is let's get to this SL", "start": 5626.6, "duration": 5.72}, {"text": "okay", "start": 5631.0, "duration": 3.92}, {"text": "so what we've learned is we have a", "start": 5632.32, "duration": 6.44}, {"text": "kernel that is code that can be executed", "start": 5634.92, "duration": 5.56}, {"text": "on the", "start": 5638.76, "duration": 4.2}, {"text": "GPU and you know that code and it's", "start": 5640.48, "duration": 4.48}, {"text": "executed operates in lock step on the", "start": 5642.96, "duration": 3.8}, {"text": "multiprocessors of the", "start": 5644.96, "duration": 5.04}, {"text": "GPU in so-called warps which are", "start": 5646.76, "duration": 5.8}, {"text": "multiples of 32 threads so it's", "start": 5650.0, "duration": 4.6}, {"text": "basically single instruction executed by", "start": 5652.56, "duration": 5.04}, {"text": "multiple threads simp", "start": 5654.6, "duration": 5.16}, {"text": "architecture um a thread is basically an", "start": 5657.6, "duration": 3.92}, {"text": "execution of a kernel with a given index", "start": 5659.76, "duration": 4.2}, {"text": "IND and you know each thread uses its", "start": 5661.52, "duration": 4.679}, {"text": "index to access a subset of a data say", "start": 5663.96, "duration": 5.8}, {"text": "an array to operate on and you know the", "start": 5666.199, "duration": 6.721}, {"text": "threads are grouped into blocks which", "start": 5669.76, "duration": 4.76}, {"text": "execute on the same", "start": 5672.92, "duration": 3.719}, {"text": "multiprocessor because that's the case", "start": 5674.52, "duration": 3.599}, {"text": "they can synchronize data so I'm not", "start": 5676.639, "duration": 2.6}, {"text": "showing this but there's some", "start": 5678.119, "duration": 2.801}, {"text": "information about that in the", "start": 5679.239, "duration": 4.321}, {"text": "slides um and then the grid is the all", "start": 5680.92, "duration": 4.799}, {"text": "the threats you know all the BL blocks", "start": 5683.56, "duration": 4.2}, {"text": "that are running in the GPU and you know", "start": 5685.719, "duration": 3.92}, {"text": "from that you can get an information", "start": 5687.76, "duration": 4.6}, {"text": "about the total number of threats", "start": 5689.639, "duration": 5.801}, {"text": "um so here's an example right um You", "start": 5692.36, "duration": 5.279}, {"text": "have that grid with certain number of", "start": 5695.44, "duration": 3.799}, {"text": "blocks and each block has a certain", "start": 5697.639, "duration": 4.04}, {"text": "number of", "start": 5699.239, "duration": 2.44}, {"text": "threats that's pictorially how how you", "start": 5701.84, "duration": 6.64}, {"text": "have to think about this right", "start": 5704.6, "duration": 3.88}, {"text": "um we have this C buil-in variables that", "start": 5708.92, "duration": 5.799}, {"text": "I talked about for the you know grid", "start": 5712.44, "duration": 5.08}, {"text": "Dimension block Dimension block index uh", "start": 5714.719, "duration": 4.721}, {"text": "block Dimension and the thread index in", "start": 5717.52, "duration": 5.8}, {"text": "the block and for this example here", "start": 5719.44, "duration": 7.44}, {"text": "which looks sort of like crappy Graphics", "start": 5723.32, "duration": 5.12}, {"text": "that's actually just taken out from an", "start": 5726.88, "duration": 6.6}, {"text": "old um uh ca ca um", "start": 5728.44, "duration": 8.799}, {"text": "um language CUA language guide but yeah", "start": 5733.48, "duration": 7.32}, {"text": "it would be six blocks three * two um so", "start": 5737.239, "duration": 5.801}, {"text": "two dimensional right and four * three", "start": 5740.8, "duration": 4.12}, {"text": "threads per block so a total of 72", "start": 5743.04, "duration": 3.52}, {"text": "threads of course in practice you're not", "start": 5744.92, "duration": 3.6}, {"text": "going to do something with you know", "start": 5746.56, "duration": 4.28}, {"text": "always have 32 multiples of 32 threats", "start": 5748.52, "duration": 3.48}, {"text": "per BL", "start": 5750.84, "duration": 3.04}, {"text": "that's just for illustration", "start": 5752.0, "duration": 4.4}, {"text": "purposes and we have the global keyword", "start": 5753.88, "duration": 5.0}, {"text": "for a function that executes in the", "start": 5756.4, "duration": 5.719}, {"text": "device um there's also device functions", "start": 5758.88, "duration": 5.08}, {"text": "um when the global function you can call", "start": 5762.119, "duration": 5.161}, {"text": "that actually from the from the from the", "start": 5763.96, "duration": 7.199}, {"text": "CPU and we have those cter API has a lot", "start": 5767.28, "duration": 5.48}, {"text": "of other functions you know to handle", "start": 5771.159, "duration": 3.881}, {"text": "memory and um just you know look it up", "start": 5772.76, "duration": 6.2}, {"text": "in the in the cter guide and then the", "start": 5775.04, "duration": 5.8}, {"text": "cter kernel launch configuration that's", "start": 5778.96, "duration": 6.96}, {"text": "in this angle brackets here the shr", "start": 5780.84, "duration": 7.359}, {"text": "notation yeah so that's what we've", "start": 5785.92, "duration": 4.68}, {"text": "learned so far um here some more", "start": 5788.199, "duration": 5.04}, {"text": "information about how the", "start": 5790.6, "duration": 8.96}, {"text": "memory um relates to each other okay um", "start": 5793.239, "duration": 9.681}, {"text": "so if this is the GPU so the grid that I", "start": 5799.56, "duration": 5.159}, {"text": "talked about all the threats you know", "start": 5802.92, "duration": 4.319}, {"text": "they're running on the GPU so they have", "start": 5804.719, "duration": 4.881}, {"text": "access to global memory right they also", "start": 5807.239, "duration": 3.641}, {"text": "have access to something that's called", "start": 5809.6, "duration": 3.24}, {"text": "constant memory that can be set from the", "start": 5810.88, "duration": 4.759}, {"text": "CPU and read during the execution of the", "start": 5812.84, "duration": 4.76}, {"text": "cies so you might want to store", "start": 5815.639, "duration": 4.441}, {"text": "something like P in there right or some", "start": 5817.6, "duration": 3.92}, {"text": "parameters for the", "start": 5820.08, "duration": 3.2}, {"text": "simulation and then you have those", "start": 5821.52, "duration": 4.32}, {"text": "blocks they run on a multiprocessor so", "start": 5823.28, "duration": 5.12}, {"text": "they can access their shared memory and", "start": 5825.84, "duration": 3.96}, {"text": "then you have the individual threads", "start": 5828.4, "duration": 3.48}, {"text": "that have access to the registers when", "start": 5829.8, "duration": 3.839}, {"text": "you know it's automatically generated", "start": 5831.88, "duration": 3.799}, {"text": "when the code is compiled", "start": 5833.639, "duration": 5.08}, {"text": "right um there's also something called", "start": 5835.679, "duration": 4.96}, {"text": "local memory so once you run out of", "start": 5838.719, "duration": 3.761}, {"text": "registers", "start": 5840.639, "duration": 3.6}, {"text": "it's not really local it's it's threat", "start": 5842.48, "duration": 3.199}, {"text": "local in a sense that only the threat", "start": 5844.239, "duration": 3.121}, {"text": "can see that but it gets stored actually", "start": 5845.679, "duration": 4.161}, {"text": "in global memory um that's when you", "start": 5847.36, "duration": 4.319}, {"text": "spill basically out of your registers", "start": 5849.84, "duration": 3.52}, {"text": "the compiler does this automatically and", "start": 5851.679, "duration": 3.321}, {"text": "that significantly slows down your code", "start": 5853.36, "duration": 3.12}, {"text": "so that's where you'll have to do some", "start": 5855.0, "duration": 5.08}, {"text": "profiling and use inside tools inside", "start": 5856.48, "duration": 5.56}, {"text": "compute to understand how that what's", "start": 5860.08, "duration": 4.079}, {"text": "happening in your code and to optimize", "start": 5862.04, "duration": 5.72}, {"text": "it so that's there's an important thing", "start": 5864.159, "duration": 5.161}, {"text": "so when you program you want to avoid", "start": 5867.76, "duration": 3.2}, {"text": "data trampers between the CPU and the", "start": 5869.32, "duration": 4.919}, {"text": "GPU Q because the PCI Express bus is low", "start": 5870.96, "duration": 6.8}, {"text": "slow um you can hide memory access", "start": 5874.239, "duration": 6.4}, {"text": "latency meaning you know getting memory", "start": 5877.76, "duration": 5.72}, {"text": "from this data from this Global", "start": 5880.639, "duration": 6.241}, {"text": "memory by launching many threads um and", "start": 5883.48, "duration": 4.84}, {"text": "then you can take advantage of fast", "start": 5886.88, "duration": 3.48}, {"text": "share memory by tiling data so I'm not", "start": 5888.32, "duration": 3.52}, {"text": "talking much about this but this is", "start": 5890.36, "duration": 4.52}, {"text": "basically same as cache blocking in in", "start": 5891.84, "duration": 6.359}, {"text": "in CPUs right so you basically load the", "start": 5894.88, "duration": 4.92}, {"text": "data stored here and Shar memory and", "start": 5898.199, "duration": 3.241}, {"text": "then all your threats if they have", "start": 5899.8, "duration": 3.2}, {"text": "multiple times that they need to access", "start": 5901.44, "duration": 3.199}, {"text": "the data they can do this very fast", "start": 5903.0, "duration": 4.239}, {"text": "because this is very fast", "start": 5904.639, "duration": 4.56}, {"text": "memory and then you have these constant", "start": 5907.239, "duration": 5.88}, {"text": "memory that you can use um that is very", "start": 5909.199, "duration": 5.801}, {"text": "efficient if multiple threats need the", "start": 5913.119, "duration": 2.681}, {"text": "same", "start": 5915.0, "duration": 3.159}, {"text": "data", "start": 5915.8, "duration": 4.319}, {"text": "um and so there's a matrix", "start": 5918.159, "duration": 3.281}, {"text": "multiplication", "start": 5920.119, "duration": 4.761}, {"text": "example that I'm I'm I'm going to skip", "start": 5921.44, "duration": 5.799}, {"text": "over because you know there's no time", "start": 5924.88, "duration": 7.44}, {"text": "actually for us to look at this um but", "start": 5927.239, "duration": 7.4}, {"text": "what that example oops where's my", "start": 5932.32, "duration": 4.359}, {"text": "pointer lost my", "start": 5934.639, "duration": 4.48}, {"text": "pointer", "start": 5936.679, "duration": 5.281}, {"text": "um what that what that example is doing", "start": 5939.119, "duration": 6.0}, {"text": "is is um it makes use of two dimensional", "start": 5941.96, "duration": 4.679}, {"text": "grids and blocks and shared memory and", "start": 5945.119, "duration": 4.401}, {"text": "threat synchronization and you know", "start": 5946.639, "duration": 4.281}, {"text": "there's some optimizations in there", "start": 5949.52, "duration": 2.96}, {"text": "still it's much slower than the highly", "start": 5950.92, "duration": 4.799}, {"text": "optimized blast Library", "start": 5952.48, "duration": 5.719}, {"text": "um there's some information about Atomic", "start": 5955.719, "duration": 5.681}, {"text": "operations to avoid race conditions um", "start": 5958.199, "duration": 7.52}, {"text": "um and there's an example in there as", "start": 5961.4, "duration": 5.68}, {"text": "well and I have that in the in the", "start": 5965.719, "duration": 4.801}, {"text": "source code and I will skip over this", "start": 5967.08, "duration": 6.159}, {"text": "because um we want to do some Hands-On", "start": 5970.52, "duration": 6.159}, {"text": "sessions okay um and so we're going to", "start": 5973.239, "duration": 6.96}, {"text": "skip to accessing GPU noes and running", "start": 5976.679, "duration": 7.0}, {"text": "GPU jobs and sdsc expands and I want", "start": 5980.199, "duration": 4.881}, {"text": "that you have a little bit of time to", "start": 5983.679, "duration": 3.52}, {"text": "explore this yourself um you have a good", "start": 5985.08, "duration": 4.96}, {"text": "amount of time", "start": 5987.199, "duration": 7.48}, {"text": "um uh until 1:30 so but I don't want to", "start": 5990.04, "duration": 6.52}, {"text": "spend too much time because I also want", "start": 5994.679, "duration": 3.841}, {"text": "to use it to open ACC and have some", "start": 5996.56, "duration": 4.679}, {"text": "hands on exercise for that as well so", "start": 5998.52, "duration": 6.119}, {"text": "what I will do is I go through some", "start": 6001.239, "duration": 7.321}, {"text": "slides now and then there is specific", "start": 6004.639, "duration": 6.201}, {"text": "information also on", "start": 6008.56, "duration": 4.079}, {"text": "the", "start": 6010.84, "duration": 5.72}, {"text": "um the GitHub website", "start": 6012.639, "duration": 6.761}, {"text": "okay so I'll just walk you through this", "start": 6016.56, "duration": 4.599}, {"text": "and you have all that information on the", "start": 6019.4, "duration": 3.319}, {"text": "GitHub website as", "start": 6021.159, "duration": 5.641}, {"text": "well um you know once you log into", "start": 6022.719, "duration": 5.721}, {"text": "expans you know you you get onto the", "start": 6026.8, "duration": 3.6}, {"text": "login note obviously right so we know", "start": 6028.44, "duration": 5.36}, {"text": "that um then just as a background again", "start": 6030.4, "duration": 6.08}, {"text": "so the GPU nodes we have two different", "start": 6033.8, "duration": 6.08}, {"text": "partitions on on on on expans so we have", "start": 6036.48, "duration": 6.199}, {"text": "a GPU partition that gives you access to", "start": 6039.88, "duration": 5.239}, {"text": "entire GPU noes so you you'll get four", "start": 6042.679, "duration": 4.241}, {"text": "gpus so you will have to have a code", "start": 6045.119, "duration": 4.401}, {"text": "that actually makes use of four gpus and", "start": 6046.92, "duration": 4.04}, {"text": "then there's a GPU shared project", "start": 6049.52, "duration": 3.4}, {"text": "partition where you get access to", "start": 6050.96, "duration": 4.0}, {"text": "individual gpus right so those you know", "start": 6052.92, "duration": 4.52}, {"text": "if you had a batch drob you'd have the", "start": 6054.96, "duration": 5.639}, {"text": "option to use the partition GPU or GPU", "start": 6057.44, "duration": 4.759}, {"text": "share", "start": 6060.599, "duration": 4.52}, {"text": "um in addition to the partition name um", "start": 6062.199, "duration": 6.121}, {"text": "you must specify the number of gpus so", "start": 6065.119, "duration": 5.321}, {"text": "for us to access the GPU noes you know", "start": 6068.32, "duration": 3.56}, {"text": "you don't have to do this so there", "start": 6070.44, "duration": 3.32}, {"text": "there's an allias def but I just want to", "start": 6071.88, "duration": 4.88}, {"text": "show this to you and um so if you if you", "start": 6073.76, "duration": 4.479}, {"text": "try yourself and if you have an", "start": 6076.76, "duration": 3.28}, {"text": "allocation and so on so you know how to", "start": 6078.239, "duration": 3.321}, {"text": "use that", "start": 6080.04, "duration": 4.72}, {"text": "um so for interactive access for example", "start": 6081.56, "duration": 4.76}, {"text": "you know you would be issuing a command", "start": 6084.76, "duration": 3.479}, {"text": "that looks like this um and we have an", "start": 6086.32, "duration": 4.16}, {"text": "allias for that for the specific", "start": 6088.239, "duration": 5.88}, {"text": "reservation as well um you use a GPU", "start": 6090.48, "duration": 6.719}, {"text": "share partition on a single note we want", "start": 6094.119, "duration": 6.761}, {"text": "one GPU and now we want one task that's", "start": 6097.199, "duration": 7.52}, {"text": "a CPU task for note and 10 CPU", "start": 6100.88, "duration": 6.239}, {"text": "cores um like I mentioned you know we", "start": 6104.719, "duration": 5.761}, {"text": "have 40 CPU cores on a GPU mode so if", "start": 6107.119, "duration": 5.161}, {"text": "you ask for a single GPU you shouldn't", "start": 6110.48, "duration": 4.8}, {"text": "ask for more than 10 CPU cores otherwise", "start": 6112.28, "duration": 5.919}, {"text": "you will be charged for using two gpus", "start": 6115.28, "duration": 4.319}, {"text": "because you know somebody else wouldn't", "start": 6118.199, "duration": 4.04}, {"text": "be able to use this cores that are you", "start": 6119.599, "duration": 6.04}, {"text": "know sort of like proportionally belong", "start": 6122.239, "duration": 5.641}, {"text": "to to a different GPU", "start": 6125.639, "duration": 5.321}, {"text": "right um and then you have that's a CPU", "start": 6127.88, "duration": 5.44}, {"text": "memory um again don't use more than a", "start": 6130.96, "duration": 4.52}, {"text": "quarter of available", "start": 6133.32, "duration": 4.76}, {"text": "memory and you know then srun would", "start": 6135.48, "duration": 6.48}, {"text": "basically go ahead and learn allocate a", "start": 6138.08, "duration": 6.519}, {"text": "a note for you and you'll get onto on an", "start": 6141.96, "duration": 4.32}, {"text": "expans compute note that now would have", "start": 6144.599, "duration": 3.04}, {"text": "a", "start": 6146.28, "duration": 5.16}, {"text": "GPU so yeah so if you make requests", "start": 6147.639, "duration": 6.96}, {"text": "yourself um you know you should do that", "start": 6151.44, "duration": 4.88}, {"text": "proportional to the number of available", "start": 6154.599, "duration": 4.0}, {"text": "resources and those are the resources on", "start": 6156.32, "duration": 5.12}, {"text": "a GPU Noe right so if you use only one", "start": 6158.599, "duration": 5.441}, {"text": "GPU use 10 CPU cores and not more than a", "start": 6161.44, "duration": 5.239}, {"text": "quarter of the the available", "start": 6164.04, "duration": 8.679}, {"text": "Ram um I think 993 I I would be", "start": 6166.679, "duration": 9.681}, {"text": "I would just not use more than 90 um", "start": 6172.719, "duration": 6.121}, {"text": "just be the safe", "start": 6176.36, "duration": 4.04}, {"text": "side", "start": 6178.84, "duration": 4.6}, {"text": "um so you can you can try that yourself", "start": 6180.4, "duration": 6.319}, {"text": "now um I I'll have a few more slides", "start": 6183.44, "duration": 4.759}, {"text": "that I show you and then I I'll go to", "start": 6186.719, "duration": 3.44}, {"text": "the GitHub repository and show you um", "start": 6188.199, "duration": 4.04}, {"text": "what you can go through and try", "start": 6190.159, "duration": 5.721}, {"text": "out um so if you you should have this", "start": 6192.239, "duration": 7.841}, {"text": "command available srun GPU shared and", "start": 6195.88, "duration": 5.56}, {"text": "that should give you", "start": 6200.08, "duration": 5.28}, {"text": "interactive access to a shared GPU", "start": 6201.44, "duration": 7.84}, {"text": "single GPU and a shared GPU node for 4", "start": 6205.36, "duration": 6.799}, {"text": "hours um yeah you try to get access to", "start": 6209.28, "duration": 6.839}, {"text": "an expans GPU note now and let us know", "start": 6212.159, "duration": 5.56}, {"text": "if that doesn't", "start": 6216.119, "duration": 5.04}, {"text": "work which I hope it works for", "start": 6217.719, "duration": 5.641}, {"text": "everybody and then you can", "start": 6221.159, "duration": 5.201}, {"text": "do it don't have to but yeah maybe just", "start": 6223.36, "duration": 5.48}, {"text": "do module Purge and module", "start": 6226.36, "duration": 6.92}, {"text": "reset um this is thec specific stuff um", "start": 6228.84, "duration": 6.2}, {"text": "yeah you can also load that it's not", "start": 6233.28, "duration": 6.04}, {"text": "really required for using cuter but um", "start": 6235.04, "duration": 5.639}, {"text": "doesn't", "start": 6239.32, "duration": 4.52}, {"text": "hurt then you can load the Cuda tool kit", "start": 6240.679, "duration": 6.681}, {"text": "you can load the PGI compilers or you", "start": 6243.84, "duration": 8.359}, {"text": "can load the um NV HPC um SDK so if you", "start": 6247.36, "duration": 8.879}, {"text": "load NV HPC don't load these uhet or", "start": 6252.199, "duration": 6.321}, {"text": "vice", "start": 6256.239, "duration": 2.281}, {"text": "versa", "start": 6259.599, "duration": 3.0}, {"text": "um if you are on a GPU Noe then you can", "start": 6262.679, "duration": 4.92}, {"text": "issue the NV SMI command that's the", "start": 6265.84, "duration": 5.0}, {"text": "system management interface um and it", "start": 6267.599, "duration": 5.761}, {"text": "will tell you some information about", "start": 6270.84, "duration": 5.319}, {"text": "installed driver in cter version and", "start": 6273.36, "duration": 4.4}, {"text": "then the GPU so you'll see something", "start": 6276.159, "duration": 5.161}, {"text": "like okay there's a Tesla V100 62 GPU", "start": 6277.76, "duration": 6.12}, {"text": "it's currently using only 67 watts of", "start": 6281.32, "duration": 4.919}, {"text": "300 so it's probably idling and yeah", "start": 6283.88, "duration": 4.12}, {"text": "it's idling because you know there's no", "start": 6286.239, "duration": 4.48}, {"text": "memory allocat so it's has to still 32 2", "start": 6288.0, "duration": 5.76}, {"text": "gab of memory free it's also pretty cool", "start": 6290.719, "duration": 6.201}, {"text": "it's only 45 Centigrade um so if you run", "start": 6293.76, "duration": 5.32}, {"text": "a code on it for longer time that", "start": 6296.92, "duration": 6.0}, {"text": "temperature will go up right um and you", "start": 6299.08, "duration": 5.24}, {"text": "know should show something like no", "start": 6302.92, "duration": 3.239}, {"text": "running processes F because well there's", "start": 6304.32, "duration": 3.799}, {"text": "no process can't be running in the GPU", "start": 6306.159, "duration": 3.801}, {"text": "otherwise you know you have a job", "start": 6308.119, "duration": 5.08}, {"text": "running on the GPU you'll see the name", "start": 6309.96, "duration": 4.52}, {"text": "of the", "start": 6313.199, "duration": 3.681}, {"text": "process and", "start": 6314.48, "duration": 5.08}, {"text": "um um it's it's it's which GPU is", "start": 6316.88, "duration": 4.44}, {"text": "running on and then", "start": 6319.56, "duration": 5.0}, {"text": "uh the process ID and so", "start": 6321.32, "duration": 3.24}, {"text": "on um if you have cter loaded um or NV", "start": 6326.52, "duration": 8.48}, {"text": "HPC um then the the the CUA C compiler", "start": 6331.119, "duration": 6.281}, {"text": "should be available so nvcc can issue", "start": 6335.0, "duration": 6.0}, {"text": "nvcc version same for the PGI", "start": 6337.4, "duration": 5.6}, {"text": "compiler", "start": 6341.0, "duration": 6.48}, {"text": "um and", "start": 6343.0, "duration": 4.48}, {"text": "oops Yeah so um and and then and then", "start": 6348.92, "duration": 5.759}, {"text": "we'll go through the", "start": 6353.04, "duration": 4.639}, {"text": "um exercises so this is accessing the", "start": 6354.679, "duration": 7.56}, {"text": "GPU noes so let me just", "start": 6357.679, "duration": 4.56}, {"text": "quickly I guess I should increase this", "start": 6365.56, "duration": 6.44}, {"text": "size", "start": 6369.679, "duration": 4.04}, {"text": "here", "start": 6372.0, "duration": 4.8}, {"text": "um right so if you go to the summer", "start": 6373.719, "duration": 4.88}, {"text": "Institute GitHub", "start": 6376.8, "duration": 4.76}, {"text": "repository um first of all clone it if", "start": 6378.599, "duration": 7.361}, {"text": "you clone it on SDC", "start": 6381.56, "duration": 6.72}, {"text": "expanse um you'll have the Cuda samples", "start": 6385.96, "duration": 4.279}, {"text": "available so we have this you know this", "start": 6388.28, "duration": 5.359}, {"text": "is the summer Institute um dat", "start": 6390.239, "duration": 8.36}, {"text": "repository okay and here 5.2a is the uh", "start": 6393.639, "duration": 7.441}, {"text": "GPU", "start": 6398.599, "duration": 2.481}, {"text": "session okay and here's the read me file", "start": 6401.159, "duration": 5.161}, {"text": "um", "start": 6404.599, "duration": 4.881}, {"text": "so this has the information I was just", "start": 6406.32, "duration": 4.96}, {"text": "talking about access the GP noes and", "start": 6409.48, "duration": 3.84}, {"text": "running drops and sdsc expans so you can", "start": 6411.28, "duration": 4.8}, {"text": "go through this there's information on", "start": 6413.32, "duration": 4.319}, {"text": "what you should", "start": 6416.08, "duration": 3.72}, {"text": "see um and then there's information", "start": 6417.639, "duration": 5.96}, {"text": "about the Hands-On exercises okay um so", "start": 6419.8, "duration": 6.359}, {"text": "literally we'll do those now I'll give", "start": 6423.599, "duration": 6.201}, {"text": "you some time maybe", "start": 6426.159, "duration": 8.161}, {"text": "um 10 minutes or so", "start": 6429.8, "duration": 4.52}, {"text": "um maybe until 1 we can do that you know", "start": 6435.52, "duration": 5.24}, {"text": "15 minutes should be a nice amount time", "start": 6438.96, "duration": 5.199}, {"text": "you can you can go through this um and", "start": 6440.76, "duration": 5.68}, {"text": "then compile and run the matrix", "start": 6444.159, "duration": 4.56}, {"text": "multiplication examples and so on I will", "start": 6446.44, "duration": 4.92}, {"text": "show this to the on slides to you but", "start": 6448.719, "duration": 5.801}, {"text": "you have in and output here and you will", "start": 6451.36, "duration": 6.279}, {"text": "recognize all of that from this slides", "start": 6454.52, "duration": 5.44}, {"text": "um I'll just go through the slides", "start": 6457.639, "duration": 4.641}, {"text": "because that's easy", "start": 6459.96, "duration": 5.88}, {"text": "to um to", "start": 6462.28, "duration": 5.439}, {"text": "show", "start": 6465.84, "duration": 4.72}, {"text": "um so the ca tool kit right so it's", "start": 6467.719, "duration": 5.041}, {"text": "available from Nvidia and it's also", "start": 6470.56, "duration": 3.96}, {"text": "station mians but don't copy everything", "start": 6472.76, "duration": 3.359}, {"text": "it's a lot of data just takes a lot of", "start": 6474.52, "duration": 7.56}, {"text": "time right um but I I have", "start": 6476.119, "duration": 9.6}, {"text": "that uh select examples here in the sdsc", "start": 6482.08, "duration": 5.639}, {"text": "summer Institute GitHub repository so if", "start": 6485.719, "duration": 4.561}, {"text": "you've cloned that um if you cloned it", "start": 6487.719, "duration": 5.92}, {"text": "before do a git pull to to update it", "start": 6490.28, "duration": 5.72}, {"text": "right so because I uploaded the slides", "start": 6493.639, "duration": 4.841}, {"text": "um and some of the things last", "start": 6496.0, "duration": 5.08}, {"text": "night um then there should", "start": 6498.48, "duration": 5.719}, {"text": "directory 5.2a GPU Computing and", "start": 6501.08, "duration": 5.36}, {"text": "programming Nvidia cter samples so those", "start": 6504.199, "duration": 5.281}, {"text": "have select Nvidia CA samples and either", "start": 6506.44, "duration": 4.84}, {"text": "you can compile them all if you go into", "start": 6509.48, "duration": 4.92}, {"text": "that directory and this this option SMS", "start": 6511.28, "duration": 7.2}, {"text": "equals 70 that's just the um 7.0 um", "start": 6514.4, "duration": 7.48}, {"text": "that's the architecture of the the V 100", "start": 6518.48, "duration": 7.92}, {"text": "gpus or you go into specific example", "start": 6521.88, "duration": 6.759}, {"text": "subdirectories and there is a device", "start": 6526.4, "duration": 4.48}, {"text": "query example", "start": 6528.639, "duration": 5.441}, {"text": "and uh that's very very very interesting", "start": 6530.88, "duration": 4.759}, {"text": "because so this basically queries", "start": 6534.08, "duration": 3.599}, {"text": "information about the GPU so that's like", "start": 6535.639, "duration": 3.841}, {"text": "what I said you know you can use cter", "start": 6537.679, "duration": 3.56}, {"text": "functions to query information about the", "start": 6539.48, "duration": 4.159}, {"text": "GPU and if you look into the source code", "start": 6541.239, "duration": 3.92}, {"text": "that's in there you know you can see how", "start": 6543.639, "duration": 4.04}, {"text": "that is done um so it's interesting to", "start": 6545.159, "duration": 5.361}, {"text": "to inspect those source code examples um", "start": 6547.679, "duration": 4.56}, {"text": "if you run that it gives you information", "start": 6550.52, "duration": 3.96}, {"text": "about the GPU it tells you what type of", "start": 6552.239, "duration": 5.88}, {"text": "GPU it is um the the cuter capability", "start": 6554.48, "duration": 6.159}, {"text": "version the memory the course", "start": 6558.119, "duration": 5.281}, {"text": "available and so on so a lot of lot of", "start": 6560.639, "duration": 5.441}, {"text": "interesting information about the", "start": 6563.4, "duration": 4.88}, {"text": "GPU the other example is the matrix", "start": 6566.08, "duration": 3.8}, {"text": "multiplication", "start": 6568.28, "duration": 5.12}, {"text": "example so there is a hand coded matrix", "start": 6569.88, "duration": 4.839}, {"text": "multiplication that has a lot of", "start": 6573.4, "duration": 3.08}, {"text": "optimizations in there like cache", "start": 6574.719, "duration": 4.721}, {"text": "blocking and so on and it measures the", "start": 6576.48, "duration": 4.96}, {"text": "performance that you get and it's", "start": 6579.44, "duration": 4.799}, {"text": "interesting so run this so remember we", "start": 6581.44, "duration": 8.36}, {"text": "had about 7.8 Tera flops um um so 7,800", "start": 6584.239, "duration": 9.841}, {"text": "G flops and we getting only about", "start": 6589.8, "duration": 7.28}, {"text": "3.2 um very that", "start": 6594.08, "duration": 5.72}, {"text": "right now if you go there's an example", "start": 6597.08, "duration": 6.039}, {"text": "that uses q+ Library um if you compile", "start": 6599.8, "duration": 6.04}, {"text": "that and run that um you'll see that you", "start": 6603.119, "duration": 4.841}, {"text": "get very very close to the peak floating", "start": 6605.84, "duration": 4.16}, {"text": "Point performance so you know that", "start": 6607.96, "duration": 4.6}, {"text": "basically tells you yeah use the cuas", "start": 6610.0, "duration": 5.84}, {"text": "functions for instance if you", "start": 6612.56, "duration": 5.84}, {"text": "can", "start": 6615.84, "duration": 5.799}, {"text": "and then then a different directory here", "start": 6618.4, "duration": 6.68}, {"text": "in uh in in this subd directory that um", "start": 6621.639, "duration": 5.881}, {"text": "is called CA samples and this has this", "start": 6625.08, "duration": 4.32}, {"text": "hello world the addition the vector", "start": 6627.52, "duration": 3.4}, {"text": "addition and then the squaring Matrix", "start": 6629.4, "duration": 3.08}, {"text": "elements and one the stencil that we", "start": 6630.92, "duration": 3.799}, {"text": "didn't discuss but if you want to go and", "start": 6632.48, "duration": 5.08}, {"text": "come back after the summer Institute and", "start": 6634.719, "duration": 4.841}, {"text": "and read up on this and try those out um", "start": 6637.56, "duration": 4.519}, {"text": "feel free to do that um check the read", "start": 6639.56, "duration": 4.679}, {"text": "me files in there there you can compile", "start": 6642.079, "duration": 3.761}, {"text": "and run those examples those are very", "start": 6644.239, "duration": 4.561}, {"text": "simple examples um and there are also", "start": 6645.84, "duration": 5.44}, {"text": "exercises in there that basically I just", "start": 6648.8, "duration": 5.319}, {"text": "deleted some some things and said okay", "start": 6651.28, "duration": 5.04}, {"text": "can you do you you know figure out what", "start": 6654.119, "duration": 5.08}, {"text": "you need to put in there to make the", "start": 6656.32, "duration": 4.359}, {"text": "code run", "start": 6659.199, "duration": 6.801}, {"text": "correctly so um yeah let's do this um", "start": 6660.679, "duration": 6.92}, {"text": "until 1", "start": 6666.0, "duration": 4.52}, {"text": "pm. you can", "start": 6667.599, "duration": 6.441}, {"text": "follow these examples here um I they're", "start": 6670.52, "duration": 4.639}, {"text": "explaining", "start": 6674.04, "duration": 3.639}, {"text": "exactly um what to", "start": 6675.159, "duration": 5.681}, {"text": "do um", "start": 6677.679, "duration": 8.0}, {"text": "and we'll stop once you get to open", "start": 6680.84, "duration": 8.68}, {"text": "ACC and so I will continue at 1M to talk", "start": 6685.679, "duration": 5.761}, {"text": "about open ACC in the meantime if you", "start": 6689.52, "duration": 3.199}, {"text": "have any questions that you have to", "start": 6691.44, "duration": 2.279}, {"text": "answer", "start": 6692.719, "duration": 3.841}, {"text": "those Andy we have one question in the", "start": 6693.719, "duration": 4.841}, {"text": "help desk", "start": 6696.56, "duration": 4.559}, {"text": "Anna um I'll let you look at that", "start": 6698.56, "duration": 5.72}, {"text": "command not found and possibly with your", "start": 6701.119, "duration": 4.641}, {"text": "examples there it's answering that", "start": 6704.28, "duration": 3.68}, {"text": "question but I don't need the", "start": 6705.76, "duration": 6.2}, {"text": "answer okay let's see", "start": 6707.96, "duration": 4.0}, {"text": "srun command F oh that's crazy", "start": 6714.44, "duration": 4.679}, {"text": "oh okay um let me share the ex entire", "start": 6725.8, "duration": 7.56}, {"text": "command um let me just log in but sr.", "start": 6729.159, "duration": 5.761}, {"text": "command command not found are you on the", "start": 6733.36, "duration": 5.52}, {"text": "login Noe no it is a login", "start": 6734.92, "duration": 6.96}, {"text": "Noe", "start": 6738.88, "duration": 3.0}, {"text": "so here I am on", "start": 6746.079, "duration": 6.12}, {"text": "the lockin", "start": 6748.84, "duration": 3.359}, {"text": "Note", "start": 6752.32, "duration": 3.0}, {"text": "um so this would be the command let me", "start": 6766.04, "duration": 5.8}, {"text": "copy", "start": 6768.92, "duration": 2.92}, {"text": "uh copy this um", "start": 6778.079, "duration": 9.241}, {"text": "oops put this in", "start": 6783.199, "duration": 4.121}, {"text": "back see if this", "start": 6790.92, "duration": 3.64}, {"text": "works", "start": 6798.76, "duration": 3.0}, {"text": "if I do this let's see what happens so I", "start": 6813.639, "duration": 5.52}, {"text": "got onto a GPU note", "start": 6815.36, "duration": 3.799}, {"text": "um oops module I to say module", "start": 6819.719, "duration": 6.041}, {"text": "[Music]", "start": 6822.73, "duration": 3.03}, {"text": "Purge", "start": 6828.76, "duration": 6.68}, {"text": "um is a default I keep forgetting", "start": 6831.079, "duration": 4.361}, {"text": "myself", "start": 6858.679, "duration": 3.0}, {"text": "reset yeah so this already loaded the", "start": 6866.239, "duration": 6.92}, {"text": "um do you have this slur module", "start": 6869.56, "duration": 7.24}, {"text": "loaded so that is", "start": 6873.159, "duration": 3.641}, {"text": "for so for", "start": 6879.92, "duration": 3.48}, {"text": "Anna yeah but that should be in the", "start": 6885.28, "duration": 5.76}, {"text": "login note I I don't know", "start": 6887.28, "duration": 6.439}, {"text": "an know if it still doesn't work um", "start": 6891.04, "duration": 4.88}, {"text": "maybe we need to ask Mahi", "start": 6893.719, "duration": 5.44}, {"text": "mahida or", "start": 6895.92, "duration": 3.239}, {"text": "Martin so if", "start": 6899.88, "duration": 5.08}, {"text": "the GPU module is loaded then you can", "start": 6901.92, "duration": 5.679}, {"text": "load um you know you can also check with", "start": 6904.96, "duration": 5.04}, {"text": "module", "start": 6907.599, "duration": 2.401}, {"text": "Avail um you know you should see you", "start": 6911.119, "duration": 5.321}, {"text": "know n HPC is available and by default", "start": 6913.96, "duration": 5.199}, {"text": "this one will be loaded um or if you", "start": 6916.44, "duration": 5.48}, {"text": "load the shter module", "start": 6919.159, "duration": 8.48}, {"text": "um you'd have um by default this", "start": 6921.92, "duration": 5.719}, {"text": "one let me load NV HPC as an", "start": 6928.76, "duration": 4.56}, {"text": "example", "start": 6933.52, "duration": 6.92}, {"text": "um so now I have nvcc", "start": 6936.0, "duration": 4.44}, {"text": "available and yeah splits out the", "start": 6941.44, "duration": 5.96}, {"text": "corresponding version and then", "start": 6944.119, "duration": 6.721}, {"text": "um there is of course also the the NB", "start": 6947.4, "duration": 5.88}, {"text": "Porton for", "start": 6950.84, "duration": 6.2}, {"text": "instance media Porton", "start": 6953.28, "duration": 3.76}, {"text": "compiler and yeah", "start": 6958.639, "duration": 7.361}, {"text": "so inia SMI shows you know I have a GPU", "start": 6962.76, "duration": 5.959}, {"text": "available here and there's nothing", "start": 6966.0, "duration": 5.36}, {"text": "running at the", "start": 6968.719, "duration": 2.641}, {"text": "moment", "start": 6978.52, "duration": 3.0}, {"text": "and let me go back I think there was", "start": 6984.199, "duration": 3.96}, {"text": "another", "start": 6985.719, "duration": 2.44}, {"text": "question okay so the question says I", "start": 6996.92, "duration": 5.08}, {"text": "would like to know if a code can be run", "start": 6999.88, "duration": 5.12}, {"text": "both on CPU and", "start": 7002.0, "duration": 3.0}, {"text": "GPU", "start": 7005.04, "duration": 5.119}, {"text": "um now the question I have yeah", "start": 7007.199, "duration": 4.841}, {"text": "I'm not not sure exactly what she mean", "start": 7010.159, "duration": 4.281}, {"text": "with that", "start": 7012.04, "duration": 5.119}, {"text": "um so", "start": 7014.44, "duration": 7.0}, {"text": "usually you have a code that often you", "start": 7017.159, "duration": 7.281}, {"text": "start with code that runs on the CPU and", "start": 7021.44, "duration": 7.04}, {"text": "then you rewrite parts of it to run on", "start": 7024.44, "duration": 6.639}, {"text": "the GPU so the computer intensive", "start": 7028.48, "duration": 5.92}, {"text": "Parts um so you still will have code", "start": 7031.079, "duration": 4.881}, {"text": "that runs in the CPU but you know it has", "start": 7034.4, "duration": 3.44}, {"text": "to be compiled differently separately", "start": 7035.96, "duration": 5.199}, {"text": "different executables um", "start": 7037.84, "duration": 5.319}, {"text": "now with compiler directives like open", "start": 7041.159, "duration": 4.201}, {"text": "ACC you have basically a CPU code and", "start": 7043.159, "duration": 4.801}, {"text": "you can compile the player and then you", "start": 7045.36, "duration": 4.4}, {"text": "add these compiler directives the", "start": 7047.96, "duration": 6.119}, {"text": "pragmas and you either compile the code", "start": 7049.76, "duration": 7.52}, {"text": "taking those pragmas into", "start": 7054.079, "duration": 3.201}, {"text": "account", "start": 7061.84, "duration": 6.56}, {"text": "sorry sorry my my audio just dropped I", "start": 7064.56, "duration": 6.84}, {"text": "think can you still hear me", "start": 7068.4, "duration": 3.0}, {"text": "yes we can okay um so I was talking", "start": 7072.0, "duration": 5.92}, {"text": "about open ACC um so you insert the", "start": 7075.04, "duration": 5.679}, {"text": "pragmas into the source", "start": 7077.92, "duration": 6.759}, {"text": "code and then you can compile it and you", "start": 7080.719, "duration": 5.641}, {"text": "know the pragmas are basically in", "start": 7084.679, "duration": 3.801}, {"text": "comment lines and the compiler for the", "start": 7086.36, "duration": 3.799}, {"text": "CPU will completely ignore those so you", "start": 7088.48, "duration": 5.719}, {"text": "still have your CPU code and um then you", "start": 7090.159, "duration": 5.601}, {"text": "can compile a different version where", "start": 7094.199, "duration": 3.361}, {"text": "you tell the compiler to take those", "start": 7095.76, "duration": 4.6}, {"text": "pragas into account and it will generate", "start": 7097.56, "duration": 5.4}, {"text": "code that then will execute partially on", "start": 7100.36, "duration": 4.319}, {"text": "the GPU I mean those regions where you", "start": 7102.96, "duration": 3.6}, {"text": "told it that should run on the", "start": 7104.679, "duration": 4.601}, {"text": "GPU so in some sense you can have source", "start": 7106.56, "duration": 6.0}, {"text": "code that yes is able to", "start": 7109.28, "duration": 6.28}, {"text": "run on the CPU and if you compile it", "start": 7112.56, "duration": 4.92}, {"text": "differently on the GPU but I mean you", "start": 7115.56, "duration": 3.599}, {"text": "don't have the same executable that will", "start": 7117.48, "duration": 4.239}, {"text": "do the same things so one and the same", "start": 7119.159, "duration": 4.601}, {"text": "executable will not run on the GPU and", "start": 7121.719, "duration": 2.96}, {"text": "the", "start": 7123.76, "duration": 3.08}, {"text": "CPU but of course like I showed you", "start": 7124.679, "duration": 3.641}, {"text": "usually you", "start": 7126.84, "duration": 4.359}, {"text": "have you have some sort of like code to", "start": 7128.32, "duration": 5.72}, {"text": "runs the CPU and then it will call the", "start": 7131.199, "duration": 5.361}, {"text": "functions to be executed on GPU so it's", "start": 7134.04, "duration": 3.96}, {"text": "always a little bit of a mix you always", "start": 7136.56, "duration": 3.8}, {"text": "need a", "start": 7138.0, "duration": 2.36}, {"text": "CPU", "start": 7158.239, "duration": 3.0}, {"text": "okay there's an error here cannot find", "start": 7179.239, "duration": 7.0}, {"text": "minus lq plus ah okay", "start": 7182.639, "duration": 8.241}, {"text": "um so ham has a", "start": 7186.239, "duration": 9.081}, {"text": "error and I think what's Happening Here", "start": 7190.88, "duration": 8.199}, {"text": "is if we're going through those", "start": 7195.32, "duration": 6.72}, {"text": "exercises um compile and run matrix", "start": 7199.079, "duration": 5.401}, {"text": "multiplication with a Q blast Library", "start": 7202.04, "duration": 5.88}, {"text": "did you do these export commands", "start": 7204.48, "duration": 9.199}, {"text": "here um so this is this is", "start": 7207.92, "duration": 8.4}, {"text": "a I would", "start": 7213.679, "duration": 6.281}, {"text": "say an oversight of how an HPC was", "start": 7216.32, "duration": 6.44}, {"text": "installed by bright cluster Computing on", "start": 7219.96, "duration": 3.719}, {"text": "on", "start": 7222.76, "duration": 3.76}, {"text": "expans um these should be automatically", "start": 7223.679, "duration": 5.881}, {"text": "added to you know this path and the and", "start": 7226.52, "duration": 5.0}, {"text": "the you know the library path and and", "start": 7229.56, "duration": 4.159}, {"text": "the Linker paths but it's not been done", "start": 7231.52, "duration": 4.88}, {"text": "so we have to accept this manually so", "start": 7233.719, "duration": 5.641}, {"text": "the problem you see is", "start": 7236.4, "duration": 6.4}, {"text": "probably let me see I", "start": 7239.36, "duration": 6.64}, {"text": "have let me do this myself right", "start": 7242.8, "duration": 5.319}, {"text": "um", "start": 7246.0, "duration": 3.8}, {"text": "f", "start": 7248.119, "duration": 5.48}, {"text": "that fix it awesome fix it thank", "start": 7249.8, "duration": 3.799}, {"text": "you yeah so usually you would expect", "start": 7254.44, "duration": 3.96}, {"text": "that you load in the HPC and this is all", "start": 7256.639, "duration": 6.921}, {"text": "said correctly um but", "start": 7258.4, "duration": 5.16}, {"text": "yeah unfortunately that's not the", "start": 7263.639, "duration": 4.201}, {"text": "case", "start": 7278.04, "duration": 3.0}, {"text": "Andy do you see the question in the help", "start": 7373.32, "duration": 3.44}, {"text": "desk from", "start": 7375.119, "duration": 4.881}, {"text": "Kyle oh sorry um I went back to my", "start": 7376.76, "duration": 8.28}, {"text": "slides so I hadn't monitored", "start": 7380.0, "duration": 5.04}, {"text": "that nvcc command not found okay", "start": 7397.88, "duration": 12.359}, {"text": "so did you load the um NB", "start": 7403.76, "duration": 9.479}, {"text": "HPC", "start": 7410.239, "duration": 3.0}, {"text": "module this this will not compil with", "start": 7413.28, "duration": 4.08}, {"text": "the", "start": 7416.119, "duration": 6.48}, {"text": "um CA module because it requires", "start": 7417.36, "duration": 8.319}, {"text": "um it requires a higher CUO version than", "start": 7422.599, "duration": 5.401}, {"text": "the one that we have installed because", "start": 7425.679, "duration": 3.721}, {"text": "the", "start": 7428.0, "duration": 4.0}, {"text": "they made some updates to those um", "start": 7429.4, "duration": 6.48}, {"text": "Nvidia um samples that actually would", "start": 7432.0, "duration": 5.84}, {"text": "compile but they they build files then", "start": 7435.88, "duration": 3.56}, {"text": "make files they checking for certain", "start": 7437.84, "duration": 4.239}, {"text": "things um that is only available in a", "start": 7439.44, "duration": 4.6}, {"text": "newer cter version um but with the NV", "start": 7442.079, "duration": 6.281}, {"text": "HPC it should works so if you do a", "start": 7444.04, "duration": 7.72}, {"text": "module list if you have check if TI", "start": 7448.36, "duration": 8.239}, {"text": "check if you have um NV HPC", "start": 7451.76, "duration": 4.839}, {"text": "loaded", "start": 7457.8, "duration": 3.0}, {"text": "yeah so K if you do", "start": 7466.36, "duration": 3.6}, {"text": "um NV", "start": 7470.719, "duration": 3.44}, {"text": "HPC", "start": 7487.76, "duration": 3.0}, {"text": "and then so if you if you issue nvcc D-", "start": 7509.679, "duration": 4.801}, {"text": "version you should you should get this", "start": 7512.599, "duration": 4.361}, {"text": "output", "start": 7514.48, "duration": 2.48}, {"text": "here", "start": 7517.679, "duration": 3.0}, {"text": "and then in addition you need to", "start": 7523.079, "duration": 5.681}, {"text": "do this export command again this has to", "start": 7525.0, "duration": 6.079}, {"text": "do with um the version of the", "start": 7528.76, "duration": 7.399}, {"text": "cter samples andv video's cter samples", "start": 7531.079, "duration": 5.08}, {"text": "um okay I I assume that most of you had", "start": 7543.4, "duration": 4.799}, {"text": "a little bit of a chance to play around", "start": 7546.599, "duration": 3.241}, {"text": "with that", "start": 7548.199, "duration": 3.161}, {"text": "um", "start": 7549.84, "duration": 3.12}, {"text": "perhaps", "start": 7551.36, "duration": 3.839}, {"text": "compile all those examples that I", "start": 7552.96, "duration": 3.239}, {"text": "mentioned", "start": 7555.199, "duration": 2.52}, {"text": "here", "start": 7556.199, "duration": 4.641}, {"text": "um and so so we have a half an hour", "start": 7557.719, "duration": 6.641}, {"text": "about half an hour left um so let me go", "start": 7560.84, "duration": 6.04}, {"text": "to open ACC explain to you what open ACC", "start": 7564.36, "duration": 5.08}, {"text": "is", "start": 7566.88, "duration": 2.56}, {"text": "um give you a brief introduction to op", "start": 7571.92, "duration": 5.44}, {"text": "ACC and then hopefully we'll have", "start": 7574.92, "duration": 5.6}, {"text": "another 10 to 15 minutes to play with", "start": 7577.36, "duration": 6.68}, {"text": "that I'm always overly optimistic with", "start": 7580.52, "duration": 7.599}, {"text": "respect to time so hope we have enough", "start": 7584.04, "duration": 4.079}, {"text": "time so open ACC is directive based", "start": 7588.159, "duration": 7.04}, {"text": "programming and it's an open standard", "start": 7592.239, "duration": 5.801}, {"text": "for expressing accelerated parallelism", "start": 7595.199, "duration": 4.721}, {"text": "so what that means it is it is a", "start": 7598.04, "duration": 4.8}, {"text": "standard it's you know um being adopted", "start": 7599.92, "duration": 5.48}, {"text": "by different", "start": 7602.84, "duration": 6.04}, {"text": "um vendors not only not not only inidia", "start": 7605.4, "duration": 7.08}, {"text": "right so in some sense portable and it's", "start": 7608.88, "duration": 5.56}, {"text": "designed to make porting to gpus easy", "start": 7612.48, "duration": 4.96}, {"text": "quick and portable right so easy means", "start": 7614.44, "duration": 4.08}, {"text": "you know you don't have to write these", "start": 7617.44, "duration": 3.759}, {"text": "computer kernels quick yeah it's faster", "start": 7618.52, "duration": 4.36}, {"text": "because of that and then portable you", "start": 7621.199, "duration": 4.321}, {"text": "know it should work on different", "start": 7622.88, "duration": 4.759}, {"text": "Generations but also different GPU", "start": 7625.52, "duration": 4.44}, {"text": "architectures because in principle the", "start": 7627.639, "duration": 4.56}, {"text": "standard doesn't say it has to be acute", "start": 7629.96, "duration": 6.119}, {"text": "or capable GPU right and it's open in P", "start": 7632.199, "duration": 5.321}, {"text": "like compiler", "start": 7636.079, "duration": 3.881}, {"text": "directives um if the compiler doesn't", "start": 7637.52, "duration": 3.8}, {"text": "understand the directives it will ignore", "start": 7639.96, "duration": 3.52}, {"text": "them so you can compile your code still", "start": 7641.32, "duration": 6.08}, {"text": "um with your whatever favorite uh CPU", "start": 7643.48, "duration": 6.239}, {"text": "compiler um so the code can work with or", "start": 7647.4, "duration": 4.64}, {"text": "without accelerators um it's available", "start": 7649.719, "duration": 3.761}, {"text": "for Porton and", "start": 7652.04, "duration": 4.28}, {"text": "C uh it's fully supported by the PGI", "start": 7653.48, "duration": 5.84}, {"text": "compilers crate compilers and CRA", "start": 7656.32, "duration": 4.48}, {"text": "there's a partial support by new", "start": 7659.32, "duration": 3.96}, {"text": "compilers um but they also of course you", "start": 7660.8, "duration": 4.48}, {"text": "know going into open and key", "start": 7663.28, "duration": 6.319}, {"text": "Direction um and yeah so the really the", "start": 7665.28, "duration": 7.16}, {"text": "most mature compilers are the PGI or", "start": 7669.599, "duration": 6.281}, {"text": "nowadays basically the niga", "start": 7672.44, "duration": 6.32}, {"text": "compilers um there's also open in P but", "start": 7675.88, "duration": 5.48}, {"text": "it's not yet as major for gpus and I", "start": 7678.76, "duration": 5.0}, {"text": "don't know much about it I have never", "start": 7681.36, "duration": 4.879}, {"text": "used it so I will also not discuss much", "start": 7683.76, "duration": 3.959}, {"text": "here I mean I've used open MP but not", "start": 7686.239, "duration": 4.241}, {"text": "for offloading to", "start": 7687.719, "duration": 6.641}, {"text": "gpus so there's a PGI Community Edition", "start": 7690.48, "duration": 6.159}, {"text": "available under this uh link here but", "start": 7694.36, "duration": 5.52}, {"text": "it's been replaced by the Nidia HPC SDK", "start": 7696.639, "duration": 5.52}, {"text": "so you know you just get the um Nidia", "start": 7699.88, "duration": 3.48}, {"text": "HPC", "start": 7702.159, "duration": 4.48}, {"text": "SDK um you can still load though the we", "start": 7703.36, "duration": 8.199}, {"text": "have the PGI um modules on expans if you", "start": 7706.639, "duration": 6.56}, {"text": "wanted to use", "start": 7711.559, "duration": 6.241}, {"text": "those um and here's a simple example so", "start": 7713.199, "duration": 6.601}, {"text": "remember I we've been talking about", "start": 7717.8, "duration": 4.12}, {"text": "vector addition and S xpy which is", "start": 7719.8, "duration": 3.6}, {"text": "basically vector addition with some", "start": 7721.92, "duration": 4.12}, {"text": "additional you know multiplication here", "start": 7723.4, "duration": 6.48}, {"text": "of the scaling of one of the vect", "start": 7726.04, "duration": 5.84}, {"text": "and if you were to implement that in", "start": 7729.88, "duration": 5.719}, {"text": "serial right um if an example in Pon on", "start": 7731.88, "duration": 7.16}, {"text": "the right and in C on the left you just", "start": 7735.599, "duration": 5.96}, {"text": "have a for Loop or or a do Loop right", "start": 7739.04, "duration": 5.079}, {"text": "that just just this vector", "start": 7741.559, "duration": 5.04}, {"text": "addition", "start": 7744.119, "duration": 5.241}, {"text": "um and so you could write this function", "start": 7746.599, "duration": 5.08}, {"text": "here right instead of using a plus", "start": 7749.36, "duration": 3.719}, {"text": "library of course you would use a blast", "start": 7751.679, "duration": 3.241}, {"text": "library but let's assume there is no", "start": 7753.079, "duration": 3.48}, {"text": "blast Library you would write that", "start": 7754.92, "duration": 4.319}, {"text": "function yourself and that's what it", "start": 7756.559, "duration": 7.481}, {"text": "does and um now instead of you know", "start": 7759.239, "duration": 7.601}, {"text": "writing a cuter kernel and you know like", "start": 7764.04, "duration": 4.4}, {"text": "this Vector Edition that we did and", "start": 7766.84, "duration": 4.12}, {"text": "doing the memory copies and so on well", "start": 7768.44, "duration": 4.6}, {"text": "all you do is you insert a pragma ACC", "start": 7770.96, "duration": 3.96}, {"text": "kernels here or you have a region here", "start": 7773.04, "duration": 4.36}, {"text": "ACC kernels and ACC and", "start": 7774.92, "duration": 4.44}, {"text": "kernels um in", "start": 7777.4, "duration": 6.239}, {"text": "Pon and that's it and and and now it", "start": 7779.36, "duration": 6.759}, {"text": "should magically work on on the", "start": 7783.639, "duration": 5.48}, {"text": "CPU and so it does right so here's the", "start": 7786.119, "duration": 5.841}, {"text": "entire code so here's our SXP function", "start": 7789.119, "duration": 6.04}, {"text": "it has the pragma ACC kernels here so", "start": 7791.96, "duration": 7.159}, {"text": "it's really tells okay open ACC generate", "start": 7795.159, "duration": 7.641}, {"text": "kernel for this Loop okay for this", "start": 7799.119, "duration": 5.841}, {"text": "region so it's inside of this region of", "start": 7802.8, "duration": 5.08}, {"text": "you know Del limited by the C brackets", "start": 7804.96, "duration": 5.56}, {"text": "but it will try to parallelize that and", "start": 7807.88, "duration": 4.279}, {"text": "this is the entire program this just the", "start": 7810.52, "duration": 3.4}, {"text": "main program where you know we're just", "start": 7812.159, "duration": 5.761}, {"text": "setting some input values here and um", "start": 7813.92, "duration": 6.639}, {"text": "then then we call the SXP", "start": 7817.92, "duration": 6.759}, {"text": "function um if you have the the P group", "start": 7820.559, "duration": 7.08}, {"text": "pil so there's like pgcc is the C", "start": 7824.679, "duration": 5.92}, {"text": "compiler pgf KN is the foron compiler", "start": 7827.639, "duration": 4.761}, {"text": "for 90", "start": 7830.599, "duration": 4.56}, {"text": "compiler now", "start": 7832.4, "duration": 6.64}, {"text": "um if you just use pgcc or PG f90 on the", "start": 7835.159, "duration": 8.841}, {"text": "c or f90 code um you know", "start": 7839.04, "duration": 8.32}, {"text": "um without these options here um it's", "start": 7844.0, "duration": 6.4}, {"text": "just going to generate the code for the", "start": 7847.36, "duration": 6.6}, {"text": "CPU um now if you say minus ACC it tells", "start": 7850.4, "duration": 6.159}, {"text": "the compiler oh there are open ACC Pras", "start": 7853.96, "duration": 4.92}, {"text": "in there so do interpret those and", "start": 7856.559, "duration": 6.281}, {"text": "generate code for the GPU via open ACC", "start": 7858.88, "duration": 5.359}, {"text": "and then you have to define a Target", "start": 7862.84, "duration": 2.759}, {"text": "architecture", "start": 7864.239, "duration": 4.641}, {"text": "so um Tesla are basically the data", "start": 7865.599, "duration": 6.761}, {"text": "center GP so you tell it to use Tesla", "start": 7868.88, "duration": 6.279}, {"text": "you probably can leave that off", "start": 7872.36, "duration": 6.4}, {"text": "um um in the newer versions of the p GCC", "start": 7875.159, "duration": 6.0}, {"text": "compiler or you know the NB nvs", "start": 7878.76, "duration": 6.799}, {"text": "compilers um the NB HPC SDK um don't", "start": 7881.159, "duration": 7.721}, {"text": "require these options anymore um but you", "start": 7885.559, "duration": 5.761}, {"text": "have to same minus AC right and then", "start": 7888.88, "duration": 4.48}, {"text": "this is just from information so you're", "start": 7891.32, "duration": 4.0}, {"text": "requesting some information about what", "start": 7893.36, "duration": 3.96}, {"text": "what what does the compiler actually do", "start": 7895.32, "duration": 3.68}, {"text": "when he accelerates the code when he", "start": 7897.32, "duration": 5.16}, {"text": "generates basically the GPU code so if", "start": 7899.0, "duration": 6.199}, {"text": "you issue that command it will tell give", "start": 7902.48, "duration": 4.32}, {"text": "you some output because you you", "start": 7905.199, "duration": 3.601}, {"text": "requested this information and it tells", "start": 7906.8, "duration": 4.12}, {"text": "you okay there's in line eight it", "start": 7908.8, "duration": 5.399}, {"text": "generates a copy in and it generates a", "start": 7910.92, "duration": 4.56}, {"text": "copy of", "start": 7914.199, "duration": 4.641}, {"text": "Y and in line nine it recognizes oh this", "start": 7915.48, "duration": 6.36}, {"text": "loop is parallelizable and it generates", "start": 7918.84, "duration": 5.279}, {"text": "an accelerator kernel so it generates a", "start": 7921.84, "duration": 6.399}, {"text": "kernel for you generates Tesla code and", "start": 7924.119, "duration": 6.201}, {"text": "so for line n gives you some more", "start": 7928.239, "duration": 4.281}, {"text": "information about you know um the loop", "start": 7930.32, "duration": 4.56}, {"text": "vectorization with the gang and vectors", "start": 7932.52, "duration": 5.84}, {"text": "and so that's basically what maps to", "start": 7934.88, "duration": 6.279}, {"text": "threads and blocks so you see you know", "start": 7938.36, "duration": 4.92}, {"text": "these are basically block idx and thread", "start": 7941.159, "duration": 4.801}, {"text": "idx so what what it did is actually it", "start": 7943.28, "duration": 4.56}, {"text": "it generated code and by default", "start": 7945.96, "duration": 4.759}, {"text": "generated um code with a kernel launch", "start": 7947.84, "duration": 7.839}, {"text": "configuration of um 128 threats per", "start": 7950.719, "duration": 8.241}, {"text": "block and", "start": 7955.679, "duration": 7.52}, {"text": "remember X is an input Y is an input or", "start": 7958.96, "duration": 7.159}, {"text": "Y is also an output of the function so", "start": 7963.199, "duration": 6.88}, {"text": "it copies only EX to the GPU but not", "start": 7966.119, "duration": 6.6}, {"text": "back and for y it copies to the GPU and", "start": 7970.079, "duration": 4.361}, {"text": "when it's done back so that's the copy", "start": 7972.719, "duration": 3.641}, {"text": "and copy function so it seems to do all", "start": 7974.44, "duration": 3.0}, {"text": "these things", "start": 7976.36, "duration": 2.6}, {"text": "automatically", "start": 7977.44, "duration": 4.119}, {"text": "and then of course there are many many", "start": 7978.96, "duration": 5.92}, {"text": "more directives that you can use and", "start": 7981.559, "duration": 5.921}, {"text": "like you know You' see it now um okay", "start": 7984.88, "duration": 4.6}, {"text": "now I've switched left is water and the", "start": 7987.48, "duration": 5.52}, {"text": "right is c um so you often have these", "start": 7989.48, "duration": 5.759}, {"text": "directives with optional Clauses that", "start": 7993.0, "duration": 4.639}, {"text": "you can add um they are followed by", "start": 7995.239, "duration": 6.201}, {"text": "structure code block and in foron you", "start": 7997.639, "duration": 5.361}, {"text": "often you know you have to pair them", "start": 8001.44, "duration": 3.6}, {"text": "with a matching end directive so", "start": 8003.0, "duration": 3.84}, {"text": "surrounding a structure code BL like", "start": 8005.04, "duration": 3.32}, {"text": "that for do Loop right otherwise it", "start": 8006.84, "duration": 3.319}, {"text": "doesn't know where to end while then see", "start": 8008.36, "duration": 4.6}, {"text": "you have the brackets qu brackets so it", "start": 8010.159, "duration": 5.08}, {"text": "knows where where that", "start": 8012.96, "duration": 6.0}, {"text": "ends um and there the kernels construct", "start": 8015.239, "duration": 5.561}, {"text": "right so that's the one that we used", "start": 8018.96, "duration": 4.52}, {"text": "track my ACC kernels so you see it's", "start": 8020.8, "duration": 4.919}, {"text": "followed by structured code block here", "start": 8023.48, "duration": 3.8}, {"text": "or you have the code block here in", "start": 8025.719, "duration": 5.4}, {"text": "between the Chronos and Chronos um um", "start": 8027.28, "duration": 6.799}, {"text": "problems and yeah", "start": 8031.119, "duration": 5.241}, {"text": "so then you can have Clauses and the", "start": 8034.079, "duration": 3.921}, {"text": "Clauses can you know can have if", "start": 8036.36, "duration": 4.759}, {"text": "statements there if a certain condition", "start": 8038.0, "duration": 5.719}, {"text": "is used or you know for asynchronous", "start": 8041.119, "duration": 5.12}, {"text": "exitu or data Clauses so let's look at", "start": 8043.719, "duration": 3.761}, {"text": "data", "start": 8046.239, "duration": 3.92}, {"text": "Clauses data Clauses you know can you", "start": 8047.48, "duration": 7.159}, {"text": "can use copy and then list is a list of", "start": 8050.159, "duration": 8.761}, {"text": "um um um it's a list of variables you", "start": 8054.639, "duration": 6.681}, {"text": "know arrays or you know that that that", "start": 8058.92, "duration": 5.36}, {"text": "you want to copy copy means you know", "start": 8061.32, "duration": 5.359}, {"text": "allocate memory on the GPU copy data", "start": 8064.28, "duration": 4.56}, {"text": "from the host to the GPU when entering", "start": 8066.679, "duration": 4.641}, {"text": "that region and copy the data to the", "start": 8068.84, "duration": 4.239}, {"text": "host when exiting the region and then", "start": 8071.32, "duration": 5.319}, {"text": "deallocate it copy in means just copy it", "start": 8073.079, "duration": 5.281}, {"text": "in but not back out right so those were", "start": 8076.639, "duration": 3.44}, {"text": "the two things that you've seen that", "start": 8078.36, "duration": 5.44}, {"text": "that the the compiler automatically did", "start": 8080.079, "duration": 6.48}, {"text": "um and then copy out means just copy out", "start": 8083.8, "duration": 4.2}, {"text": "right so that's basically just outut", "start": 8086.559, "duration": 3.64}, {"text": "data create means basically allocating", "start": 8088.0, "duration": 5.239}, {"text": "memory present means okay and this", "start": 8090.199, "duration": 4.52}, {"text": "region when we hit that region of the", "start": 8093.239, "duration": 4.281}, {"text": "code those variables are already present", "start": 8094.719, "duration": 6.321}, {"text": "on the GPU so don't just just use those", "start": 8097.52, "duration": 6.0}, {"text": "right um so you could imagine that you", "start": 8101.04, "duration": 6.8}, {"text": "have different regions of your code um", "start": 8103.52, "duration": 6.36}, {"text": "where you know you you you have a larger", "start": 8107.84, "duration": 3.6}, {"text": "code that's not just a single function", "start": 8109.88, "duration": 5.839}, {"text": "right um and you basically create", "start": 8111.44, "duration": 5.84}, {"text": "allocate memory somewhere and then you", "start": 8115.719, "duration": 3.081}, {"text": "do some", "start": 8117.28, "duration": 4.2}, {"text": "copy your operations you generate data", "start": 8118.8, "duration": 4.359}, {"text": "you compute something and then you you", "start": 8121.48, "duration": 3.44}, {"text": "hit another region where that you also", "start": 8123.159, "duration": 3.281}, {"text": "want to parallelize and the data is", "start": 8124.92, "duration": 3.759}, {"text": "already present and so those are things", "start": 8126.44, "duration": 4.679}, {"text": "that you can tell open", "start": 8128.679, "duration": 6.161}, {"text": "ACC and let's look at an example and I", "start": 8131.119, "duration": 6.321}, {"text": "have this example the sa xpy and this", "start": 8134.84, "duration": 5.2}, {"text": "this example they are in the repository", "start": 8137.44, "duration": 6.119}, {"text": "for you to play with and test it", "start": 8140.04, "duration": 7.199}, {"text": "um just as a background what this does", "start": 8143.559, "duration": 7.241}, {"text": "is basically Ally um for solving laas", "start": 8147.239, "duration": 5.521}, {"text": "equation two Dimension you know that's", "start": 8150.8, "duration": 5.52}, {"text": "um you know heat equation or there there", "start": 8152.76, "duration": 5.72}, {"text": "are many different", "start": 8156.32, "duration": 4.319}, {"text": "algorithms that that use this type of", "start": 8158.48, "duration": 3.52}, {"text": "operation it's really a stencil", "start": 8160.639, "duration": 3.801}, {"text": "operation where in this case we have a", "start": 8162.0, "duration": 5.119}, {"text": "two-dimensional grid and we have", "start": 8164.44, "duration": 5.159}, {"text": "starting values", "start": 8167.119, "duration": 5.681}, {"text": "and then we do an iteration the", "start": 8169.599, "duration": 6.881}, {"text": "iteration here is is an index K so our", "start": 8172.8, "duration": 7.799}, {"text": "next inter iteration at step k +", "start": 8176.48, "duration": 8.04}, {"text": "one um we want to", "start": 8180.599, "duration": 6.201}, {"text": "compute the value is basically an", "start": 8184.52, "duration": 5.199}, {"text": "average of the neighboring values okay", "start": 8186.8, "duration": 6.679}, {"text": "so you see we we need to look at the", "start": 8189.719, "duration": 6.481}, {"text": "neighboring uh um elements to the left", "start": 8193.479, "duration": 5.16}, {"text": "to the uh right to the top and to the", "start": 8196.2, "duration": 4.76}, {"text": "bottom and then just divide those by", "start": 8198.639, "duration": 4.441}, {"text": "four so that's what the algorithm does", "start": 8200.96, "duration": 3.759}, {"text": "right", "start": 8203.08, "duration": 6.279}, {"text": "um this is the C codee right so", "start": 8204.719, "duration": 8.64}, {"text": "um we do this iteration until basically", "start": 8209.359, "duration": 5.921}, {"text": "between two steps the value of this", "start": 8213.359, "duration": 3.881}, {"text": "Matrix element a or this grid point", "start": 8215.28, "duration": 4.159}, {"text": "doesn't change anymore within a certain", "start": 8217.24, "duration": 5.84}, {"text": "threshold so we have a while loop here", "start": 8219.439, "duration": 6.641}, {"text": "okay where we iterate as long as our", "start": 8223.08, "duration": 6.399}, {"text": "error so the maximum difference between", "start": 8226.08, "duration": 5.84}, {"text": "the current and the previous iteration", "start": 8229.479, "duration": 5.681}, {"text": "is larger than a threshold", "start": 8231.92, "duration": 6.12}, {"text": "tolerance and while we have't exceeded", "start": 8235.16, "duration": 4.8}, {"text": "maximum iteration so we can say okay do", "start": 8238.04, "duration": 5.599}, {"text": "only 1,000 iterations then stop right so", "start": 8239.96, "duration": 6.559}, {"text": "we set an error to zero and then we have", "start": 8243.639, "duration": 5.481}, {"text": "this double Loop right where we go just", "start": 8246.519, "duration": 5.361}, {"text": "through each element I and J and we", "start": 8249.12, "duration": 4.559}, {"text": "compute the new", "start": 8251.88, "duration": 5.479}, {"text": "element as uh you know the average of", "start": 8253.679, "duration": 6.76}, {"text": "the neighboring elements right and then", "start": 8257.359, "duration": 5.841}, {"text": "we look at the error we update the error", "start": 8260.439, "duration": 5.601}, {"text": "as basically the maximum of you know the", "start": 8263.2, "duration": 5.239}, {"text": "new uh Matrix element or you know grid", "start": 8266.04, "duration": 4.639}, {"text": "element minus the previous one", "start": 8268.439, "duration": 5.16}, {"text": "okay um when this Loop is done all we", "start": 8270.679, "duration": 4.72}, {"text": "have to do is we need to swap the input", "start": 8273.599, "duration": 5.201}, {"text": "and output arrays um this is sort of", "start": 8275.399, "duration": 4.881}, {"text": "stupid here because really we just need", "start": 8278.8, "duration": 3.639}, {"text": "to swap the pointers but this just for", "start": 8280.28, "duration": 5.239}, {"text": "illustration purposes um for open AC so", "start": 8282.439, "duration": 5.08}, {"text": "in reality you know you would just swap", "start": 8285.519, "duration": 3.601}, {"text": "the pointers here you don't need to", "start": 8287.519, "duration": 4.2}, {"text": "really copy the data but here we're", "start": 8289.12, "duration": 5.199}, {"text": "copying the data basically from the new", "start": 8291.719, "duration": 6.361}, {"text": "output uh array into the pr this one and", "start": 8294.319, "duration": 5.36}, {"text": "then and then we increase our counter", "start": 8298.08, "duration": 5.0}, {"text": "and we do this whole thing again now", "start": 8299.679, "duration": 6.92}, {"text": "great this is a double Loop um I do", "start": 8303.08, "duration": 5.0}, {"text": "something in the Matrix let's just do", "start": 8306.599, "duration": 4.201}, {"text": "this in parallel on the GPU and then", "start": 8308.08, "duration": 4.92}, {"text": "let's do this also in parallel on GPU", "start": 8310.8, "duration": 4.96}, {"text": "right so pragma ACC Kels like in the", "start": 8313.0, "duration": 5.24}, {"text": "Saxy example", "start": 8315.76, "duration": 6.839}, {"text": "great um now we compile this and you can", "start": 8318.24, "duration": 5.96}, {"text": "use the fortron version there's in the", "start": 8322.599, "duration": 2.96}, {"text": "example there's a fortron version and", "start": 8324.2, "duration": 5.159}, {"text": "there's also C version um and you'll see", "start": 8325.559, "duration": 5.16}, {"text": "what it does you know generates this", "start": 8329.359, "duration": 4.401}, {"text": "copy out copy in accelerator kernel", "start": 8330.719, "duration": 5.081}, {"text": "generated and so on you get all this", "start": 8333.76, "duration": 3.959}, {"text": "information um so it generates two", "start": 8335.8, "duration": 4.559}, {"text": "kernels for the two regions here right", "start": 8337.719, "duration": 3.521}, {"text": "for", "start": 8340.359, "duration": 5.401}, {"text": "this um um update you know the jaob", "start": 8341.24, "duration": 6.92}, {"text": "update and for the", "start": 8345.76, "duration": 7.919}, {"text": "um um swap data elements copy operation", "start": 8348.16, "duration": 8.88}, {"text": "okay well let's run this these are all", "start": 8353.679, "duration": 5.441}, {"text": "timings so if you you play around with", "start": 8357.04, "duration": 4.0}, {"text": "that on expans you'll get very different", "start": 8359.12, "duration": 4.319}, {"text": "numbers of course", "start": 8361.04, "duration": 6.08}, {"text": "right I have an opening version of this", "start": 8363.439, "duration": 6.401}, {"text": "and so this was in the predecessor of of", "start": 8367.12, "duration": 6.04}, {"text": "expans and so okay thousand iterations", "start": 8369.84, "duration": 6.08}, {"text": "took like 69 seconds for the whatever", "start": 8373.16, "duration": 5.439}, {"text": "Matrix size the grid size that we have", "start": 8375.92, "duration": 4.559}, {"text": "um you get a speed up of about two when", "start": 8378.599, "duration": 4.76}, {"text": "I use two open and P threats three and", "start": 8380.479, "duration": 5.0}, {"text": "four you know", "start": 8383.359, "duration": 4.881}, {"text": "um you know with four and six opening P", "start": 8385.479, "duration": 5.281}, {"text": "thre so at some point it becomes slower", "start": 8388.24, "duration": 5.64}, {"text": "so you know goes down to 17 seconds", "start": 8390.76, "duration": 5.0}, {"text": "something like that um you can you can", "start": 8393.88, "duration": 5.479}, {"text": "try up to 10 cores on the on the GPU no", "start": 8395.76, "duration": 6.16}, {"text": "right if you compile it on the GPU no", "start": 8399.359, "duration": 4.96}, {"text": "you could compile that with open also in", "start": 8401.92, "duration": 5.32}, {"text": "the expans C you know of", "start": 8404.319, "duration": 5.921}, {"text": "course and open ACC what we just added", "start": 8407.24, "duration": 5.56}, {"text": "those pragmas and oh my gosh it's 500", "start": 8410.24, "duration": 5.4}, {"text": "seconds right it's super slow so it's", "start": 8412.8, "duration": 5.72}, {"text": "um uh that's a complete fail I would say", "start": 8415.64, "duration": 6.44}, {"text": "right so what happened um now you can", "start": 8418.52, "duration": 6.68}, {"text": "set this environment variable pgac time", "start": 8422.08, "duration": 7.64}, {"text": "equals one that activates profiling and", "start": 8425.2, "duration": 6.36}, {"text": "and then you just run that executable", "start": 8429.72, "duration": 5.08}, {"text": "again and you will notice that here we", "start": 8431.56, "duration": 5.799}, {"text": "have a compute region a kernel is being", "start": 8434.8, "duration": 5.44}, {"text": "launched 1,000 times so because you know", "start": 8437.359, "duration": 4.361}, {"text": "we I said the maximum number of", "start": 8440.24, "duration": 3.04}, {"text": "iterations to", "start": 8441.72, "duration": 4.92}, {"text": "1,000 um and it takes about 1.5 seconds", "start": 8443.28, "duration": 5.48}, {"text": "so these are mic Ms here", "start": 8446.64, "duration": 3.64}, {"text": "right", "start": 8448.76, "duration": 3.679}, {"text": "1.4 5 million", "start": 8450.28, "duration": 5.36}, {"text": "micros but we have data copy in and data", "start": 8452.439, "duration": 6.04}, {"text": "copy out and they take like 22.5 seconds", "start": 8455.64, "duration": 5.12}, {"text": "like okay this is crazy I'm copying data", "start": 8458.479, "duration": 4.441}, {"text": "all the time right so all this time is", "start": 8460.76, "duration": 4.24}, {"text": "spent transferring data between the host", "start": 8462.92, "duration": 3.76}, {"text": "and the", "start": 8465.0, "duration": 4.28}, {"text": "device and basically what's happening in", "start": 8466.68, "duration": 6.32}, {"text": "each iteration here in this V Loop um", "start": 8469.28, "duration": 6.079}, {"text": "you know because I have this kernel here", "start": 8473.0, "duration": 4.6}, {"text": "open AC inspected this and says okay I", "start": 8475.359, "duration": 4.881}, {"text": "need a new on the GPU and I need a on", "start": 8477.6, "duration": 6.719}, {"text": "the GPU so I copy this in from the CPU I", "start": 8480.24, "duration": 7.04}, {"text": "do my update and a copy those back right", "start": 8484.319, "duration": 4.881}, {"text": "so we have these copies happen every", "start": 8487.28, "duration": 4.68}, {"text": "iteration of the outra vi and of course", "start": 8489.2, "duration": 5.48}, {"text": "that's not necessary but you know open", "start": 8491.96, "duration": 4.56}, {"text": "ACC doesn't know that I mean there's no", "start": 8494.68, "duration": 3.32}, {"text": "way for it to know so you need to help", "start": 8496.52, "duration": 3.64}, {"text": "the compiler and that's where you need", "start": 8498.0, "duration": 5.319}, {"text": "these data regions so you add a prma", "start": 8500.16, "duration": 4.72}, {"text": "here ACC", "start": 8503.319, "duration": 5.681}, {"text": "data copy a to the GPU and allocate a", "start": 8504.88, "duration": 6.479}, {"text": "new on the GPU and that's all we need in", "start": 8509.0, "duration": 4.6}, {"text": "that region and that will help the", "start": 8511.359, "duration": 4.401}, {"text": "compiler because now once it generates", "start": 8513.6, "duration": 4.719}, {"text": "this kernel you know a is already in the", "start": 8515.76, "duration": 5.32}, {"text": "GPU a new is already allocated in the", "start": 8518.319, "duration": 5.12}, {"text": "GPU so it doesn't need to copy the data", "start": 8521.08, "duration": 3.92}, {"text": "just keeps it on", "start": 8523.439, "duration": 4.521}, {"text": "GPU and that pragma is outside of that V", "start": 8525.0, "duration": 5.24}, {"text": "Loop so it will copy back only after", "start": 8527.96, "duration": 5.0}, {"text": "after the um iterations are done right", "start": 8530.24, "duration": 5.0}, {"text": "of course we want a back because we want", "start": 8532.96, "duration": 4.399}, {"text": "to have the a the converged solution as", "start": 8535.24, "duration": 3.4}, {"text": "an", "start": 8537.359, "duration": 3.761}, {"text": "output and with that you have helped the", "start": 8538.64, "duration": 4.88}, {"text": "compiler and now you recompile it and", "start": 8541.12, "duration": 5.12}, {"text": "now we see if we run that on the GPU", "start": 8543.52, "duration": 5.2}, {"text": "those were the you know k80 Kepler", "start": 8546.24, "duration": 3.72}, {"text": "architectures that's even two", "start": 8548.72, "duration": 4.679}, {"text": "generations older than the e100s um is", "start": 8549.96, "duration": 4.439}, {"text": "now", "start": 8553.399, "duration": 4.761}, {"text": "three 3.4 times faster than than using", "start": 8554.399, "duration": 6.441}, {"text": "six um opening T threads right so now we", "start": 8558.16, "duration": 4.48}, {"text": "have actually we got the time down from", "start": 8560.84, "duration": 5.44}, {"text": "like 70 seconds to 5 seconds and U that", "start": 8562.64, "duration": 5.64}, {"text": "that with that said you know um open", "start": 8566.28, "duration": 5.56}, {"text": "apcc gives it much more options um to", "start": 8568.28, "duration": 5.32}, {"text": "control parallelization why are there", "start": 8571.84, "duration": 5.24}, {"text": "gang worker and Vector Clauses and know", "start": 8573.6, "duration": 5.16}, {"text": "that's the reason why I introduce you", "start": 8577.08, "duration": 3.2}, {"text": "also to ca because if you don't", "start": 8578.76, "duration": 3.04}, {"text": "understand CUA you don't know what these", "start": 8580.28, "duration": 3.48}, {"text": "things are you know um so gangs", "start": 8581.8, "duration": 3.519}, {"text": "correspond to blocks that share the", "start": 8583.76, "duration": 4.84}, {"text": "resources such as cash and so on and the", "start": 8585.319, "duration": 5.08}, {"text": "threats they work in lock step so those", "start": 8588.6, "duration": 5.64}, {"text": "are basically the the warps um um the", "start": 8590.399, "duration": 5.92}, {"text": "vector cles and the worker are the are", "start": 8594.24, "duration": 4.84}, {"text": "the threats per", "start": 8596.319, "duration": 2.761}, {"text": "block and so by understanding more about", "start": 8599.24, "duration": 5.92}, {"text": "the open ACC execution model and the GPU", "start": 8601.6, "duration": 5.96}, {"text": "Hardware you can get higher speed UPS on", "start": 8605.16, "duration": 4.159}, {"text": "on on even higher speed UPS on the code", "start": 8607.56, "duration": 3.24}, {"text": "you know there better optimizations that", "start": 8609.319, "duration": 2.96}, {"text": "you couldn't", "start": 8610.8, "duration": 4.24}, {"text": "make um often you have to reorganize the", "start": 8612.279, "duration": 5.721}, {"text": "code you have to often what you have to", "start": 8615.04, "duration": 5.48}, {"text": "do is you have to rearrange how memory", "start": 8618.0, "duration": 5.68}, {"text": "is laid out how data is stored and so on", "start": 8620.52, "duration": 7.28}, {"text": "and and so it makes it easier than than", "start": 8623.68, "duration": 5.44}, {"text": "using cter", "start": 8627.8, "duration": 3.519}, {"text": "but depending on the problem and how", "start": 8629.12, "duration": 4.359}, {"text": "your code looks like that you start with", "start": 8631.319, "duration": 4.96}, {"text": "it can still be a significant amount of", "start": 8633.479, "duration": 5.641}, {"text": "work um there some more information here", "start": 8636.279, "duration": 6.16}, {"text": "about open ACC and tips and tricks um", "start": 8639.12, "duration": 6.72}, {"text": "this is for compulation we've seen that", "start": 8642.439, "duration": 7.721}, {"text": "um um not much I need to tell you um and", "start": 8645.84, "duration": 6.519}, {"text": "I just say you have a look at the hands", "start": 8650.16, "duration": 3.52}, {"text": "on", "start": 8652.359, "duration": 3.641}, {"text": "exercises um", "start": 8653.68, "duration": 4.719}, {"text": "finally", "start": 8656.0, "duration": 5.68}, {"text": "these handson exercises um that that", "start": 8658.399, "duration": 5.121}, {"text": "that GitHub repository read me file has", "start": 8661.68, "duration": 4.24}, {"text": "some information right um for you to get", "start": 8663.52, "duration": 5.44}, {"text": "started there is this Saxy example and", "start": 8665.92, "duration": 5.88}, {"text": "this La plus Tod um is it contains this", "start": 8668.96, "duration": 5.96}, {"text": "jaob iteration um check the read me", "start": 8671.8, "duration": 5.8}, {"text": "files in those directories I compile and", "start": 8674.92, "duration": 6.72}, {"text": "run the open ACC examples and then can", "start": 8677.6, "duration": 6.12}, {"text": "so you can use the PGI compilers or you", "start": 8681.64, "duration": 3.32}, {"text": "can try to use", "start": 8683.72, "duration": 4.04}, {"text": "nbpc um so the Nvidia comp pish um", "start": 8684.96, "duration": 5.12}, {"text": "should be able to do this the same way", "start": 8687.76, "duration": 3.719}, {"text": "and then you can check the timings you", "start": 8690.08, "duration": 3.399}, {"text": "know in the CPU and", "start": 8691.479, "duration": 4.481}, {"text": "serial uh opening P", "start": 8693.479, "duration": 4.8}, {"text": "parallel and running on the GPU with", "start": 8695.96, "duration": 5.64}, {"text": "open ACC what you get on the um expans", "start": 8698.279, "duration": 5.721}, {"text": "GPU noes and with a V 100", "start": 8701.6, "duration": 7.44}, {"text": "G um I have two or three more slides", "start": 8704.0, "duration": 7.84}, {"text": "I'll just briefly gloss over them it's", "start": 8709.04, "duration": 4.76}, {"text": "three slides I just wanted to mention", "start": 8711.84, "duration": 3.8}, {"text": "that these profiling", "start": 8713.8, "duration": 3.599}, {"text": "tools um", "start": 8715.64, "duration": 4.92}, {"text": "so the older tools nvpr and nvp that's", "start": 8717.399, "duration": 6.161}, {"text": "for Cuda and the inside tools really", "start": 8720.56, "duration": 4.799}, {"text": "those you have the inside systems that", "start": 8723.56, "duration": 5.16}, {"text": "gives you an overview of the entire code", "start": 8725.359, "duration": 5.721}, {"text": "execution um this is really for graphics", "start": 8728.72, "duration": 4.12}, {"text": "development I have no clue about this", "start": 8731.08, "duration": 4.92}, {"text": "but um inside computers detail panel", "start": 8732.84, "duration": 4.68}, {"text": "performance so once you get there once", "start": 8736.0, "duration": 4.08}, {"text": "you WR UT code um these are very very", "start": 8737.52, "duration": 6.16}, {"text": "good tools um performance optimizations", "start": 8740.08, "duration": 5.399}, {"text": "and then there's also profiling tools", "start": 8743.68, "duration": 5.04}, {"text": "for de learning app applications so DL", "start": 8745.479, "duration": 8.92}, {"text": "Prof um and you know it works with nbtx", "start": 8748.72, "duration": 8.36}, {"text": "um plugins that are available in tensor", "start": 8754.399, "duration": 3.641}, {"text": "flow and", "start": 8757.08, "duration": 2.92}, {"text": "pytorch", "start": 8758.04, "duration": 5.0}, {"text": "and um", "start": 8760.0, "duration": 6.12}, {"text": "so there's already optimized versions by", "start": 8763.04, "duration": 4.88}, {"text": "Nvidia for their Hardware that that", "start": 8766.12, "duration": 4.359}, {"text": "contain ntx markers that basically tell", "start": 8767.92, "duration": 4.24}, {"text": "the compiler you know what's happening", "start": 8770.479, "duration": 4.361}, {"text": "and you know time stamps and so on", "start": 8772.16, "duration": 5.52}, {"text": "annotate um and focusing sections of", "start": 8774.84, "duration": 5.36}, {"text": "code that are important to the user and", "start": 8777.68, "duration": 4.719}, {"text": "the deal Prof itself calls these inside", "start": 8780.2, "duration": 4.36}, {"text": "systems tools to collect profiling data", "start": 8782.399, "duration": 3.92}, {"text": "and correlates it with the Deep learning", "start": 8784.56, "duration": 3.08}, {"text": "model so if you have a deep learning", "start": 8786.319, "duration": 2.761}, {"text": "application you can also actually do", "start": 8787.64, "duration": 2.639}, {"text": "some", "start": 8789.08, "duration": 3.52}, {"text": "profiling um and you can get", "start": 8790.279, "duration": 4.241}, {"text": "informations about are my gpus being", "start": 8792.6, "duration": 3.92}, {"text": "utilized or do I do a lot of data", "start": 8794.52, "duration": 4.48}, {"text": "transfers am I using the tenso course", "start": 8796.52, "duration": 5.68}, {"text": "yes or no um if not what's the reason", "start": 8799.0, "duration": 5.56}, {"text": "can I switch those on how can I improve", "start": 8802.2, "duration": 3.8}, {"text": "performance so there's a lot of", "start": 8804.56, "duration": 4.24}, {"text": "information like that", "start": 8806.0, "duration": 2.8}, {"text": "um and that's really pretty", "start": 8809.439, "duration": 6.401}, {"text": "straightforward to use um it just adds", "start": 8812.72, "duration": 5.24}, {"text": "you know poens of flow no additional", "start": 8815.84, "duration": 4.12}, {"text": "code modifications", "start": 8817.96, "duration": 5.0}, {"text": "required um you just if you want to", "start": 8819.96, "duration": 4.72}, {"text": "profile command line interface just", "start": 8822.96, "duration": 3.04}, {"text": "prepended with", "start": 8824.68, "duration": 4.2}, {"text": "DPR and then you can visualize the", "start": 8826.0, "duration": 5.279}, {"text": "results with a DPR viewer you know so", "start": 8828.88, "duration": 4.92}, {"text": "you'll get information um like", "start": 8831.279, "duration": 6.0}, {"text": "this um for p Tor you need to add Lin of", "start": 8833.8, "duration": 8.679}, {"text": "cod um to enable M Pro P toor nbtx", "start": 8837.279, "duration": 8.721}, {"text": "module and other than that is the same", "start": 8842.479, "duration": 6.041}, {"text": "then we can run deal Prof on on on your", "start": 8846.0, "duration": 5.0}, {"text": "code and with that you know thanks for", "start": 8848.52, "duration": 7.32}, {"text": "listening let's go to the um open ACC", "start": 8851.0, "duration": 6.92}, {"text": "tutorials um just play around a little", "start": 8855.84, "duration": 4.96}, {"text": "bit with that um yeah if you have any", "start": 8857.92, "duration": 6.16}, {"text": "questions I hope I can answer them um if", "start": 8860.8, "duration": 5.0}, {"text": "you have any other problems contact help", "start": 8864.08, "duration": 3.6}, {"text": "at x.org", "start": 8865.8, "duration": 5.32}, {"text": "and uh that brings me to the end of uh", "start": 8867.68, "duration": 6.04}, {"text": "my slides and here is information about", "start": 8871.12, "duration": 6.239}, {"text": "the Hands-On exercises for open", "start": 8873.72, "duration": 6.639}, {"text": "ACC", "start": 8877.359, "duration": 3.0}]