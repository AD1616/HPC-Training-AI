[{"text": "my name is bob sanchez i'm the director", "start": 0.08, "duration": 4.0}, {"text": "of education here at the san diego", "start": 1.839, "duration": 3.841}, {"text": "supercomputer center", "start": 4.08, "duration": 3.199}, {"text": "and i'm going to be i'm giving a very", "start": 5.68, "duration": 3.6}, {"text": "high level talk on parallel computing", "start": 7.279, "duration": 3.28}, {"text": "concepts", "start": 9.28, "duration": 3.6}, {"text": "um if you want to follow along take a", "start": 10.559, "duration": 5.841}, {"text": "look in the chat i had posted the um", "start": 12.88, "duration": 5.92}, {"text": "links to it to a pdf of the presentation", "start": 16.4, "duration": 5.039}, {"text": "and to a github repo that i used to", "start": 18.8, "duration": 5.76}, {"text": "generate some of the figures", "start": 21.439, "duration": 3.121}, {"text": "so", "start": 25.599, "duration": 3.041}, {"text": "this session um is really intended for", "start": 26.48, "duration": 4.959}, {"text": "for a very broad audience", "start": 28.64, "duration": 5.28}, {"text": "so we're looking at anybody who", "start": 31.439, "duration": 3.021}, {"text": "currently", "start": 33.92, "duration": 3.6}, {"text": "[Music]", "start": 34.46, "duration": 3.06}, {"text": "got too many messages popping up um okay", "start": 38.399, "duration": 5.041}, {"text": "um for for anybody who currently plans", "start": 41.28, "duration": 3.68}, {"text": "to run or is thinking about running", "start": 43.44, "duration": 5.119}, {"text": "applications on parallel computers", "start": 44.96, "duration": 5.68}, {"text": "um if you write proposals for computer", "start": 48.559, "duration": 4.081}, {"text": "time on campus clusters", "start": 50.64, "duration": 3.68}, {"text": "nationally allocated systems or other", "start": 52.64, "duration": 2.8}, {"text": "resources", "start": 54.32, "duration": 2.879}, {"text": "so if we have any", "start": 55.44, "duration": 4.48}, {"text": "more senior pis than on the call you", "start": 57.199, "duration": 4.641}, {"text": "know a lot of i know that a lot of you", "start": 59.92, "duration": 4.16}, {"text": "aren't directly involved in programming", "start": 61.84, "duration": 4.16}, {"text": "anymore that you might be the one", "start": 64.08, "duration": 3.92}, {"text": "leading the group you have graduate", "start": 66.0, "duration": 4.32}, {"text": "students post docs and so on who are", "start": 68.0, "duration": 5.119}, {"text": "they're doing the actual computing but", "start": 70.32, "duration": 4.08}, {"text": "you still need to understand the", "start": 73.119, "duration": 2.881}, {"text": "parallel computing concept so that you", "start": 74.4, "duration": 4.24}, {"text": "can write a good proposal", "start": 76.0, "duration": 5.36}, {"text": "um we're also looking at anybody who you", "start": 78.64, "duration": 4.64}, {"text": "know is purchasing time and compute", "start": 81.36, "duration": 3.84}, {"text": "resources and wants to return", "start": 83.28, "duration": 3.839}, {"text": "sorry and once maximize the return on", "start": 85.2, "duration": 4.0}, {"text": "investment for example if you're running", "start": 87.119, "duration": 4.801}, {"text": "if you're running in the cloud on aws or", "start": 89.2, "duration": 4.959}, {"text": "google cloud or azure um the same", "start": 91.92, "duration": 3.12}, {"text": "principles that we're going to be", "start": 94.159, "duration": 3.201}, {"text": "talking about here today apply there", "start": 95.04, "duration": 3.84}, {"text": "also", "start": 97.36, "duration": 3.36}, {"text": "um if you're thinking about purchasing", "start": 98.88, "duration": 3.36}, {"text": "hardware for your lab", "start": 100.72, "duration": 3.52}, {"text": "or and i'm sure this is this plus a lot", "start": 102.24, "duration": 3.44}, {"text": "of you if you're just curious about", "start": 104.24, "duration": 3.839}, {"text": "parallel computing", "start": 105.68, "duration": 5.52}, {"text": "so why are we doing this training", "start": 108.079, "duration": 6.161}, {"text": "so we've been involved um here at scsc", "start": 111.2, "duration": 5.519}, {"text": "and more broadly as part of xc we've", "start": 114.24, "duration": 4.64}, {"text": "been doing training for decades", "start": 116.719, "duration": 5.04}, {"text": "and you know very very very um very very", "start": 118.88, "duration": 4.48}, {"text": "skilled people doing the training doing", "start": 121.759, "duration": 2.881}, {"text": "the training", "start": 123.36, "duration": 2.96}, {"text": "um", "start": 124.64, "duration": 4.0}, {"text": "a lot of great technical content but we", "start": 126.32, "duration": 3.999}, {"text": "realized that a lot of the training that", "start": 128.64, "duration": 3.92}, {"text": "we do in parallel computing is targeted", "start": 130.319, "duration": 4.241}, {"text": "people who write their own parallel", "start": 132.56, "duration": 3.28}, {"text": "applications", "start": 134.56, "duration": 3.92}, {"text": "and it focuses on programmer topics so", "start": 135.84, "duration": 5.039}, {"text": "again all very valuable but only if", "start": 138.48, "duration": 3.759}, {"text": "you're actually a programmer or", "start": 140.879, "duration": 4.881}, {"text": "developer so things like mpi openmp cuda", "start": 142.239, "duration": 7.201}, {"text": "profile and performance tending", "start": 145.76, "duration": 3.68}, {"text": "so as a consequence we find that the end", "start": 151.28, "duration": 4.4}, {"text": "users who are not developers", "start": 153.44, "duration": 3.92}, {"text": "rarely or never get a proper", "start": 155.68, "duration": 4.32}, {"text": "introduction parallel computing", "start": 157.36, "duration": 4.64}, {"text": "um but even if you don't write your own", "start": 160.0, "duration": 4.08}, {"text": "code it's so important to understand the", "start": 162.0, "duration": 4.239}, {"text": "basic principles of parallel computing", "start": 164.08, "duration": 4.08}, {"text": "so that you can make the most effective", "start": 166.239, "duration": 6.161}, {"text": "use of valuable cyber infrastructure", "start": 168.16, "duration": 4.24}, {"text": "so before we dive into the a little bit", "start": 172.64, "duration": 3.84}, {"text": "of the technical content we're going to", "start": 175.2, "duration": 2.8}, {"text": "address some of the myths of parallel", "start": 176.48, "duration": 2.8}, {"text": "computing", "start": 178.0, "duration": 3.2}, {"text": "and the first one and i hear this over", "start": 179.28, "duration": 4.56}, {"text": "and over is that parallel computing is", "start": 181.2, "duration": 5.2}, {"text": "for astrophysicists engineers climate", "start": 183.84, "duration": 4.56}, {"text": "modelers and others who are working in", "start": 186.4, "duration": 5.199}, {"text": "traditionally math intensive fields", "start": 188.4, "duration": 5.919}, {"text": "and that is um", "start": 191.599, "duration": 4.401}, {"text": "you know i hope many of you already know", "start": 194.319, "duration": 3.521}, {"text": "that this is incorrect", "start": 196.0, "duration": 4.48}, {"text": "so when i first started at sdsc decades", "start": 197.84, "duration": 5.36}, {"text": "ago that was partially true our user", "start": 200.48, "duration": 4.399}, {"text": "base was over overwhelmingly", "start": 203.2, "duration": 4.319}, {"text": "astrophysicists and engineers but today", "start": 204.879, "duration": 4.241}, {"text": "we find that nearly every field of", "start": 207.519, "duration": 3.921}, {"text": "research makes these parallel computing", "start": 209.12, "duration": 4.32}, {"text": "and this includes the social sciences", "start": 211.44, "duration": 4.24}, {"text": "life sciences arts and humanities in", "start": 213.44, "duration": 4.0}, {"text": "addition to what we call the the usual", "start": 215.68, "duration": 3.6}, {"text": "suspects the chemists physicists", "start": 217.44, "duration": 4.96}, {"text": "engineers and so on", "start": 219.28, "duration": 3.12}, {"text": "another myth that i hear parallel", "start": 222.72, "duration": 4.0}, {"text": "computing is that throwing more hardware", "start": 224.319, "duration": 4.401}, {"text": "at a problem will automatically reduce", "start": 226.72, "duration": 5.519}, {"text": "the time to the time to solution", "start": 228.72, "duration": 4.64}, {"text": "and", "start": 232.239, "duration": 2.801}, {"text": "of course first of all parallel", "start": 233.36, "duration": 3.519}, {"text": "computing is only going to help if you", "start": 235.04, "duration": 3.52}, {"text": "already have an application that has", "start": 236.879, "duration": 3.121}, {"text": "been written to take advantage of", "start": 238.56, "duration": 3.92}, {"text": "parallel hardware and even if you do", "start": 240.0, "duration": 4.08}, {"text": "have a parallel code there's going to be", "start": 242.48, "duration": 3.52}, {"text": "an inherent limit on the scalability of", "start": 244.08, "duration": 4.48}, {"text": "that code", "start": 246.0, "duration": 2.56}, {"text": "and there's one caveat though", "start": 249.68, "duration": 4.8}, {"text": "a high throughput computing workload can", "start": 252.239, "duration": 4.161}, {"text": "use parallel computing to run many", "start": 254.48, "duration": 4.24}, {"text": "single core instances of an application", "start": 256.4, "duration": 6.48}, {"text": "to achieve a mid-near perfect scaling", "start": 258.72, "duration": 4.16}, {"text": "and the third myth is", "start": 264.4, "duration": 4.56}, {"text": "um that they need to be a programmer or", "start": 267.04, "duration": 3.52}, {"text": "a software to make use of parallel", "start": 268.96, "duration": 4.0}, {"text": "computing and again this was partially", "start": 270.56, "duration": 5.04}, {"text": "true maybe if you go back 25 years there", "start": 272.96, "duration": 4.88}, {"text": "wasn't a whole lot of mature third-party", "start": 275.6, "duration": 4.159}, {"text": "software out there if you were a", "start": 277.84, "duration": 3.76}, {"text": "computational chemist or a molecular", "start": 279.759, "duration": 3.841}, {"text": "biologist you pretty much had to write", "start": 281.6, "duration": 4.159}, {"text": "your own um but now", "start": 283.6, "duration": 3.68}, {"text": "most of the users of our parallel", "start": 285.759, "duration": 3.121}, {"text": "computers they are not programmers", "start": 287.28, "duration": 2.4}, {"text": "they're", "start": 288.88, "duration": 2.8}, {"text": "they're really using mature third-party", "start": 289.68, "duration": 3.6}, {"text": "software that's been developed elsewhere", "start": 291.68, "duration": 4.32}, {"text": "and made available to the community", "start": 293.28, "duration": 5.359}, {"text": "so in a nutshell most of you and i think", "start": 296.0, "duration": 4.4}, {"text": "most of you here are going to be using", "start": 298.639, "duration": 4.161}, {"text": "somebody else's code so for example if", "start": 300.4, "duration": 4.079}, {"text": "you're doing climate and weather", "start": 302.8, "duration": 4.32}, {"text": "modeling you might use an application", "start": 304.479, "duration": 7.041}, {"text": "like wharf or um or empaths or cesm", "start": 307.12, "duration": 6.88}, {"text": "if you're doing molecular dynamics", "start": 311.52, "duration": 5.2}, {"text": "um of biological systems of proteins and", "start": 314.0, "duration": 5.52}, {"text": "lipids and and other large complexes you", "start": 316.72, "duration": 6.4}, {"text": "might be using amber or nandi or gromacs", "start": 319.52, "duration": 5.519}, {"text": "if you're doing electronic structure", "start": 323.12, "duration": 4.4}, {"text": "calculations or", "start": 325.039, "duration": 3.44}, {"text": "um", "start": 327.52, "duration": 2.399}, {"text": "computational chemistry you're going to", "start": 328.479, "duration": 2.801}, {"text": "use codes", "start": 329.919, "duration": 4.641}, {"text": "like let's say such as um cp2k games", "start": 331.28, "duration": 5.199}, {"text": "dowsing and others and if you're", "start": 334.56, "duration": 4.32}, {"text": "constructing phylogenetic trees you", "start": 336.479, "duration": 4.401}, {"text": "might use applications like racks melon", "start": 338.88, "duration": 4.4}, {"text": "beasts so we find that for every for", "start": 340.88, "duration": 4.24}, {"text": "every user who's actually developing", "start": 343.28, "duration": 4.0}, {"text": "code there are many who are using", "start": 345.12, "duration": 5.2}, {"text": "somebody else's code", "start": 347.28, "duration": 3.04}, {"text": "so just going to give a very very high", "start": 351.039, "duration": 4.88}, {"text": "level view of what a parallel computer", "start": 353.919, "duration": 4.4}, {"text": "is so these modern clusters and parallel", "start": 355.919, "duration": 4.161}, {"text": "computers they consist of multiple", "start": 358.319, "duration": 4.961}, {"text": "compute nodes each connected by a", "start": 360.08, "duration": 5.44}, {"text": "um each connected together by a fast", "start": 363.28, "duration": 3.199}, {"text": "network", "start": 365.52, "duration": 3.44}, {"text": "each of these nodes typically contains", "start": 366.479, "duration": 4.481}, {"text": "one or more typically two multi-core", "start": 368.96, "duration": 3.359}, {"text": "processes", "start": 370.96, "duration": 3.44}, {"text": "in fact all of you are probably being", "start": 372.319, "duration": 4.561}, {"text": "exposed to parallel computing every day", "start": 374.4, "duration": 4.0}, {"text": "even if you're not aware of it because", "start": 376.88, "duration": 3.599}, {"text": "your laptop probably has a multi-core", "start": 378.4, "duration": 4.0}, {"text": "processor in it um and there'll be", "start": 380.479, "duration": 3.921}, {"text": "multiple threads executing at the same", "start": 382.4, "duration": 4.239}, {"text": "time doing different tests", "start": 384.4, "duration": 4.16}, {"text": "so what i'm showing on the right here is", "start": 386.639, "duration": 4.881}, {"text": "a the figure is a logical view", "start": 388.56, "duration": 6.16}, {"text": "of a super computer this is the expanse", "start": 391.52, "duration": 5.679}, {"text": "system here at scsc but if you see", "start": 394.72, "duration": 4.64}, {"text": "diagrams for the other machines that are", "start": 397.199, "duration": 3.921}, {"text": "available through exceed", "start": 399.36, "duration": 5.6}, {"text": "um stampede stampede 2 um bridges 2", "start": 401.12, "duration": 6.16}, {"text": "um anvil delta and the other systems are", "start": 404.96, "duration": 4.0}, {"text": "coming online they'll all look pretty", "start": 407.28, "duration": 4.08}, {"text": "similar to this where it's racks of", "start": 408.96, "duration": 5.92}, {"text": "hardware joint um", "start": 411.36, "duration": 3.52}, {"text": "racks of hardware compute nodes gpu", "start": 414.96, "duration": 4.239}, {"text": "nodes that they'd interact with each", "start": 417.199, "duration": 3.521}, {"text": "other through a high speed network", "start": 419.199, "duration": 5.201}, {"text": "typically ethernet or or infiniband", "start": 420.72, "duration": 5.36}, {"text": "and in order to effectively use this", "start": 424.4, "duration": 3.359}, {"text": "hardware we need applications being", "start": 426.08, "duration": 4.32}, {"text": "paralyzed so it can run on multiple", "start": 427.759, "duration": 5.601}, {"text": "cores within a node or across multiple", "start": 430.4, "duration": 5.68}, {"text": "nodes", "start": 433.36, "duration": 4.08}, {"text": "so getting into a little bit of the", "start": 436.08, "duration": 4.88}, {"text": "little bit of the technical content", "start": 437.44, "duration": 3.52}, {"text": "sorry i'm getting into the technical", "start": 444.08, "duration": 2.88}, {"text": "content we're going to talk just a", "start": 445.68, "duration": 3.519}, {"text": "little bit about processes and threads", "start": 446.96, "duration": 4.56}, {"text": "so these are terms that you may have um", "start": 449.199, "duration": 5.041}, {"text": "that you may hear use periodically you", "start": 451.52, "duration": 5.119}, {"text": "might be wondering what they are", "start": 454.24, "duration": 4.56}, {"text": "a process you could think that is an", "start": 456.639, "duration": 4.881}, {"text": "instance of a program with access to its", "start": 458.8, "duration": 5.6}, {"text": "own memory state and file descriptors", "start": 461.52, "duration": 6.32}, {"text": "so it can can open and close files", "start": 464.4, "duration": 5.6}, {"text": "threads these are lightweight entities", "start": 467.84, "duration": 5.12}, {"text": "that execute inside of a process so", "start": 470.0, "duration": 4.639}, {"text": "every process is going to have at least", "start": 472.96, "duration": 2.88}, {"text": "one thread", "start": 474.639, "duration": 3.601}, {"text": "and threads within a process can access", "start": 475.84, "duration": 5.759}, {"text": "can access shared memory", "start": 478.24, "duration": 3.359}, {"text": "okay so the um if you try to do a search", "start": 483.28, "duration": 5.84}, {"text": "online for a description of threads and", "start": 486.879, "duration": 4.641}, {"text": "processes they tend to be geared toward", "start": 489.12, "duration": 4.16}, {"text": "computer scientists but i found a couple", "start": 491.52, "duration": 4.56}, {"text": "of resources that i think do a", "start": 493.28, "duration": 4.4}, {"text": "that do a pretty good job of addressing", "start": 496.08, "duration": 3.6}, {"text": "the topic so there's", "start": 497.68, "duration": 4.48}, {"text": "um one thread that i found on stack", "start": 499.68, "duration": 4.239}, {"text": "overflow", "start": 502.16, "duration": 3.759}, {"text": "which i think is a little bit a little", "start": 503.919, "duration": 3.761}, {"text": "bit on the nerdier side it's really", "start": 505.919, "duration": 3.84}, {"text": "targeted more at programmers and", "start": 507.68, "duration": 3.44}, {"text": "developers but i think there's a lot of", "start": 509.759, "duration": 3.601}, {"text": "valuable information in there", "start": 511.12, "duration": 4.64}, {"text": "and if you want a lighter view a more", "start": 513.36, "duration": 4.88}, {"text": "informal view of the difference between", "start": 515.76, "duration": 4.719}, {"text": "threads and threads and processes i", "start": 518.24, "duration": 4.479}, {"text": "think the second link does a pretty good", "start": 520.479, "duration": 4.48}, {"text": "job", "start": 522.719, "duration": 2.24}, {"text": "so some of the key differences between", "start": 528.72, "duration": 4.0}, {"text": "processes and threads i'm highlighting", "start": 530.959, "duration": 2.721}, {"text": "here", "start": 532.72, "duration": 4.16}, {"text": "so so processes they incur more overhead", "start": 533.68, "duration": 4.64}, {"text": "that they're they're they're heavier", "start": 536.88, "duration": 2.24}, {"text": "weight", "start": 538.32, "duration": 1.519}, {"text": "um", "start": 539.12, "duration": 2.719}, {"text": "but but they're also more flexible", "start": 539.839, "duration": 4.321}, {"text": "multiple processes can be run within a", "start": 541.839, "duration": 4.721}, {"text": "compute node or you can run across", "start": 544.16, "duration": 4.16}, {"text": "multiple compute nodes what we call", "start": 546.56, "duration": 4.88}, {"text": "called distributed memory parallelism", "start": 548.32, "duration": 6.0}, {"text": "threads are lighter weight they incur", "start": 551.44, "duration": 4.959}, {"text": "less overhead", "start": 554.32, "duration": 3.68}, {"text": "um if you have a have an application", "start": 556.399, "duration": 3.921}, {"text": "that's threading you can also reduce the", "start": 558.0, "duration": 3.92}, {"text": "memory footprint", "start": 560.32, "duration": 2.959}, {"text": "since threads", "start": 561.92, "duration": 3.76}, {"text": "since threads within a process all have", "start": 563.279, "duration": 4.161}, {"text": "access to the same pool of data they", "start": 565.68, "duration": 3.76}, {"text": "could simultaneously access that same", "start": 567.44, "duration": 4.64}, {"text": "data structure", "start": 569.44, "duration": 4.0}, {"text": "limitation of threads there was that", "start": 572.08, "duration": 3.36}, {"text": "they're less flexible so multiple", "start": 573.44, "duration": 4.399}, {"text": "threads associated with process can only", "start": 575.44, "duration": 4.64}, {"text": "be run within a compute node what we", "start": 577.839, "duration": 2.961}, {"text": "call", "start": 580.08, "duration": 4.48}, {"text": "shared memory parallel parallelism", "start": 580.8, "duration": 3.76}, {"text": "okay so i know that the description", "start": 586.56, "duration": 4.0}, {"text": "process and threads it's still it's", "start": 588.48, "duration": 4.0}, {"text": "still a little abstract", "start": 590.56, "duration": 4.16}, {"text": "um", "start": 592.48, "duration": 2.24}, {"text": "but um but but i think that it's so", "start": 596.16, "duration": 3.6}, {"text": "important that you that you have a feel", "start": 597.76, "duration": 4.24}, {"text": "for processing threads because this is", "start": 599.76, "duration": 4.4}, {"text": "going to determine how and where you can", "start": 602.0, "duration": 4.399}, {"text": "run your applications", "start": 604.16, "duration": 4.0}, {"text": "so what we call distributed memory", "start": 606.399, "duration": 3.041}, {"text": "applications", "start": 608.16, "duration": 3.119}, {"text": "these are things that run across", "start": 609.44, "duration": 3.519}, {"text": "multiple nodes", "start": 611.279, "duration": 4.24}, {"text": "um this involves multiple processes", "start": 612.959, "duration": 5.601}, {"text": "multiple instances of a program", "start": 615.519, "duration": 5.601}, {"text": "shared memory applications threading", "start": 618.56, "duration": 4.24}, {"text": "should only be run on a single node and", "start": 621.12, "duration": 2.8}, {"text": "we're going to talk about that in the", "start": 622.8, "duration": 2.8}, {"text": "next few slides about the performance", "start": 623.92, "duration": 3.84}, {"text": "implications there", "start": 625.6, "duration": 4.0}, {"text": "now it gets a little more a little more", "start": 627.76, "duration": 3.04}, {"text": "complicated", "start": 629.6, "duration": 2.96}, {"text": "um when we get into what we call hybrid", "start": 630.8, "duration": 4.08}, {"text": "applications so so these are their", "start": 632.56, "duration": 4.56}, {"text": "applications that that use a mix of", "start": 634.88, "duration": 4.639}, {"text": "processes and threading within the", "start": 637.12, "duration": 3.68}, {"text": "process", "start": 639.519, "duration": 3.041}, {"text": "and if you're running one of these", "start": 640.8, "duration": 3.36}, {"text": "hybrid applications which are becoming", "start": 642.56, "duration": 3.279}, {"text": "more and more common you're going to", "start": 644.16, "duration": 3.52}, {"text": "need to consider the balance between", "start": 645.839, "duration": 4.081}, {"text": "threads and processes", "start": 647.68, "duration": 4.0}, {"text": "and in all cases when you're actually", "start": 649.92, "duration": 4.08}, {"text": "running these jobs on the supercomputers", "start": 651.68, "duration": 4.08}, {"text": "you're going to need to consider how the", "start": 654.0, "duration": 3.68}, {"text": "processes and threads are mapped and", "start": 655.76, "duration": 4.639}, {"text": "bound to cores so in this talk it's very", "start": 657.68, "duration": 4.24}, {"text": "very introductory we're not actually", "start": 660.399, "duration": 4.081}, {"text": "getting into running applications but in", "start": 661.92, "duration": 4.56}, {"text": "some other training that we have within", "start": 664.48, "duration": 4.799}, {"text": "within scsc nxt", "start": 666.48, "duration": 6.0}, {"text": "we do cover the details of of launching", "start": 669.279, "duration": 6.161}, {"text": "jobs and how you can make sure that that", "start": 672.48, "duration": 5.12}, {"text": "threads are bound to particular cpus", "start": 675.44, "duration": 4.399}, {"text": "that they don't migrate and that you can", "start": 677.6, "duration": 3.359}, {"text": "this will help you to improve the", "start": 679.839, "duration": 3.68}, {"text": "performance of your application", "start": 680.959, "duration": 4.081}, {"text": "and then finally if you're aware of", "start": 683.519, "duration": 3.361}, {"text": "threads and processes this will help you", "start": 685.04, "duration": 4.479}, {"text": "to understand how your code is utilizing", "start": 686.88, "duration": 5.6}, {"text": "the hardware and identify some some", "start": 689.519, "duration": 6.241}, {"text": "common performance issues", "start": 692.48, "duration": 3.28}, {"text": "so i'm going to touch very briefly on a", "start": 696.8, "duration": 4.0}, {"text": "couple of topics i mentioned these", "start": 698.959, "duration": 4.801}, {"text": "earlier on mpi and openmp", "start": 700.8, "duration": 4.719}, {"text": "we're not here to teach you mpi and", "start": 703.76, "duration": 3.36}, {"text": "openmp today", "start": 705.519, "duration": 2.801}, {"text": "um if you're not if you're not a", "start": 707.12, "duration": 2.959}, {"text": "programmer or developer these aren't", "start": 708.32, "duration": 3.84}, {"text": "things that you need to learn", "start": 710.079, "duration": 3.681}, {"text": "but i think that you all need to be", "start": 712.16, "duration": 3.76}, {"text": "aware of", "start": 713.76, "duration": 3.759}, {"text": "you don't need to be aware of these", "start": 715.92, "duration": 2.88}, {"text": "topics", "start": 717.519, "duration": 4.801}, {"text": "so mpi is a", "start": 718.8, "duration": 6.08}, {"text": "standard for paralyzing c c plus plus", "start": 722.32, "duration": 4.0}, {"text": "and fortran code", "start": 724.88, "duration": 4.16}, {"text": "so that it can run on distributed memory", "start": 726.32, "duration": 5.68}, {"text": "multiple compute node systems", "start": 729.04, "duration": 4.96}, {"text": "so while it's not officially adopted by", "start": 732.0, "duration": 4.399}, {"text": "any of the major standards bodies it's", "start": 734.0, "duration": 4.959}, {"text": "really become the defacto standard i.e", "start": 736.399, "duration": 4.801}, {"text": "it's pretty much everyone uses it to", "start": 738.959, "duration": 4.88}, {"text": "develop parallel", "start": 741.2, "duration": 4.319}, {"text": "now what gets a little confusing is", "start": 743.839, "duration": 3.521}, {"text": "you'll hear about mpi", "start": 745.519, "duration": 3.681}, {"text": "but then you may also hear of things", "start": 747.36, "duration": 5.36}, {"text": "called like open mpi or mvap h or m", "start": 749.2, "duration": 5.36}, {"text": "pitch these are just different", "start": 752.72, "duration": 5.119}, {"text": "implementations of mpi so mpi is the", "start": 754.56, "duration": 5.92}, {"text": "standard it describes the api", "start": 757.839, "duration": 5.841}, {"text": "but open mpi mva pitch and m pitch along", "start": 760.48, "duration": 6.159}, {"text": "with vendor support versions of mpi are", "start": 763.68, "duration": 5.92}, {"text": "the actual implementations", "start": 766.639, "duration": 5.44}, {"text": "now mpi applications they can be run", "start": 769.6, "duration": 5.2}, {"text": "within a shared memory node", "start": 772.079, "duration": 5.2}, {"text": "all widely used mpi implementations are", "start": 774.8, "duration": 4.56}, {"text": "optimized to take advantage of that", "start": 777.279, "duration": 3.68}, {"text": "faster communications that you're going", "start": 779.36, "duration": 3.76}, {"text": "to have within a node relative to", "start": 780.959, "duration": 3.88}, {"text": "communicating across", "start": 783.12, "duration": 3.92}, {"text": "them one of the beautiful things about", "start": 784.839, "duration": 4.12}, {"text": "mpi is that it's portable and it can be", "start": 787.04, "duration": 3.359}, {"text": "used anywhere", "start": 788.959, "duration": 3.041}, {"text": "back in the early days of parallel", "start": 790.399, "duration": 4.161}, {"text": "computing it was a lot harder um each", "start": 792.0, "duration": 4.88}, {"text": "vendor might have its own way of doing", "start": 794.56, "duration": 5.12}, {"text": "power of doing parallelism", "start": 796.88, "duration": 4.639}, {"text": "that made it really hard to write", "start": 799.68, "duration": 4.719}, {"text": "multiple code you tend to be", "start": 801.519, "duration": 4.801}, {"text": "tied to a particular resource like i", "start": 804.399, "duration": 4.481}, {"text": "said mpi is portable you can use it", "start": 806.32, "duration": 3.68}, {"text": "anywhere", "start": 808.88, "duration": 3.36}, {"text": "but once you have a properly written", "start": 810.0, "duration": 4.48}, {"text": "written mpi application you can import", "start": 812.24, "duration": 4.56}, {"text": "it to any of the systems", "start": 814.48, "duration": 3.52}, {"text": "and then finally though i want to", "start": 816.8, "duration": 4.159}, {"text": "mention that mpi is often synonymous", "start": 818.0, "duration": 5.04}, {"text": "with synonymous with distributed memory", "start": 820.959, "duration": 3.521}, {"text": "parallelization", "start": 823.04, "duration": 4.239}, {"text": "but there are other options out there", "start": 824.48, "duration": 6.479}, {"text": "for example chon plus plus is used to", "start": 827.279, "duration": 6.081}, {"text": "um paralyze nandi but one of the most", "start": 830.959, "duration": 3.761}, {"text": "popular", "start": 833.36, "duration": 3.68}, {"text": "molecular dynamics applications", "start": 834.72, "duration": 4.88}, {"text": "there's um the upc languages that are", "start": 837.04, "duration": 4.88}, {"text": "developed at national labs x10 and", "start": 839.6, "duration": 4.96}, {"text": "others so even though mpi is going to be", "start": 841.92, "duration": 4.4}, {"text": "predominant just be aware that there are", "start": 844.56, "duration": 5.839}, {"text": "other ways to paralyze the codes", "start": 846.32, "duration": 4.079}, {"text": "so i i said in the beginning that this", "start": 850.72, "duration": 4.16}, {"text": "that this talk is not going to be geared", "start": 853.04, "duration": 3.68}, {"text": "at programmers and developers it's going", "start": 854.88, "duration": 3.199}, {"text": "to be", "start": 856.72, "duration": 4.0}, {"text": "really looking at the", "start": 858.079, "duration": 4.56}, {"text": "um end users", "start": 860.72, "duration": 3.919}, {"text": "so bear with me if you're not interested", "start": 862.639, "duration": 3.601}, {"text": "in programming you can't ignore what's", "start": 864.639, "duration": 3.521}, {"text": "going on in the left hand left hand side", "start": 866.24, "duration": 3.44}, {"text": "of the screen", "start": 868.16, "duration": 3.359}, {"text": "but i figured it would be useful for you", "start": 869.68, "duration": 4.08}, {"text": "to at least see an example of what mpi", "start": 871.519, "duration": 3.12}, {"text": "is", "start": 873.76, "duration": 2.72}, {"text": "so if you've ever taken a programming", "start": 874.639, "duration": 4.401}, {"text": "class you've probably done a hello world", "start": 876.48, "duration": 5.2}, {"text": "program so i'm showing over here on the", "start": 879.04, "duration": 5.84}, {"text": "on the left hand side of the gray box a", "start": 881.68, "duration": 5.279}, {"text": "very very simple c program that prints", "start": 884.88, "duration": 5.44}, {"text": "hello world to the screen", "start": 886.959, "duration": 3.361}, {"text": "now an mpi version of this code", "start": 890.639, "duration": 5.281}, {"text": "and i've highlighted all of the all of", "start": 893.68, "duration": 5.279}, {"text": "the new code in bold and purple", "start": 895.92, "duration": 5.52}, {"text": "um it shows what we what we would do if", "start": 898.959, "duration": 5.12}, {"text": "we wanted to paralyze this application", "start": 901.44, "duration": 4.88}, {"text": "so that each process", "start": 904.079, "duration": 5.2}, {"text": "writes out um", "start": 906.32, "duration": 2.959}, {"text": "writes out its name its id and hello", "start": 909.36, "duration": 4.8}, {"text": "world to the terminal so we're not going", "start": 911.76, "duration": 4.319}, {"text": "to go through all the content here you", "start": 914.16, "duration": 3.84}, {"text": "can see though that it's pretty dense", "start": 916.079, "duration": 6.401}, {"text": "mpi applications they look a lot like um", "start": 918.0, "duration": 6.8}, {"text": "they look a lot like c programs", "start": 922.48, "duration": 6.96}, {"text": "um they tend to be fairly abstract again", "start": 924.8, "duration": 6.0}, {"text": "if you're not a programmer or an", "start": 929.44, "duration": 3.199}, {"text": "application developer you don't need to", "start": 930.8, "duration": 4.32}, {"text": "know mpi you just need to be aware that", "start": 932.639, "duration": 5.12}, {"text": "it exists and if you if you need to", "start": 935.12, "duration": 4.24}, {"text": "build your own app build your own", "start": 937.759, "duration": 3.841}, {"text": "executables by that i mean you're", "start": 939.36, "duration": 4.0}, {"text": "downloading somebody's source code you", "start": 941.6, "duration": 4.159}, {"text": "need to build the application to run", "start": 943.36, "duration": 3.919}, {"text": "on a computer", "start": 945.759, "duration": 2.801}, {"text": "then you need to make sure that you're", "start": 947.279, "duration": 2.8}, {"text": "using the appropriate wrappers and", "start": 948.56, "duration": 3.68}, {"text": "compilers so that you link in the mpi", "start": 950.079, "duration": 4.801}, {"text": "libraries", "start": 952.24, "duration": 5.279}, {"text": "okay openmp switching gears is an", "start": 954.88, "duration": 4.959}, {"text": "application programming interface for", "start": 957.519, "duration": 3.68}, {"text": "shared memory", "start": 959.839, "duration": 2.481}, {"text": "um", "start": 961.199, "duration": 2.961}, {"text": "doing parallelization with the in a node", "start": 962.32, "duration": 4.16}, {"text": "parallel programming in cc lesson", "start": 964.16, "duration": 3.44}, {"text": "fortran", "start": 966.48, "duration": 3.039}, {"text": "so this is if we want to do thread level", "start": 967.6, "duration": 3.599}, {"text": "parallelization", "start": 969.519, "duration": 3.841}, {"text": "openmp provides a collection of compiler", "start": 971.199, "duration": 3.921}, {"text": "directives library routines and", "start": 973.36, "duration": 3.68}, {"text": "environment variables", "start": 975.12, "duration": 4.48}, {"text": "importantly openmp is supported by all", "start": 977.04, "duration": 5.599}, {"text": "of the major compilers including the ibm", "start": 979.6, "duration": 6.4}, {"text": "intel gcc that's the gnu compiler", "start": 982.639, "duration": 4.961}, {"text": "collection", "start": 986.0, "duration": 6.079}, {"text": "ppgi and the amd optimizing um", "start": 987.6, "duration": 7.28}, {"text": "cnc plus plus compilers afcc", "start": 992.079, "duration": 5.921}, {"text": "um and we have the latter so we have", "start": 994.88, "duration": 3.92}, {"text": "um", "start": 998.0, "duration": 5.519}, {"text": "gcc pgi and the aocc available here on", "start": 998.8, "duration": 5.76}, {"text": "the", "start": 1003.519, "duration": 3.521}, {"text": "on on the expense of the computer at scc", "start": 1004.56, "duration": 4.32}, {"text": "and you will find the rest of these on", "start": 1007.04, "duration": 5.039}, {"text": "many of the expands allocated systems", "start": 1008.88, "duration": 4.879}, {"text": "like mpi", "start": 1012.079, "duration": 4.401}, {"text": "what makes um openmp so powerful is that", "start": 1013.759, "duration": 4.401}, {"text": "it's portable and it can be used", "start": 1016.48, "duration": 3.52}, {"text": "anywhere", "start": 1018.16, "duration": 5.52}, {"text": "and also like mpi tends to be synonymous", "start": 1020.0, "duration": 6.16}, {"text": "with distributed memory memory", "start": 1023.68, "duration": 3.759}, {"text": "parallelization", "start": 1026.16, "duration": 3.679}, {"text": "openmp is often synonymous with shared", "start": 1027.439, "duration": 4.721}, {"text": "memory parallelization but be aware that", "start": 1029.839, "duration": 3.921}, {"text": "there are a lot of other options out", "start": 1032.16, "duration": 3.44}, {"text": "there there's a programming language", "start": 1033.76, "duration": 4.48}, {"text": "called silk which is an extension of of", "start": 1035.6, "duration": 5.839}, {"text": "c to um to the handle threaded to handle", "start": 1038.24, "duration": 4.959}, {"text": "multiple threads there's something", "start": 1041.439, "duration": 4.321}, {"text": "called posix threads or p threads and", "start": 1043.199, "duration": 4.801}, {"text": "they're specialized libraries for python", "start": 1045.76, "duration": 4.64}, {"text": "r and other programming languages that", "start": 1048.0, "duration": 4.559}, {"text": "allow you to do um shared memory or", "start": 1050.4, "duration": 5.279}, {"text": "threaded parallelism", "start": 1052.559, "duration": 3.12}, {"text": "so again if you're not not a programmer", "start": 1056.559, "duration": 3.921}, {"text": "you don't need to you don't need to know", "start": 1058.48, "duration": 4.319}, {"text": "this feel free to ignore what's going on", "start": 1060.48, "duration": 4.24}, {"text": "on the left hand side of the screen but", "start": 1062.799, "duration": 3.601}, {"text": "if you are a programmer you might", "start": 1064.72, "duration": 3.6}, {"text": "recognize what's going on here we're", "start": 1066.4, "duration": 4.32}, {"text": "taking two arrays a and b where we're", "start": 1068.32, "duration": 4.0}, {"text": "initializing them", "start": 1070.72, "duration": 3.52}, {"text": "and then in the loop at the bottom we", "start": 1072.32, "duration": 4.88}, {"text": "are adding them element by element", "start": 1074.24, "duration": 3.679}, {"text": "now", "start": 1077.2, "duration": 3.28}, {"text": "applications paralyzed using using", "start": 1077.919, "duration": 5.281}, {"text": "openmp tend to be much more readable", "start": 1080.48, "duration": 4.96}, {"text": "than mpi programs since they often", "start": 1083.2, "duration": 4.479}, {"text": "involve relatively minor changes to the", "start": 1085.44, "duration": 4.72}, {"text": "code so you see here that i just defined", "start": 1087.679, "duration": 5.161}, {"text": "a few variables and at the bottom i'm", "start": 1090.16, "duration": 4.32}, {"text": "using", "start": 1092.84, "duration": 3.959}, {"text": "it using a pragma if this was c code or", "start": 1094.48, "duration": 5.68}, {"text": "a directive if this was fortran code to", "start": 1096.799, "duration": 5.12}, {"text": "parallelize that loop again we don't", "start": 1100.16, "duration": 3.519}, {"text": "need to get into the details but you", "start": 1101.919, "duration": 4.88}, {"text": "just need to be aware of openmp that it", "start": 1103.679, "duration": 4.081}, {"text": "exists", "start": 1106.799, "duration": 3.601}, {"text": "and like mpi applications", "start": 1107.76, "duration": 4.72}, {"text": "if you're building your executable from", "start": 1110.4, "duration": 4.159}, {"text": "source code you need to make sure that", "start": 1112.48, "duration": 4.24}, {"text": "you use the appropriate compiler flights", "start": 1114.559, "duration": 4.0}, {"text": "and if you look at the user guide for", "start": 1116.72, "duration": 4.4}, {"text": "expanse or any of the other xc", "start": 1118.559, "duration": 4.321}, {"text": "allocated resources", "start": 1121.12, "duration": 3.76}, {"text": "you'll see you'll find um instructions", "start": 1122.88, "duration": 3.84}, {"text": "on how to do this for each of the major", "start": 1124.88, "duration": 5.039}, {"text": "compilers that they support", "start": 1126.72, "duration": 3.199}, {"text": "so to bring that all together you know", "start": 1131.039, "duration": 4.321}, {"text": "kind of kind of the big picture", "start": 1132.559, "duration": 4.801}, {"text": "um", "start": 1135.36, "duration": 3.679}, {"text": "you know on the left-hand side we're", "start": 1137.36, "duration": 5.6}, {"text": "talking about mpi we use mpi to manage", "start": 1139.039, "duration": 5.681}, {"text": "multiple processes", "start": 1142.96, "duration": 4.4}, {"text": "and then m-pitch and m-vap edge and open", "start": 1144.72, "duration": 5.44}, {"text": "mpi and the vendor implementations these", "start": 1147.36, "duration": 6.72}, {"text": "are all specific implementations of mpi", "start": 1150.16, "duration": 5.519}, {"text": "now", "start": 1154.08, "duration": 4.64}, {"text": "what one point of confusion here is", "start": 1155.679, "duration": 4.561}, {"text": "you know whether or not these different", "start": 1158.72, "duration": 3.839}, {"text": "implementations do different things they", "start": 1160.24, "duration": 4.64}, {"text": "don't they they all support the mpi", "start": 1162.559, "duration": 4.881}, {"text": "standards so you don't need to write", "start": 1164.88, "duration": 4.72}, {"text": "this the code doesn't need to be written", "start": 1167.44, "duration": 5.28}, {"text": "for m pitch or m that or open mpi", "start": 1169.6, "duration": 6.0}, {"text": "like i said mpi is a standard mpi codes", "start": 1172.72, "duration": 5.199}, {"text": "should run everywhere on the right hand", "start": 1175.6, "duration": 5.52}, {"text": "side when we're talking about threads", "start": 1177.919, "duration": 5.681}, {"text": "we can we can manage multiple threads", "start": 1181.12, "duration": 4.4}, {"text": "using openmp", "start": 1183.6, "duration": 4.56}, {"text": "and then openmp is is implemented by the", "start": 1185.52, "duration": 6.64}, {"text": "compilers by gcc intel aocc and and", "start": 1188.16, "duration": 6.399}, {"text": "others", "start": 1192.16, "duration": 2.399}, {"text": "all right so things get a little more", "start": 1195.44, "duration": 3.2}, {"text": "complicated and that we can have these", "start": 1196.88, "duration": 3.84}, {"text": "hybrid applications", "start": 1198.64, "duration": 4.159}, {"text": "so many modern parallel applications are", "start": 1200.72, "duration": 3.92}, {"text": "built using a hybrid approach to take", "start": 1202.799, "duration": 4.0}, {"text": "advantage of both distributed and shared", "start": 1204.64, "duration": 5.039}, {"text": "memory so this typically involves mpi", "start": 1206.799, "duration": 4.24}, {"text": "and openmp", "start": 1209.679, "duration": 4.161}, {"text": "so mpi to", "start": 1211.039, "duration": 4.721}, {"text": "break up your code into into multiple", "start": 1213.84, "duration": 4.64}, {"text": "processes and then openmp to run to", "start": 1215.76, "duration": 4.72}, {"text": "execute multiple threads within each", "start": 1218.48, "duration": 3.76}, {"text": "process", "start": 1220.48, "duration": 4.079}, {"text": "um hybrid thread sorry hybrid codes they", "start": 1222.24, "duration": 4.48}, {"text": "have some advantages over purely shared", "start": 1224.559, "duration": 4.721}, {"text": "or distributed memory applications", "start": 1226.72, "duration": 4.959}, {"text": "so shared memory apps they have limited", "start": 1229.28, "duration": 4.879}, {"text": "scalability um they may have limited", "start": 1231.679, "duration": 4.721}, {"text": "scalability within the node and they can", "start": 1234.159, "duration": 5.601}, {"text": "definitely not run across multiple nodes", "start": 1236.4, "duration": 5.12}, {"text": "distribute distributed memory apps on", "start": 1239.76, "duration": 3.76}, {"text": "the other hand may have higher memory", "start": 1241.52, "duration": 4.159}, {"text": "requirements and more overhead when", "start": 1243.52, "duration": 4.08}, {"text": "running within node so typically we're", "start": 1245.679, "duration": 3.681}, {"text": "going to try to use processes to", "start": 1247.6, "duration": 4.0}, {"text": "parallelize across nodes", "start": 1249.36, "duration": 4.4}, {"text": "um thread threads to parallelize within", "start": 1251.6, "duration": 4.4}, {"text": "nodes", "start": 1253.76, "duration": 4.32}, {"text": "so we're going to take a look at a very", "start": 1256.0, "duration": 4.88}, {"text": "very simplified parallel computer of", "start": 1258.08, "duration": 4.64}, {"text": "course this is much smaller than", "start": 1260.88, "duration": 3.12}, {"text": "anything you would actually encounter", "start": 1262.72, "duration": 2.88}, {"text": "we're just going to use this to walk", "start": 1264.0, "duration": 3.679}, {"text": "through a couple of examples", "start": 1265.6, "duration": 4.4}, {"text": "so let's consider a", "start": 1267.679, "duration": 5.12}, {"text": "very simple system it just contains it", "start": 1270.0, "duration": 6.0}, {"text": "contains two compute nodes each with 16", "start": 1272.799, "duration": 5.601}, {"text": "cores and that these nodes can talk to", "start": 1276.0, "duration": 4.559}, {"text": "each other through it through a network", "start": 1278.4, "duration": 4.32}, {"text": "the interconnect this could be", "start": 1280.559, "duration": 5.841}, {"text": "typically ethernet or", "start": 1282.72, "duration": 3.68}, {"text": "or or infiniband", "start": 1287.039, "duration": 4.401}, {"text": "so what i'm showing here in um", "start": 1288.559, "duration": 5.761}, {"text": "the large box in gray is the node and", "start": 1291.44, "duration": 7.68}, {"text": "within it we have our 16 compute course", "start": 1294.32, "duration": 4.8}, {"text": "so if we're running a purely message", "start": 1299.76, "duration": 4.24}, {"text": "pass an application", "start": 1301.919, "duration": 3.76}, {"text": "these these are applications that they", "start": 1304.0, "duration": 4.799}, {"text": "have been paralyzed using mpi", "start": 1305.679, "duration": 5.441}, {"text": "typically we're going to one run one", "start": 1308.799, "duration": 4.321}, {"text": "process per core so i'm showing the", "start": 1311.12, "duration": 4.559}, {"text": "processes here in orange so this is an", "start": 1313.12, "duration": 5.039}, {"text": "example of an application running 32", "start": 1315.679, "duration": 7.761}, {"text": "processes across two 16 core nodes", "start": 1318.159, "duration": 5.281}, {"text": "now if we have a purely threaded", "start": 1323.679, "duration": 3.761}, {"text": "application let's say it's been", "start": 1326.0, "duration": 3.12}, {"text": "paralyzed using", "start": 1327.44, "duration": 3.52}, {"text": "only openmp", "start": 1329.12, "duration": 4.24}, {"text": "or silk or p threads or the various", "start": 1330.96, "duration": 5.12}, {"text": "options in python or python r we're", "start": 1333.36, "duration": 4.559}, {"text": "going to be restricted to running within", "start": 1336.08, "duration": 3.2}, {"text": "a single node", "start": 1337.919, "duration": 2.88}, {"text": "so in this case i'm showing this", "start": 1339.28, "duration": 3.84}, {"text": "threaded application single process but", "start": 1340.799, "duration": 6.561}, {"text": "with 16 threads running across 16 cores", "start": 1343.12, "duration": 5.919}, {"text": "and i have a little caveat here at the", "start": 1347.36, "duration": 2.88}, {"text": "bottom", "start": 1349.039, "duration": 3.76}, {"text": "um technically any programming model can", "start": 1350.24, "duration": 5.12}, {"text": "be mapped to any hardware but what we", "start": 1352.799, "duration": 4.641}, {"text": "find though is in practice threaded", "start": 1355.36, "duration": 3.52}, {"text": "applications really need to be run", "start": 1357.44, "duration": 3.359}, {"text": "within a single node for for best", "start": 1358.88, "duration": 4.48}, {"text": "performance", "start": 1360.799, "duration": 2.561}, {"text": "okay when we get into hybrid", "start": 1364.96, "duration": 4.48}, {"text": "applications again typically mpi plus", "start": 1366.4, "duration": 5.68}, {"text": "openmp but other other combinations are", "start": 1369.44, "duration": 4.0}, {"text": "possible", "start": 1372.08, "duration": 3.2}, {"text": "here we're showing", "start": 1373.44, "duration": 4.32}, {"text": "a case where we have two processes per", "start": 1375.28, "duration": 6.8}, {"text": "node and eight threads per process", "start": 1377.76, "duration": 4.32}, {"text": "a typical scenario is to run one process", "start": 1384.159, "duration": 4.4}, {"text": "per node", "start": 1387.44, "duration": 2.96}, {"text": "and then use threads within a node but", "start": 1388.559, "duration": 4.801}, {"text": "this is becoming a little less common um", "start": 1390.4, "duration": 5.2}, {"text": "i would say in in the past when the", "start": 1393.36, "duration": 3.92}, {"text": "nodes weren't quite as fat when they", "start": 1395.6, "duration": 5.36}, {"text": "contained maybe 12 or 16 or even 32", "start": 1397.28, "duration": 5.68}, {"text": "cores this is where we would typically", "start": 1400.96, "duration": 4.48}, {"text": "run a hybrid application but now that", "start": 1402.96, "duration": 5.76}, {"text": "the modern multi multi-core processes", "start": 1405.44, "duration": 5.68}, {"text": "with 16 cores per processor two", "start": 1408.72, "duration": 4.959}, {"text": "processors per node for a total of 128", "start": 1411.12, "duration": 5.039}, {"text": "cores the next generation of amd", "start": 1413.679, "duration": 3.921}, {"text": "hardware is going to have even more", "start": 1416.159, "duration": 2.801}, {"text": "cores", "start": 1417.6, "duration": 2.16}, {"text": "um", "start": 1418.96, "duration": 2.959}, {"text": "you're going to find that we may not", "start": 1419.76, "duration": 5.84}, {"text": "always want to do this that we", "start": 1421.919, "duration": 3.681}, {"text": "may want to go back to a case where", "start": 1425.84, "duration": 2.959}, {"text": "we're running", "start": 1427.36, "duration": 4.0}, {"text": "multiple processes per node and multiple", "start": 1428.799, "duration": 5.921}, {"text": "threads within a within a process", "start": 1431.36, "duration": 4.559}, {"text": "so", "start": 1434.72, "duration": 3.6}, {"text": "this is where it gets a little tricky", "start": 1435.919, "duration": 3.841}, {"text": "if you're running these hybrid", "start": 1438.32, "duration": 2.719}, {"text": "applications", "start": 1439.76, "duration": 3.039}, {"text": "you're going to need to think about how", "start": 1441.039, "duration": 4.721}, {"text": "to choose the best balance between cores", "start": 1442.799, "duration": 4.48}, {"text": "and threads", "start": 1445.76, "duration": 3.68}, {"text": "and questions how do how do we choose", "start": 1447.279, "duration": 3.361}, {"text": "this balance", "start": 1449.44, "duration": 2.64}, {"text": "so", "start": 1450.64, "duration": 5.919}, {"text": "going back to our um hypothetical", "start": 1452.08, "duration": 6.88}, {"text": "parallel computer with with 16 cores per", "start": 1456.559, "duration": 3.441}, {"text": "node", "start": 1458.96, "duration": 2.959}, {"text": "now we can do everything from on the", "start": 1460.0, "duration": 5.36}, {"text": "left-hand side one process per node with", "start": 1461.919, "duration": 7.041}, {"text": "16 waves 16 threads per process", "start": 1465.36, "duration": 6.319}, {"text": "to the other extreme of one process per", "start": 1468.96, "duration": 3.44}, {"text": "core", "start": 1471.679, "duration": 2.0}, {"text": "and i'm going to say the only way to", "start": 1472.4, "duration": 4.879}, {"text": "really know is to is benchmark your code", "start": 1473.679, "duration": 5.36}, {"text": "look at both the", "start": 1477.279, "duration": 3.441}, {"text": "but both the run time for different", "start": 1479.039, "duration": 6.801}, {"text": "combinations and the and memory usage", "start": 1480.72, "duration": 6.8}, {"text": "we're going to switch gears a little bit", "start": 1485.84, "duration": 3.68}, {"text": "um talk about to talk about the", "start": 1487.52, "duration": 5.039}, {"text": "scalability of parallel applications", "start": 1489.52, "duration": 6.32}, {"text": "before we wrap up with some benchmarking", "start": 1492.559, "duration": 6.161}, {"text": "so if you know one law in parallel", "start": 1495.84, "duration": 5.92}, {"text": "computing it's probably amdahl's law", "start": 1498.72, "duration": 4.88}, {"text": "so this is the you could think of", "start": 1501.76, "duration": 4.48}, {"text": "amdahl's law as being the equals mc", "start": 1503.6, "duration": 5.04}, {"text": "squared or the f equals m a of a", "start": 1506.24, "duration": 4.24}, {"text": "parallel computing", "start": 1508.64, "duration": 4.399}, {"text": "and amdahl's law tells you the absolute", "start": 1510.48, "duration": 4.96}, {"text": "limit on the speed up of a code as a", "start": 1513.039, "duration": 4.321}, {"text": "function of the proportion of the code", "start": 1515.44, "duration": 4.239}, {"text": "that can be paralyzed and the number of", "start": 1517.36, "duration": 5.199}, {"text": "processes so as i mentioned this is this", "start": 1519.679, "duration": 4.88}, {"text": "is truly the most fundamental law of", "start": 1522.559, "duration": 4.48}, {"text": "parallel computing if you only memorize", "start": 1524.559, "duration": 5.681}, {"text": "one law this is the one to know", "start": 1527.039, "duration": 5.281}, {"text": "so let's say that p is the fraction of", "start": 1530.24, "duration": 3.84}, {"text": "the code that can be parallelized and", "start": 1532.32, "duration": 3.44}, {"text": "when i say fraction the code i don't", "start": 1534.08, "duration": 4.16}, {"text": "mean the number of functions or routines", "start": 1535.76, "duration": 4.96}, {"text": "the number of lines of software i mean", "start": 1538.24, "duration": 4.0}, {"text": "the", "start": 1540.72, "duration": 2.4}, {"text": "um", "start": 1542.24, "duration": 2.64}, {"text": "what where", "start": 1543.12, "duration": 4.559}, {"text": "i would put the execution time so if we", "start": 1544.88, "duration": 4.88}, {"text": "have an operation what let's say it's", "start": 1547.679, "duration": 4.721}, {"text": "the multiplying two matrices or", "start": 1549.76, "duration": 4.64}, {"text": "calculating eigenvalues", "start": 1552.4, "duration": 3.44}, {"text": "you know if that's an operation that", "start": 1554.4, "duration": 2.879}, {"text": "could be that could be done in parallel", "start": 1555.84, "duration": 3.439}, {"text": "that's parallel content", "start": 1557.279, "duration": 4.081}, {"text": "s is the fraction the code that must be", "start": 1559.279, "duration": 4.64}, {"text": "run sequentially so there may be a lot", "start": 1561.36, "duration": 4.72}, {"text": "of operations that need to be that just", "start": 1563.919, "duration": 5.201}, {"text": "can't be paralyzed um let's say it's the", "start": 1566.08, "duration": 4.8}, {"text": "um", "start": 1569.12, "duration": 3.76}, {"text": "it's the reading reading of an input", "start": 1570.88, "duration": 5.76}, {"text": "file in certain cases or the", "start": 1572.88, "duration": 6.24}, {"text": "um that the calculation result", "start": 1576.64, "duration": 4.639}, {"text": "that needs to be done once but but then", "start": 1579.12, "duration": 4.64}, {"text": "broadcast to all the processes so that's", "start": 1581.279, "duration": 4.961}, {"text": "our that that's our sequential fraction", "start": 1583.76, "duration": 3.68}, {"text": "and of course", "start": 1586.24, "duration": 2.48}, {"text": "the um", "start": 1587.44, "duration": 4.08}, {"text": "the parallel the potentially paralyzable", "start": 1588.72, "duration": 5.12}, {"text": "fraction of the code plus the fraction", "start": 1591.52, "duration": 4.48}, {"text": "the code that must be run sequentially", "start": 1593.84, "duration": 4.8}, {"text": "has to equal one and n is the number of", "start": 1596.0, "duration": 4.4}, {"text": "processes", "start": 1598.64, "duration": 3.76}, {"text": "so the theoretical speed up that we", "start": 1600.4, "duration": 4.96}, {"text": "could get from running on n processors", "start": 1602.4, "duration": 4.56}, {"text": "is one over", "start": 1605.36, "duration": 6.919}, {"text": "one minus p plus p over n", "start": 1606.96, "duration": 5.319}, {"text": "so as the number of processes goes to", "start": 1613.84, "duration": 4.8}, {"text": "infinity the theoretical speed up is", "start": 1616.08, "duration": 4.32}, {"text": "going to depend only on the proportion", "start": 1618.64, "duration": 3.76}, {"text": "of the parallel content", "start": 1620.4, "duration": 5.279}, {"text": "so if we go back go back to amdahl's law", "start": 1622.4, "duration": 5.92}, {"text": "we let n go to infinity we end up with 1", "start": 1625.679, "duration": 5.841}, {"text": "over 1 minus p or 1 over s", "start": 1628.32, "duration": 4.479}, {"text": "so", "start": 1631.52, "duration": 2.399}, {"text": "looking at right now you're probably", "start": 1632.799, "duration": 3.36}, {"text": "thinking oh that's not so bad", "start": 1633.919, "duration": 4.561}, {"text": "but as we'll show in the next slide it", "start": 1636.159, "duration": 5.361}, {"text": "doesn't take much serial content to quit", "start": 1638.48, "duration": 6.88}, {"text": "to quickly impact the speed up", "start": 1641.52, "duration": 3.84}, {"text": "so what i'm showing here is the speed up", "start": 1646.64, "duration": 5.039}, {"text": "of code how many times faster it runs as", "start": 1648.72, "duration": 4.959}, {"text": "we start running on running on more", "start": 1651.679, "duration": 3.12}, {"text": "cores", "start": 1653.679, "duration": 2.801}, {"text": "and i'm showing this for four different", "start": 1654.799, "duration": 5.36}, {"text": "cases for for parallel content of 50", "start": 1656.48, "duration": 4.88}, {"text": "75", "start": 1660.159, "duration": 2.161}, {"text": "90", "start": 1661.36, "duration": 3.679}, {"text": "and 95", "start": 1662.32, "duration": 2.719}, {"text": "so the first thing that you want the", "start": 1665.44, "duration": 3.76}, {"text": "first big takeaway here", "start": 1667.2, "duration": 4.16}, {"text": "is that the maximum speed up that you", "start": 1669.2, "duration": 3.12}, {"text": "get", "start": 1671.36, "duration": 3.76}, {"text": "even if you have 95 percent paralyzable", "start": 1672.32, "duration": 5.92}, {"text": "content it's only a 20x", "start": 1675.12, "duration": 4.559}, {"text": "and that that's", "start": 1678.24, "duration": 6.08}, {"text": "that that's only a small fraction of a", "start": 1679.679, "duration": 4.641}, {"text": "sorry that and that that's only a small", "start": 1685.52, "duration": 3.92}, {"text": "fraction of the compute power on a", "start": 1687.76, "duration": 4.639}, {"text": "single compute node", "start": 1689.44, "duration": 2.959}, {"text": "now if we go a little bit further you", "start": 1693.2, "duration": 3.76}, {"text": "think let's say we have a code code with", "start": 1695.039, "duration": 4.801}, {"text": "99 parallel content", "start": 1696.96, "duration": 5.04}, {"text": "if we look at that table on the right", "start": 1699.84, "duration": 5.04}, {"text": "we see even if we have only one percent", "start": 1702.0, "duration": 5.44}, {"text": "serial content the maximum speed up that", "start": 1704.88, "duration": 5.12}, {"text": "we get i think by throwing thousands and", "start": 1707.44, "duration": 4.8}, {"text": "thousands of processes in this problem", "start": 1710.0, "duration": 5.36}, {"text": "is only 100x so again that's still less", "start": 1712.24, "duration": 5.12}, {"text": "than a full compute node and not", "start": 1715.36, "duration": 4.96}, {"text": "anywhere close to the full power of a", "start": 1717.36, "duration": 5.84}, {"text": "multi-node supercomputer", "start": 1720.32, "duration": 5.2}, {"text": "and not only that you're probably not", "start": 1723.2, "duration": 3.92}, {"text": "going to get that hundred that that", "start": 1725.52, "duration": 4.159}, {"text": "hundred x speed up so i have an arrow on", "start": 1727.12, "duration": 4.24}, {"text": "the figure or", "start": 1729.679, "duration": 4.321}, {"text": "which indicates um", "start": 1731.36, "duration": 5.76}, {"text": "running that that code with 99 parallel", "start": 1734.0, "duration": 4.64}, {"text": "content", "start": 1737.12, "duration": 2.32}, {"text": "on", "start": 1738.64, "duration": 1.759}, {"text": "um", "start": 1739.44, "duration": 4.8}, {"text": "on 128 cores or one expanse or bridges", "start": 1740.399, "duration": 4.801}, {"text": "to", "start": 1744.24, "duration": 3.679}, {"text": "compute node so we can see here we're", "start": 1745.2, "duration": 6.479}, {"text": "using we're using 128 cores but we only", "start": 1747.919, "duration": 5.601}, {"text": "got a 60", "start": 1751.679, "duration": 4.161}, {"text": "wait we only got a 60 x speed up so", "start": 1753.52, "duration": 5.279}, {"text": "that's really a terrible use of the of", "start": 1755.84, "duration": 5.04}, {"text": "that computer you're you're wasting a", "start": 1758.799, "duration": 3.841}, {"text": "lot wasting a lot of hardware and we're", "start": 1760.88, "duration": 3.44}, {"text": "going to talk in the next few slides", "start": 1762.64, "duration": 3.12}, {"text": "about where", "start": 1764.32, "duration": 3.52}, {"text": "i'm toward the end of talk you know", "start": 1765.76, "duration": 3.919}, {"text": "where where we should be running so you", "start": 1767.84, "duration": 3.68}, {"text": "can see just that little bit of serial", "start": 1769.679, "duration": 5.041}, {"text": "content can really really impact your on", "start": 1771.52, "duration": 5.92}, {"text": "scalability", "start": 1774.72, "duration": 2.72}, {"text": "now on top of that in addition to", "start": 1777.52, "duration": 3.519}, {"text": "amdahl's law", "start": 1779.36, "duration": 3.52}, {"text": "there are other factors that affect", "start": 1781.039, "duration": 4.081}, {"text": "scalability so keep in mind that andol's", "start": 1782.88, "duration": 4.48}, {"text": "law is a theoretical upper limit on", "start": 1785.12, "duration": 4.08}, {"text": "speed up so we're going to have other", "start": 1787.36, "duration": 3.199}, {"text": "things we're going to have the", "start": 1789.2, "duration": 3.52}, {"text": "communications overhead we're going to", "start": 1790.559, "duration": 4.48}, {"text": "have limitations due to problem size", "start": 1792.72, "duration": 4.0}, {"text": "let's say we're looking at problem of a", "start": 1795.039, "duration": 4.561}, {"text": "fixed size we can only split it up so", "start": 1796.72, "duration": 4.72}, {"text": "far and distribute it across multiple", "start": 1799.6, "duration": 3.439}, {"text": "threads of processes", "start": 1801.44, "duration": 3.119}, {"text": "we're also going to have run into a", "start": 1803.039, "duration": 4.801}, {"text": "problem of of uneven load balancing", "start": 1804.559, "duration": 4.161}, {"text": "where", "start": 1807.84, "duration": 3.28}, {"text": "um all of the processes aren't doing the", "start": 1808.72, "duration": 5.199}, {"text": "same amount of work", "start": 1811.12, "duration": 4.799}, {"text": "so in real life applications that", "start": 1813.919, "duration": 3.76}, {"text": "involve communication", "start": 1815.919, "duration": 3.681}, {"text": "if they're synchronization events they", "start": 1817.679, "duration": 3.12}, {"text": "were all the threads of the process", "start": 1819.6, "duration": 2.959}, {"text": "processes have to complete their work", "start": 1820.799, "duration": 3.12}, {"text": "before we move on", "start": 1822.559, "duration": 3.521}, {"text": "or if we have what we call irregular", "start": 1823.919, "duration": 4.721}, {"text": "problems instead of nice cartesian grids", "start": 1826.08, "duration": 4.719}, {"text": "like i'll be showing in um next few", "start": 1828.64, "duration": 3.36}, {"text": "slides", "start": 1830.799, "duration": 2.561}, {"text": "um but", "start": 1832.0, "duration": 4.0}, {"text": "your irregular domains complex complex", "start": 1833.36, "duration": 5.52}, {"text": "geometries our speed up can be much less", "start": 1836.0, "duration": 6.399}, {"text": "than predicted by amdahl's law", "start": 1838.88, "duration": 3.519}, {"text": "so look taking a look at load balancing", "start": 1842.799, "duration": 4.801}, {"text": "so when we paralyze the code we need to", "start": 1845.44, "duration": 4.16}, {"text": "take the computational work we need to", "start": 1847.6, "duration": 4.0}, {"text": "divide into chunks that could be", "start": 1849.6, "duration": 4.559}, {"text": "executed independently now they may need", "start": 1851.6, "duration": 4.88}, {"text": "to communicate occasionally but but it's", "start": 1854.159, "duration": 4.161}, {"text": "that division of work that allows us to", "start": 1856.48, "duration": 4.4}, {"text": "take advantage of a parallel computer", "start": 1858.32, "duration": 4.479}, {"text": "so if the work cannot be distributed", "start": 1860.88, "duration": 4.399}, {"text": "evenly then processors are going to sit", "start": 1862.799, "duration": 4.561}, {"text": "idle waiting for the longest chunk to", "start": 1865.279, "duration": 3.201}, {"text": "finish", "start": 1867.36, "duration": 3.52}, {"text": "so i'm showing four tests here", "start": 1868.48, "duration": 4.4}, {"text": "that these could be processes", "start": 1870.88, "duration": 5.2}, {"text": "say um parallelization done using mpi or", "start": 1872.88, "duration": 5.919}, {"text": "threads that the concept is the same", "start": 1876.08, "duration": 4.959}, {"text": "but imagine that at blue that the blue", "start": 1878.799, "duration": 4.24}, {"text": "bar represents the time", "start": 1881.039, "duration": 4.081}, {"text": "that each of those um each of those", "start": 1883.039, "duration": 3.921}, {"text": "processes is busy", "start": 1885.12, "duration": 4.64}, {"text": "and then the um red stripe blocks our", "start": 1886.96, "duration": 5.36}, {"text": "idle time so let's say we we begin our", "start": 1889.76, "duration": 3.919}, {"text": "calculation", "start": 1892.32, "duration": 4.56}, {"text": "we assign a chunk of work to task 0 1 2", "start": 1893.679, "duration": 4.72}, {"text": "and 3", "start": 1896.88, "duration": 3.44}, {"text": "we see that test 2 takes a little bit", "start": 1898.399, "duration": 3.681}, {"text": "longer than everyone else", "start": 1900.32, "duration": 4.8}, {"text": "so test 0 test 1 and test 3 they're", "start": 1902.08, "duration": 4.479}, {"text": "gonna be sitting there they're gonna be", "start": 1905.12, "duration": 4.32}, {"text": "idle just wait until task two finishes", "start": 1906.559, "duration": 4.0}, {"text": "until we get to one of these", "start": 1909.44, "duration": 3.52}, {"text": "synchronization synchronization points", "start": 1910.559, "duration": 4.321}, {"text": "where all the tasks must complete before", "start": 1912.96, "duration": 3.68}, {"text": "proceeding let's say", "start": 1914.88, "duration": 3.76}, {"text": "process have to exchange newly computed", "start": 1916.64, "duration": 4.08}, {"text": "results or threads must finish updating", "start": 1918.64, "duration": 3.519}, {"text": "the shared array", "start": 1920.72, "duration": 3.6}, {"text": "then after that centralization point", "start": 1922.159, "duration": 4.561}, {"text": "let's say we assign new chunks of work", "start": 1924.32, "duration": 3.76}, {"text": "and here the situation is a little bit", "start": 1926.72, "duration": 4.0}, {"text": "different in this case task 1", "start": 1928.08, "duration": 5.599}, {"text": "got the got to sign the biggest chunk", "start": 1930.72, "duration": 5.12}, {"text": "and tasks zero two and three", "start": 1933.679, "duration": 4.72}, {"text": "um i had shorter chunks so now they're", "start": 1935.84, "duration": 4.48}, {"text": "all gonna sit idle waiting waiting for", "start": 1938.399, "duration": 4.16}, {"text": "test one to complete so again this is", "start": 1940.32, "duration": 4.16}, {"text": "one of the factors that's going to", "start": 1942.559, "duration": 4.161}, {"text": "that's going to impact the", "start": 1944.48, "duration": 5.28}, {"text": "um scalability of the code", "start": 1946.72, "duration": 6.4}, {"text": "another one is communications overhead", "start": 1949.76, "duration": 4.96}, {"text": "so if you're doing", "start": 1953.12, "duration": 3.279}, {"text": "something like computational flow", "start": 1954.72, "duration": 4.199}, {"text": "dynamics magnetohydride", "start": 1956.399, "duration": 4.16}, {"text": "magnetohydrodynamics so essentially", "start": 1958.919, "duration": 3.561}, {"text": "simulations of plasmas", "start": 1960.559, "duration": 4.161}, {"text": "climate and weather simulations these", "start": 1962.48, "duration": 4.4}, {"text": "all involve solving systems of partial", "start": 1964.72, "duration": 4.16}, {"text": "differential equations", "start": 1966.88, "duration": 4.159}, {"text": "and the way we do that computationally", "start": 1968.88, "duration": 4.159}, {"text": "is we will um", "start": 1971.039, "duration": 5.12}, {"text": "we would discretize our domain we will", "start": 1973.039, "duration": 4.161}, {"text": "um", "start": 1976.159, "duration": 3.441}, {"text": "do the calculations on a grid and if we", "start": 1977.2, "duration": 4.88}, {"text": "want to do this in parallel we need to", "start": 1979.6, "duration": 5.36}, {"text": "take that grid and distribute it across", "start": 1982.08, "duration": 5.76}, {"text": "multiple multiple processes", "start": 1984.96, "duration": 4.319}, {"text": "so in this case", "start": 1987.84, "duration": 3.92}, {"text": "and this of course is an unrealistically", "start": 1989.279, "duration": 4.321}, {"text": "small problem but imagine that we have a", "start": 1991.76, "duration": 4.639}, {"text": "16 by 16 grid and we're going to divide", "start": 1993.6, "duration": 5.12}, {"text": "it into four 8x8 chunks that are", "start": 1996.399, "duration": 6.081}, {"text": "distributed across the process", "start": 1998.72, "duration": 3.76}, {"text": "now let's assume that each cell is", "start": 2003.679, "duration": 4.161}, {"text": "updated using the values of the four", "start": 2005.6, "duration": 3.84}, {"text": "neighboring cells", "start": 2007.84, "duration": 4.079}, {"text": "so for a cell that's within the interior", "start": 2009.44, "duration": 4.959}, {"text": "of each chunk these calculations can be", "start": 2011.919, "duration": 4.48}, {"text": "done within each process so i've", "start": 2014.399, "duration": 3.921}, {"text": "highlighted one cell in each of those", "start": 2016.399, "duration": 3.52}, {"text": "four in each of those four chunks", "start": 2018.32, "duration": 4.719}, {"text": "highlighted with red and i show in blue", "start": 2019.919, "duration": 5.041}, {"text": "that the four neighboring cells that it", "start": 2023.039, "duration": 5.12}, {"text": "needs to get data from", "start": 2024.96, "duration": 3.199}, {"text": "now it gets a little more complicated", "start": 2031.679, "duration": 2.961}, {"text": "for the cells that are at the boundaries", "start": 2033.2, "duration": 3.68}, {"text": "of the chunks so the data belonging to", "start": 2034.64, "duration": 4.8}, {"text": "the neighboring processes is needed so", "start": 2036.88, "duration": 4.639}, {"text": "to accommodate this we need a halo of", "start": 2039.44, "duration": 4.56}, {"text": "ghost cells as we call them and data", "start": 2041.519, "duration": 4.88}, {"text": "must be communicated between processes", "start": 2044.0, "duration": 4.56}, {"text": "and that data communications it takes", "start": 2046.399, "duration": 4.641}, {"text": "time so this data movement it's going to", "start": 2048.56, "duration": 4.88}, {"text": "depend on both the latency", "start": 2051.04, "duration": 4.559}, {"text": "and the bandwidth of the network so", "start": 2053.44, "duration": 4.719}, {"text": "latency is essentially how long it takes", "start": 2055.599, "duration": 4.48}, {"text": "that first bit of information to be", "start": 2058.159, "duration": 4.161}, {"text": "transferred on bandwidth is the rate at", "start": 2060.079, "duration": 4.401}, {"text": "which you can transfer the data", "start": 2062.32, "duration": 4.88}, {"text": "and this communication it's going to", "start": 2064.48, "duration": 4.24}, {"text": "it's going to introduce overhead and", "start": 2067.2, "duration": 2.959}, {"text": "it's going to further cut into the", "start": 2068.72, "duration": 4.0}, {"text": "scalability of your application", "start": 2070.159, "duration": 5.121}, {"text": "so to show what the um communication", "start": 2072.72, "duration": 4.08}, {"text": "pattern would look like", "start": 2075.28, "duration": 4.639}, {"text": "um if we consider those two those um fit", "start": 2076.8, "duration": 5.279}, {"text": "two chunks on the top", "start": 2079.919, "duration": 5.68}, {"text": "um the one in the upper left is going to", "start": 2082.079, "duration": 5.84}, {"text": "um is going is going to pass that that", "start": 2085.599, "duration": 4.401}, {"text": "column of dark blue cells", "start": 2087.919, "duration": 4.561}, {"text": "over to the um", "start": 2090.0, "duration": 4.56}, {"text": "over the process executing the chunk of", "start": 2092.48, "duration": 3.599}, {"text": "the upper right", "start": 2094.56, "duration": 3.279}, {"text": "and that's going to be held in the ghost", "start": 2096.079, "duration": 5.201}, {"text": "cells similarly these the chunk in the", "start": 2097.839, "duration": 4.561}, {"text": "upper right", "start": 2101.28, "duration": 3.52}, {"text": "is going to communicate a column of data", "start": 2102.4, "duration": 4.56}, {"text": "over to the um", "start": 2104.8, "duration": 4.48}, {"text": "oh the process on the upper left", "start": 2106.96, "duration": 4.639}, {"text": "so now after we do that communications", "start": 2109.28, "duration": 4.48}, {"text": "we can we can finish the calculations", "start": 2111.599, "duration": 3.76}, {"text": "for all of those cells that are around", "start": 2113.76, "duration": 3.28}, {"text": "the edge of the domain", "start": 2115.359, "duration": 3.521}, {"text": "and then just to show you what the rest", "start": 2117.04, "duration": 3.84}, {"text": "of the communication pattern looks like", "start": 2118.88, "duration": 4.239}, {"text": "so again this communications overhead is", "start": 2120.88, "duration": 4.64}, {"text": "going to impact the performance and", "start": 2123.119, "duration": 5.041}, {"text": "scalability", "start": 2125.52, "duration": 4.559}, {"text": "so at this point you're probably you", "start": 2128.16, "duration": 3.439}, {"text": "know ready to throw up your hands and", "start": 2130.079, "duration": 3.921}, {"text": "think wow how am i with everything", "start": 2131.599, "duration": 4.561}, {"text": "working against me you know the these", "start": 2134.0, "duration": 4.88}, {"text": "hard limits imposed by amdahl's law", "start": 2136.16, "duration": 4.88}, {"text": "um", "start": 2138.88, "duration": 5.04}, {"text": "low load imbalance um communications", "start": 2141.04, "duration": 3.92}, {"text": "overhead", "start": 2143.92, "duration": 2.32}, {"text": "you know all these things that affect", "start": 2144.96, "duration": 3.2}, {"text": "the scalability how is anybody ever", "start": 2146.24, "duration": 3.92}, {"text": "going to use all of the cores", "start": 2148.16, "duration": 4.24}, {"text": "on a single modern compute node let", "start": 2150.16, "duration": 3.52}, {"text": "alone the full power of large", "start": 2152.4, "duration": 3.28}, {"text": "supercomputers", "start": 2153.68, "duration": 4.159}, {"text": "so first the reality is that most", "start": 2155.68, "duration": 4.399}, {"text": "parallel applications are not going to", "start": 2157.839, "duration": 4.321}, {"text": "scale to thousands or even hundreds of", "start": 2160.079, "duration": 4.721}, {"text": "cores in fact if you get", "start": 2162.16, "duration": 3.52}, {"text": "um", "start": 2164.8, "duration": 2.64}, {"text": "if you have an account on any navy", "start": 2165.68, "duration": 3.919}, {"text": "exceed machines and you take a look at", "start": 2167.44, "duration": 4.159}, {"text": "the queue you will see that there are a", "start": 2169.599, "duration": 4.48}, {"text": "lot of jobs in there um that that are", "start": 2171.599, "duration": 5.841}, {"text": "using anywhere from a single core to", "start": 2174.079, "duration": 4.961}, {"text": "um", "start": 2177.44, "duration": 4.56}, {"text": "to to to ascent to a single node", "start": 2179.04, "duration": 4.88}, {"text": "and then second of all", "start": 2182.0, "duration": 3.839}, {"text": "there are applications that do achieve", "start": 2183.92, "duration": 4.32}, {"text": "high scalability but they employ several", "start": 2185.839, "duration": 4.081}, {"text": "strategies", "start": 2188.24, "duration": 3.52}, {"text": "so first of all", "start": 2189.92, "duration": 3.76}, {"text": "you can grow the problem size with the", "start": 2191.76, "duration": 3.92}, {"text": "number of cars or nodes so let's say", "start": 2193.68, "duration": 4.0}, {"text": "we're doing molecular dynamic simulation", "start": 2195.68, "duration": 3.2}, {"text": "material", "start": 2197.68, "duration": 2.72}, {"text": "um we're originally", "start": 2198.88, "duration": 4.08}, {"text": "say working with um", "start": 2200.4, "duration": 4.48}, {"text": "with a million atoms or a million", "start": 2202.96, "duration": 4.159}, {"text": "particles we're not going to try to take", "start": 2204.88, "duration": 4.64}, {"text": "that problem and run it across 1000", "start": 2207.119, "duration": 4.161}, {"text": "compute nodes we're going to grow that", "start": 2209.52, "duration": 3.599}, {"text": "we're going to solve a much larger", "start": 2211.28, "duration": 4.4}, {"text": "problem maybe look looking at looking at", "start": 2213.119, "duration": 4.801}, {"text": "billions of potentially trillions of", "start": 2215.68, "duration": 4.159}, {"text": "trons of atoms", "start": 2217.92, "duration": 3.6}, {"text": "and if you want to know a little bit", "start": 2219.839, "duration": 3.041}, {"text": "more about", "start": 2221.52, "duration": 3.04}, {"text": "you know the scaling that you see as you", "start": 2222.88, "duration": 3.92}, {"text": "increase problem size with the number of", "start": 2224.56, "duration": 4.4}, {"text": "nodes um you can look into gus", "start": 2226.8, "duration": 4.24}, {"text": "gustafson's law i didn't have a chance", "start": 2228.96, "duration": 3.52}, {"text": "to go into it here it's a little more", "start": 2231.04, "duration": 3.92}, {"text": "technical but it does it addresses this", "start": 2232.48, "duration": 3.92}, {"text": "issue", "start": 2234.96, "duration": 3.119}, {"text": "another thing we can do is overlap", "start": 2236.4, "duration": 4.0}, {"text": "communications with computations", "start": 2238.079, "duration": 4.721}, {"text": "so while we're doing the calculations on", "start": 2240.4, "duration": 5.12}, {"text": "those interior cells of our domains we", "start": 2242.8, "duration": 4.64}, {"text": "could be at the same time", "start": 2245.52, "duration": 5.04}, {"text": "um communicating data between processes", "start": 2247.44, "duration": 4.639}, {"text": "so that by the time we get to their", "start": 2250.56, "duration": 3.2}, {"text": "cells around the boundary we have the", "start": 2252.079, "duration": 3.121}, {"text": "data that we need", "start": 2253.76, "duration": 3.599}, {"text": "we can use dynamic load balancing to", "start": 2255.2, "duration": 4.8}, {"text": "sign work the cores as they become idle", "start": 2257.359, "duration": 5.281}, {"text": "and we can also do computations that", "start": 2260.0, "duration": 4.8}, {"text": "increase the ratio of computation and", "start": 2262.64, "duration": 3.36}, {"text": "communication", "start": 2264.8, "duration": 4.96}, {"text": "so for example if we are doing um", "start": 2266.0, "duration": 5.2}, {"text": "if we're doing computational fluid", "start": 2269.76, "duration": 2.8}, {"text": "dynamics", "start": 2271.2, "duration": 3.12}, {"text": "and we decide to go to the next step and", "start": 2272.56, "duration": 3.519}, {"text": "look at combustion where we actually", "start": 2274.32, "duration": 3.36}, {"text": "have to take into account the chemistry", "start": 2276.079, "duration": 3.681}, {"text": "that's going on the cells that's very", "start": 2277.68, "duration": 4.64}, {"text": "computationally intense intensive and", "start": 2279.76, "duration": 4.8}, {"text": "that increases our ratio of computation", "start": 2282.32, "duration": 4.08}, {"text": "and communication and that code will", "start": 2284.56, "duration": 4.72}, {"text": "likely be more scalable", "start": 2286.4, "duration": 4.959}, {"text": "so running parallel applications", "start": 2289.28, "duration": 3.839}, {"text": "so so far we've covered the basics", "start": 2291.359, "duration": 3.121}, {"text": "parallel computing we talked a little", "start": 2293.119, "duration": 3.601}, {"text": "bit about hardware threads processes", "start": 2294.48, "duration": 3.92}, {"text": "hybrid applications", "start": 2296.72, "duration": 4.32}, {"text": "the implementations amdahl's law and", "start": 2298.4, "duration": 5.6}, {"text": "other factors affect scalability", "start": 2301.04, "duration": 5.12}, {"text": "so we've we've looked at a lot of theory", "start": 2304.0, "duration": 3.76}, {"text": "and backgrounds this is great i think", "start": 2306.16, "duration": 3.28}, {"text": "you all need to know this", "start": 2307.76, "duration": 4.64}, {"text": "but the big question is as an end user", "start": 2309.44, "duration": 5.12}, {"text": "running somebody else's application on a", "start": 2312.4, "duration": 4.719}, {"text": "super computer how many processes do we", "start": 2314.56, "duration": 5.2}, {"text": "use when we run that application", "start": 2317.119, "duration": 4.881}, {"text": "and the only way to definitively answer", "start": 2319.76, "duration": 4.319}, {"text": "that question is to perform a scaling", "start": 2322.0, "duration": 4.72}, {"text": "study where a representative problem is", "start": 2324.079, "duration": 5.76}, {"text": "run on different numbers of processes", "start": 2326.72, "duration": 6.0}, {"text": "and by representative we mean a problem", "start": 2329.839, "duration": 5.041}, {"text": "of the same size say the same grid", "start": 2332.72, "duration": 4.56}, {"text": "dimension the number of particles a", "start": 2334.88, "duration": 5.04}, {"text": "number of images number of genomes etc", "start": 2337.28, "duration": 4.88}, {"text": "the same level of complexity so if", "start": 2339.92, "duration": 4.08}, {"text": "you're a computational chemist the level", "start": 2342.16, "duration": 3.36}, {"text": "of theory", "start": 2344.0, "duration": 2.56}, {"text": "um", "start": 2345.52, "duration": 2.96}, {"text": "if you're", "start": 2346.56, "duration": 3.92}, {"text": "doing other applications", "start": 2348.48, "duration": 5.04}, {"text": "the either the type of analysis the type", "start": 2350.48, "duration": 5.28}, {"text": "physics that's being treated so your", "start": 2353.52, "duration": 4.16}, {"text": "representative problem has to look like", "start": 2355.76, "duration": 3.359}, {"text": "the research problem that you want to", "start": 2357.68, "duration": 2.399}, {"text": "solve", "start": 2359.119, "duration": 3.441}, {"text": "so of course you're not going to take a", "start": 2360.079, "duration": 3.441}, {"text": "full", "start": 2362.56, "duration": 3.68}, {"text": "climate simulation run it for um running", "start": 2363.52, "duration": 4.8}, {"text": "for a hundred years in order to do the", "start": 2366.24, "duration": 4.24}, {"text": "benchmarking but you could take that", "start": 2368.32, "duration": 4.32}, {"text": "problem and run it for just a few time", "start": 2370.48, "duration": 5.599}, {"text": "steps in in order to get a feel for", "start": 2372.64, "duration": 4.32}, {"text": "um", "start": 2376.079, "duration": 3.441}, {"text": "but for how the runtime will grow", "start": 2376.96, "duration": 6.32}, {"text": "as you do more times", "start": 2379.52, "duration": 5.92}, {"text": "so presenting scaling results", "start": 2383.28, "duration": 3.92}, {"text": "um we we see this a lot in the in the", "start": 2385.44, "duration": 5.04}, {"text": "allocation process in fact exceed has a", "start": 2387.2, "duration": 5.919}, {"text": "has a great um what webinar that they do", "start": 2390.48, "duration": 4.72}, {"text": "a few times a year where they get into", "start": 2393.119, "duration": 3.601}, {"text": "this issue of how you present your", "start": 2395.2, "duration": 3.2}, {"text": "scaling data", "start": 2396.72, "duration": 3.68}, {"text": "so believe it or not these plots on the", "start": 2398.4, "duration": 3.76}, {"text": "left and right hand side", "start": 2400.4, "duration": 2.719}, {"text": "um", "start": 2402.16, "duration": 3.04}, {"text": "are scaling curves for two different", "start": 2403.119, "duration": 4.801}, {"text": "codes with different scalability", "start": 2405.2, "duration": 4.8}, {"text": "but the way that it's being presented", "start": 2407.92, "duration": 4.399}, {"text": "it's really hard to tell which one is", "start": 2410.0, "duration": 3.28}, {"text": "better", "start": 2412.319, "duration": 3.681}, {"text": "because the timings that large core", "start": 2413.28, "duration": 6.0}, {"text": "counts are indistinguishable", "start": 2416.0, "duration": 3.28}, {"text": "so the right way to present the scaling", "start": 2419.839, "duration": 4.641}, {"text": "data is instead of using linear axes to", "start": 2421.599, "duration": 5.121}, {"text": "use log axes", "start": 2424.48, "duration": 4.0}, {"text": "um first of all look at the different", "start": 2426.72, "duration": 4.879}, {"text": "time scales for um on the left axis for", "start": 2428.48, "duration": 5.2}, {"text": "for the two plots the example on the", "start": 2431.599, "duration": 4.0}, {"text": "left is something that you're never", "start": 2433.68, "duration": 4.24}, {"text": "going to see that this is a perfectly", "start": 2435.599, "duration": 3.841}, {"text": "scalable code", "start": 2437.92, "duration": 4.159}, {"text": "um we could see that the red line", "start": 2439.44, "duration": 3.84}, {"text": "um", "start": 2442.079, "duration": 3.52}, {"text": "plotted in this log log scale it is", "start": 2443.28, "duration": 5.76}, {"text": "linear i've included a solid black line", "start": 2445.599, "duration": 4.24}, {"text": "um", "start": 2449.04, "duration": 3.039}, {"text": "as a guide fit to show what what linear", "start": 2449.839, "duration": 3.76}, {"text": "scaling should be", "start": 2452.079, "duration": 3.361}, {"text": "i've also plotted the parallel", "start": 2453.599, "duration": 3.041}, {"text": "efficiency", "start": 2455.44, "duration": 4.0}, {"text": "so this is the speed up divided by the", "start": 2456.64, "duration": 5.04}, {"text": "number of processes basically this means", "start": 2459.44, "duration": 4.32}, {"text": "that we're running perfectly efficiently", "start": 2461.68, "duration": 3.04}, {"text": "as we", "start": 2463.76, "duration": 3.359}, {"text": "you use more cores processes", "start": 2464.72, "duration": 4.48}, {"text": "so on the right and again this is the", "start": 2467.119, "duration": 3.761}, {"text": "same data that we're seeing on the", "start": 2469.2, "duration": 3.84}, {"text": "previous slide this is showing a more", "start": 2470.88, "duration": 3.76}, {"text": "realistic code", "start": 2473.04, "duration": 2.72}, {"text": "that", "start": 2474.64, "duration": 2.959}, {"text": "you know as we increase the core count", "start": 2475.76, "duration": 4.24}, {"text": "to two to four to eight it runs a little", "start": 2477.599, "duration": 4.24}, {"text": "bit slower", "start": 2480.0, "duration": 3.44}, {"text": "um we can see that the parallel", "start": 2481.839, "duration": 4.48}, {"text": "efficiency though tends to drop pretty", "start": 2483.44, "duration": 5.52}, {"text": "quickly after after about eight cores", "start": 2486.319, "duration": 4.8}, {"text": "and by the time we get to by the time we", "start": 2488.96, "duration": 5.52}, {"text": "get to running on 128 cores we can see", "start": 2491.119, "duration": 5.121}, {"text": "that we've only achieved a parallel", "start": 2494.48, "duration": 5.68}, {"text": "efficiency of about 20", "start": 2496.24, "duration": 3.92}, {"text": "okay so where should you be on the", "start": 2500.8, "duration": 3.6}, {"text": "scaling curve", "start": 2502.48, "duration": 3.68}, {"text": "so we're gonna um cover a couple of", "start": 2504.4, "duration": 4.16}, {"text": "guidelines in these last few slides so", "start": 2506.16, "duration": 4.48}, {"text": "if your work is not particularly", "start": 2508.56, "duration": 3.759}, {"text": "sensitive to the time to complete a", "start": 2510.64, "duration": 4.32}, {"text": "single run consider using a core count", "start": 2512.319, "duration": 5.121}, {"text": "that's at or very close to 100", "start": 2514.96, "duration": 3.68}, {"text": "efficiency", "start": 2517.44, "duration": 3.28}, {"text": "even if that means running on a single", "start": 2518.64, "duration": 3.04}, {"text": "core", "start": 2520.72, "duration": 2.24}, {"text": "so i know if you if you have a", "start": 2521.68, "duration": 2.8}, {"text": "calculation that's going to take a long", "start": 2522.96, "duration": 3.6}, {"text": "long time you don't want to wait days or", "start": 2524.48, "duration": 4.72}, {"text": "weeks for it but if you need to do many", "start": 2526.56, "duration": 4.799}, {"text": "calculations and you really don't care", "start": 2529.2, "duration": 3.919}, {"text": "about the time for any single", "start": 2531.359, "duration": 3.841}, {"text": "calculation to be completed", "start": 2533.119, "duration": 3.281}, {"text": "but you're more interested in the time", "start": 2535.2, "duration": 3.44}, {"text": "to complete that entire workload you", "start": 2536.4, "duration": 4.56}, {"text": "should really be running out here", "start": 2538.64, "duration": 3.76}, {"text": "um", "start": 2540.96, "duration": 3.52}, {"text": "you know in in or close to the linear", "start": 2542.4, "duration": 5.28}, {"text": "scaling regime where you're getting um", "start": 2544.48, "duration": 5.52}, {"text": "where you're getting parallel efficiency", "start": 2547.68, "duration": 5.04}, {"text": "that that's say 80 or better and this", "start": 2550.0, "duration": 4.64}, {"text": "especially makes sense for parameter", "start": 2552.72, "duration": 3.68}, {"text": "sweep workflows let's say we're doing", "start": 2554.64, "duration": 3.52}, {"text": "the same calculation", "start": 2556.4, "duration": 3.52}, {"text": "many times but with different sets of", "start": 2558.16, "duration": 4.32}, {"text": "inputs", "start": 2559.92, "duration": 2.56}, {"text": "okay sometimes it's okay to go a little", "start": 2563.839, "duration": 4.561}, {"text": "bit further out on that scaling curve if", "start": 2566.16, "duration": 4.4}, {"text": "the job would take an unreasonably long", "start": 2568.4, "duration": 4.88}, {"text": "time at lower core counts or if the", "start": 2570.56, "duration": 4.64}, {"text": "shorter time dissolution helps you make", "start": 2573.28, "duration": 5.039}, {"text": "res helps make progress in your research", "start": 2575.2, "duration": 5.119}, {"text": "so if you have a code that does not have", "start": 2578.319, "duration": 4.0}, {"text": "checkpoint restart capabilities that", "start": 2580.319, "duration": 3.841}, {"text": "means that you can stop you can save the", "start": 2582.319, "duration": 3.76}, {"text": "state of the code read that back in and", "start": 2584.16, "duration": 3.6}, {"text": "continue", "start": 2586.079, "duration": 3.921}, {"text": "or the runtime would exceed q limits you", "start": 2587.76, "duration": 4.0}, {"text": "may have no choice but to run at higher", "start": 2590.0, "duration": 4.4}, {"text": "core cuts", "start": 2591.76, "duration": 2.64}, {"text": "and then sometimes it's okay to go even", "start": 2594.56, "duration": 3.68}, {"text": "further out", "start": 2596.96, "duration": 2.48}, {"text": "um", "start": 2598.24, "duration": 2.96}, {"text": "so let's say that you have calculations", "start": 2599.44, "duration": 3.36}, {"text": "that need to be run on a regular", "start": 2601.2, "duration": 4.08}, {"text": "schedule say you're collecting data", "start": 2602.8, "duration": 4.319}, {"text": "um data every day it needs to be", "start": 2605.28, "duration": 4.079}, {"text": "processed overnight the analysis has to", "start": 2607.119, "duration": 4.72}, {"text": "be available in the morning sure then", "start": 2609.359, "duration": 4.561}, {"text": "you can run you can run a lower co core", "start": 2611.839, "duration": 4.081}, {"text": "counts or if it's something that's", "start": 2613.92, "duration": 4.0}, {"text": "absolutely critical let's say that", "start": 2615.92, "duration": 4.64}, {"text": "you're doing um a tornado or tsunami", "start": 2617.92, "duration": 5.12}, {"text": "prediction i would use as many cores as", "start": 2620.56, "duration": 4.4}, {"text": "you can to get the absolute best", "start": 2623.04, "duration": 4.0}, {"text": "performance even if it impacts your", "start": 2624.96, "duration": 4.399}, {"text": "power efficiency again though most of", "start": 2627.04, "duration": 3.84}, {"text": "you are not going to be doing that", "start": 2629.359, "duration": 2.801}, {"text": "you're going to be doing scientific", "start": 2630.88, "duration": 3.6}, {"text": "workloads where time dissolution is not", "start": 2632.16, "duration": 4.159}, {"text": "as critical so you should be running at", "start": 2634.48, "duration": 4.0}, {"text": "a high power like efficiency let me just", "start": 2636.319, "duration": 4.481}, {"text": "check the chat", "start": 2638.48, "duration": 3.599}, {"text": "um", "start": 2640.8, "duration": 3.12}, {"text": "so there's a question is it possible to", "start": 2642.079, "duration": 4.0}, {"text": "do this on exceed machines or recharge", "start": 2643.92, "duration": 5.439}, {"text": "per node rather than per core", "start": 2646.079, "duration": 6.561}, {"text": "like it looks such a stampede too no so", "start": 2649.359, "duration": 4.72}, {"text": "um", "start": 2652.64, "duration": 2.959}, {"text": "yeah the", "start": 2654.079, "duration": 3.921}, {"text": "different xc resources are offered in", "start": 2655.599, "duration": 4.081}, {"text": "different ways", "start": 2658.0, "duration": 4.319}, {"text": "expands and comic before it and bridges", "start": 2659.68, "duration": 4.639}, {"text": "and bridges to all allow the shared", "start": 2662.319, "duration": 2.961}, {"text": "nodes", "start": 2664.319, "duration": 3.121}, {"text": "um but on stampede 2 you just need to", "start": 2665.28, "duration": 4.88}, {"text": "use the need to use the entire node and", "start": 2667.44, "duration": 4.48}, {"text": "stampede 2 is also", "start": 2670.16, "duration": 3.12}, {"text": "i'm looking a little bit of a different", "start": 2671.92, "duration": 4.08}, {"text": "user base it was designed for highly", "start": 2673.28, "duration": 4.799}, {"text": "scalable applications", "start": 2676.0, "duration": 3.44}, {"text": "and", "start": 2678.079, "duration": 2.641}, {"text": "yeah and the second part of the question", "start": 2679.44, "duration": 3.44}, {"text": "can we do this without wasting allocated", "start": 2680.72, "duration": 3.84}, {"text": "compute time", "start": 2682.88, "duration": 2.4}, {"text": "um", "start": 2684.56, "duration": 2.799}, {"text": "if you're running in a shared in a", "start": 2685.28, "duration": 3.28}, {"text": "shared queue", "start": 2687.359, "duration": 2.48}, {"text": "on", "start": 2688.56, "duration": 3.36}, {"text": "on expansion or bridges too", "start": 2689.839, "duration": 4.721}, {"text": "you would only be charged for the for", "start": 2691.92, "duration": 4.8}, {"text": "for the compute cores that you requested", "start": 2694.56, "duration": 4.32}, {"text": "so let's say you requested eight cores", "start": 2696.72, "duration": 3.68}, {"text": "somebody else is using the rest of the", "start": 2698.88, "duration": 3.76}, {"text": "rest of that note you're only", "start": 2700.4, "duration": 4.24}, {"text": "you're only charge for the eight whereas", "start": 2702.64, "duration": 4.56}, {"text": "on stampede since it's allocated by the", "start": 2704.64, "duration": 3.52}, {"text": "node", "start": 2707.2, "duration": 3.119}, {"text": "once you grab that node as far as the", "start": 2708.16, "duration": 4.0}, {"text": "accounting goes they don't care what you", "start": 2710.319, "duration": 3.601}, {"text": "do with it you could be using one core", "start": 2712.16, "duration": 3.28}, {"text": "you could be using all the cars you're", "start": 2713.92, "duration": 3.04}, {"text": "gonna have the you're gonna have the", "start": 2715.44, "duration": 4.96}, {"text": "same charge against your allocation", "start": 2716.96, "duration": 3.44}, {"text": "and then um other considerations i'm", "start": 2722.88, "duration": 4.239}, {"text": "just going to go over this very quickly", "start": 2725.04, "duration": 3.84}, {"text": "but sometimes you have an application", "start": 2727.119, "duration": 4.24}, {"text": "that has a large memory footprint", "start": 2728.88, "duration": 4.239}, {"text": "so typically", "start": 2731.359, "duration": 3.361}, {"text": "when you submit a job", "start": 2733.119, "duration": 4.161}, {"text": "you can request memory in proportion to", "start": 2734.72, "duration": 4.08}, {"text": "the core account so we'll go to the", "start": 2737.28, "duration": 5.16}, {"text": "example again of expense where we have", "start": 2738.8, "duration": 6.559}, {"text": "256 gigabytes of memory per standard", "start": 2742.44, "duration": 6.04}, {"text": "node and 128 cores so that means that we", "start": 2745.359, "duration": 6.24}, {"text": "have two gigabytes available", "start": 2748.48, "duration": 5.92}, {"text": "of it available per core but what if i", "start": 2751.599, "duration": 5.121}, {"text": "have an application with a really large", "start": 2754.4, "duration": 5.439}, {"text": "memory footprint where i need um or", "start": 2756.72, "duration": 4.8}, {"text": "where i need four gigabytes or eight", "start": 2759.839, "duration": 4.081}, {"text": "gigabytes per per um", "start": 2761.52, "duration": 5.839}, {"text": "per core in that case sorry per process", "start": 2763.92, "duration": 4.64}, {"text": "in that case", "start": 2767.359, "duration": 2.801}, {"text": "you're just going to have to request", "start": 2768.56, "duration": 4.08}, {"text": "more resources i'm going to refer you to", "start": 2770.16, "duration": 5.199}, {"text": "the user guides um for for for bridges", "start": 2772.64, "duration": 4.8}, {"text": "and and expanse for the right way to do", "start": 2775.359, "duration": 4.081}, {"text": "that but yeah you may you may be stuck", "start": 2777.44, "duration": 3.6}, {"text": "just having to", "start": 2779.44, "duration": 2.399}, {"text": "um", "start": 2781.04, "duration": 2.96}, {"text": "having to ask for more cores", "start": 2781.839, "duration": 4.961}, {"text": "um get poor scaling and you can also use", "start": 2784.0, "duration": 6.4}, {"text": "specialized large memory notes", "start": 2786.8, "duration": 3.6}, {"text": "so just about done here we've only", "start": 2790.48, "duration": 4.72}, {"text": "scratched the surface um we didn't we", "start": 2792.88, "duration": 4.56}, {"text": "didn't talk about how to actually run", "start": 2795.2, "duration": 5.6}, {"text": "jobs or do the accounting or so on", "start": 2797.44, "duration": 5.84}, {"text": "so first of all exceed and scc have a", "start": 2800.8, "duration": 4.559}, {"text": "lot of other training resources covering", "start": 2803.28, "duration": 4.24}, {"text": "a wide range of topics i might have", "start": 2805.359, "duration": 5.121}, {"text": "links here for exceed and for scsc", "start": 2807.52, "duration": 4.96}, {"text": "and then the user guides for for these", "start": 2810.48, "duration": 4.56}, {"text": "nationally allocated resources", "start": 2812.48, "duration": 5.2}, {"text": "um contain all the practical information", "start": 2815.04, "duration": 4.48}, {"text": "that you're going to need on the job", "start": 2817.68, "duration": 4.32}, {"text": "submission accounting and compilation", "start": 2819.52, "duration": 4.799}, {"text": "and data movement the available software", "start": 2822.0, "duration": 4.88}, {"text": "and a lot of this is site specific so", "start": 2824.319, "duration": 3.921}, {"text": "i'm going to say", "start": 2826.88, "duration": 5.36}, {"text": "you know go go to the um", "start": 2828.24, "duration": 5.76}, {"text": "go go to those user guides for all of", "start": 2832.24, "duration": 3.2}, {"text": "that information", "start": 2834.0, "duration": 3.68}, {"text": "and for a lot of this content", "start": 2835.44, "duration": 4.56}, {"text": "um that's available on exceed you need a", "start": 2837.68, "duration": 4.32}, {"text": "user portable account but you can create", "start": 2840.0, "duration": 3.359}, {"text": "one of those for free it only takes a", "start": 2842.0, "duration": 4.0}, {"text": "couple of minutes", "start": 2843.359, "duration": 2.641}, {"text": "so in conclusion", "start": 2846.48, "duration": 3.92}, {"text": "um i i hope you know everybody's come", "start": 2848.48, "duration": 3.52}, {"text": "away you know realizing that parallel", "start": 2850.4, "duration": 3.36}, {"text": "computing is for everyone who wants to", "start": 2852.0, "duration": 3.76}, {"text": "accomplish more research and solve more", "start": 2853.76, "duration": 4.24}, {"text": "challenging problems it doesn't matter", "start": 2855.76, "duration": 4.48}, {"text": "what your domain is in fact at least", "start": 2858.0, "duration": 4.0}, {"text": "with it within exceed", "start": 2860.24, "duration": 4.319}, {"text": "um we've made a real strong effort over", "start": 2862.0, "duration": 4.64}, {"text": "the last 10 years", "start": 2864.559, "duration": 4.481}, {"text": "to make parallel computing more", "start": 2866.64, "duration": 4.479}, {"text": "accessible to", "start": 2869.04, "duration": 4.48}, {"text": "take everyone outside of the again the", "start": 2871.119, "duration": 4.0}, {"text": "usual suspects the computational", "start": 2873.52, "duration": 3.76}, {"text": "chemists and astrophysicists", "start": 2875.119, "duration": 4.0}, {"text": "so if you're from the social sciences", "start": 2877.28, "duration": 5.279}, {"text": "the arts and humanities life sciences", "start": 2879.119, "duration": 5.72}, {"text": "absolutely you you can use these", "start": 2882.559, "duration": 4.961}, {"text": "resources um kind of beat this home", "start": 2884.839, "duration": 3.72}, {"text": "through the", "start": 2887.52, "duration": 2.96}, {"text": "through the entire talk but you don't", "start": 2888.559, "duration": 4.401}, {"text": "need to be a programmer to use parallel", "start": 2890.48, "duration": 4.48}, {"text": "computers but you do need to know some", "start": 2892.96, "duration": 4.159}, {"text": "of the fundamentals to effectively use", "start": 2894.96, "duration": 3.879}, {"text": "the parallel", "start": 2897.119, "duration": 3.841}, {"text": "computer a little bit of the technical", "start": 2898.839, "duration": 4.52}, {"text": "content processes are instances of", "start": 2900.96, "duration": 4.399}, {"text": "programs threads are run within a", "start": 2903.359, "duration": 4.72}, {"text": "process and access shared data mpi and", "start": 2905.359, "duration": 5.521}, {"text": "openmp are the most common ways that you", "start": 2908.079, "duration": 5.601}, {"text": "see to paralyze codes", "start": 2910.88, "duration": 3.92}, {"text": "talk a little bit about about", "start": 2913.68, "duration": 3.84}, {"text": "scalability omdahl's law gives you an", "start": 2914.8, "duration": 4.88}, {"text": "absolute upper limit on scalability but", "start": 2917.52, "duration": 4.24}, {"text": "there are other factors that affect", "start": 2919.68, "duration": 4.639}, {"text": "scalability load imbalance communication", "start": 2921.76, "duration": 4.24}, {"text": "overhead and so on", "start": 2924.319, "duration": 3.601}, {"text": "and then finally know how to display", "start": 2926.0, "duration": 3.76}, {"text": "your scaling data this is particularly", "start": 2927.92, "duration": 4.56}, {"text": "important if you are um submitting a", "start": 2929.76, "duration": 5.599}, {"text": "proposal to a taxi or um other", "start": 2932.48, "duration": 4.96}, {"text": "organizations that that allocate", "start": 2935.359, "duration": 4.24}, {"text": "computer time and know how to choose", "start": 2937.44, "duration": 4.0}, {"text": "your forecast okay take into", "start": 2939.599, "duration": 4.321}, {"text": "consideration you know memory footprint", "start": 2941.44, "duration": 5.36}, {"text": "time to solution and so on", "start": 2943.92, "duration": 4.56}, {"text": "and then we have this in the chat", "start": 2946.8, "duration": 5.12}, {"text": "already but if you're interested in the", "start": 2948.48, "duration": 4.4}, {"text": "um", "start": 2951.92, "duration": 4.0}, {"text": "jupiter notebooks that i use to", "start": 2952.88, "duration": 4.32}, {"text": "create some of the figures in the", "start": 2955.92, "duration": 3.679}, {"text": "presentation particularly for the for", "start": 2957.2, "duration": 4.48}, {"text": "the scaling plots or for amdahl's law", "start": 2959.599, "duration": 4.48}, {"text": "they're available in this github repo in", "start": 2961.68, "duration": 5.2}, {"text": "fact you might find this very useful if", "start": 2964.079, "duration": 4.641}, {"text": "you're in the process or planning to", "start": 2966.88, "duration": 4.4}, {"text": "write nxt proposal you could", "start": 2968.72, "duration": 4.48}, {"text": "take my notebooks and just plug your own", "start": 2971.28, "duration": 3.52}, {"text": "numbers in there", "start": 2973.2, "duration": 3.68}, {"text": "and with that i'm all done i'm happy to", "start": 2974.8, "duration": 4.96}, {"text": "take any questions", "start": 2976.88, "duration": 2.88}, {"text": "okay so um", "start": 2983.68, "duration": 5.2}, {"text": "let me scroll back through the question", "start": 2987.2, "duration": 4.24}, {"text": "okay so i see um", "start": 2988.88, "duration": 5.439}, {"text": "a quick question here from from abhishek", "start": 2991.44, "duration": 4.48}, {"text": "could you explain what is the difference", "start": 2994.319, "duration": 3.441}, {"text": "between strong and great and weak", "start": 2995.92, "duration": 4.639}, {"text": "scaling and when is each one relevant", "start": 2997.76, "duration": 5.44}, {"text": "yes so i yeah good great great question", "start": 3000.559, "duration": 4.0}, {"text": "um i'll go", "start": 3003.2, "duration": 2.8}, {"text": "into that a little bit more detail next", "start": 3004.559, "duration": 3.921}, {"text": "time i do this talk so strong scaling is", "start": 3006.0, "duration": 6.24}, {"text": "when you take a problem of a fixed size", "start": 3008.48, "duration": 6.56}, {"text": "and you run it on increasing numbers of", "start": 3012.24, "duration": 5.839}, {"text": "processor cores so let's say i'm doing a", "start": 3015.04, "duration": 5.6}, {"text": "molecular dynamic simulation with with", "start": 3018.079, "duration": 5.921}, {"text": "10 million atoms or a cfd calculation", "start": 3020.64, "duration": 4.479}, {"text": "with", "start": 3024.0, "duration": 3.28}, {"text": "with 100 million grid cells so i'm", "start": 3025.119, "duration": 4.161}, {"text": "taking that same problem i'm running on", "start": 3027.28, "duration": 5.279}, {"text": "on one core 2 core 4 core 8 core and so", "start": 3029.28, "duration": 5.279}, {"text": "on weak scaling", "start": 3032.559, "duration": 5.201}, {"text": "is where i allow the", "start": 3034.559, "duration": 6.321}, {"text": "is where i allow the program to grow as", "start": 3037.76, "duration": 4.16}, {"text": "i", "start": 3040.88, "duration": 2.959}, {"text": "um", "start": 3041.92, "duration": 4.08}, {"text": "as i use as they use more nodes", "start": 3043.839, "duration": 4.881}, {"text": "so let's say i'm running a", "start": 3046.0, "duration": 4.24}, {"text": "million particle molecular dynamic", "start": 3048.72, "duration": 3.68}, {"text": "stimulation on one note and then two", "start": 3050.24, "duration": 4.079}, {"text": "million on two nodes and four million", "start": 3052.4, "duration": 4.959}, {"text": "and on on four nodes and so on and so on", "start": 3054.319, "duration": 5.76}, {"text": "and in that case perfect weak scaling", "start": 3057.359, "duration": 5.441}, {"text": "would be as if if we see the the run", "start": 3060.079, "duration": 6.161}, {"text": "time remain constant as the size of the", "start": 3062.8, "duration": 4.4}, {"text": "problem", "start": 3066.24, "duration": 3.2}, {"text": "and the um", "start": 3067.2, "duration": 4.639}, {"text": "and and the number of processes is", "start": 3069.44, "duration": 4.159}, {"text": "increased", "start": 3071.839, "duration": 3.681}, {"text": "and then finally there's a question here", "start": 3073.599, "duration": 4.161}, {"text": "from jibo loom", "start": 3075.52, "duration": 4.4}, {"text": "um if i could give a short introduction", "start": 3077.76, "duration": 4.319}, {"text": "an application about hyper threading and", "start": 3079.92, "duration": 5.52}, {"text": "how it works for mpi and openmp", "start": 3082.079, "duration": 4.961}, {"text": "yeah so i didn't i didn't mention hyper", "start": 3085.44, "duration": 3.28}, {"text": "threading that is that's a hardware", "start": 3087.04, "duration": 2.64}, {"text": "topic", "start": 3088.72, "duration": 3.839}, {"text": "um but a lot of modern processes allow", "start": 3089.68, "duration": 5.28}, {"text": "you to run what they call two hardware", "start": 3092.559, "duration": 6.481}, {"text": "threads um on on each compute core", "start": 3094.96, "duration": 7.92}, {"text": "now to you as an end as an end user", "start": 3099.04, "duration": 5.76}, {"text": "that's just going to appear", "start": 3102.88, "duration": 4.719}, {"text": "as a as an additional compute card so", "start": 3104.8, "duration": 6.319}, {"text": "for example on expanse we have 128", "start": 3107.599, "duration": 6.24}, {"text": "physical cpus per", "start": 3111.119, "duration": 5.281}, {"text": "per node but if we turned on hyper", "start": 3113.839, "duration": 6.081}, {"text": "threading it would look like 256.", "start": 3116.4, "duration": 5.439}, {"text": "so the i'm hyper threading has", "start": 3119.92, "duration": 5.679}, {"text": "applications for for for some", "start": 3121.839, "duration": 4.801}, {"text": "um", "start": 3125.599, "duration": 3.52}, {"text": "for typically for business applications", "start": 3126.64, "duration": 5.04}, {"text": "but for a lot of", "start": 3129.119, "duration": 4.72}, {"text": "um hpc applications we turned off so", "start": 3131.68, "duration": 3.76}, {"text": "basically it would just look to you like", "start": 3133.839, "duration": 4.081}, {"text": "you had twice as many cars and you would", "start": 3135.44, "duration": 5.919}, {"text": "program in in exactly the same way", "start": 3137.92, "duration": 5.6}, {"text": "and then finally um question here from", "start": 3141.359, "duration": 4.401}, {"text": "vincent is there any resource they", "start": 3143.52, "duration": 4.0}, {"text": "recommend that goes into more details", "start": 3145.76, "duration": 3.44}, {"text": "about parallelization without assuming", "start": 3147.52, "duration": 4.24}, {"text": "prior knowledge you know off the top of", "start": 3149.2, "duration": 6.879}, {"text": "my head i don't know but i am going to", "start": 3151.76, "duration": 5.44}, {"text": "um", "start": 3156.079, "duration": 3.681}, {"text": "i'm going to look into that", "start": 3157.2, "duration": 4.879}, {"text": "and", "start": 3159.76, "duration": 6.68}, {"text": "if you could do me a favor", "start": 3162.079, "duration": 4.361}, {"text": "and and send me an email and i will um", "start": 3167.599, "duration": 5.041}, {"text": "follow up with you later", "start": 3170.88, "duration": 4.16}, {"text": "and then there's a question from tom", "start": 3172.64, "duration": 5.84}, {"text": "lorado how do gpus fit into this is it", "start": 3175.04, "duration": 5.36}, {"text": "basically threading before specialized", "start": 3178.48, "duration": 5.359}, {"text": "compilers yes so um", "start": 3180.4, "duration": 6.159}, {"text": "you you could think of gpus as being", "start": 3183.839, "duration": 5.52}, {"text": "massively multi-threaded multi-threaded", "start": 3186.559, "duration": 4.081}, {"text": "hardware", "start": 3189.359, "duration": 3.841}, {"text": "um i really didn't didn't get into this", "start": 3190.64, "duration": 4.719}, {"text": "um you don't just", "start": 3193.2, "duration": 4.639}, {"text": "yeah there is a there is a special um", "start": 3195.359, "duration": 4.881}, {"text": "compiler that that is used in in order", "start": 3197.839, "duration": 5.76}, {"text": "to generate um code to run on the gpus", "start": 3200.24, "duration": 6.16}, {"text": "um and how do gpus fit into this", "start": 3203.599, "duration": 4.881}, {"text": "so when you're using the gpu generally", "start": 3206.4, "duration": 3.76}, {"text": "you're going to", "start": 3208.48, "duration": 4.24}, {"text": "um have that that entire gpu will be", "start": 3210.16, "duration": 4.48}, {"text": "allocated to you there's no sharing of a", "start": 3212.72, "duration": 4.24}, {"text": "gpu but everything that we talked about", "start": 3214.64, "duration": 4.64}, {"text": "in terms of scalability if you have a", "start": 3216.96, "duration": 5.04}, {"text": "multi-gpu application you would want to", "start": 3219.28, "duration": 4.559}, {"text": "do the same thing you would want to do", "start": 3222.0, "duration": 3.2}, {"text": "the um", "start": 3223.839, "duration": 3.681}, {"text": "a benchmarking and scaling study to see", "start": 3225.2, "duration": 6.08}, {"text": "how many gpus you should be running on", "start": 3227.52, "duration": 3.76}, {"text": "and", "start": 3231.68, "duration": 3.439}, {"text": "um", "start": 3232.8, "duration": 2.319}, {"text": "there's a question here from george", "start": 3235.44, "duration": 3.679}, {"text": "switzer", "start": 3237.68, "duration": 3.36}, {"text": "um are there additional considerations", "start": 3239.119, "duration": 4.161}, {"text": "necessary we're working with commercial", "start": 3241.04, "duration": 3.279}, {"text": "codes", "start": 3243.28, "duration": 2.96}, {"text": "or other purchase software solutions", "start": 3244.319, "duration": 3.52}, {"text": "where the user may not have access to", "start": 3246.24, "duration": 3.2}, {"text": "the source", "start": 3247.839, "duration": 4.0}, {"text": "um", "start": 3249.44, "duration": 2.399}, {"text": "i i think i think the the best answer is", "start": 3252.079, "duration": 3.28}, {"text": "it's really", "start": 3254.48, "duration": 1.76}, {"text": "no", "start": 3255.359, "duration": 3.841}, {"text": "um and in fact for the most part if", "start": 3256.24, "duration": 4.4}, {"text": "you're using", "start": 3259.2, "duration": 3.84}, {"text": "open source codes", "start": 3260.64, "duration": 5.84}, {"text": "such as um amber and namdi and bromax", "start": 3263.04, "duration": 4.799}, {"text": "and um", "start": 3266.48, "duration": 4.079}, {"text": "and games and cp2k and so forth you're", "start": 3267.839, "duration": 4.24}, {"text": "probably not going to build it from", "start": 3270.559, "duration": 3.601}, {"text": "source um that's something where that", "start": 3272.079, "duration": 4.72}, {"text": "that's case where our use of services", "start": 3274.16, "duration": 4.32}, {"text": "will build those applications", "start": 3276.799, "duration": 4.0}, {"text": "making sure to use the best um mpi", "start": 3278.48, "duration": 4.4}, {"text": "libraries and compiler options get", "start": 3280.799, "duration": 3.201}, {"text": "performance", "start": 3282.88, "duration": 2.0}, {"text": "so", "start": 3284.0, "duration": 3.119}, {"text": "i would say as far as an end user there", "start": 3284.88, "duration": 4.64}, {"text": "are really no other considerations", "start": 3287.119, "duration": 5.761}, {"text": "except other than possibly licensing", "start": 3289.52, "duration": 5.599}, {"text": "um", "start": 3292.88, "duration": 2.239}, {"text": "you know the you know you need to make", "start": 3295.839, "duration": 5.361}, {"text": "sure that the license is available for", "start": 3297.52, "duration": 6.319}, {"text": "what we call", "start": 3301.2, "duration": 2.639}, {"text": "if you're going to be running on our", "start": 3304.559, "duration": 2.881}, {"text": "resources you probably want to have a", "start": 3305.839, "duration": 4.161}, {"text": "floating license so they denied not tied", "start": 3307.44, "duration": 5.119}, {"text": "to any particular um compute node but", "start": 3310.0, "duration": 4.559}, {"text": "otherwise everything else that i said", "start": 3312.559, "duration": 5.361}, {"text": "you know as an end user um", "start": 3314.559, "duration": 4.881}, {"text": "i think applies", "start": 3317.92, "duration": 2.879}, {"text": "and i'm going to see if i could answer a", "start": 3319.44, "duration": 3.2}, {"text": "few more questions before we run out of", "start": 3320.799, "duration": 3.921}, {"text": "time", "start": 3322.64, "duration": 3.6}, {"text": "cursor", "start": 3324.72, "duration": 2.639}, {"text": "um", "start": 3326.24, "duration": 2.8}, {"text": "bob did you actually uh answer a", "start": 3327.359, "duration": 3.841}, {"text": "question regarding um let's see is it", "start": 3329.04, "duration": 4.079}, {"text": "possible to do this on extreme machines", "start": 3331.2, "duration": 4.48}, {"text": "where where our char where we are", "start": 3333.119, "duration": 4.72}, {"text": "charged per node", "start": 3335.68, "duration": 4.639}, {"text": "yep yep yep okay okay awesome just take", "start": 3337.839, "duration": 3.841}, {"text": "them yay", "start": 3340.319, "duration": 3.441}, {"text": "um so we're we're actually at the top of", "start": 3341.68, "duration": 3.6}, {"text": "the hour but i'm happy to continue", "start": 3343.76, "duration": 3.44}, {"text": "answering questions for anybody who", "start": 3345.28, "duration": 3.839}, {"text": "wants to", "start": 3347.2, "duration": 3.76}, {"text": "wants to stick around", "start": 3349.119, "duration": 4.24}, {"text": "um", "start": 3350.96, "duration": 2.399}, {"text": "okay", "start": 3354.16, "duration": 3.679}, {"text": "so there's a question from yogesh", "start": 3355.28, "duration": 5.2}, {"text": "how to identify dependencies and process", "start": 3357.839, "duration": 6.081}, {"text": "and threads do we have a tool for for", "start": 3360.48, "duration": 5.92}, {"text": "the same", "start": 3363.92, "duration": 2.48}, {"text": "um", "start": 3367.119, "duration": 2.24}, {"text": "i don't think how to answer that there", "start": 3370.88, "duration": 2.959}, {"text": "are", "start": 3372.48, "duration": 3.52}, {"text": "so so i think my dependencies you're", "start": 3373.839, "duration": 4.081}, {"text": "talking about the", "start": 3376.0, "duration": 3.599}, {"text": "they're talking about processes that", "start": 3377.92, "duration": 3.36}, {"text": "need to communicate data they need to", "start": 3379.599, "duration": 3.841}, {"text": "exchange data or", "start": 3381.28, "duration": 4.0}, {"text": "um or threads that need need to", "start": 3383.44, "duration": 3.04}, {"text": "synchronize", "start": 3385.28, "duration": 2.88}, {"text": "so there are tools out there there are", "start": 3386.48, "duration": 5.76}, {"text": "profiling tools um", "start": 3388.16, "duration": 4.08}, {"text": "oh i think the the most powerful one i", "start": 3393.119, "duration": 5.521}, {"text": "could think of is called tau t-a", "start": 3395.52, "duration": 4.64}, {"text": "t-t-a-u", "start": 3398.64, "duration": 3.919}, {"text": "and that will um you know really dive", "start": 3400.16, "duration": 4.24}, {"text": "into the", "start": 3402.559, "duration": 2.721}, {"text": "um", "start": 3404.4, "duration": 3.04}, {"text": "in into those interactions", "start": 3405.28, "duration": 4.96}, {"text": "um it's much more advanced as an end", "start": 3407.44, "duration": 5.52}, {"text": "user you're probably not concerned with", "start": 3410.24, "duration": 4.559}, {"text": "that but if you are developing your own", "start": 3412.96, "duration": 3.52}, {"text": "code that has something that you would", "start": 3414.799, "duration": 2.881}, {"text": "want to", "start": 3416.48, "duration": 3.119}, {"text": "follow up on and we probably have", "start": 3417.68, "duration": 4.96}, {"text": "training for that with the next seed", "start": 3419.599, "duration": 5.281}, {"text": "and", "start": 3422.64, "duration": 2.24}, {"text": "great and", "start": 3425.359, "duration": 5.361}, {"text": "if there's anybody whose question i miss", "start": 3427.76, "duration": 4.48}, {"text": "please", "start": 3430.72, "duration": 3.68}, {"text": "put please post into the chat i think i", "start": 3432.24, "duration": 4.96}, {"text": "got everybody", "start": 3434.4, "duration": 2.8}, {"text": "okay well if there are no other", "start": 3444.96, "duration": 5.359}, {"text": "questions i am going to oh okay um", "start": 3446.64, "duration": 6.159}, {"text": "quick question for from from ali smith", "start": 3450.319, "duration": 5.28}, {"text": "for expense can you run parallel jobs on", "start": 3452.799, "duration": 5.601}, {"text": "the shared note yes absolutely", "start": 3455.599, "duration": 5.841}, {"text": "so um when you request when you decide", "start": 3458.4, "duration": 5.28}, {"text": "to run a job on a shared node you can", "start": 3461.44, "duration": 5.2}, {"text": "choose anything from one core up up to", "start": 3463.68, "duration": 5.2}, {"text": "all the cores in that node so let's say", "start": 3466.64, "duration": 4.479}, {"text": "you have an application that", "start": 3468.88, "duration": 4.239}, {"text": "very very common say with computational", "start": 3471.119, "duration": 5.281}, {"text": "chemistry where it only scales to eight", "start": 3473.119, "duration": 6.641}, {"text": "or 16 cars yes you can submit a job and", "start": 3476.4, "duration": 5.919}, {"text": "just request those 16 calls", "start": 3479.76, "duration": 4.799}, {"text": "um and also you can within a note you", "start": 3482.319, "duration": 4.8}, {"text": "can run mpi or", "start": 3484.559, "duration": 6.0}, {"text": "um the threaded applications", "start": 3487.119, "duration": 6.641}, {"text": "okay can mpi be used for peer-to-peer", "start": 3490.559, "duration": 4.56}, {"text": "compute", "start": 3493.76, "duration": 4.96}, {"text": "um you know mario i'm sorry that's um", "start": 3495.119, "duration": 5.521}, {"text": "i don't know enough about peer-to-peer", "start": 3498.72, "duration": 5.359}, {"text": "computing to to answer that", "start": 3500.64, "duration": 5.919}, {"text": "but my", "start": 3504.079, "duration": 4.401}, {"text": "yeah yeah so i'll i'll i'll just stop", "start": 3506.559, "duration": 3.681}, {"text": "there and", "start": 3508.48, "duration": 3.68}, {"text": "avoid giving a give you an incorrect", "start": 3510.24, "duration": 4.92}, {"text": "answer", "start": 3512.16, "duration": 3.0}, {"text": "okay and then there's another question", "start": 3517.119, "duration": 4.641}, {"text": "for from vincent um i understand the", "start": 3519.2, "duration": 4.56}, {"text": "theoretical difference between process", "start": 3521.76, "duration": 4.4}, {"text": "and thread but some codes are not easy", "start": 3523.76, "duration": 4.319}, {"text": "to define as either", "start": 3526.16, "duration": 4.0}, {"text": "is there a way to know if a piece of", "start": 3528.079, "duration": 5.121}, {"text": "code is a process or thread", "start": 3530.16, "duration": 5.199}, {"text": "yes so um", "start": 3533.2, "duration": 3.44}, {"text": "where to put it", "start": 3535.359, "duration": 3.841}, {"text": "so so", "start": 3536.64, "duration": 2.56}, {"text": "a a chunk of code isn't exactly a", "start": 3540.24, "duration": 4.16}, {"text": "process or a thread", "start": 3542.88, "duration": 4.959}, {"text": "um it's the execution of that code", "start": 3544.4, "duration": 5.76}, {"text": "so if the code say had been paralyzed", "start": 3547.839, "duration": 4.0}, {"text": "using mpi there will be multiple", "start": 3550.16, "duration": 4.48}, {"text": "processes and while that's running if", "start": 3551.839, "duration": 5.601}, {"text": "you log into that node and execute top", "start": 3554.64, "duration": 6.159}, {"text": "or h top you will see each of those um", "start": 3557.44, "duration": 5.6}, {"text": "each of those individual processes which", "start": 3560.799, "duration": 5.121}, {"text": "have a process id associated with it", "start": 3563.04, "duration": 4.29}, {"text": "um if you", "start": 3565.92, "duration": 2.639}, {"text": "[Music]", "start": 3567.33, "duration": 3.229}, {"text": "if you want to see the threads at least", "start": 3568.559, "duration": 4.721}, {"text": "within top and h-top", "start": 3570.559, "duration": 4.721}, {"text": "there's uh there's a way to turn on", "start": 3573.28, "duration": 4.4}, {"text": "thread viewing um you just type capital", "start": 3575.28, "duration": 4.0}, {"text": "h at the", "start": 3577.68, "duration": 4.08}, {"text": "um at command line and it will show you", "start": 3579.28, "duration": 4.48}, {"text": "the threads that are off that are", "start": 3581.76, "duration": 3.68}, {"text": "executing within", "start": 3583.76, "duration": 4.079}, {"text": "within that process", "start": 3585.44, "duration": 3.6}, {"text": "um", "start": 3587.839, "duration": 3.201}, {"text": "now if you have access to the source", "start": 3589.04, "duration": 3.279}, {"text": "code", "start": 3591.04, "duration": 3.279}, {"text": "of course you can just go in there and", "start": 3592.319, "duration": 4.561}, {"text": "you can look for", "start": 3594.319, "duration": 4.961}, {"text": "you can look for um call calls the mpi", "start": 3596.88, "duration": 6.56}, {"text": "library or openmp directives", "start": 3599.28, "duration": 4.16}, {"text": "yes and that that's nicole um let less", "start": 3603.839, "duration": 5.681}, {"text": "than one full node for", "start": 3606.24, "duration": 3.28}, {"text": "yeah i should i should have pointed out", "start": 3610.4, "duration": 3.6}, {"text": "earlier but when you're running in the", "start": 3612.24, "duration": 3.28}, {"text": "shared node", "start": 3614.0, "duration": 3.839}, {"text": "i think that was answering al ali's", "start": 3615.52, "duration": 3.52}, {"text": "question", "start": 3617.839, "duration": 3.841}, {"text": "so there are 128 cores per node you can", "start": 3619.04, "duration": 6.799}, {"text": "request anywhere from 1 to 127", "start": 3621.68, "duration": 6.96}, {"text": "um and if you use all 128 then you would", "start": 3625.839, "duration": 6.561}, {"text": "just be in the in the regular team", "start": 3628.64, "duration": 6.24}, {"text": "all right and a question from ed hall ed", "start": 3632.4, "duration": 5.439}, {"text": "that is a fantastic question", "start": 3634.88, "duration": 5.76}, {"text": "um if you use a subset of cores on a", "start": 3637.839, "duration": 5.841}, {"text": "note of expense but all of the memory", "start": 3640.64, "duration": 5.439}, {"text": "are you charged for all of the cores", "start": 3643.68, "duration": 3.76}, {"text": "yes you are", "start": 3646.079, "duration": 3.681}, {"text": "um", "start": 3647.44, "duration": 2.32}, {"text": "we we may we may have a presentation on", "start": 3649.92, "duration": 5.6}, {"text": "on this somewhere slurm", "start": 3652.64, "duration": 4.64}, {"text": "has a um", "start": 3655.52, "duration": 4.4}, {"text": "a fairly involved way of doing the of", "start": 3657.28, "duration": 4.24}, {"text": "doing the charging", "start": 3659.92, "duration": 3.36}, {"text": "so yes we we", "start": 3661.52, "duration": 4.24}, {"text": "you you can get memory in proportion to", "start": 3663.28, "duration": 6.16}, {"text": "the course but let's say that you need", "start": 3665.76, "duration": 6.079}, {"text": "you you have a serial code it just uses", "start": 3669.44, "duration": 5.679}, {"text": "one core but it needs all of that all of", "start": 3671.839, "duration": 5.121}, {"text": "that memory you are going to be charged", "start": 3675.119, "duration": 3.68}, {"text": "for the entire note", "start": 3676.96, "duration": 2.879}, {"text": "um", "start": 3678.799, "duration": 3.681}, {"text": "that said though if you request one core", "start": 3679.839, "duration": 5.52}, {"text": "and all the memory those other cores are", "start": 3682.48, "duration": 4.48}, {"text": "going to be available for somebody else", "start": 3685.359, "duration": 3.521}, {"text": "to use assuming that there was enough", "start": 3686.96, "duration": 4.56}, {"text": "memory enough memory left over", "start": 3688.88, "duration": 5.36}, {"text": "so ed if you have um any", "start": 3691.52, "duration": 3.839}, {"text": "you know", "start": 3694.24, "duration": 2.72}, {"text": "any questions i know i know you're a", "start": 3695.359, "duration": 3.921}, {"text": "campus champion i think at virginia i", "start": 3696.96, "duration": 4.96}, {"text": "could put you in touch with our", "start": 3699.28, "duration": 4.0}, {"text": "um", "start": 3701.92, "duration": 3.76}, {"text": "with one of our very talented system who", "start": 3703.28, "duration": 6.6}, {"text": "can go into a lot more detail", "start": 3705.68, "duration": 4.2}, {"text": "great and then thank you everybody for", "start": 3712.319, "duration": 4.8}, {"text": "the vote for the kind comments", "start": 3714.319, "duration": 5.201}, {"text": "and yes and nicole thanks thanks for", "start": 3717.119, "duration": 3.92}, {"text": "putting that in there so you know in", "start": 3719.52, "duration": 2.96}, {"text": "this talk we didn't have a chance to get", "start": 3721.039, "duration": 3.921}, {"text": "into the specifics of any machine", "start": 3722.48, "duration": 6.72}, {"text": "but yeah if you go to our um", "start": 3724.96, "duration": 6.8}, {"text": "if you go to our user guide you'll see", "start": 3729.2, "duration": 4.639}, {"text": "um all of the detail on the different", "start": 3731.76, "duration": 6.319}, {"text": "cues or partitions that are available", "start": 3733.839, "duration": 4.24}, {"text": "right if that is it if um", "start": 3738.96, "duration": 4.399}, {"text": "if there are no more questions we will", "start": 3741.839, "duration": 3.921}, {"text": "go ahead and wrap things up thank you so", "start": 3743.359, "duration": 4.081}, {"text": "much everybody and", "start": 3745.76, "duration": 3.12}, {"text": "look forward to seeing you at future", "start": 3747.44, "duration": 4.48}, {"text": "training events", "start": 3748.88, "duration": 3.04}]