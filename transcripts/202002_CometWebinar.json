[{"text": "okay I'm going to go ahead and get", "start": 0.78, "duration": 4.22}, {"text": "started", "start": 2.52, "duration": 2.48}, {"text": "hello everyone thanks for joining my", "start": 5.819, "duration": 4.881}, {"text": "name is Jeff sale", "start": 7.74, "duration": 2.96}, {"text": "can everyone hear me okay", "start": 10.86, "duration": 3.14}, {"text": "yep sounds good Jeff", "start": 14.519, "duration": 5.461}, {"text": "great thanks um just a little bit of", "start": 17.22, "duration": 6.12}, {"text": "house cleaning before we get started", "start": 19.98, "duration": 5.48}, {"text": "um", "start": 23.34, "duration": 2.12}, {"text": "this is an exceed event so I didn't", "start": 26.939, "duration": 4.441}, {"text": "update the event itself", "start": 28.8, "duration": 3.959}, {"text": "um but we want to make sure everyone's", "start": 31.38, "duration": 3.179}, {"text": "aware of the exceed code of conduct when", "start": 32.759, "duration": 6.14}, {"text": "attending these webinars uh", "start": 34.559, "duration": 4.34}, {"text": "and if I can ask folks whoops", "start": 39.36, "duration": 5.06}, {"text": "and if I can ask folks to self-register", "start": 45.54, "duration": 6.6}, {"text": "I mean myself mark their attendance by", "start": 48.3, "duration": 5.7}, {"text": "logging into the exceed user portal and", "start": 52.14, "duration": 3.36}, {"text": "browsing to the course calendar and then", "start": 54.0, "duration": 3.36}, {"text": "scrolling down where you'll see a", "start": 55.5, "duration": 3.3}, {"text": "listing of your previous training", "start": 57.36, "duration": 3.839}, {"text": "classes that makes my job a little bit", "start": 58.8, "duration": 4.559}, {"text": "easier in tracking attendance so we can", "start": 61.199, "duration": 4.92}, {"text": "report to exceed", "start": 63.359, "duration": 4.201}, {"text": "but okay", "start": 66.119, "duration": 2.101}, {"text": "um", "start": 67.56, "duration": 2.76}, {"text": "I want to start off by introducing Abe", "start": 68.22, "duration": 5.04}, {"text": "Abe Stern is an Nvidia Solutions", "start": 70.32, "duration": 5.94}, {"text": "architect he got his PhD in", "start": 73.26, "duration": 4.26}, {"text": "computational chemistry from the", "start": 76.26, "duration": 2.82}, {"text": "University of South Florida and did a", "start": 77.52, "duration": 5.22}, {"text": "postdoc at UC Irvine he's focused on", "start": 79.08, "duration": 5.28}, {"text": "Higher Education and Research and his", "start": 82.74, "duration": 3.239}, {"text": "interests lie at the intersection of", "start": 84.36, "duration": 3.6}, {"text": "scientific Computing and machine", "start": 85.979, "duration": 3.541}, {"text": "learning especially as applied to", "start": 87.96, "duration": 4.019}, {"text": "problems in the chemistry and Material", "start": 89.52, "duration": 6.12}, {"text": "Science domain so with that I will go", "start": 91.979, "duration": 6.541}, {"text": "ahead and mute myself and stop sharing", "start": 95.64, "duration": 6.14}, {"text": "and take it away", "start": 98.52, "duration": 3.26}, {"text": "thanks very much Jeff", "start": 102.72, "duration": 5.16}, {"text": "share my screen here", "start": 105.659, "duration": 4.081}, {"text": "hopefully you can see the slide can you", "start": 107.88, "duration": 5.18}, {"text": "confirm if you can see the slide", "start": 109.74, "duration": 3.32}, {"text": "yes yep", "start": 114.119, "duration": 4.5}, {"text": "great thank you", "start": 116.22, "duration": 6.06}, {"text": "all right thanks so much", "start": 118.619, "duration": 6.78}, {"text": "okay great so um thanks Jeff uh my name", "start": 122.28, "duration": 6.479}, {"text": "is Abe Stern I'm um I'm actually a data", "start": 125.399, "duration": 5.881}, {"text": "scientist at Nvidia On The Higher", "start": 128.759, "duration": 3.961}, {"text": "Education and Research solution", "start": 131.28, "duration": 3.959}, {"text": "architecture team so it's a team of", "start": 132.72, "duration": 4.44}, {"text": "solution architect but formerly I'm a", "start": 135.239, "duration": 3.601}, {"text": "data scientist", "start": 137.16, "duration": 3.06}, {"text": "um as just said my background's in", "start": 138.84, "duration": 3.84}, {"text": "computational chemistry", "start": 140.22, "duration": 6.239}, {"text": "um and at Nvidia I tend to focus uh I", "start": 142.68, "duration": 5.279}, {"text": "tend to work at the intersection of", "start": 146.459, "duration": 5.401}, {"text": "scientific Computing and AI", "start": 147.959, "duration": 7.561}, {"text": "um particularly uh on problems where", "start": 151.86, "duration": 5.22}, {"text": "machine learning or artificial", "start": 155.52, "duration": 3.84}, {"text": "intelligence is applied in the chemistry", "start": 157.08, "duration": 3.78}, {"text": "domain", "start": 159.36, "duration": 4.8}, {"text": "um so today I will be talking about uh", "start": 160.86, "duration": 6.78}, {"text": "Rapids and Cuda python", "start": 164.16, "duration": 9.78}, {"text": "so in Rapids we have a suite of machine", "start": 167.64, "duration": 8.959}, {"text": "learning libraries and tools", "start": 173.94, "duration": 6.12}, {"text": "particularly for manipulating data", "start": 176.599, "duration": 4.36}, {"text": "frames", "start": 180.06, "duration": 4.22}, {"text": "okay so if you've used pandas before", "start": 180.959, "duration": 6.481}, {"text": "Rapids is on one hand a drop-in", "start": 184.28, "duration": 6.52}, {"text": "replacement a GPU accelerated drop-in", "start": 187.44, "duration": 6.719}, {"text": "replacement for pandas for GPU", "start": 190.8, "duration": 5.519}, {"text": "accelerated data frame operations", "start": 194.159, "duration": 3.901}, {"text": "manipulations", "start": 196.319, "duration": 4.021}, {"text": "and we'll also be talking about Cuda", "start": 198.06, "duration": 4.8}, {"text": "python so particularly the library", "start": 200.34, "duration": 6.2}, {"text": "number which exposes the Cuda", "start": 202.86, "duration": 7.62}, {"text": "programming API so you can get", "start": 206.54, "duration": 6.839}, {"text": "um GPU acceleration you expose the Cuda", "start": 210.48, "duration": 6.36}, {"text": "API so you can be programming for the", "start": 213.379, "duration": 7.181}, {"text": "GPU in Cuda right from python so you can", "start": 216.84, "duration": 7.58}, {"text": "do this from a Jupiter notebook", "start": 220.56, "duration": 8.94}, {"text": "so a pretty exciting stuff I think uh", "start": 224.42, "duration": 7.36}, {"text": "um but these are uh these are both", "start": 229.5, "duration": 4.26}, {"text": "python libraries and this is a", "start": 231.78, "duration": 4.44}, {"text": "scientific Computing Forum so let's set", "start": 233.76, "duration": 5.399}, {"text": "the stage a little bit and motivate why", "start": 236.22, "duration": 4.799}, {"text": "we'd be talking about python for", "start": 239.159, "duration": 3.66}, {"text": "scientific computing", "start": 241.019, "duration": 4.021}, {"text": "so one of the exciting trends that we're", "start": 242.819, "duration": 4.441}, {"text": "seeing in high performance Computing is", "start": 245.04, "duration": 5.16}, {"text": "that the domains of those leveraging", "start": 247.26, "duration": 6.059}, {"text": "high performance Computing resources is", "start": 250.2, "duration": 4.5}, {"text": "broadening", "start": 253.319, "duration": 4.021}, {"text": "so traditionally you think of high", "start": 254.7, "duration": 4.379}, {"text": "performance those users of high", "start": 257.34, "duration": 3.54}, {"text": "performance Computing machines these are", "start": 259.079, "duration": 3.481}, {"text": "coming from domains like computational", "start": 260.88, "duration": 4.22}, {"text": "chemistry computational physics", "start": 262.56, "duration": 5.82}, {"text": "engineering doing fluid dynamics", "start": 265.1, "duration": 4.78}, {"text": "um you know maybe weather climate", "start": 268.38, "duration": 4.14}, {"text": "simulation but increasingly we're seeing", "start": 269.88, "duration": 5.819}, {"text": "other domains also start to use high", "start": 272.52, "duration": 5.76}, {"text": "performance Computing and in particular", "start": 275.699, "duration": 4.161}, {"text": "I'm talking about", "start": 278.28, "duration": 5.46}, {"text": "machine learning deep learning and", "start": 279.86, "duration": 5.68}, {"text": "increasingly you know scientific", "start": 283.74, "duration": 3.78}, {"text": "visualization leveraging high", "start": 285.54, "duration": 5.599}, {"text": "performance Computing resources", "start": 287.52, "duration": 3.619}, {"text": "um so this has put Nvidia sort of front", "start": 291.54, "duration": 5.46}, {"text": "and center we uh these are these are two", "start": 294.419, "duration": 5.521}, {"text": "of our kind of core", "start": 297.0, "duration": 5.16}, {"text": "um uh domains that we accelerate that is", "start": 299.94, "duration": 4.62}, {"text": "uh machine learning deep learning and", "start": 302.16, "duration": 4.44}, {"text": "scientific Computing and you can see", "start": 304.56, "duration": 5.639}, {"text": "that's reflected in the fraction of", "start": 306.6, "duration": 6.84}, {"text": "machines on the top 500 that are GPU", "start": 310.199, "duration": 8.341}, {"text": "accelerated so that fc9 as of sc19 we", "start": 313.44, "duration": 7.4}, {"text": "accelerate 41", "start": 318.54, "duration": 6.06}, {"text": "of the machines on the top 500 list that", "start": 320.84, "duration": 6.82}, {"text": "is the five the list of 500 uh fastest", "start": 324.6, "duration": 4.92}, {"text": "machines in the world", "start": 327.66, "duration": 3.18}, {"text": "um or at least those are the submitted", "start": 329.52, "duration": 5.519}, {"text": "benchmarks and uh including the world's", "start": 330.84, "duration": 7.199}, {"text": "fastest uh Summit and second fastest", "start": 335.039, "duration": 6.0}, {"text": "Sierra sitting at Oak Ridge and Lawrence", "start": 338.039, "duration": 4.861}, {"text": "Livermore", "start": 341.039, "duration": 2.94}, {"text": "um", "start": 342.9, "duration": 5.04}, {"text": "so what's exciting is that these aren't", "start": 343.979, "duration": 7.981}, {"text": "um kind of disparate domains meaning", "start": 347.94, "duration": 6.599}, {"text": "um it's not just uh people doing machine", "start": 351.96, "duration": 4.86}, {"text": "learning and you know with blinders on", "start": 354.539, "duration": 3.901}, {"text": "and they're doing basic machine learning", "start": 356.82, "duration": 3.78}, {"text": "research using HPC resources what's", "start": 358.44, "duration": 4.14}, {"text": "really exciting is sort of the", "start": 360.6, "duration": 4.5}, {"text": "Confluence of both of these domains", "start": 362.58, "duration": 7.339}, {"text": "coming together right where uh AI is now", "start": 365.1, "duration": 7.8}, {"text": "complementing traditional algorithms and", "start": 369.919, "duration": 5.5}, {"text": "scientific Computing so I'll give you an", "start": 372.9, "duration": 3.84}, {"text": "example", "start": 375.419, "duration": 4.62}, {"text": "so in the business of uh lead Discovery", "start": 376.74, "duration": 7.5}, {"text": "okay drug Discovery the task is to", "start": 380.039, "duration": 8.22}, {"text": "identify new compounds new molecular", "start": 384.24, "duration": 7.2}, {"text": "structures with certain properties", "start": 388.259, "duration": 5.94}, {"text": "either material Properties or maybe uh", "start": 391.44, "duration": 5.759}, {"text": "binding activity to a certain protein or", "start": 394.199, "duration": 4.861}, {"text": "something like this", "start": 397.199, "duration": 4.261}, {"text": "of course if we are approaching this the", "start": 399.06, "duration": 5.84}, {"text": "traditional way we know how to go from", "start": 401.46, "duration": 6.299}, {"text": "structure that is given the chemical", "start": 404.9, "duration": 6.04}, {"text": "structure we know how to compute many of", "start": 407.759, "duration": 5.641}, {"text": "these properties we can solve nearly", "start": 410.94, "duration": 4.8}, {"text": "exactly the Schrodinger equation solve", "start": 413.4, "duration": 4.44}, {"text": "for the electronic structure and compute", "start": 415.74, "duration": 5.88}, {"text": "those properties the problem is twofold", "start": 417.84, "duration": 6.72}, {"text": "really the calculations that I'm", "start": 421.62, "duration": 6.359}, {"text": "referring to are exceedingly expensive", "start": 424.56, "duration": 6.18}, {"text": "and", "start": 427.979, "duration": 5.94}, {"text": "um the chemical space that is the number", "start": 430.74, "duration": 5.94}, {"text": "of possible compounds out there that we", "start": 433.919, "duration": 4.861}, {"text": "would have to screen the number of", "start": 436.68, "duration": 4.26}, {"text": "possible structures that we would have", "start": 438.78, "duration": 5.3}, {"text": "to compute properties for", "start": 440.94, "duration": 5.72}, {"text": "the size of chemical space is", "start": 444.08, "duration": 6.58}, {"text": "overwhelmingly vast so uh this makes", "start": 446.66, "duration": 6.7}, {"text": "intractable sort of just Brute Force", "start": 450.66, "duration": 5.7}, {"text": "approach where we would just screen all", "start": 453.36, "duration": 4.679}, {"text": "the possible structures and find the", "start": 456.36, "duration": 3.42}, {"text": "ones that we want", "start": 458.039, "duration": 6.0}, {"text": "so what researchers have done is use AI", "start": 459.78, "duration": 8.28}, {"text": "use a variational autoencoder to invert", "start": 464.039, "duration": 7.081}, {"text": "the problem so they've developed a", "start": 468.06, "duration": 7.32}, {"text": "technique where you can specify a", "start": 471.12, "duration": 6.18}, {"text": "property and using a variational auto", "start": 475.38, "duration": 5.46}, {"text": "encoder a trained model the model from", "start": 477.3, "duration": 6.6}, {"text": "the property will generate possible", "start": 480.84, "duration": 5.4}, {"text": "structures that might match those Target", "start": 483.9, "duration": 5.9}, {"text": "properties that you're interested in", "start": 486.24, "duration": 3.56}, {"text": "another example from molecular Dynamics", "start": 489.86, "duration": 4.959}, {"text": "so here those of you familiar that's", "start": 493.139, "duration": 3.84}, {"text": "being reviewed but the task of molecular", "start": 494.819, "duration": 7.021}, {"text": "Dynamics is to basically com look at the", "start": 496.979, "duration": 7.021}, {"text": "structure and dynamics of a chemical", "start": 501.84, "duration": 4.919}, {"text": "system at the atomic level and to do", "start": 504.0, "duration": 8.279}, {"text": "this we rely on a calculation of the the", "start": 506.759, "duration": 7.321}, {"text": "interaction energies between all the", "start": 512.279, "duration": 3.841}, {"text": "atoms in the system and there are", "start": 514.08, "duration": 4.92}, {"text": "various levels of theory uh accuracy", "start": 516.12, "duration": 5.159}, {"text": "that you could use to compute those", "start": 519.0, "duration": 5.66}, {"text": "interaction energies all the way from a", "start": 521.279, "duration": 6.24}, {"text": "coarse simple to compute empirical", "start": 524.66, "duration": 5.02}, {"text": "description of the energies all the way", "start": 527.519, "duration": 5.94}, {"text": "up to a full treatment of the electronic", "start": 529.68, "duration": 6.42}, {"text": "structures and electron correlation in a", "start": 533.459, "duration": 5.101}, {"text": "super Accurate Way of computing the", "start": 536.1, "duration": 4.739}, {"text": "interaction energies and then eventually", "start": 538.56, "duration": 3.6}, {"text": "you're going to use the interaction", "start": 540.839, "duration": 3.44}, {"text": "energies to", "start": 542.16, "duration": 4.5}, {"text": "integrate Newton's equations of motion", "start": 544.279, "duration": 5.441}, {"text": "and get a picture of the Motions of all", "start": 546.66, "duration": 6.06}, {"text": "these atoms and these and from this uh", "start": 549.72, "duration": 5.179}, {"text": "the Dynamics of the chemical system", "start": 552.72, "duration": 4.679}, {"text": "you're learning something about the", "start": 554.899, "duration": 4.861}, {"text": "system that you're you're studying so it", "start": 557.399, "duration": 6.361}, {"text": "researchers have done is parametrize", "start": 559.76, "duration": 7.54}, {"text": "train a model an AI model", "start": 563.76, "duration": 6.36}, {"text": "to reproduce", "start": 567.3, "duration": 6.36}, {"text": "high level of theory electronic", "start": 570.12, "duration": 5.399}, {"text": "structure calculations", "start": 573.66, "duration": 6.359}, {"text": "at a fraction of the cost that is using", "start": 575.519, "duration": 9.201}, {"text": "a set of DFT level configurations", "start": 580.019, "duration": 7.141}, {"text": "they've trained a machine learning model", "start": 584.72, "duration": 5.38}, {"text": "to predict approximate the interaction", "start": 587.16, "duration": 6.0}, {"text": "energy for those pairs of atoms okay so", "start": 590.1, "duration": 6.12}, {"text": "they've trained a DST level interaction", "start": 593.16, "duration": 5.94}, {"text": "energy in this machine learning model", "start": 596.22, "duration": 7.22}, {"text": "what that buys you is the fact that", "start": 599.1, "duration": 7.2}, {"text": "inferring from a machine learned model", "start": 603.44, "duration": 5.76}, {"text": "you can do at", "start": 606.3, "duration": 4.74}, {"text": "literally", "start": 609.2, "duration": 3.579}, {"text": "300", "start": 611.04, "duration": 4.1}, {"text": "000 times faster", "start": 612.779, "duration": 5.221}, {"text": "roughly a millionth of the computational", "start": 615.14, "duration": 5.58}, {"text": "expense", "start": 618.0, "duration": 6.18}, {"text": "than as compared to a full treatment of", "start": 620.72, "duration": 5.619}, {"text": "the electronic structure problem so you", "start": 624.18, "duration": 3.96}, {"text": "can imagine if you can compute those", "start": 626.339, "duration": 4.68}, {"text": "interaction energies three hundred", "start": 628.14, "duration": 5.28}, {"text": "thousand times faster", "start": 631.019, "duration": 5.341}, {"text": "then this unlocks the possibility of", "start": 633.42, "duration": 6.68}, {"text": "doing a longer scale simulations", "start": 636.36, "duration": 7.14}, {"text": "larger system sizes that is more atoms", "start": 640.1, "duration": 6.28}, {"text": "and dramatically increases the kind of", "start": 643.5, "duration": 4.56}, {"text": "science that you can start doing with", "start": 646.38, "duration": 3.84}, {"text": "these types of simulations", "start": 648.06, "duration": 3.779}, {"text": "and I should say", "start": 650.22, "duration": 4.619}, {"text": "um this work is uh Adrian reutberg", "start": 651.839, "duration": 7.041}, {"text": "Justin Smith and Alexander isaf", "start": 654.839, "duration": 4.041}, {"text": "so these are core uh to uh scientific", "start": 660.779, "duration": 5.461}, {"text": "Computing machine learning", "start": 663.899, "duration": 5.221}, {"text": "um uh deep learning and um we're", "start": 666.24, "duration": 5.159}, {"text": "committed to accelerating science and so", "start": 669.12, "duration": 5.459}, {"text": "you can see here from a basket of", "start": 671.399, "duration": 5.281}, {"text": "applications that I'm sure you recognize", "start": 674.579, "duration": 6.541}, {"text": "Amber chroma lamps milk namdi Quantum", "start": 676.68, "duration": 7.68}, {"text": "espresso you can see how our approach to", "start": 681.12, "duration": 6.12}, {"text": "GPU accelerated Computing has picked up", "start": 684.36, "duration": 6.18}, {"text": "where Moore's law has left off and we do", "start": 687.24, "duration": 6.839}, {"text": "this not only by delivering great", "start": 690.54, "duration": 6.299}, {"text": "Hardware but there's a rich software", "start": 694.079, "duration": 6.541}, {"text": "stack underneath that and before we get", "start": 696.839, "duration": 8.041}, {"text": "into the uh our main content with Rapids", "start": 700.62, "duration": 7.62}, {"text": "and Cuda python I want to make sure", "start": 704.88, "duration": 5.88}, {"text": "you're aware of some of the key", "start": 708.24, "duration": 6.56}, {"text": "components of our software stack", "start": 710.76, "duration": 4.04}, {"text": "of course the bottom row of the stack", "start": 715.56, "duration": 5.64}, {"text": "I'm showing the hardware because", "start": 718.98, "duration": 5.76}, {"text": "underneath everything is our Hardware", "start": 721.2, "duration": 6.18}, {"text": "um but the software stack really begins", "start": 724.74, "duration": 6.06}, {"text": "with Cuda Cuda is the primary", "start": 727.38, "duration": 6.54}, {"text": "programming API for gpus", "start": 730.8, "duration": 6.24}, {"text": "and accessible through C C plus plus and", "start": 733.92, "duration": 4.32}, {"text": "Fortran", "start": 737.04, "duration": 3.359}, {"text": "and on top of that", "start": 738.24, "duration": 6.539}, {"text": "we build a whole Suite of libraries that", "start": 740.399, "duration": 7.62}, {"text": "you can further build applications on so", "start": 744.779, "duration": 5.941}, {"text": "the lot the GPU accelerated libraries", "start": 748.019, "duration": 4.681}, {"text": "are", "start": 750.72, "duration": 5.16}, {"text": "um grouped here for illustration into", "start": 752.7, "duration": 5.52}, {"text": "machine learning and this is where the", "start": 755.88, "duration": 5.28}, {"text": "Rapids qdf data frame GPU accelerated", "start": 758.22, "duration": 6.78}, {"text": "data frames uh coup ml for GPU", "start": 761.16, "duration": 5.76}, {"text": "accelerated machine learning libraries", "start": 765.0, "duration": 4.62}, {"text": "graph Analytics", "start": 766.92, "duration": 4.859}, {"text": "and then we have our deep learning", "start": 769.62, "duration": 4.86}, {"text": "libraries also if you want to roll your", "start": 771.779, "duration": 6.901}, {"text": "own so to speak could call these um uh", "start": 774.48, "duration": 7.02}, {"text": "libraries directly from C C plus plus", "start": 778.68, "duration": 5.339}, {"text": "these are cool DNN all the major", "start": 781.5, "duration": 5.7}, {"text": "Frameworks of course are are leveraging", "start": 784.019, "duration": 5.94}, {"text": "code DNN under the hood so if you're", "start": 787.2, "duration": 5.16}, {"text": "using a framework like tensorflow or Pi", "start": 789.959, "duration": 4.741}, {"text": "torch under the hood there are of course", "start": 792.36, "duration": 6.24}, {"text": "calling code DNN Cutlass tensor RT for", "start": 794.7, "duration": 6.5}, {"text": "inference", "start": 798.6, "duration": 2.6}, {"text": "um I'm in the Box labeled HPC we have uh", "start": 801.42, "duration": 8.159}, {"text": "um an interesting programming API called", "start": 806.7, "duration": 5.879}, {"text": "open ACC which I'll touch on in briefly", "start": 809.579, "duration": 5.341}, {"text": "in one moment but also a suite of", "start": 812.579, "duration": 4.981}, {"text": "scientific Computing libraries", "start": 814.92, "duration": 6.0}, {"text": "so let's double click on the some of the", "start": 817.56, "duration": 6.66}, {"text": "uh what I consider core scientific", "start": 820.92, "duration": 5.88}, {"text": "Computing libraries so these libraries", "start": 824.22, "duration": 7.44}, {"text": "really leverage domains uh um things", "start": 826.8, "duration": 7.08}, {"text": "that are widely used in scientific", "start": 831.66, "duration": 5.52}, {"text": "Computing so uh of several linear linear", "start": 833.88, "duration": 7.019}, {"text": "algebra routines for example coup laws", "start": 837.18, "duration": 7.399}, {"text": "provides complete support for all 152", "start": 840.899, "duration": 8.221}, {"text": "standard blogs routines Coos sparse is a", "start": 844.579, "duration": 6.7}, {"text": "library that contains basic linear", "start": 849.12, "duration": 4.32}, {"text": "algebra subroutines for handling sparse", "start": 851.279, "duration": 6.601}, {"text": "matrices to sft GPU accelerated Fourier", "start": 853.44, "duration": 7.339}, {"text": "transforms", "start": 857.88, "duration": 2.899}, {"text": "um what else coup solver contains law", "start": 860.82, "duration": 5.88}, {"text": "pack-like features for Matrix", "start": 865.139, "duration": 3.901}, {"text": "factorization triangular solve routines", "start": 866.7, "duration": 5.4}, {"text": "for dense matrices a sparsely Square", "start": 869.04, "duration": 5.94}, {"text": "solver eigensolvers Matrix", "start": 872.1, "duration": 5.52}, {"text": "factorizations such as lud composition", "start": 874.98, "duration": 5.039}, {"text": "QR decomposition singular value", "start": 877.62, "duration": 5.94}, {"text": "decomposition colesky decomposition and", "start": 880.019, "duration": 7.88}, {"text": "more so check out uh", "start": 883.56, "duration": 9.899}, {"text": "docs.nvidia.com look for uh the uh at", "start": 887.899, "duration": 8.861}, {"text": "the broad number of GPA accelerated", "start": 893.459, "duration": 5.701}, {"text": "libraries we offer", "start": 896.76, "duration": 5.22}, {"text": "um and and use them we built them for", "start": 899.16, "duration": 3.919}, {"text": "this community", "start": 901.98, "duration": 5.82}, {"text": "so so check it out", "start": 903.079, "duration": 8.861}, {"text": "so as I mentioned it spans domains and", "start": 907.8, "duration": 6.539}, {"text": "um a lot of the GPU accelerated", "start": 911.94, "duration": 5.1}, {"text": "applications that you're using probably", "start": 914.339, "duration": 5.161}, {"text": "already are leveraging a lot of these", "start": 917.04, "duration": 5.159}, {"text": "libraries under the hood so", "start": 919.5, "duration": 7.68}, {"text": "um if you're uh maybe not necessarily uh", "start": 922.199, "duration": 6.781}, {"text": "programming", "start": 927.18, "duration": 4.74}, {"text": "um you may want to just check out the", "start": 928.98, "duration": 6.24}, {"text": "app applications that are already GPU", "start": 931.92, "duration": 5.58}, {"text": "accelerated so check out the GPU", "start": 935.22, "duration": 5.52}, {"text": "accelerated applications catalog where", "start": 937.5, "duration": 5.639}, {"text": "already there are 600 accelera", "start": 940.74, "duration": 5.7}, {"text": "accelerated applications that have some", "start": 943.139, "duration": 5.101}, {"text": "degree or another of GPU acceleration", "start": 946.44, "duration": 4.259}, {"text": "under the hood", "start": 948.24, "duration": 5.159}, {"text": "so open ACC this is a different", "start": 950.699, "duration": 4.981}, {"text": "programming model", "start": 953.399, "duration": 5.281}, {"text": "um it's a directives based programming", "start": 955.68, "duration": 4.68}, {"text": "model those of you who have programmed", "start": 958.68, "duration": 4.08}, {"text": "an openmp are probably familiar with", "start": 960.36, "duration": 7.38}, {"text": "this Paradigm and at its core it's a a", "start": 962.76, "duration": 7.1}, {"text": "directives based", "start": 967.74, "duration": 5.279}, {"text": "programming Paradigm so we use compiler", "start": 969.86, "duration": 5.86}, {"text": "directives and these are essentially", "start": 973.019, "duration": 6.241}, {"text": "hints to the compiler to suggest ways in", "start": 975.72, "duration": 5.88}, {"text": "which we could parallelize the routine", "start": 979.26, "duration": 5.639}, {"text": "so the nice thing is is that it's very", "start": 981.6, "duration": 6.299}, {"text": "simple to program and", "start": 984.899, "duration": 4.081}, {"text": "um", "start": 987.899, "duration": 3.601}, {"text": "you get a single code base if the", "start": 988.98, "duration": 4.08}, {"text": "compiler that you're using doesn't", "start": 991.5, "duration": 3.6}, {"text": "recognize", "start": 993.06, "duration": 4.56}, {"text": "um the compiler directives that you're", "start": 995.1, "duration": 4.859}, {"text": "trying to use they're safely ignored so", "start": 997.62, "duration": 5.459}, {"text": "you have a single code base", "start": 999.959, "duration": 6.5}, {"text": "and it's portable you can Target uh", "start": 1003.079, "duration": 5.88}, {"text": "multi-thread CPUs", "start": 1006.459, "duration": 6.401}, {"text": "not only Nvidia gpus but other gpus as", "start": 1008.959, "duration": 4.581}, {"text": "well", "start": 1012.86, "duration": 4.32}, {"text": "so single code base simple to use with a", "start": 1013.54, "duration": 6.219}, {"text": "few lines of code you can potentially", "start": 1017.18, "duration": 5.459}, {"text": "get orders of magnitude speed up so", "start": 1019.759, "duration": 6.3}, {"text": "certainly check out open ACC C C plus", "start": 1022.639, "duration": 6.68}, {"text": "plus and Fortran", "start": 1026.059, "duration": 3.26}, {"text": "applications that you're probably", "start": 1030.02, "duration": 4.88}, {"text": "familiar with are using them so gaussian", "start": 1031.16, "duration": 8.06}, {"text": "and vas both use open ACC directives", "start": 1034.9, "duration": 9.12}, {"text": "for some parts of their algorithm", "start": 1039.22, "duration": 4.8}, {"text": "some paths through their through their", "start": 1044.079, "duration": 4.681}, {"text": "codes", "start": 1047.66, "duration": 5.04}, {"text": "to get GPU acceleration", "start": 1048.76, "duration": 7.06}, {"text": "okay so main content", "start": 1052.7, "duration": 6.66}, {"text": "so I'm going to start by talking about", "start": 1055.82, "duration": 6.06}, {"text": "um number so number with the python", "start": 1059.36, "duration": 6.36}, {"text": "library number we expose uh", "start": 1061.88, "duration": 6.62}, {"text": "um essentially the Cuda programming API", "start": 1065.72, "duration": 5.94}, {"text": "directly in Python", "start": 1068.5, "duration": 5.62}, {"text": "so", "start": 1071.66, "duration": 5.82}, {"text": "it's it it we actually have both a high", "start": 1074.12, "duration": 5.58}, {"text": "level API", "start": 1077.48, "duration": 5.0}, {"text": "um that we", "start": 1079.7, "duration": 7.859}, {"text": "and I'll show later we can simply code", "start": 1082.48, "duration": 7.96}, {"text": "Universal a lot of the heavy lifting is", "start": 1087.559, "duration": 5.221}, {"text": "done for us but we also have the", "start": 1090.44, "duration": 5.099}, {"text": "flexibility of a very low level API with", "start": 1092.78, "duration": 5.88}, {"text": "Cuda syntax Cuda provided variables and", "start": 1095.539, "duration": 4.861}, {"text": "this gives us a tremendous amount of", "start": 1098.66, "duration": 3.96}, {"text": "power and flexibility in that we are", "start": 1100.4, "duration": 6.18}, {"text": "really doing GPU programming in Cuda in", "start": 1102.62, "duration": 7.08}, {"text": "more or less native python so no need to", "start": 1106.58, "duration": 5.459}, {"text": "leave even the the Jupiter notebook or", "start": 1109.7, "duration": 5.339}, {"text": "or python source code or compile some", "start": 1112.039, "duration": 6.301}, {"text": "extra C library and call the C C from", "start": 1115.039, "duration": 6.781}, {"text": "python no complications like that", "start": 1118.34, "duration": 6.54}, {"text": "um uh so and and the same is true for", "start": 1121.82, "duration": 5.64}, {"text": "the data movement", "start": 1124.88, "duration": 5.82}, {"text": "um the uh at the with the high level API", "start": 1127.46, "duration": 5.82}, {"text": "for a number uh data movement is handled", "start": 1130.7, "duration": 5.58}, {"text": "handled automatically uh but we also do", "start": 1133.28, "duration": 5.82}, {"text": "expose fine-grained control over data", "start": 1136.28, "duration": 4.56}, {"text": "movement so if we'd like we can move the", "start": 1139.1, "duration": 4.1}, {"text": "data", "start": 1140.84, "duration": 2.36}, {"text": "and annually", "start": 1143.38, "duration": 3.539}, {"text": "so how does", "start": 1147.08, "duration": 5.04}, {"text": "um the core is uh just in time compiled", "start": 1148.4, "duration": 6.659}, {"text": "uh Cuda kernel so we use a python", "start": 1152.12, "duration": 5.16}, {"text": "decorator that I'm showing here Cuda jit", "start": 1155.059, "duration": 4.86}, {"text": "just in time compiled so this is", "start": 1157.28, "duration": 3.72}, {"text": "defining", "start": 1159.919, "duration": 2.821}, {"text": "um a Cuda kernel that will be compiled", "start": 1161.0, "duration": 5.1}, {"text": "before execution the first time", "start": 1162.74, "duration": 4.799}, {"text": "um", "start": 1166.1, "duration": 2.6}, {"text": "um", "start": 1167.539, "duration": 4.02}, {"text": "and uh as I mentioned we have Cuda", "start": 1168.7, "duration": 4.96}, {"text": "provided variables and then we can", "start": 1171.559, "duration": 3.781}, {"text": "operate", "start": 1173.66, "duration": 5.46}, {"text": "um on on numpy arrays or", "start": 1175.34, "duration": 4.74}, {"text": "um", "start": 1179.12, "duration": 3.12}, {"text": "data structures in a very familiar", "start": 1180.08, "duration": 4.38}, {"text": "python way", "start": 1182.24, "duration": 2.88}, {"text": "um", "start": 1184.46, "duration": 2.88}, {"text": "and expose all the power of GPU", "start": 1185.12, "duration": 4.32}, {"text": "accelerated Computing right from python", "start": 1187.34, "duration": 3.48}, {"text": "so", "start": 1189.44, "duration": 2.76}, {"text": "so we're going to tear", "start": 1190.82, "duration": 4.68}, {"text": "art this kernel a little bit so I think", "start": 1192.2, "duration": 6.24}, {"text": "what we're going to do is introduce the", "start": 1195.5, "duration": 5.82}, {"text": "Core Concepts around Cuda programming", "start": 1198.44, "duration": 5.7}, {"text": "because you actually are programming in", "start": 1201.32, "duration": 6.54}, {"text": "in Cuda so let's introduce uh", "start": 1204.14, "duration": 6.96}, {"text": "essentially the the basics of Cuda so of", "start": 1207.86, "duration": 6.96}, {"text": "course gpus do work in parallel and the", "start": 1211.1, "duration": 6.84}, {"text": "work itself is performed in a thread so", "start": 1214.82, "duration": 4.859}, {"text": "I'm highlighting in green a single", "start": 1217.94, "duration": 3.08}, {"text": "thread", "start": 1219.679, "duration": 5.88}, {"text": "many threads run in parallel", "start": 1221.02, "duration": 6.399}, {"text": "and", "start": 1225.559, "duration": 5.281}, {"text": "um we refer to a collection of threads", "start": 1227.419, "duration": 6.421}, {"text": "as a block okay so there's a hierarchy", "start": 1230.84, "duration": 5.04}, {"text": "we have the threads and then we have a", "start": 1233.84, "duration": 3.18}, {"text": "block", "start": 1235.88, "duration": 4.38}, {"text": "in general there are multiple blocks", "start": 1237.02, "duration": 7.38}, {"text": "and we call the collection of blocks of", "start": 1240.26, "duration": 5.1}, {"text": "grid", "start": 1244.4, "duration": 4.92}, {"text": "okay so we have thread in white blue we", "start": 1245.36, "duration": 6.48}, {"text": "have the blocks and the collection of", "start": 1249.32, "duration": 4.979}, {"text": "blocks we call the grid", "start": 1251.84, "duration": 5.94}, {"text": "the actual program that runs on the GPU", "start": 1254.299, "duration": 6.361}, {"text": "is called the kernel so highlighted in", "start": 1257.78, "duration": 5.22}, {"text": "green we have perform work that is going", "start": 1260.66, "duration": 4.86}, {"text": "to be the code that executes on the GPU", "start": 1263.0, "duration": 4.08}, {"text": "that's the kernel", "start": 1265.52, "duration": 4.74}, {"text": "and we launch kernels with an execution", "start": 1267.08, "duration": 5.4}, {"text": "configuration and there's a special", "start": 1270.26, "duration": 4.38}, {"text": "syntax associated with that execution", "start": 1272.48, "duration": 4.199}, {"text": "configuration because this is a slightly", "start": 1274.64, "duration": 3.84}, {"text": "different model", "start": 1276.679, "duration": 3.481}, {"text": "so here", "start": 1278.48, "duration": 4.439}, {"text": "um that syntax is actually the C syntax", "start": 1280.16, "duration": 5.46}, {"text": "that's the extension that Cuda adds to", "start": 1282.919, "duration": 4.5}, {"text": "the C programming language so we have", "start": 1285.62, "duration": 4.679}, {"text": "the triple angle brackets", "start": 1287.419, "duration": 5.341}, {"text": "um between the name of the function and", "start": 1290.299, "duration": 5.101}, {"text": "the function parameters so we have", "start": 1292.76, "duration": 4.2}, {"text": "perform work then we have the launch", "start": 1295.4, "duration": 4.8}, {"text": "configuration two comma four okay in", "start": 1296.96, "duration": 6.24}, {"text": "Python that launch configuration is", "start": 1300.2, "duration": 4.62}, {"text": "actually square brackets which we'll", "start": 1303.2, "duration": 4.219}, {"text": "show you in a second", "start": 1304.82, "duration": 5.7}, {"text": "and this launch configuration specifies", "start": 1307.419, "duration": 6.64}, {"text": "the number of blocks in this case two I", "start": 1310.52, "duration": 5.279}, {"text": "want to launch this particular kernel", "start": 1314.059, "duration": 4.681}, {"text": "with two blocks and I want", "start": 1315.799, "duration": 6.36}, {"text": "um each block to have four threads okay", "start": 1318.74, "duration": 6.179}, {"text": "so that together two blocks four threads", "start": 1322.159, "duration": 5.161}, {"text": "that is my launch configuration", "start": 1324.919, "duration": 4.561}, {"text": "and every block in the grid contains", "start": 1327.32, "duration": 3.96}, {"text": "four threads", "start": 1329.48, "duration": 4.079}, {"text": "okay so", "start": 1331.28, "duration": 3.96}, {"text": "um as we said the work is performed", "start": 1333.559, "duration": 5.581}, {"text": "inside the threads each thread executes", "start": 1335.24, "duration": 7.38}, {"text": "the program so uh when the threads wake", "start": 1339.14, "duration": 6.0}, {"text": "up we have to have some mechanism of", "start": 1342.62, "duration": 4.559}, {"text": "identifying which thread which block", "start": 1345.14, "duration": 4.68}, {"text": "we're in and these are the Cuda provided", "start": 1347.179, "duration": 5.221}, {"text": "variables so when each thread wakes up", "start": 1349.82, "duration": 4.56}, {"text": "they're going to have an instantiation", "start": 1352.4, "duration": 4.62}, {"text": "of these Cuda provided variables that", "start": 1354.38, "duration": 7.2}, {"text": "Define these okay so grid dim is the", "start": 1357.02, "duration": 6.48}, {"text": "first Cuda provided variable so this is", "start": 1361.58, "duration": 5.04}, {"text": "provided initialized already for you and", "start": 1363.5, "duration": 8.4}, {"text": "grid dim refers to the dimension of the", "start": 1366.62, "duration": 7.799}, {"text": "grid so in this case this is specified", "start": 1371.9, "duration": 5.7}, {"text": "by the launch configuration so we ask", "start": 1374.419, "duration": 8.061}, {"text": "for two blocks so the grid dim is two", "start": 1377.6, "duration": 4.88}, {"text": "we also have block index now the block", "start": 1383.32, "duration": 8.2}, {"text": "index tells us which the index of the", "start": 1387.44, "duration": 6.9}, {"text": "current block that we're executing in so", "start": 1391.52, "duration": 4.92}, {"text": "all the threads", "start": 1394.34, "duration": 5.459}, {"text": "that are within the block highlighted in", "start": 1396.44, "duration": 4.739}, {"text": "green", "start": 1399.799, "duration": 5.301}, {"text": "okay the left block will wake up with", "start": 1401.179, "duration": 7.62}, {"text": "blockindex.x set to zero", "start": 1405.1, "duration": 7.0}, {"text": "and when a thread in the right hand", "start": 1408.799, "duration": 5.221}, {"text": "block wakes up", "start": 1412.1, "duration": 4.26}, {"text": "any of those each of those threads will", "start": 1414.02, "duration": 4.1}, {"text": "wake up with", "start": 1416.36, "duration": 5.76}, {"text": "blockindex.x set to 1.", "start": 1418.12, "duration": 6.539}, {"text": "okay", "start": 1422.12, "duration": 2.539}, {"text": "so similarly we have block dim so the", "start": 1426.5, "duration": 6.9}, {"text": "block dim tells us", "start": 1430.88, "duration": 6.36}, {"text": "um the dimensions of the the thread", "start": 1433.4, "duration": 6.72}, {"text": "block so in this case I've asked for", "start": 1437.24, "duration": 6.419}, {"text": "there to be four threads in this in this", "start": 1440.12, "duration": 6.179}, {"text": "per block my my X my launch", "start": 1443.659, "duration": 5.64}, {"text": "configuration is uh two blocks for", "start": 1446.299, "duration": 6.86}, {"text": "Threads uh so I wake up with", "start": 1449.299, "duration": 6.301}, {"text": "blockdim.x set to four", "start": 1453.159, "duration": 6.0}, {"text": "and uh all blocks have the same", "start": 1455.6, "duration": 5.459}, {"text": "configuration the same thread block", "start": 1459.159, "duration": 4.601}, {"text": "configuration so all blocks are going to", "start": 1461.059, "duration": 7.701}, {"text": "wake up uh with blocked in set to four", "start": 1463.76, "duration": 5.0}, {"text": "okay and finally we have thread index", "start": 1469.94, "duration": 6.78}, {"text": "thread index tells us the index within", "start": 1473.299, "duration": 4.801}, {"text": "the block", "start": 1476.72, "duration": 4.62}, {"text": "um uh that were that we're executing so", "start": 1478.1, "duration": 6.66}, {"text": "in the left block we have", "start": 1481.34, "duration": 6.48}, {"text": "um uh zero one two and three and", "start": 1484.76, "duration": 5.76}, {"text": "importantly this is relative to the", "start": 1487.82, "duration": 4.739}, {"text": "block so", "start": 1490.52, "duration": 5.22}, {"text": "um uh in the second block this is block", "start": 1492.559, "duration": 6.36}, {"text": "index one we reset and that thread index", "start": 1495.74, "duration": 6.36}, {"text": "again is zero indexed so he has thread", "start": 1498.919, "duration": 7.941}, {"text": "index 0 1 2 and 3.", "start": 1502.1, "duration": 4.76}, {"text": "okay hopefully that's clear", "start": 1507.44, "duration": 3.44}, {"text": "so", "start": 1512.96, "duration": 5.76}, {"text": "now the task is to map This Thread block", "start": 1514.88, "duration": 6.2}, {"text": "hierarchy", "start": 1518.72, "duration": 6.0}, {"text": "uh to some work so the most basic case", "start": 1521.08, "duration": 6.579}, {"text": "that we could have is a linear array of", "start": 1524.72, "duration": 6.3}, {"text": "data so in this case on the top panel I", "start": 1527.659, "duration": 6.661}, {"text": "have I'm showing a a 1D array of data", "start": 1531.02, "duration": 6.3}, {"text": "and it's indexed uh zero through seven", "start": 1534.32, "duration": 4.8}, {"text": "okay so I have one index zero through", "start": 1537.32, "duration": 4.32}, {"text": "seven mapping into some data and I have", "start": 1539.12, "duration": 6.059}, {"text": "this thread block hierarchy", "start": 1541.64, "duration": 5.76}, {"text": "given with our Cuda provided variables", "start": 1545.179, "duration": 6.24}, {"text": "and I need to map the the threads to", "start": 1547.4, "duration": 6.68}, {"text": "that data array to do some work", "start": 1551.419, "duration": 6.12}, {"text": "typically this is done via this formula", "start": 1554.08, "duration": 5.86}, {"text": "but I'm showing thread index plus block", "start": 1557.539, "duration": 5.401}, {"text": "index times blocked in this is a very", "start": 1559.94, "duration": 5.46}, {"text": "standard way of mapping the thread block", "start": 1562.94, "duration": 5.16}, {"text": "hierarchy into a linear array and you'll", "start": 1565.4, "duration": 4.74}, {"text": "see this over and over and over again", "start": 1568.1, "duration": 4.38}, {"text": "it's not necessarily how it has to be", "start": 1570.14, "duration": 4.44}, {"text": "done but it's an extremely common way", "start": 1572.48, "duration": 5.52}, {"text": "and so it's an it's an important case to", "start": 1574.58, "duration": 5.88}, {"text": "to remember because it's not Maybe not", "start": 1578.0, "duration": 4.279}, {"text": "immediately obvious", "start": 1580.46, "duration": 6.78}, {"text": "how to map the threadblock hierarchy to", "start": 1582.279, "duration": 8.02}, {"text": "standard array of work", "start": 1587.24, "duration": 5.819}, {"text": "okay so thread index plus block index", "start": 1590.299, "duration": 5.341}, {"text": "times plot dim that's a formula that", "start": 1593.059, "duration": 5.941}, {"text": "should be seared into your memory and", "start": 1595.64, "duration": 5.279}, {"text": "let's see how this works with our with", "start": 1599.0, "duration": 5.1}, {"text": "our thread block hierarchy", "start": 1600.919, "duration": 6.441}, {"text": "so for that first thread", "start": 1604.1, "duration": 7.02}, {"text": "as we know that has a thread index of", "start": 1607.36, "duration": 6.4}, {"text": "zero and it's a block index of zero", "start": 1611.12, "duration": 4.62}, {"text": "because it's the first thread in the", "start": 1613.76, "duration": 4.519}, {"text": "first block", "start": 1615.74, "duration": 2.539}, {"text": "it's trivial in this case is zero times", "start": 1618.38, "duration": 8.1}, {"text": "zero plus thread index 0 is 0 and so", "start": 1622.279, "duration": 5.88}, {"text": "naturally we start at the first element", "start": 1626.48, "duration": 4.22}, {"text": "of our data array", "start": 1628.159, "duration": 6.5}, {"text": "as we progress through the first", "start": 1630.7, "duration": 8.02}, {"text": "block that notice that that second term", "start": 1634.659, "duration": 7.661}, {"text": "block index times block dim", "start": 1638.72, "duration": 6.12}, {"text": "because we're multiplying by the block", "start": 1642.32, "duration": 5.94}, {"text": "index that second term block index times", "start": 1644.84, "duration": 7.38}, {"text": "blocked in stays constant within the", "start": 1648.26, "duration": 6.24}, {"text": "block right", "start": 1652.22, "duration": 6.86}, {"text": "so for these first four threads", "start": 1654.5, "duration": 4.58}, {"text": "we have that second term fixed at zero", "start": 1659.419, "duration": 6.181}, {"text": "zero times four is zero and so these", "start": 1662.84, "duration": 5.219}, {"text": "first four threads", "start": 1665.6, "duration": 3.36}, {"text": "um", "start": 1668.059, "duration": 4.921}, {"text": "map using thread index map to the first", "start": 1668.96, "duration": 8.18}, {"text": "elements of our data array", "start": 1672.98, "duration": 4.16}, {"text": "when we move into the second block now", "start": 1677.48, "duration": 5.64}, {"text": "we have block index of one our thread", "start": 1679.88, "duration": 7.1}, {"text": "index resets to zero that second term", "start": 1683.12, "duration": 7.02}, {"text": "one times four block index times blocked", "start": 1686.98, "duration": 6.76}, {"text": "in 1 times 4 is now four and it's fixed", "start": 1690.14, "duration": 6.659}, {"text": "at four for this block", "start": 1693.74, "duration": 5.819}, {"text": "so as we step through that thread index", "start": 1696.799, "duration": 5.641}, {"text": "thread index of zero", "start": 1699.559, "duration": 5.341}, {"text": "plus four is four", "start": 1702.44, "duration": 4.619}, {"text": "thread index of one", "start": 1704.9, "duration": 4.2}, {"text": "plus four is five", "start": 1707.059, "duration": 6.421}, {"text": "thread index of two plus four is six", "start": 1709.1, "duration": 5.88}, {"text": "and so on", "start": 1713.48, "duration": 3.54}, {"text": "so hopefully you can see how this", "start": 1714.98, "duration": 6.48}, {"text": "formula strides through the blocked in", "start": 1717.02, "duration": 8.279}, {"text": "and we can map a linear array of data", "start": 1721.46, "duration": 7.88}, {"text": "with our thread block hierarchy", "start": 1725.299, "duration": 4.041}, {"text": "so I should mention", "start": 1731.059, "duration": 6.36}, {"text": "that the 1D case", "start": 1734.26, "duration": 5.2}, {"text": "where we have", "start": 1737.419, "duration": 2.701}, {"text": "um", "start": 1739.46, "duration": 3.959}, {"text": "dimensional array of blocks and a", "start": 1740.12, "duration": 6.48}, {"text": "one-dimensional array of threads is the", "start": 1743.419, "duration": 5.061}, {"text": "simplest case we can have", "start": 1746.6, "duration": 5.1}, {"text": "higher dimensional up to three three two", "start": 1748.48, "duration": 6.52}, {"text": "and three dimensional grids and two or", "start": 1751.7, "duration": 6.92}, {"text": "three dimensional thread blocks as well", "start": 1755.0, "duration": 8.34}, {"text": "so here I'm showing you an example of I", "start": 1758.62, "duration": 6.22}, {"text": "guess an illustration of what it would", "start": 1763.34, "duration": 4.68}, {"text": "look like to have a two dimensional", "start": 1764.84, "duration": 6.9}, {"text": "thread block within the context of the", "start": 1768.02, "duration": 6.8}, {"text": "of our two", "start": 1771.74, "duration": 3.08}, {"text": "um two blocks for for our grid", "start": 1775.52, "duration": 4.74}, {"text": "okay", "start": 1779.179, "duration": 2.281}, {"text": "so you can see in the launch", "start": 1780.26, "duration": 4.919}, {"text": "configuration I'm specifying two comma", "start": 1781.46, "duration": 6.599}, {"text": "that Tuple four by four so I'm asking", "start": 1785.179, "duration": 6.48}, {"text": "for a 2d thread block where I have", "start": 1788.059, "duration": 7.321}, {"text": "um four threads by four threads", "start": 1791.659, "duration": 5.701}, {"text": "so in this case I'm going to have Cuda", "start": 1795.38, "duration": 4.1}, {"text": "provided variables not only thread", "start": 1797.36, "duration": 6.84}, {"text": "index.x but also thread index dot y", "start": 1799.48, "duration": 7.78}, {"text": "so you can see for the thread I have", "start": 1804.2, "duration": 5.339}, {"text": "highlighted", "start": 1807.26, "duration": 5.76}, {"text": "I have thread index.y initialized at two", "start": 1809.539, "duration": 6.661}, {"text": "and I have thread index.x initialized at", "start": 1813.02, "duration": 6.36}, {"text": "one so that particular thread", "start": 1816.2, "duration": 6.66}, {"text": "would be given by those Cuda provided", "start": 1819.38, "duration": 6.419}, {"text": "variables thread thread index dot X", "start": 1822.86, "duration": 5.88}, {"text": "thread index.y and of course if I", "start": 1825.799, "duration": 4.681}, {"text": "specified a three-dimensional grid I", "start": 1828.74, "duration": 4.98}, {"text": "would also have thread index.z", "start": 1830.48, "duration": 6.72}, {"text": "and the same is true of our block into", "start": 1833.72, "duration": 6.42}, {"text": "indices we can have I've been showing", "start": 1837.2, "duration": 5.88}, {"text": "examples with blockindex.x but we could", "start": 1840.14, "duration": 6.779}, {"text": "also have a two-dimensional grid where I", "start": 1843.08, "duration": 8.28}, {"text": "had block index.y and also blockindex.z", "start": 1846.919, "duration": 6.961}, {"text": "and this flexibility you can imagine how", "start": 1851.36, "duration": 4.98}, {"text": "this flexibility would help you map the", "start": 1853.88, "duration": 4.799}, {"text": "thread block hierarchy to your problem", "start": 1856.34, "duration": 6.559}, {"text": "depending on how your data was arranged", "start": 1858.679, "duration": 4.22}, {"text": "okay so in this particular case", "start": 1863.419, "duration": 6.541}, {"text": "we have a data structure called", "start": 1866.84, "duration": 8.939}, {"text": "that is indexed by a molecule okay so", "start": 1869.96, "duration": 8.28}, {"text": "this is a structure that contains", "start": 1875.779, "duration": 5.161}, {"text": "molecules and each molecule that second", "start": 1878.24, "duration": 6.0}, {"text": "index is the atom index", "start": 1880.94, "duration": 6.78}, {"text": "okay so we have molecules atoms and then", "start": 1884.24, "duration": 6.26}, {"text": "that third index is the X Y or Z", "start": 1887.72, "duration": 8.12}, {"text": "coordinate okay so chords crds", "start": 1890.5, "duration": 10.0}, {"text": "is three indexed molecule atom and", "start": 1895.84, "duration": 6.699}, {"text": "coordinate and in this particular case", "start": 1900.5, "duration": 4.2}, {"text": "what I'm trying to do is compute a", "start": 1902.539, "duration": 4.5}, {"text": "distance Matrix that is the distance", "start": 1904.7, "duration": 3.92}, {"text": "between", "start": 1907.039, "duration": 4.681}, {"text": "all pairs of atoms within the same", "start": 1908.62, "duration": 5.62}, {"text": "molecule", "start": 1911.72, "duration": 4.14}, {"text": "okay", "start": 1914.24, "duration": 5.159}, {"text": "so I've mapped because I'm Computing", "start": 1915.86, "duration": 5.64}, {"text": "this symmetric Matrix", "start": 1919.399, "duration": 5.28}, {"text": "I'm leveraging uh one of the higher", "start": 1921.5, "duration": 4.38}, {"text": "dimensional thread blocks a", "start": 1924.679, "duration": 3.12}, {"text": "two-dimensional thread block", "start": 1925.88, "duration": 3.72}, {"text": "so that if we go back to this", "start": 1927.799, "duration": 5.161}, {"text": "illustration the blocks I'm going to use", "start": 1929.6, "duration": 7.199}, {"text": "as an index into my molecule so each", "start": 1932.96, "duration": 6.24}, {"text": "block will map to a molecule", "start": 1936.799, "duration": 5.701}, {"text": "and each thread within the block", "start": 1939.2, "duration": 5.82}, {"text": "will map to an atom", "start": 1942.5, "duration": 3.96}, {"text": "okay", "start": 1945.02, "duration": 5.84}, {"text": "my problem is square and so the the", "start": 1946.46, "duration": 6.319}, {"text": "two-dimensional", "start": 1950.86, "duration": 5.26}, {"text": "thread block fits very naturally to this", "start": 1952.779, "duration": 4.841}, {"text": "type of problem", "start": 1956.12, "duration": 4.559}, {"text": "okay so hopefully that's clear how I'm", "start": 1957.62, "duration": 6.059}, {"text": "mapping the threadlock hierarchy to this", "start": 1960.679, "duration": 4.201}, {"text": "problem", "start": 1963.679, "duration": 3.141}, {"text": "and you can see", "start": 1964.88, "duration": 7.019}, {"text": "I I I I don't have to I wake up in the", "start": 1966.82, "duration": 7.26}, {"text": "kernel those first few lines of", "start": 1971.899, "duration": 6.321}, {"text": "cuda.thread index.x cuda.thread index.y", "start": 1974.08, "duration": 6.099}, {"text": "blockindex.x I wake up with those", "start": 1978.22, "duration": 4.179}, {"text": "initialized right and I'm simply", "start": 1980.179, "duration": 5.821}, {"text": "reassigning them to txty and BX", "start": 1982.399, "duration": 7.221}, {"text": "um because they're shorter", "start": 1986.0, "duration": 3.62}, {"text": "so you can see the actual", "start": 1990.74, "duration": 5.279}, {"text": "computation itself is on the last three", "start": 1993.1, "duration": 6.76}, {"text": "lines so for I in range 3 is referring", "start": 1996.019, "duration": 5.941}, {"text": "to the X Y and Z coordinates of the atom", "start": 1999.86, "duration": 4.439}, {"text": "and then you can see the meat of the", "start": 2001.96, "duration": 4.439}, {"text": "calculation is the second half of that", "start": 2004.299, "duration": 6.48}, {"text": "long line chords BX is the block index", "start": 2006.399, "duration": 5.941}, {"text": "and you can see the first chords is", "start": 2010.779, "duration": 3.301}, {"text": "indexed by TX", "start": 2012.34, "duration": 5.64}, {"text": "and the second chords index by T Y so", "start": 2014.08, "duration": 7.02}, {"text": "I'm taking that pair of atoms for that", "start": 2017.98, "duration": 5.96}, {"text": "coordinate either X Y or Z", "start": 2021.1, "duration": 5.88}, {"text": "Computing the difference querience and", "start": 2023.94, "duration": 5.56}, {"text": "returning the square root", "start": 2026.98, "duration": 5.939}, {"text": "and storing the result in Edge feeds", "start": 2029.5, "duration": 7.019}, {"text": "okay so the results Matrix", "start": 2032.919, "duration": 8.061}, {"text": "um is uh as a different shape", "start": 2036.519, "duration": 7.38}, {"text": "and you can see that that's indexed by", "start": 2040.98, "duration": 4.24}, {"text": "uh", "start": 2043.899, "duration": 7.561}, {"text": "block index or molecule by atom by atom", "start": 2045.22, "duration": 7.939}, {"text": "it's not necessarily", "start": 2051.46, "duration": 4.08}, {"text": "super important if you followed my", "start": 2053.159, "duration": 4.541}, {"text": "explanation of the algorithm what's more", "start": 2055.54, "duration": 4.44}, {"text": "important is that you see that we wake", "start": 2057.7, "duration": 5.219}, {"text": "up with the Cuda provided variables and", "start": 2059.98, "duration": 6.48}, {"text": "that we can use the different uh thread", "start": 2062.919, "duration": 8.881}, {"text": "block hierarchies to map it to a problem", "start": 2066.46, "duration": 8.939}, {"text": "and that's it so in a handful of lines I", "start": 2071.8, "duration": 6.9}, {"text": "have a GPU accelerated Cuda kernel that", "start": 2075.399, "duration": 5.341}, {"text": "will be just in time compiled and", "start": 2078.7, "duration": 4.139}, {"text": "execute on the GPU", "start": 2080.74, "duration": 3.72}, {"text": "now there's a little bit of extra work", "start": 2082.839, "duration": 4.26}, {"text": "we have to do we do have to make sure", "start": 2084.46, "duration": 5.1}, {"text": "that there's space allocated on the GPU", "start": 2087.099, "duration": 4.981}, {"text": "for the result so I said edge Feats is", "start": 2089.56, "duration": 4.859}, {"text": "where we're going to have uh store the", "start": 2092.08, "duration": 4.079}, {"text": "result of the calculation", "start": 2094.419, "duration": 3.961}, {"text": "so I need to allocate some space for", "start": 2096.159, "duration": 4.741}, {"text": "that on the GPU so I'm going to do that", "start": 2098.38, "duration": 7.56}, {"text": "by this uh allocating space that the", "start": 2100.9, "duration": 7.32}, {"text": "call is device array so cuda.r device", "start": 2105.94, "duration": 4.08}, {"text": "array and then I give it the shape and", "start": 2108.22, "duration": 2.899}, {"text": "data type", "start": 2110.02, "duration": 3.54}, {"text": "allocates the space", "start": 2111.119, "duration": 4.661}, {"text": "and I'm going to assume for this case", "start": 2113.56, "duration": 4.5}, {"text": "that we have the structure the", "start": 2115.78, "duration": 5.46}, {"text": "coordinates on the CPU maybe they're in", "start": 2118.06, "duration": 6.059}, {"text": "a numpy array and we need to transfer", "start": 2121.24, "duration": 6.9}, {"text": "those in order for the kernel to do its", "start": 2124.119, "duration": 6.96}, {"text": "work uh event we need to have that data", "start": 2128.14, "duration": 5.939}, {"text": "on the GPU so we transfer that data to", "start": 2131.079, "duration": 7.621}, {"text": "the GPU with the calls cuda.2 device", "start": 2134.079, "duration": 7.381}, {"text": "that moves it to the GPU and I get in", "start": 2138.7, "duration": 5.76}, {"text": "return a pointer structures underscore", "start": 2141.46, "duration": 6.899}, {"text": "GPU and N atoms underscore GPU these are", "start": 2144.46, "duration": 5.36}, {"text": "Pointers to", "start": 2148.359, "duration": 3.841}, {"text": "the places where they're stored on the", "start": 2149.82, "duration": 4.799}, {"text": "GPU", "start": 2152.2, "duration": 2.419}, {"text": "we launched the kernel as I mentioned", "start": 2155.76, "duration": 5.02}, {"text": "there's a little bit of extra syntax", "start": 2158.619, "duration": 5.281}, {"text": "with the the function call itself or the", "start": 2160.78, "duration": 4.92}, {"text": "kernel launch", "start": 2163.9, "duration": 4.14}, {"text": "um in C in C C plus plus that's the", "start": 2165.7, "duration": 5.04}, {"text": "triple angle brackets in number it's", "start": 2168.04, "duration": 4.74}, {"text": "simply the square brackets which looks a", "start": 2170.74, "duration": 4.68}, {"text": "little bit funny but", "start": 2172.78, "duration": 5.88}, {"text": "um uh this is this is the how we specify", "start": 2175.42, "duration": 5.4}, {"text": "the launch configuration", "start": 2178.66, "duration": 4.86}, {"text": "so you can see I have the number of", "start": 2180.82, "duration": 7.68}, {"text": "structures last XYZ by 29 by 29 that's", "start": 2183.52, "duration": 8.16}, {"text": "the maximum number of atoms in", "start": 2188.5, "duration": 7.46}, {"text": "um in this particular data set", "start": 2191.68, "duration": 4.28}, {"text": "and then the parameters so I have", "start": 2197.02, "duration": 6.3}, {"text": "um my uh pointers to the coordinates", "start": 2199.96, "duration": 6.899}, {"text": "array on the GPU and my allocated", "start": 2203.32, "duration": 7.08}, {"text": "pointer to my allocated space edge Feats", "start": 2206.859, "duration": 6.361}, {"text": "on the GPU after the kernel is done", "start": 2210.4, "duration": 5.459}, {"text": "executing we copy", "start": 2213.22, "duration": 6.54}, {"text": "um the results back so Edge Feats will", "start": 2215.859, "duration": 7.021}, {"text": "be populated with our result and Edge", "start": 2219.76, "duration": 5.96}, {"text": "feeds underscore GPU copies that data", "start": 2222.88, "duration": 5.699}, {"text": "dot copy to host copies that data back", "start": 2225.72, "duration": 5.399}, {"text": "from the GPU to the CPU", "start": 2228.579, "duration": 5.901}, {"text": "and we're done", "start": 2231.119, "duration": 3.361}, {"text": "um so in a with a relatively uh few", "start": 2234.52, "duration": 7.079}, {"text": "lines of code we expose the Cuda", "start": 2237.82, "duration": 7.259}, {"text": "programming API in most of its Glory", "start": 2241.599, "duration": 6.0}, {"text": "with the flexibility to move data back", "start": 2245.079, "duration": 6.54}, {"text": "and forth allocate space on the GPU so", "start": 2247.599, "duration": 8.221}, {"text": "this is the lowest level uh API", "start": 2251.619, "duration": 5.24}, {"text": "um", "start": 2255.82, "duration": 3.9}, {"text": "that we can program with num with number", "start": 2256.859, "duration": 7.181}, {"text": "and it's more or less like programming", "start": 2259.72, "duration": 7.26}, {"text": "in Cuda and we're we don't have to leave", "start": 2264.04, "duration": 5.819}, {"text": "our Jupiter notebook to do any of this", "start": 2266.98, "duration": 6.96}, {"text": "which is just amazing", "start": 2269.859, "duration": 5.881}, {"text": "as I mentioned there's a higher level", "start": 2273.94, "duration": 7.52}, {"text": "API we can also program numpy", "start": 2275.74, "duration": 10.32}, {"text": "u-funks or Universal functions so in in", "start": 2281.46, "duration": 8.58}, {"text": "this way we can write extremely simple", "start": 2286.06, "duration": 6.84}, {"text": "uh kernels they're they're really", "start": 2290.04, "duration": 5.2}, {"text": "functions and have it automatically", "start": 2292.9, "duration": 5.939}, {"text": "vectorized on the GPU so if you've", "start": 2295.24, "duration": 6.48}, {"text": "worked a lot with numpy", "start": 2298.839, "duration": 4.28}, {"text": "um", "start": 2301.72, "duration": 3.6}, {"text": "there are different ways", "start": 2303.119, "duration": 4.121}, {"text": "but you may have even used The", "start": 2305.32, "duration": 6.2}, {"text": "vectorized Decorator to do a CPU", "start": 2307.24, "duration": 8.339}, {"text": "vectorization over a set of operations", "start": 2311.52, "duration": 4.9}, {"text": "um", "start": 2315.579, "duration": 3.54}, {"text": "but number gives us the ability to", "start": 2316.42, "duration": 6.32}, {"text": "Target a GPU accelerator a", "start": 2319.119, "duration": 8.581}, {"text": "GPU by specifying Target equals Cuda and", "start": 2322.74, "duration": 7.379}, {"text": "in in in in the same way that we write", "start": 2327.7, "duration": 6.419}, {"text": "numpy Universal functions with The", "start": 2330.119, "duration": 6.041}, {"text": "vectorized Decorator we can now write", "start": 2334.119, "duration": 5.521}, {"text": "GPU accelerated versions of a universal", "start": 2336.16, "duration": 5.64}, {"text": "function", "start": 2339.64, "duration": 5.58}, {"text": "the nice thing is is that the kernel", "start": 2341.8, "duration": 7.2}, {"text": "launch is simple the data is moved", "start": 2345.22, "duration": 5.54}, {"text": "automatically", "start": 2349.0, "duration": 5.52}, {"text": "so we can reap a lot of benefit for", "start": 2350.76, "duration": 5.98}, {"text": "simpler algorithms when we don't need", "start": 2354.52, "duration": 3.92}, {"text": "all the flexibility", "start": 2356.74, "duration": 3.9}, {"text": "that's provided with the Cuda", "start": 2358.44, "duration": 5.159}, {"text": "programming API", "start": 2360.64, "duration": 2.959}, {"text": "all right so that's number we're going", "start": 2365.02, "duration": 7.559}, {"text": "to shift gears now and talk about Rapids", "start": 2367.66, "duration": 4.919}, {"text": "so Rapids is our open source stack for", "start": 2372.82, "duration": 7.019}, {"text": "data science", "start": 2378.16, "duration": 4.74}, {"text": "so in Rapids as I mentioned we provide", "start": 2379.839, "duration": 5.641}, {"text": "really two big things that I'm going to", "start": 2382.9, "duration": 4.08}, {"text": "focus on", "start": 2385.48, "duration": 2.7}, {"text": "um", "start": 2386.98, "duration": 5.46}, {"text": "code DF is a GPU accelerated drop-in", "start": 2388.18, "duration": 6.84}, {"text": "replacement for pandas", "start": 2392.44, "duration": 6.36}, {"text": "and for working with data frames and qml", "start": 2395.02, "duration": 7.2}, {"text": "is a GPU accelerated drop-in replacement", "start": 2398.8, "duration": 5.7}, {"text": "for many of the algorithms contained in", "start": 2402.22, "duration": 5.18}, {"text": "scikit learn", "start": 2404.5, "duration": 2.9}, {"text": "so those of you who've worked with", "start": 2408.48, "duration": 3.76}, {"text": "pandas and data frames in the past", "start": 2410.5, "duration": 4.5}, {"text": "especially from inside a jupyter", "start": 2412.24, "duration": 5.28}, {"text": "notebook where where the data frames are", "start": 2415.0, "duration": 5.4}, {"text": "pretty printed working with data frames", "start": 2417.52, "duration": 6.18}, {"text": "is a dream you have column names the", "start": 2420.4, "duration": 8.459}, {"text": "slicing is uh is super convenient the", "start": 2423.7, "duration": 9.18}, {"text": "ability to handle various types of data", "start": 2428.859, "duration": 7.321}, {"text": "within your data frame doing complicated", "start": 2432.88, "duration": 6.36}, {"text": "pivots and operations between columns", "start": 2436.18, "duration": 5.28}, {"text": "the user-defined functions it can get", "start": 2439.24, "duration": 4.08}, {"text": "very powerful and it's extremely", "start": 2441.46, "duration": 6.5}, {"text": "convenient of course the downside is is", "start": 2443.32, "duration": 8.94}, {"text": "many of the operations for data frames", "start": 2447.96, "duration": 6.159}, {"text": "are fairly slow", "start": 2452.26, "duration": 4.14}, {"text": "uh some of them are fast but if you're", "start": 2454.119, "duration": 4.261}, {"text": "not careful and you don't know exactly", "start": 2456.4, "duration": 5.939}, {"text": "how to use the syntax it can be", "start": 2458.38, "duration": 7.44}, {"text": "um extremely slow painfully slow", "start": 2462.339, "duration": 5.701}, {"text": "uh and and that's really the motivation", "start": 2465.82, "duration": 4.74}, {"text": "for why we developed uh GPU accelerated", "start": 2468.04, "duration": 5.7}, {"text": "data frame operations CDF", "start": 2470.56, "duration": 5.58}, {"text": "so we intended this to be a drop-in", "start": 2473.74, "duration": 4.859}, {"text": "replacement for pandas so a lot of the", "start": 2476.14, "duration": 4.5}, {"text": "syntax that you already know for pandas", "start": 2478.599, "duration": 4.701}, {"text": "is essentially identical", "start": 2480.64, "duration": 7.14}, {"text": "so pick up a CSV I've imported cudif as", "start": 2483.3, "duration": 7.319}, {"text": "GD GPU data frame", "start": 2487.78, "duration": 5.7}, {"text": "gd.read CSV if we're imported pandas", "start": 2490.619, "duration": 7.181}, {"text": "pandas dot read CSV or pd.read CSV", "start": 2493.48, "duration": 5.66}, {"text": "um", "start": 2497.8, "duration": 2.94}, {"text": "and", "start": 2499.14, "duration": 3.459}, {"text": "um completely we strive for", "start": 2500.74, "duration": 3.9}, {"text": "interoperability with pandas so we can", "start": 2502.599, "duration": 4.381}, {"text": "go from pandas if you're already working", "start": 2504.64, "duration": 4.86}, {"text": "in a pandas data frame", "start": 2506.98, "duration": 4.98}, {"text": "um you can go back and forth from pandas", "start": 2509.5, "duration": 4.8}, {"text": "to pandas", "start": 2511.96, "duration": 4.44}, {"text": "um so back and forth between GPU", "start": 2514.3, "duration": 4.799}, {"text": "accelerated data frame and pandas data", "start": 2516.4, "duration": 5.4}, {"text": "frame seamlessly so there are some", "start": 2519.099, "duration": 4.5}, {"text": "operations", "start": 2521.8, "duration": 4.64}, {"text": "um that uh or wait just don't cover yet", "start": 2523.599, "duration": 6.601}, {"text": "this is a relatively new product and so", "start": 2526.44, "duration": 5.98}, {"text": "we don't have complete coverage of every", "start": 2530.2, "duration": 6.06}, {"text": "pandas operation so it's really common", "start": 2532.42, "duration": 6.48}, {"text": "in practice to go back and forth from", "start": 2536.26, "duration": 4.98}, {"text": "pandas do your heavy lifting heavy", "start": 2538.9, "duration": 4.26}, {"text": "computation with the GPU accelerated", "start": 2541.24, "duration": 4.74}, {"text": "data frame and if there's some you know", "start": 2543.16, "duration": 6.72}, {"text": "uh uh operation that's not quite covered", "start": 2545.98, "duration": 5.46}, {"text": "or you don't need the GPU acceleration", "start": 2549.88, "duration": 3.84}, {"text": "board go back to the you know a two", "start": 2551.44, "duration": 4.26}, {"text": "pandas pandas data frame and continue", "start": 2553.72, "duration": 4.5}, {"text": "working in in your pandas data frame so", "start": 2555.7, "duration": 4.74}, {"text": "seamless compatibility back and forth", "start": 2558.22, "duration": 4.32}, {"text": "between GPU accelerated data frame and", "start": 2560.44, "duration": 3.54}, {"text": "pandas", "start": 2562.54, "duration": 2.42}, {"text": "um", "start": 2563.98, "duration": 5.76}, {"text": "and uh you know most of the other syntax", "start": 2564.96, "duration": 7.899}, {"text": "that were that we like is covered the", "start": 2569.74, "duration": 4.98}, {"text": "data frames are pretty printed so within", "start": 2572.859, "duration": 5.22}, {"text": "a Jupiter notebook you'll you'll you'll", "start": 2574.72, "duration": 4.82}, {"text": "still get the", "start": 2578.079, "duration": 5.0}, {"text": "familiar printing of the data frames", "start": 2579.54, "duration": 7.0}, {"text": "slicing operations are going to work uh", "start": 2583.079, "duration": 6.181}, {"text": "just as you're familiar with in pandas", "start": 2586.54, "duration": 7.319}, {"text": "so for example using a slice notation 14", "start": 2589.26, "duration": 8.44}, {"text": "colon 17 gives me rows within the index", "start": 2593.859, "duration": 9.021}, {"text": "values 14 through 16 right not inclusive", "start": 2597.7, "duration": 5.18}, {"text": "selections by column name we can either", "start": 2603.0, "duration": 6.16}, {"text": "do with the dot operator or with the", "start": 2605.8, "duration": 6.68}, {"text": "standard string", "start": 2609.16, "duration": 8.179}, {"text": "indexing like a dictionary", "start": 2612.48, "duration": 4.859}, {"text": "slicing by row and column works the same", "start": 2618.9, "duration": 5.86}, {"text": "using the Dot Lock operator look", "start": 2622.18, "duration": 6.179}, {"text": "operator so in this case I'm saying give", "start": 2624.76, "duration": 6.72}, {"text": "me rows with index equals from 14", "start": 2628.359, "duration": 7.201}, {"text": "through 21 and give me columns x y and z", "start": 2631.48, "duration": 7.139}, {"text": "it's a two-dimensional slice", "start": 2635.56, "duration": 5.7}, {"text": "and operations between the data frames", "start": 2638.619, "duration": 5.341}, {"text": "this is is of course", "start": 2641.26, "duration": 3.8}, {"text": "um", "start": 2643.96, "duration": 4.02}, {"text": "the stuff we're most interested in so", "start": 2645.06, "duration": 5.5}, {"text": "doing these kinds of uh in in this case", "start": 2647.98, "duration": 5.7}, {"text": "a very simple operation between", "start": 2650.56, "duration": 5.88}, {"text": "um columns in your data frame are just", "start": 2653.68, "duration": 5.04}, {"text": "automatic vectorization right this is", "start": 2656.44, "duration": 4.32}, {"text": "where the the power of the GPU is really", "start": 2658.72, "duration": 5.04}, {"text": "going to kick in though surprisingly and", "start": 2660.76, "duration": 5.16}, {"text": "test this for yourself", "start": 2663.76, "duration": 5.46}, {"text": "um picking up a data frame from disk as", "start": 2665.92, "duration": 4.22}, {"text": "in", "start": 2669.22, "duration": 3.66}, {"text": "gd.read CSV", "start": 2670.14, "duration": 5.86}, {"text": "or you're asking kudi F to read a CSV", "start": 2672.88, "duration": 7.38}, {"text": "file from disk and import the GPU data", "start": 2676.0, "duration": 8.28}, {"text": "frame is often uh significantly faster", "start": 2680.26, "duration": 6.359}, {"text": "than the CPU version", "start": 2684.28, "duration": 5.339}, {"text": "so a lot of calculate a lot of", "start": 2686.619, "duration": 5.521}, {"text": "operations going on in the uh in the", "start": 2689.619, "duration": 4.98}, {"text": "read CSV just populating the data frame", "start": 2692.14, "duration": 5.6}, {"text": "try it out for yourself", "start": 2694.599, "duration": 3.141}, {"text": "um we can also construct Boolean Series", "start": 2700.0, "duration": 4.079}, {"text": "so in this case we're", "start": 2701.859, "duration": 3.081}, {"text": "um", "start": 2704.079, "duration": 4.441}, {"text": "asking for this column Norm greater than", "start": 2704.94, "duration": 5.74}, {"text": "3.0 and we get return to Boolean series", "start": 2708.52, "duration": 5.76}, {"text": "and we can use that to slice uh data", "start": 2710.68, "duration": 4.74}, {"text": "sets", "start": 2714.28, "duration": 3.42}, {"text": "um slice of data frame right so I have", "start": 2715.42, "duration": 4.62}, {"text": "my selection columns here molecule name", "start": 2717.7, "duration": 6.96}, {"text": "and atom and I want to slice uh give me", "start": 2720.04, "duration": 7.14}, {"text": "the selection from my data frame using", "start": 2724.66, "duration": 4.8}, {"text": "the select columns and that Boolean", "start": 2727.18, "duration": 5.399}, {"text": "Series where the norm is greater than", "start": 2729.46, "duration": 4.02}, {"text": "three", "start": 2732.579, "duration": 3.441}, {"text": "so you can see this simple", "start": 2733.48, "duration": 5.52}, {"text": "simple data frame syntax that that", "start": 2736.02, "duration": 6.16}, {"text": "pandas pioneered all there and you just", "start": 2739.0, "duration": 6.18}, {"text": "read the reap the benefits of having a", "start": 2742.18, "duration": 6.679}, {"text": "gtu accelerated data frame", "start": 2745.18, "duration": 3.679}, {"text": "unique elements", "start": 2749.079, "duration": 6.481}, {"text": "and where we where where", "start": 2751.56, "duration": 7.72}, {"text": "it really gets exciting I think is", "start": 2755.56, "duration": 6.0}, {"text": "um that we can have user defined", "start": 2759.28, "duration": 3.839}, {"text": "functions", "start": 2761.56, "duration": 5.58}, {"text": "okay so we have the flexibility just", "start": 2763.119, "duration": 7.141}, {"text": "like we do in pandas to do user-defined", "start": 2767.14, "duration": 5.34}, {"text": "functions between", "start": 2770.26, "duration": 5.099}, {"text": "um rows and have this sort of vectorized", "start": 2772.48, "duration": 7.139}, {"text": "uh over uh our data frame we can do the", "start": 2775.359, "duration": 7.021}, {"text": "same thing with qdf and have a GPU", "start": 2779.619, "duration": 4.401}, {"text": "accelerated", "start": 2782.38, "duration": 4.08}, {"text": "user-defined function that's operating", "start": 2784.02, "duration": 4.299}, {"text": "on our data frame", "start": 2786.46, "duration": 5.399}, {"text": "so in this case I'm defining this simple", "start": 2788.319, "duration": 6.54}, {"text": "function label mass and it's going to", "start": 2791.859, "duration": 6.72}, {"text": "take an atom code and return just the", "start": 2794.859, "duration": 7.641}, {"text": "mass and sort of a dictionary type thing", "start": 2798.579, "duration": 3.921}, {"text": "um", "start": 2803.079, "duration": 2.841}, {"text": "and applying that", "start": 2803.8, "duration": 5.22}, {"text": "user-defined function over our GPU data", "start": 2805.92, "duration": 5.58}, {"text": "frame is as simple as calling", "start": 2809.02, "duration": 5.28}, {"text": "gdf dot apply rows", "start": 2811.5, "duration": 4.56}, {"text": "and", "start": 2814.3, "duration": 5.94}, {"text": "give it my function label map label Mass", "start": 2816.06, "duration": 6.22}, {"text": "tell it which columns are coming in", "start": 2820.24, "duration": 4.8}, {"text": "which columns I'm going to use uh label", "start": 2822.28, "duration": 4.74}, {"text": "and then I pass a dictionary for the", "start": 2825.04, "duration": 4.26}, {"text": "outgoing columns and", "start": 2827.02, "duration": 4.5}, {"text": "um a dictionary for any extra keyword", "start": 2829.3, "duration": 4.86}, {"text": "arguments that are needed", "start": 2831.52, "duration": 5.28}, {"text": "and you can see applying this apply Rose", "start": 2834.16, "duration": 5.04}, {"text": "to my GPU accelerated data Frameworks as", "start": 2836.8, "duration": 4.799}, {"text": "intended so", "start": 2839.2, "duration": 4.32}, {"text": "um it's nice to have the extra", "start": 2841.599, "duration": 5.641}, {"text": "flexibility to do user-defined functions", "start": 2843.52, "duration": 6.599}, {"text": "apply rows Works hopefully as you're", "start": 2847.24, "duration": 5.94}, {"text": "familiar with in but in pandas and again", "start": 2850.119, "duration": 5.041}, {"text": "you just get to reap the rewards of", "start": 2853.18, "duration": 5.96}, {"text": "having GPU accelerated data frames", "start": 2855.16, "duration": 3.98}, {"text": "um", "start": 2859.96, "duration": 4.68}, {"text": "also provides a large set of the vector", "start": 2861.54, "duration": 5.5}, {"text": "functions so we're talking about you", "start": 2864.64, "duration": 6.74}, {"text": "know Max Min clipping absolute values", "start": 2867.04, "duration": 8.1}, {"text": "as we mentioned the ability to", "start": 2871.38, "duration": 8.02}, {"text": "um Define kernel functions and", "start": 2875.14, "duration": 7.56}, {"text": "um and and mapping that kernel function", "start": 2879.4, "duration": 6.32}, {"text": "with apply rows", "start": 2882.7, "duration": 3.02}, {"text": "you know then I mean the nice thing", "start": 2888.3, "duration": 4.539}, {"text": "about operating on data frames is we can", "start": 2890.5, "duration": 6.2}, {"text": "string together a series of operations", "start": 2892.839, "duration": 8.301}, {"text": "and very quickly achieve", "start": 2896.7, "duration": 4.44}, {"text": "um what we're after in in a relatively", "start": 2901.359, "duration": 4.26}, {"text": "small amount of syntax", "start": 2903.76, "duration": 5.48}, {"text": "so you know for example here I have this", "start": 2905.619, "duration": 6.541}, {"text": "CSV file with these", "start": 2909.24, "duration": 4.56}, {"text": "um", "start": 2912.16, "duration": 5.04}, {"text": "molecule names that identify what", "start": 2913.8, "duration": 4.779}, {"text": "molecule they are but of course the", "start": 2917.2, "duration": 3.72}, {"text": "molecule names are strings so I'm", "start": 2918.579, "duration": 3.961}, {"text": "splitting the string on the underscore", "start": 2920.92, "duration": 3.899}, {"text": "I'm taking the second argument and", "start": 2922.54, "duration": 4.92}, {"text": "interpreting that as an integer", "start": 2924.819, "duration": 4.981}, {"text": "and on the line with the comment hash by", "start": 2927.46, "duration": 6.08}, {"text": "molecule construct a hash out of that", "start": 2929.8, "duration": 9.539}, {"text": "integer and taking the mod mod 4 to", "start": 2933.54, "duration": 9.22}, {"text": "construct a test strain split so in you", "start": 2939.339, "duration": 6.681}, {"text": "know four or five lines of code", "start": 2942.76, "duration": 7.16}, {"text": "doing what would take me in in C", "start": 2946.02, "duration": 6.299}, {"text": "significantly more effort", "start": 2949.92, "duration": 7.26}, {"text": "and of course in as compared to pandas", "start": 2952.319, "duration": 8.02}, {"text": "get this done in GPU accelerated way and", "start": 2957.18, "duration": 5.32}, {"text": "have it take you know a quarter of the", "start": 2960.339, "duration": 4.76}, {"text": "time or less", "start": 2962.5, "duration": 2.599}, {"text": "2df", "start": 2966.7, "duration": 5.34}, {"text": "2ml which is the other major piece of", "start": 2968.22, "duration": 8.02}, {"text": "Rapids provides a handful of machine", "start": 2972.04, "duration": 6.24}, {"text": "learning of the most commonly used", "start": 2976.24, "duration": 3.68}, {"text": "machine learning", "start": 2978.28, "duration": 4.5}, {"text": "libraries and we're constantly adding", "start": 2979.92, "duration": 4.84}, {"text": "more algorithms so I'm not going to go", "start": 2982.78, "duration": 4.799}, {"text": "through all of these but I'll just", "start": 2984.76, "duration": 4.819}, {"text": "highlight a few", "start": 2987.579, "duration": 6.0}, {"text": "so for example kite we provide cool ml", "start": 2989.579, "duration": 6.181}, {"text": "provides K nearest Neighbors", "start": 2993.579, "duration": 3.961}, {"text": "supervised machine learning for", "start": 2995.76, "duration": 4.02}, {"text": "classification", "start": 2997.54, "duration": 6.779}, {"text": "DB scan unsupervised clustering k-means", "start": 2999.78, "duration": 6.28}, {"text": "clustering another unsupervised", "start": 3004.319, "duration": 4.581}, {"text": "algorithm for clustering singular value", "start": 3006.06, "duration": 5.519}, {"text": "decomposition okay so this is a matrix", "start": 3008.9, "duration": 7.0}, {"text": "factorization routine and in fact we", "start": 3011.579, "duration": 7.02}, {"text": "provide truncated singular value", "start": 3015.9, "duration": 7.14}, {"text": "decomposition so what's common the whole", "start": 3018.599, "duration": 7.141}, {"text": "in many cases the reason you're doing", "start": 3023.04, "duration": 4.86}, {"text": "singular value decomposition is because", "start": 3025.74, "duration": 4.379}, {"text": "you're trying to approximate that Matrix", "start": 3027.9, "duration": 8.54}, {"text": "M so M what SVD does is factorize M into", "start": 3030.119, "duration": 9.661}, {"text": "uh well it's showing you use Sigma and V", "start": 3036.44, "duration": 5.26}, {"text": "where what are the sigma is this", "start": 3039.78, "duration": 4.039}, {"text": "diagonal singular values and then you", "start": 3041.7, "duration": 5.52}, {"text": "approximate M by truncating the number", "start": 3043.819, "duration": 6.52}, {"text": "of singular values that you represent", "start": 3047.22, "duration": 6.42}, {"text": "um so uh that's the what we mean by", "start": 3050.339, "duration": 6.601}, {"text": "truncated uh SVD", "start": 3053.64, "duration": 6.54}, {"text": "principal component analysis", "start": 3056.94, "duration": 5.58}, {"text": "um everybody knows what this is widely", "start": 3060.18, "duration": 4.08}, {"text": "used for dimensionality reduction we're", "start": 3062.52, "duration": 4.86}, {"text": "really trying to understand the axes", "start": 3064.26, "duration": 5.28}, {"text": "that explain the most variance in our", "start": 3067.38, "duration": 3.959}, {"text": "data", "start": 3069.54, "duration": 3.539}, {"text": "um and then for in the case of", "start": 3071.339, "duration": 4.02}, {"text": "dimensionality reduction we ignore the", "start": 3073.079, "duration": 4.74}, {"text": "rest or we project into the into that", "start": 3075.359, "duration": 4.74}, {"text": "basis", "start": 3077.819, "duration": 7.141}, {"text": "um xgboost uh supervised decision tree", "start": 3080.099, "duration": 6.361}, {"text": "um", "start": 3084.96, "duration": 4.28}, {"text": "and as of version", "start": 3086.46, "duration": 6.48}, {"text": "13.0 a uh this is the complete list of", "start": 3089.24, "duration": 6.4}, {"text": "algorithms uh that we support So in", "start": 3092.94, "duration": 4.5}, {"text": "addition to the in addition to the", "start": 3095.64, "duration": 4.5}, {"text": "algorithms that I've mentioned we have t", "start": 3097.44, "duration": 5.34}, {"text": "Snee ordinary ordinary least squares", "start": 3100.14, "duration": 5.52}, {"text": "regression elastic net regression", "start": 3102.78, "duration": 5.12}, {"text": "logistic regression", "start": 3105.66, "duration": 5.24}, {"text": "optimization algorithms", "start": 3107.9, "duration": 7.959}, {"text": "such as uh uh stochastic radiant descent", "start": 3110.9, "duration": 8.38}, {"text": "uh random Forest uh classification and", "start": 3115.859, "duration": 7.441}, {"text": "regression support Vector machines uh", "start": 3119.28, "duration": 6.059}, {"text": "kelman filtering widely used in", "start": 3123.3, "duration": 4.019}, {"text": "Aerospace", "start": 3125.339, "duration": 4.681}, {"text": "um arima widely used in financial", "start": 3127.319, "duration": 6.061}, {"text": "services or Quant finance and we're", "start": 3130.02, "duration": 7.74}, {"text": "updating this list uh uh very regularly", "start": 3133.38, "duration": 6.42}, {"text": "and in fact", "start": 3137.76, "duration": 2.72}, {"text": "um", "start": 3139.8, "duration": 3.539}, {"text": "tomorrow this list could be extended so", "start": 3140.48, "duration": 5.2}, {"text": "uh be sure to keep up with what", "start": 3143.339, "duration": 5.041}, {"text": "algorithms if you're the algorithm of", "start": 3145.68, "duration": 5.7}, {"text": "your choice is not on here shoot me an", "start": 3148.38, "duration": 5.28}, {"text": "email and let me know we're always", "start": 3151.38, "duration": 4.5}, {"text": "interested in hearing what algorithms", "start": 3153.66, "duration": 3.84}, {"text": "people are using and providing that", "start": 3155.88, "duration": 3.9}, {"text": "feedback to the Rapids team and", "start": 3157.5, "duration": 4.92}, {"text": "hopefully get that algorithm implemented", "start": 3159.78, "duration": 5.039}, {"text": "in the next version or two and get a GPU", "start": 3162.42, "duration": 3.919}, {"text": "accelerated", "start": 3164.819, "duration": 4.561}, {"text": "last thing I'll mention is uh you should", "start": 3166.339, "duration": 5.561}, {"text": "certainly check out our container", "start": 3169.38, "duration": 6.86}, {"text": "repository we offer uh more than 50", "start": 3171.9, "duration": 7.679}, {"text": "containers that are optimized GPU", "start": 3176.24, "duration": 5.98}, {"text": "optimized these are containers for deep", "start": 3179.579, "duration": 5.641}, {"text": "learning machine learning and high", "start": 3182.22, "duration": 6.0}, {"text": "performance computing so certainly check", "start": 3185.22, "duration": 6.26}, {"text": "out our container repository at", "start": 3188.22, "duration": 5.24}, {"text": "ngc.nvidia.com", "start": 3191.48, "duration": 3.54}, {"text": "and", "start": 3193.46, "duration": 4.599}, {"text": "hopefully you'll find the application", "start": 3195.02, "duration": 5.559}, {"text": "container that you're looking for", "start": 3198.059, "duration": 4.741}, {"text": "with that I'll wrap up thank you very", "start": 3200.579, "duration": 3.661}, {"text": "much and I'd be happy to answer any", "start": 3202.8, "duration": 3.74}, {"text": "questions", "start": 3204.24, "duration": 2.3}, {"text": "thanks Avia there was a question in the", "start": 3206.76, "duration": 4.98}, {"text": "chat that was kindly answered by another", "start": 3209.64, "duration": 4.199}, {"text": "attendee but if you want to take a look", "start": 3211.74, "duration": 5.52}, {"text": "just to make sure it was can we launch", "start": 3213.839, "duration": 5.52}, {"text": "kernels with Max possible threads and", "start": 3217.26, "duration": 4.92}, {"text": "blocks for any task leaving some threads", "start": 3219.359, "duration": 5.421}, {"text": "idle", "start": 3222.18, "duration": 2.6}, {"text": "yeah", "start": 3225.8, "duration": 3.279}, {"text": "um so if I think about if I understand", "start": 3227.4, "duration": 3.659}, {"text": "the question", "start": 3229.079, "duration": 5.641}, {"text": "um can you have more threads than you", "start": 3231.059, "duration": 5.581}, {"text": "have work to do", "start": 3234.72, "duration": 4.8}, {"text": "um and the answer is yes definitely and", "start": 3236.64, "duration": 6.78}, {"text": "the way that that's typically handled is", "start": 3239.52, "duration": 6.12}, {"text": "by", "start": 3243.42, "duration": 6.36}, {"text": "um checking the bounds for you know your", "start": 3245.64, "duration": 7.08}, {"text": "the the the the the the array that you", "start": 3249.78, "duration": 4.62}, {"text": "want to perform work on", "start": 3252.72, "duration": 5.46}, {"text": "so say you have say my data array in", "start": 3254.4, "duration": 6.179}, {"text": "that example I showed", "start": 3258.18, "duration": 5.28}, {"text": "eight elements in there right because it", "start": 3260.579, "duration": 5.52}, {"text": "was just convenient we had two blocks", "start": 3263.46, "duration": 5.099}, {"text": "four threads per block and so that's", "start": 3266.099, "duration": 4.921}, {"text": "eight threads so I was showing eight", "start": 3268.559, "duration": 4.861}, {"text": "units of work to do but we could", "start": 3271.02, "duration": 4.38}, {"text": "certainly map that same launch", "start": 3273.42, "duration": 5.76}, {"text": "configuration to seven elements of work", "start": 3275.4, "duration": 6.419}, {"text": "to do and we would simply bounce check", "start": 3279.18, "duration": 5.639}, {"text": "to see you know is my thread index going", "start": 3281.819, "duration": 4.381}, {"text": "to map to a data array that doesn't", "start": 3284.819, "duration": 5.461}, {"text": "exist if so if I am out of bounds then", "start": 3286.2, "duration": 7.26}, {"text": "simply return don't do anything so", "start": 3290.28, "duration": 5.279}, {"text": "um that thread will be quote unquote", "start": 3293.46, "duration": 5.04}, {"text": "idle it just won't do anything and so", "start": 3295.559, "duration": 4.981}, {"text": "that's how we would handle a a thread", "start": 3298.5, "duration": 6.079}, {"text": "block mismatch like that very common", "start": 3300.54, "duration": 6.66}, {"text": "there was another one will Rapids work", "start": 3304.579, "duration": 5.26}, {"text": "on my GT 1030 and windows is there still", "start": 3307.2, "duration": 5.46}, {"text": "no support for NVIDIA cards uh in newer", "start": 3309.839, "duration": 6.98}, {"text": "Mac os's even for scientific purposes", "start": 3312.66, "duration": 4.159}, {"text": "um so the 10 30 uh we we", "start": 3319.98, "duration": 8.66}, {"text": "um", "start": 3326.579, "duration": 2.061}, {"text": "the the official answer is we support", "start": 3330.68, "duration": 7.06}, {"text": "Pascal Volta or higher architectures", "start": 3333.3, "duration": 5.66}, {"text": "um", "start": 3337.74, "duration": 6.42}, {"text": "and uh yeah you know unofficially your", "start": 3338.96, "duration": 7.599}, {"text": "mileage may vary you can try it and and", "start": 3344.16, "duration": 4.76}, {"text": "check", "start": 3346.559, "duration": 2.361}, {"text": "um", "start": 3349.26, "duration": 2.18}, {"text": "and the uh the Mac the Mac support I'll", "start": 3351.72, "duration": 5.099}, {"text": "have to I'll have to check on Mac", "start": 3355.14, "duration": 3.66}, {"text": "support I don't know that the answer off", "start": 3356.819, "duration": 5.661}, {"text": "to the off the top of my head for that", "start": 3358.8, "duration": 3.68}, {"text": "let's see some folks are asking about", "start": 3367.859, "duration": 3.781}, {"text": "how to self-mark attended attendance", "start": 3369.54, "duration": 3.48}, {"text": "I'll send that in an email to the", "start": 3371.64, "duration": 2.939}, {"text": "registrants and that'll that'll help", "start": 3373.02, "duration": 3.059}, {"text": "them", "start": 3374.579, "duration": 2.881}, {"text": "um okay", "start": 3376.079, "duration": 3.061}, {"text": "uh the one more question what is the", "start": 3377.46, "duration": 3.06}, {"text": "performance of number compared to open", "start": 3379.14, "duration": 5.82}, {"text": "ACC and Cuda in C C plus plus", "start": 3380.52, "duration": 6.66}, {"text": "oh that's tough", "start": 3384.96, "duration": 5.46}, {"text": "um it's tough to it's tough to compare", "start": 3387.18, "duration": 4.86}, {"text": "performance between the different", "start": 3390.42, "duration": 4.74}, {"text": "libraries so let's let's say open ACC", "start": 3392.04, "duration": 6.12}, {"text": "takuda", "start": 3395.16, "duration": 3.0}, {"text": "um", "start": 3398.64, "duration": 3.78}, {"text": "while this is not in general true", "start": 3399.3, "duration": 7.2}, {"text": "uh in many cases so what open ACC is", "start": 3402.42, "duration": 6.84}, {"text": "doing under the hood is taking a best", "start": 3406.5, "duration": 6.24}, {"text": "guess at what a compiled Cuda kernel", "start": 3409.26, "duration": 6.0}, {"text": "would look like a perfectly optimized", "start": 3412.74, "duration": 4.74}, {"text": "Cuda kernel would look like for the", "start": 3415.26, "duration": 4.2}, {"text": "algorithm that you're trying to paralyze", "start": 3417.48, "duration": 4.92}, {"text": "many cases it's right and if you were to", "start": 3419.46, "duration": 5.52}, {"text": "write your own handcrafted Cuda kernel", "start": 3422.4, "duration": 5.159}, {"text": "performance would be the same but", "start": 3424.98, "duration": 5.94}, {"text": "sometimes it's not quite as optimal as a", "start": 3427.559, "duration": 6.901}, {"text": "hand tune hand optimized Cuda kernel", "start": 3430.92, "duration": 6.54}, {"text": "um so the what you get with the", "start": 3434.46, "duration": 4.099}, {"text": "convenience", "start": 3437.46, "duration": 3.78}, {"text": "sometimes there's a little bit of a", "start": 3438.559, "duration": 4.06}, {"text": "penalty you could do a little bit better", "start": 3441.24, "duration": 3.78}, {"text": "if you hand crafted that that Cuda", "start": 3442.619, "duration": 3.96}, {"text": "kernel", "start": 3445.02, "duration": 3.36}, {"text": "um making the comparison", "start": 3446.579, "duration": 3.54}, {"text": "for", "start": 3448.38, "duration": 4.679}, {"text": "you know operations that we're doing in", "start": 3450.119, "duration": 6.661}, {"text": "Rapids uh to handcrafted Cuda I mean", "start": 3453.059, "duration": 7.081}, {"text": "everything in Rapids is a Cuda kernel", "start": 3456.78, "duration": 6.72}, {"text": "under the hood right there is C code", "start": 3460.14, "duration": 7.5}, {"text": "hand crafted C code under that", "start": 3463.5, "duration": 9.0}, {"text": "um uh python API uh so", "start": 3467.64, "duration": 7.86}, {"text": "I suppose the you know the answer there", "start": 3472.5, "duration": 5.04}, {"text": "is it's the same because it is it is", "start": 3475.5, "duration": 5.3}, {"text": "handcrafted Cuda code", "start": 3477.54, "duration": 3.26}, {"text": "okay I think that's it uh please send", "start": 3484.559, "duration": 5.221}, {"text": "some send some questions via email if", "start": 3487.5, "duration": 4.559}, {"text": "you still have some questions thank you", "start": 3489.78, "duration": 4.38}, {"text": "very much Abe for the presentation it", "start": 3492.059, "duration": 4.141}, {"text": "was excellent and thanks everyone for", "start": 3494.16, "duration": 4.74}, {"text": "joining bye thanks", "start": 3496.2, "duration": 5.3}, {"text": "so much", "start": 3498.9, "duration": 2.6}]