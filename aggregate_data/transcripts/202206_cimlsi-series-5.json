[{"text": "um yeah welcome back everybody so I will", "start": 0.32, "duration": 5.76}, {"text": "talk about GP Computing and um basically", "start": 2.76, "duration": 5.52}, {"text": "introduce you a little bit to you know", "start": 6.08, "duration": 4.679}, {"text": "what What GPU architecture we have how", "start": 8.28, "duration": 4.96}, {"text": "it looks like and what is the software", "start": 10.759, "duration": 4.641}, {"text": "infrastructure that we use in order", "start": 13.24, "duration": 6.56}, {"text": "to um you know execute code on on gpus", "start": 15.4, "duration": 6.2}, {"text": "and how you can can program a little bit", "start": 19.8, "duration": 3.36}, {"text": "give you a little bit of a background on", "start": 21.6, "duration": 3.36}, {"text": "that", "start": 23.16, "duration": 5.519}, {"text": "um so what what we'll cover is basically", "start": 24.96, "duration": 5.52}, {"text": "a little bit of Hardware overview", "start": 28.679, "duration": 5.841}, {"text": "you um just briefly uh touch on GPU", "start": 30.48, "duration": 6.68}, {"text": "accelerated software examples and then", "start": 34.52, "duration": 5.0}, {"text": "I'll show you a little bit on how to", "start": 37.16, "duration": 5.239}, {"text": "program gpus and finally you know we'll", "start": 39.52, "duration": 3.879}, {"text": "actually", "start": 42.399, "duration": 3.761}, {"text": "interactively um well you know you can", "start": 43.399, "duration": 4.361}, {"text": "do that you can follow information that", "start": 46.16, "duration": 4.52}, {"text": "I also uploaded to the GitHub repository", "start": 47.76, "duration": 5.88}, {"text": "just in the read me on how to access the", "start": 50.68, "duration": 7.64}, {"text": "expans GPU noes um run GPU drops I and", "start": 53.64, "duration": 6.559}, {"text": "develop GPU software so we will just", "start": 58.32, "duration": 5.199}, {"text": "compile some examples and and run", "start": 60.199, "duration": 5.641}, {"text": "those and", "start": 63.519, "duration": 5.361}, {"text": "so I I like to start this presentations", "start": 65.84, "duration": 5.76}, {"text": "you know asking about what is a GPU and", "start": 68.88, "duration": 5.12}, {"text": "you know it's basically an accelerator", "start": 71.6, "duration": 4.4}, {"text": "Hardware um that's a specialized", "start": 74.0, "duration": 3.92}, {"text": "Hardware component to speed up some", "start": 76.0, "duration": 5.2}, {"text": "aspect of a Computing workload and in", "start": 77.92, "duration": 7.12}, {"text": "the case of gpus it is um you know was", "start": 81.2, "duration": 6.2}, {"text": "developed initially entirely to Rend the", "start": 85.04, "duration": 5.8}, {"text": "computer Graphics right and", "start": 87.4, "duration": 6.28}, {"text": "so you see some of the older gpus over", "start": 90.84, "duration": 5.84}, {"text": "here and and this one here in 2008 is", "start": 93.68, "duration": 5.32}, {"text": "one of the first gpus that was actually", "start": 96.68, "duration": 6.56}, {"text": "um easily generally programmable for for", "start": 99.0, "duration": 6.56}, {"text": "general purpose computations and so all", "start": 103.24, "duration": 4.0}, {"text": "that development that led up there was", "start": 105.56, "duration": 4.879}, {"text": "driven by a big big um $150 billion", "start": 107.24, "duration": 5.839}, {"text": "gaming industry um that's why we have", "start": 110.439, "duration": 5.761}, {"text": "you know a lot of R&D dollars spent in", "start": 113.079, "duration": 5.241}, {"text": "that space and that translates basically", "start": 116.2, "duration": 5.08}, {"text": "into development sta gave us very very", "start": 118.32, "duration": 6.28}, {"text": "um powerful Hardware that now we can use", "start": 121.28, "duration": 6.04}, {"text": "um also for data center gpus so nowadays", "start": 124.6, "duration": 5.079}, {"text": "actually the market for data center gpus", "start": 127.32, "duration": 5.44}, {"text": "is also pretty big and it's a sizable um", "start": 129.679, "duration": 6.2}, {"text": "chunk of revenue for companies like", "start": 132.76, "duration": 7.08}, {"text": "Nvidia um so mod gpus are programmable", "start": 135.879, "duration": 6.08}, {"text": "for general", "start": 139.84, "duration": 4.479}, {"text": "purpose um but you know they differ", "start": 141.959, "duration": 4.28}, {"text": "obviously from CPUs so they do have a", "start": 144.319, "duration": 4.681}, {"text": "simplified Core Design um with limited", "start": 146.239, "duration": 4.441}, {"text": "architectural features will touch on", "start": 149.0, "duration": 4.519}, {"text": "that um and are partially exposed to", "start": 150.68, "duration": 5.04}, {"text": "memory hierarchy so they it's it's", "start": 153.519, "duration": 5.681}, {"text": "relatively easy nowadays to program gpus", "start": 155.72, "duration": 5.439}, {"text": "and in particular you know if you use", "start": 159.2, "duration": 3.8}, {"text": "software Frameworks that could help you", "start": 161.159, "duration": 5.041}, {"text": "with that um I'll show you some of those", "start": 163.0, "duration": 4.68}, {"text": "um but there are still some things you", "start": 166.2, "duration": 2.88}, {"text": "need to keep in mind so it's a good idea", "start": 167.68, "duration": 4.76}, {"text": "to understand how the hardware works and", "start": 169.08, "duration": 4.799}, {"text": "going back to why is there such an", "start": 172.44, "duration": 4.12}, {"text": "interesting gpus is you're probably", "start": 173.879, "duration": 4.601}, {"text": "familiar with M", "start": 176.56, "duration": 4.0}, {"text": "law um", "start": 178.48, "duration": 3.64}, {"text": "you know that the transistor count in", "start": 180.56, "duration": 3.48}, {"text": "integrated circuits doubles about every", "start": 182.12, "duration": 5.44}, {"text": "two years and that exponential growth is", "start": 184.04, "duration": 6.119}, {"text": "actually still true so this is not fully", "start": 187.56, "duration": 4.399}, {"text": "up to date so it stopped somewhere here", "start": 190.159, "duration": 3.561}, {"text": "this data that that I took from this", "start": 191.959, "duration": 4.521}, {"text": "website in 2018 but essentially what you", "start": 193.72, "duration": 5.72}, {"text": "see here is is still true you see the", "start": 196.48, "duration": 5.399}, {"text": "number of transistors still grows", "start": 199.44, "duration": 4.96}, {"text": "exponentially however um the single", "start": 201.879, "duration": 4.841}, {"text": "threat performance is not going up very", "start": 204.4, "duration": 4.039}, {"text": "much anymore so you know since the mid", "start": 206.72, "duration": 3.92}, {"text": "2000s the clock frequency are sort of", "start": 208.439, "duration": 5.201}, {"text": "constant um the C single CPU core", "start": 210.64, "duration": 5.08}, {"text": "performance is roughly constant it's not", "start": 213.64, "duration": 3.56}, {"text": "not true but you know has an increased", "start": 215.72, "duration": 3.92}, {"text": "exponentially anymore and so the main", "start": 217.2, "duration": 4.2}, {"text": "performance increas is actually due to", "start": 219.64, "duration": 4.12}, {"text": "CPU course per processor and that's what", "start": 221.4, "duration": 5.64}, {"text": "you see here that um the number of", "start": 223.76, "duration": 5.839}, {"text": "logical course that we have in CPUs um", "start": 227.04, "duration": 5.0}, {"text": "started to rise right so now nowadays we", "start": 229.599, "duration": 6.2}, {"text": "have these 20 course CPS 32 core CPS and", "start": 232.04, "duration": 7.36}, {"text": "so on um what that means is you know in", "start": 235.799, "duration": 6.121}, {"text": "the past we could wait two years and any", "start": 239.4, "duration": 3.88}, {"text": "code that we wrote you know would", "start": 241.92, "duration": 3.2}, {"text": "basically run twice as fast and that's", "start": 243.28, "duration": 3.519}, {"text": "not true anymore so you really have to", "start": 245.12, "duration": 5.839}, {"text": "write parallel code and um in the case", "start": 246.799, "duration": 7.28}, {"text": "of gpus is so-called massively parallel", "start": 250.959, "duration": 5.96}, {"text": "code because we have actually um many", "start": 254.079, "duration": 5.201}, {"text": "many more compute cores or or compute", "start": 256.919, "duration": 6.881}, {"text": "units than um available on on", "start": 259.28, "duration": 7.68}, {"text": "CPUs um if you look at this slide", "start": 263.8, "duration": 7.839}, {"text": "here um there is", "start": 266.96, "duration": 7.76}, {"text": "uh a a a a plot on the left and on the", "start": 271.639, "duration": 5.0}, {"text": "right for the difference between those", "start": 274.72, "duration": 4.12}, {"text": "plots is let me check so these are", "start": 276.639, "duration": 4.12}, {"text": "single Precision so that's 32bit", "start": 278.84, "duration": 3.68}, {"text": "floating Point performance and double", "start": 280.759, "duration": 4.601}, {"text": "Precision that's 64 bit floating Point", "start": 282.52, "duration": 5.119}, {"text": "performance um those graphs looks look", "start": 285.36, "duration": 4.96}, {"text": "very similar so you know we basically", "start": 287.639, "duration": 5.361}, {"text": "can discuss just one of those and you", "start": 290.32, "duration": 4.719}, {"text": "know the take-home messages if you look", "start": 293.0, "duration": 5.12}, {"text": "at CPUs and you know state-ofthe-art", "start": 295.039, "duration": 5.641}, {"text": "CPUs um you know the floating Point", "start": 298.12, "duration": 4.799}, {"text": "performance is significantly lower than", "start": 300.68, "duration": 6.6}, {"text": "that of um um data center GPS um well", "start": 302.919, "duration": 5.601}, {"text": "the difference the main difference here", "start": 307.28, "duration": 3.88}, {"text": "is you know these are gaming gpus and so", "start": 308.52, "duration": 5.119}, {"text": "relatively cheap gpus and and on those", "start": 311.16, "duration": 5.24}, {"text": "you get a very high 32bit floating Point", "start": 313.639, "duration": 4.641}, {"text": "performance if you want to have 64-bit", "start": 316.4, "duration": 3.28}, {"text": "floating Point", "start": 318.28, "duration": 3.72}, {"text": "performance um you have to go with these", "start": 319.68, "duration": 4.2}, {"text": "data center gpus that are significantly", "start": 322.0, "duration": 4.199}, {"text": "more expensive so they they are quite", "start": 323.88, "duration": 5.4}, {"text": "expensive but um you know the raw", "start": 326.199, "duration": 5.28}, {"text": "computer performance is much higher than", "start": 329.28, "duration": 4.08}, {"text": "than on CPUs and that's that's why", "start": 331.479, "duration": 3.56}, {"text": "people are interested and that's why you", "start": 333.36, "duration": 3.48}, {"text": "know there's a lot of success with", "start": 335.039, "duration": 4.521}, {"text": "gpus in high performance", "start": 336.84, "duration": 5.76}, {"text": "Computing um you know the floating Point", "start": 339.56, "duration": 5.4}, {"text": "performance is not everything um if you", "start": 342.6, "duration": 5.879}, {"text": "look on the left plot here um that's a", "start": 344.96, "duration": 6.4}, {"text": "plot of the memory bandwidth between you", "start": 348.479, "duration": 5.241}, {"text": "know what is the the ram so the memory", "start": 351.36, "duration": 5.679}, {"text": "that you have on a on a on a CPU and a", "start": 353.72, "duration": 6.52}, {"text": "processor that's plotted here for INT", "start": 357.039, "duration": 6.921}, {"text": "CPUs um and the memory the ram that you", "start": 360.24, "duration": 7.079}, {"text": "have on a GPU right so how fast can you", "start": 363.96, "duration": 6.6}, {"text": "get data basically from Ram to the CPU", "start": 367.319, "duration": 5.681}, {"text": "or for compute right or from from the", "start": 370.56, "duration": 4.72}, {"text": "memory on the GPU to the GPU processor", "start": 373.0, "duration": 6.199}, {"text": "to do some computer and why is that", "start": 375.28, "duration": 6.759}, {"text": "important it's important because many", "start": 379.199, "duration": 5.4}, {"text": "algorithms and you know um software", "start": 382.039, "duration": 5.481}, {"text": "implementations of algorithms they have", "start": 384.599, "duration": 4.961}, {"text": "they are actually due to the high", "start": 387.52, "duration": 4.079}, {"text": "loading point performance they're not", "start": 389.56, "duration": 3.88}, {"text": "not actually compute bound anymore but", "start": 391.599, "duration": 3.961}, {"text": "they're actually limited by how quickly", "start": 393.44, "duration": 4.84}, {"text": "you can move the data from memory to the", "start": 395.56, "duration": 5.0}, {"text": "CPU or to the GPU processor for", "start": 398.28, "duration": 6.24}, {"text": "computing right and or store it back so", "start": 400.56, "duration": 5.8}, {"text": "you know the higher the memory bandwidth", "start": 404.52, "duration": 3.64}, {"text": "you know the higher performance in this", "start": 406.36, "duration": 4.119}, {"text": "case um for your application and you can", "start": 408.16, "duration": 5.039}, {"text": "see that um gpus have a significantly", "start": 410.479, "duration": 6.801}, {"text": "higher memory per um bandwidth than than", "start": 413.199, "duration": 6.641}, {"text": "CPUs so you can Shuffle much more data", "start": 417.28, "duration": 5.479}, {"text": "uh in a given uh uh amount of", "start": 419.84, "duration": 7.12}, {"text": "time and finally if you you know run a", "start": 422.759, "duration": 5.84}, {"text": "data center even if you're at home and", "start": 426.96, "duration": 5.359}, {"text": "you you run a a a computer 247 you know", "start": 428.599, "duration": 5.801}, {"text": "you to play a computer game 247 you've", "start": 432.319, "duration": 3.56}, {"text": "notice something on your electricity", "start": 434.4, "duration": 4.4}, {"text": "bill so you know that it's important to", "start": 435.879, "duration": 6.081}, {"text": "also see how much power these devices", "start": 438.8, "duration": 7.239}, {"text": "draw and um you know a typical CPU will", "start": 441.96, "duration": 6.239}, {"text": "draw somewhere you know at least a", "start": 446.039, "duration": 5.521}, {"text": "single socket like uh 150 watt um and", "start": 448.199, "duration": 6.4}, {"text": "gpus you know they they can draw depends", "start": 451.56, "duration": 5.96}, {"text": "really so the maximum um", "start": 454.599, "duration": 7.28}, {"text": "TDP um is typically around 250 to 350", "start": 457.52, "duration": 7.6}, {"text": "watt depending on what type of GPU um um", "start": 461.879, "duration": 7.04}, {"text": "you know you you have in your system so", "start": 465.12, "duration": 6.32}, {"text": "um yeah you know a fair comparison might", "start": 468.919, "duration": 4.801}, {"text": "be a single GPU to one to two socket CPU", "start": 471.44, "duration": 3.92}, {"text": "server depending on the type of CPU or", "start": 473.72, "duration": 3.52}, {"text": "GPU that you have in your", "start": 475.36, "duration": 4.92}, {"text": "system um and and this year's an", "start": 477.24, "duration": 6.399}, {"text": "example of uh Hardware that was top of", "start": 480.28, "duration": 6.44}, {"text": "the line in 2018 so now that's a while", "start": 483.639, "duration": 6.28}, {"text": "ago but um that comparison is in here", "start": 486.72, "duration": 5.439}, {"text": "because um you know expans is a few", "start": 489.919, "duration": 4.441}, {"text": "years old now already and we have Tesla", "start": 492.159, "duration": 6.48}, {"text": "v00 um gpus in expands right um so", "start": 494.36, "duration": 6.119}, {"text": "actually each node has four gpus I'll", "start": 498.639, "duration": 5.081}, {"text": "show a little bit more about that um but", "start": 500.479, "duration": 4.801}, {"text": "that's an example where I say okay you", "start": 503.72, "duration": 5.4}, {"text": "have two two uh b00 gpus and you had two", "start": 505.28, "duration": 8.8}, {"text": "top of line um Intel uh uh processors at", "start": 509.12, "duration": 7.279}, {"text": "the time and you can see you know what", "start": 514.08, "duration": 5.12}, {"text": "what be the peak um so DP stands for", "start": 516.399, "duration": 4.801}, {"text": "64-bit so double Precision floating", "start": 519.2, "duration": 4.24}, {"text": "Point performance single Precision", "start": 521.2, "duration": 3.88}, {"text": "floating Point performance and you know", "start": 523.44, "duration": 3.64}, {"text": "you can see that you have a much higher", "start": 525.08, "duration": 5.199}, {"text": "performance with the gpus um and there's", "start": 527.08, "duration": 4.64}, {"text": "something called half Precision that's", "start": 530.279, "duration": 4.201}, {"text": "actually um 16 bit um that's something", "start": 531.72, "duration": 5.36}, {"text": "that's not natively available in in CPUs", "start": 534.48, "duration": 4.0}, {"text": "but if you can get away with that and", "start": 537.08, "duration": 2.879}, {"text": "you know some machine learn", "start": 538.48, "duration": 3.359}, {"text": "applications and or deep learning", "start": 539.959, "duration": 4.241}, {"text": "applications that's possible", "start": 541.839, "duration": 4.841}, {"text": "um you know you might even write your", "start": 544.2, "duration": 4.319}, {"text": "own code for other applications but you", "start": 546.68, "duration": 4.32}, {"text": "have to be very careful that the", "start": 548.519, "duration": 5.76}, {"text": "the um accuracy of of your simulation", "start": 551.0, "duration": 5.519}, {"text": "for instance you know is not negatively", "start": 554.279, "duration": 4.201}, {"text": "affected by a limited Precision that", "start": 556.519, "duration": 4.721}, {"text": "that you're using um if you can do that", "start": 558.48, "duration": 4.68}, {"text": "you get like you know really really high", "start": 561.24, "duration": 5.159}, {"text": "um um uh compute", "start": 563.16, "duration": 5.919}, {"text": "performance and the there you see the", "start": 566.399, "duration": 4.641}, {"text": "difference in the peak memory bandwidth", "start": 569.079, "duration": 4.361}, {"text": "to the ram right um it's significantly", "start": 571.04, "duration": 3.52}, {"text": "higher to the", "start": 573.44, "duration": 4.079}, {"text": "gpus and however you have to take", "start": 574.56, "duration": 4.839}, {"text": "something else into account um and and", "start": 577.519, "duration": 3.32}, {"text": "that depends a little bit on the system", "start": 579.399, "duration": 5.641}, {"text": "you on um on expans you know the the uh", "start": 580.839, "duration": 7.56}, {"text": "gpus they are um I'm sitting on a PCI", "start": 585.04, "duration": 5.479}, {"text": "Express bus so the data needs to go", "start": 588.399, "duration": 4.56}, {"text": "through the PCI Express Bus and that's a", "start": 590.519, "duration": 4.161}, {"text": "significant autom so if you have a large", "start": 592.959, "duration": 4.521}, {"text": "amount of data that is sitting on your", "start": 594.68, "duration": 6.56}, {"text": "hard drive you have to read that in", "start": 597.48, "duration": 6.599}, {"text": "right but then you also have to or or", "start": 601.24, "duration": 5.159}, {"text": "you generate it on the fly or or you", "start": 604.079, "duration": 3.681}, {"text": "retrieve it from", "start": 606.399, "duration": 3.401}, {"text": "anywhere if you want to process it on", "start": 607.76, "duration": 3.88}, {"text": "the GPU you have to you know send it", "start": 609.8, "duration": 3.56}, {"text": "through that PCI Express bus from the", "start": 611.64, "duration": 4.36}, {"text": "CPU Ram to the GPU and you know that can", "start": 613.36, "duration": 4.36}, {"text": "be slow in a bottleneck so if you don't", "start": 616.0, "duration": 4.519}, {"text": "do enough compute per data element on", "start": 617.72, "duration": 5.72}, {"text": "the on the GPU then it will be actually", "start": 620.519, "duration": 4.521}, {"text": "faster to just do the processing on a", "start": 623.44, "duration": 3.639}, {"text": "CPU so those are a few things that you", "start": 625.04, "duration": 5.68}, {"text": "know you always have to keep in mind and", "start": 627.079, "duration": 4.841}, {"text": "right so this would be the power", "start": 630.72, "duration": 2.72}, {"text": "consumption and the purchase cost you", "start": 631.92, "duration": 4.52}, {"text": "know in this case uh you know was", "start": 633.44, "duration": 4.839}, {"text": "equivalent so if you go out nowadays I", "start": 636.44, "duration": 3.88}, {"text": "guess you know you buy a state-ofthe-art", "start": 638.279, "duration": 4.68}, {"text": "you know a100 GPU it's probably in the", "start": 640.32, "duration": 6.16}, {"text": "same um ballpack I don't know the exact", "start": 642.959, "duration": 6.32}, {"text": "exact numbers but you know similar also", "start": 646.48, "duration": 4.919}, {"text": "from other vendors if you would buy a GP", "start": 649.279, "duration": 3.041}, {"text": "from", "start": 651.399, "duration": 4.44}, {"text": "AMD um with you know they have also high", "start": 652.32, "duration": 5.079}, {"text": "performance gpus probably with a", "start": 655.839, "duration": 3.041}, {"text": "software stack that I would say is not", "start": 657.399, "duration": 2.401}, {"text": "as", "start": 658.88, "duration": 2.16}, {"text": "as complete as", "start": 659.8, "duration": 3.12}, {"text": "invidious um the question is you know", "start": 661.04, "duration": 3.359}, {"text": "you write code you put a lot of effort", "start": 662.92, "duration": 4.52}, {"text": "into it is a portable and you know in", "start": 664.399, "duration": 6.321}, {"text": "some sense yes if you", "start": 667.44, "duration": 6.0}, {"text": "use you know code that basically", "start": 670.72, "duration": 5.44}, {"text": "compiles also for other hardw and you", "start": 673.44, "duration": 4.199}, {"text": "can achieve that if you were to use open", "start": 676.16, "duration": 3.56}, {"text": "CL or open ACC if it's you know a", "start": 677.639, "duration": 4.801}, {"text": "compiled code um otherwise often you can", "start": 679.72, "duration": 4.48}, {"text": "use libraries and they they're easily", "start": 682.44, "duration": 3.36}, {"text": "replaceable than the equivalent", "start": 684.2, "duration": 3.759}, {"text": "libraries for other systems so you know", "start": 685.8, "duration": 3.8}, {"text": "I would say in noway you can write", "start": 687.959, "duration": 3.921}, {"text": "portable code on", "start": 689.6, "duration": 5.28}, {"text": "GPS", "start": 691.88, "duration": 3.0}, {"text": "um now now to give you a little bit of a", "start": 696.32, "duration": 5.959}, {"text": "perspective um this was 2001 the number", "start": 698.519, "duration": 6.601}, {"text": "one top 500 machine was at Lawrence", "start": 702.279, "duration": 5.641}, {"text": "liore National Lab as white and it had a", "start": 705.12, "duration": 5.159}, {"text": "peak floating Point performance of 12", "start": 707.92, "duration": 7.159}, {"text": "Tera flops okay machine cost 110 million", "start": 710.279, "duration": 7.521}, {"text": "us um that was 20 years ago so it would", "start": 715.079, "duration": 4.88}, {"text": "be much more nowadays um", "start": 717.8, "duration": 5.68}, {"text": "um if you compare that to expanse um you", "start": 719.959, "duration": 5.88}, {"text": "know expans is much smaller so this", "start": 723.48, "duration": 5.08}, {"text": "thing was filling many many more RS than", "start": 725.839, "duration": 5.0}, {"text": "what what we have in expans you know we", "start": 728.56, "duration": 5.36}, {"text": "have on expans we have 3.4 peda flops um", "start": 730.839, "duration": 6.401}, {"text": "you know that's like um three orders of", "start": 733.92, "duration": 5.96}, {"text": "magnitude faster just on the CPUs and", "start": 737.24, "duration": 5.68}, {"text": "then we have 52 GPU nodes and each of", "start": 739.88, "duration": 5.24}, {"text": "those GPU notes has four of these um", "start": 742.92, "duration": 6.88}, {"text": "Nvidia v00 gpus and so you know in", "start": 745.12, "duration": 8.36}, {"text": "in terms of um double Precision floating", "start": 749.8, "duration": 5.2}, {"text": "Point performance for all the gpus", "start": 753.48, "duration": 5.12}, {"text": "that's 1.6 ped flops just for the um", "start": 755.0, "duration": 6.639}, {"text": "gpus in addition to the you know CPU um", "start": 758.6, "duration": 4.84}, {"text": "um performance that we have and that", "start": 761.639, "duration": 5.121}, {"text": "Hardware cost only10 million us now in", "start": 763.44, "duration": 5.72}, {"text": "2020 um you know there's new gpus coming", "start": 766.76, "duration": 6.0}, {"text": "out and so on um you and you know the", "start": 769.16, "duration": 5.08}, {"text": "price goes up and down but let's say you", "start": 772.76, "duration": 5.24}, {"text": "have a about four to $5,000 budget um", "start": 774.24, "duration": 5.44}, {"text": "you you can buy", "start": 778.0, "duration": 3.76}, {"text": "Hardware in a desktop workstation that", "start": 779.68, "duration": 4.88}, {"text": "gives you at least a single Precision so", "start": 781.76, "duration": 6.6}, {"text": "um 32bit floating Point um operations", "start": 784.56, "duration": 7.839}, {"text": "119 they say about 100 all 100 Tera", "start": 788.36, "duration": 7.12}, {"text": "flops um performance right or you say", "start": 792.399, "duration": 6.68}, {"text": "120 um that's an order of magnitude more", "start": 795.48, "duration": 5.919}, {"text": "than that entire machine room 21 years", "start": 799.079, "duration": 4.081}, {"text": "ago so we have a lot of compute power at", "start": 801.399, "duration": 5.321}, {"text": "your disposal um um that's that's really", "start": 803.16, "duration": 6.4}, {"text": "exciting I think and and um you should", "start": 806.72, "duration": 6.0}, {"text": "make use of it and you know lots of", "start": 809.56, "duration": 4.6}, {"text": "great science is going to come out of", "start": 812.72, "duration": 3.72}, {"text": "that I'm", "start": 814.16, "duration": 2.28}, {"text": "sure um right", "start": 816.8, "duration": 6.56}, {"text": "so so what's the catch you know um you", "start": 819.519, "duration": 5.601}, {"text": "know you want to use gpus and the", "start": 823.36, "duration": 4.039}, {"text": "manager comes and tells you you", "start": 825.12, "duration": 4.92}, {"text": "know I did my part by reading about gpus", "start": 827.399, "duration": 3.841}, {"text": "in a trade Journal now you do the", "start": 830.04, "duration": 3.159}, {"text": "software part and then he comes back and", "start": 831.24, "duration": 4.0}, {"text": "you part taking so long so it really", "start": 833.199, "duration": 4.521}, {"text": "depends where you are and how you have", "start": 835.24, "duration": 4.399}, {"text": "to write your code um", "start": 837.72, "duration": 4.039}, {"text": "if you actually really have to deal with", "start": 839.639, "duration": 5.961}, {"text": "a um um writing the GPU code yourself as", "start": 841.759, "duration": 5.76}, {"text": "opposed to just using libraries or", "start": 845.6, "duration": 3.799}, {"text": "Frameworks to implement that then it can", "start": 847.519, "duration": 4.721}, {"text": "be quite complex actually right um so if", "start": 849.399, "duration": 5.961}, {"text": "you compare GPU and CPUs and this", "start": 852.24, "duration": 6.279}, {"text": "diagram here is schematically just um", "start": 855.36, "duration": 5.0}, {"text": "you know the real estate the space that", "start": 858.519, "duration": 4.32}, {"text": "you have on the Silicon chip of of a CPU", "start": 860.36, "duration": 5.719}, {"text": "and a GPU processor so in a CPU you have", "start": 862.839, "duration": 4.761}, {"text": "a lot of you know", "start": 866.079, "duration": 3.801}, {"text": "control um", "start": 867.6, "duration": 4.72}, {"text": "Hardware um and then a few arithmetic", "start": 869.88, "duration": 4.24}, {"text": "logical units that do you know the the", "start": 872.32, "duration": 3.48}, {"text": "computations and you have a lot of cache", "start": 874.12, "duration": 5.519}, {"text": "memory that takes care um you know of of", "start": 875.8, "duration": 6.76}, {"text": "um loading and storing memory quite", "start": 879.639, "duration": 5.56}, {"text": "quite efficiently right improving", "start": 882.56, "duration": 4.68}, {"text": "getting over that barrier of that memory", "start": 885.199, "duration": 4.281}, {"text": "bandwidth limitations effectively by", "start": 887.24, "duration": 4.8}, {"text": "reusing data that is cached closely to", "start": 889.48, "duration": 4.08}, {"text": "the CPU and of course you have to", "start": 892.04, "duration": 3.08}, {"text": "program a little bit that but there's a", "start": 893.56, "duration": 4.8}, {"text": "lot of cach man gpus are very different", "start": 895.12, "duration": 5.0}, {"text": "instead you have thousands of simplistic", "start": 898.36, "duration": 2.64}, {"text": "compute", "start": 900.12, "duration": 3.24}, {"text": "cores uh these are packaged into a few", "start": 901.0, "duration": 4.12}, {"text": "multiprocessors so there's usually like", "start": 903.36, "duration": 3.719}, {"text": "64 cores", "start": 905.12, "duration": 5.0}, {"text": "in you know processing elements and each", "start": 907.079, "duration": 4.721}, {"text": "multiprocessor and there's on the order", "start": 910.12, "duration": 4.079}, {"text": "of 100 multiprocessors on a GPU", "start": 911.8, "duration": 5.839}, {"text": "depending on the GPU that that you buy", "start": 914.199, "duration": 6.88}, {"text": "and so there's much less control um", "start": 917.639, "duration": 5.801}, {"text": "Hardware uh and cach so you have to", "start": 921.079, "duration": 4.921}, {"text": "manage that and keep that in in in mind", "start": 923.44, "duration": 4.8}, {"text": "the other thing is you know we heard", "start": 926.0, "duration": 4.04}, {"text": "about MPI", "start": 928.24, "duration": 4.399}, {"text": "and we heard about open MP um threading", "start": 930.04, "duration": 4.039}, {"text": "effect effectively these threats you", "start": 932.639, "duration": 2.721}, {"text": "know on a CPU they can work", "start": 934.079, "duration": 4.281}, {"text": "independently of each other right um", "start": 935.36, "duration": 6.0}, {"text": "that's not the case on the GPU for each", "start": 938.36, "duration": 5.2}, {"text": "multiprocessor um they operate in lock", "start": 941.36, "duration": 3.56}, {"text": "steps so they need to do the same", "start": 943.56, "duration": 3.759}, {"text": "operation at the same time um which", "start": 944.92, "duration": 4.719}, {"text": "means you know you have um what is a", "start": 947.319, "duration": 4.08}, {"text": "data parallel computation you need to", "start": 949.639, "duration": 3.601}, {"text": "write your algorithms in such a way that", "start": 951.399, "duration": 3.321}, {"text": "they can you know the different", "start": 953.24, "duration": 5.079}, {"text": "processing elements can can uh work", "start": 954.72, "duration": 5.239}, {"text": "different threats", "start": 958.319, "duration": 3.561}, {"text": "um can work on the same instructions at", "start": 959.959, "duration": 6.36}, {"text": "the same time and well you can you can", "start": 961.88, "duration": 6.0}, {"text": "uh make use of vectorized loads in", "start": 966.319, "duration": 4.801}, {"text": "stores and you sort of like there's not", "start": 967.88, "duration": 4.56}, {"text": "it's not as bad as it used to be to", "start": 971.12, "duration": 2.92}, {"text": "manage memory hierarchy but you need to", "start": 972.44, "duration": 5.639}, {"text": "be aware of it and um this is again you", "start": 974.04, "duration": 7.68}, {"text": "know historically this is uh I believe", "start": 978.079, "duration": 6.401}, {"text": "Tesla T10 I think that was the first or", "start": 981.72, "duration": 4.359}, {"text": "at least one of the earliest um data", "start": 984.48, "duration": 4.52}, {"text": "center gpus that Nvidia was selling um", "start": 986.079, "duration": 5.76}, {"text": "um so that was in", "start": 989.0, "duration": 7.639}, {"text": "2009 and that had only 240 um um", "start": 991.839, "duration": 7.68}, {"text": "processing course uh or 30 double", "start": 996.639, "duration": 5.361}, {"text": "Precision processing course and the", "start": 999.519, "duration": 3.921}, {"text": "reason I'm showing this is because", "start": 1002.0, "duration": 3.04}, {"text": "schematically it still looks a little", "start": 1003.44, "duration": 4.12}, {"text": "bit like this um so you know the broad", "start": 1005.04, "duration": 4.76}, {"text": "view hasn't changed a lot so you have", "start": 1007.56, "duration": 4.399}, {"text": "these multiprocessors in this case", "start": 1009.8, "duration": 5.44}, {"text": "there's like um I don't know one two", "start": 1011.959, "duration": 5.521}, {"text": "three four five 6 S 8 nine 10", "start": 1015.24, "duration": 3.76}, {"text": "multiprocessors", "start": 1017.48, "duration": 3.24}, {"text": "and this schem magic and you know see", "start": 1019.0, "duration": 5.36}, {"text": "each of those processors has now um or", "start": 1020.72, "duration": 5.68}, {"text": "you know multiprocessors has one two", "start": 1024.36, "duration": 4.64}, {"text": "three four 5 six seven eight", "start": 1026.4, "duration": 6.08}, {"text": "um um single Precision", "start": 1029.0, "duration": 6.0}, {"text": "units um you know that's not what they", "start": 1032.48, "duration": 3.68}, {"text": "had but you know this is just for", "start": 1035.0, "duration": 2.919}, {"text": "schematically because you can't put too", "start": 1036.16, "duration": 4.48}, {"text": "much onto this", "start": 1037.919, "duration": 5.4}, {"text": "um um schematic here otherwise you", "start": 1040.64, "duration": 5.039}, {"text": "wouldn't Reed very well um then there's", "start": 1043.319, "duration": 5.201}, {"text": "some instruction cache and data cache", "start": 1045.679, "duration": 4.36}, {"text": "and", "start": 1048.52, "duration": 4.159}, {"text": "um there's shared memory that you can", "start": 1050.039, "duration": 5.401}, {"text": "manually manage um it's like man", "start": 1052.679, "duration": 6.081}, {"text": "manually um handled handled um cash", "start": 1055.44, "duration": 4.72}, {"text": "space effect", "start": 1058.76, "duration": 3.32}, {"text": "effectively and then there's this", "start": 1060.16, "duration": 4.96}, {"text": "multi-thread issuer that you know", "start": 1062.08, "duration": 4.839}, {"text": "automatically launches the threats for", "start": 1065.12, "duration": 4.04}, {"text": "you based on the on the API that you're", "start": 1066.919, "duration": 5.561}, {"text": "using for for NVIDIA that's secter", "start": 1069.16, "duration": 6.36}, {"text": "API and you know it still looks the same", "start": 1072.48, "duration": 5.48}, {"text": "so you have to program with this concept", "start": 1075.52, "duration": 3.48}, {"text": "in mind that you have these", "start": 1077.96, "duration": 2.839}, {"text": "multiprocessors and all these processing", "start": 1079.0, "duration": 3.039}, {"text": "units that are on each of those", "start": 1080.799, "duration": 2.88}, {"text": "multiprocessors they're operating lock", "start": 1082.039, "duration": 2.921}, {"text": "step so they need to do the same", "start": 1083.679, "duration": 3.721}, {"text": "operation at the same time otherwise the", "start": 1084.96, "duration": 3.719}, {"text": "operation gets", "start": 1087.4, "duration": 3.56}, {"text": "serialized and you know One Core would", "start": 1088.679, "duration": 4.36}, {"text": "do an operation and the other compute", "start": 1090.96, "duration": 6.0}, {"text": "cor here would do nothing at the same", "start": 1093.039, "duration": 7.52}, {"text": "time um now there's something new and", "start": 1096.96, "duration": 5.68}, {"text": "interesting that that in particular is", "start": 1100.559, "duration": 4.36}, {"text": "interesting for U machine learning for", "start": 1102.64, "duration": 4.8}, {"text": "deep learning applications are so called", "start": 1104.919, "duration": 5.801}, {"text": "tensor course so um a few years back you", "start": 1107.44, "duration": 5.0}, {"text": "know Nvidia has realized you know a lot", "start": 1110.72, "duration": 4.36}, {"text": "of these deep learning applications and", "start": 1112.44, "duration": 4.359}, {"text": "new networks they require basically", "start": 1115.08, "duration": 2.959}, {"text": "tensor", "start": 1116.799, "duration": 5.201}, {"text": "operations um they they they have to use", "start": 1118.039, "duration": 7.681}, {"text": "a um so-called MMA operations that's a", "start": 1122.0, "duration": 6.159}, {"text": "matrix multiplication and ACC", "start": 1125.72, "duration": 4.52}, {"text": "accumulation um what that means is", "start": 1128.159, "duration": 4.321}, {"text": "basically you know you you you multiply", "start": 1130.24, "duration": 5.28}, {"text": "two matrices and you know accumulate", "start": 1132.48, "duration": 6.0}, {"text": "that into different Matrix and you know", "start": 1135.52, "duration": 5.32}, {"text": "it can be at different", "start": 1138.48, "duration": 6.559}, {"text": "um uh floating Point uh data types for", "start": 1140.84, "duration": 6.68}, {"text": "instance you know fp16 Matrix", "start": 1145.039, "duration": 4.321}, {"text": "multiplications and then the result gets", "start": 1147.52, "duration": 4.92}, {"text": "stored either in fp16 or fp32 and", "start": 1149.36, "duration": 5.08}, {"text": "there's specialized Hardware that does", "start": 1152.44, "duration": 4.96}, {"text": "that um very efficiently um to help", "start": 1154.44, "duration": 5.08}, {"text": "accelerate these matrix multiplication", "start": 1157.4, "duration": 5.04}, {"text": "accumulation operations and that was", "start": 1159.52, "duration": 5.2}, {"text": "introduced with the Nvidia wter", "start": 1162.44, "duration": 6.359}, {"text": "architecture uh with fp16 data types and", "start": 1164.72, "duration": 6.76}, {"text": "the Amper architecture which is the the", "start": 1168.799, "duration": 4.12}, {"text": "the successor of the vulture", "start": 1171.48, "duration": 4.079}, {"text": "architecture supports that also for um", "start": 1172.919, "duration": 4.88}, {"text": "64 bit floating points and then there's", "start": 1175.559, "duration": 5.841}, {"text": "this tensor float 32 and um I believe", "start": 1177.799, "duration": 6.321}, {"text": "the B float 16 was introduced by by", "start": 1181.4, "duration": 6.68}, {"text": "Google um data types and so the Deep", "start": 1184.12, "duration": 5.88}, {"text": "learning operations can really benefit", "start": 1188.08, "duration": 5.079}, {"text": "from these tensor cores um and there's", "start": 1190.0, "duration": 6.36}, {"text": "fully connected um linear and dense", "start": 1193.159, "duration": 5.76}, {"text": "layers uh convolutional layers the", "start": 1196.36, "duration": 4.439}, {"text": "current layers they also they all make", "start": 1198.919, "duration": 5.0}, {"text": "use um of this Hardware can make use of", "start": 1200.799, "duration": 4.601}, {"text": "that", "start": 1203.919, "duration": 3.681}, {"text": "Hardware um the tensor course can also", "start": 1205.4, "duration": 3.6}, {"text": "used for mixed Precision Matrix", "start": 1207.6, "duration": 3.04}, {"text": "operation that's actually the Q blast", "start": 1209.0, "duration": 2.96}, {"text": "Library if you're familiar with that if", "start": 1210.64, "duration": 4.96}, {"text": "you're doing regular um you know linear", "start": 1211.96, "duration": 5.04}, {"text": "algebra", "start": 1215.6, "duration": 5.0}, {"text": "operations um they can also if that is", "start": 1217.0, "duration": 6.559}, {"text": "something that you know is is", "start": 1220.6, "duration": 6.4}, {"text": "is useful for you in terms of mixed", "start": 1223.559, "duration": 5.921}, {"text": "Precision operations if you know that", "start": 1227.0, "duration": 4.08}, {"text": "you know your code", "start": 1229.48, "duration": 5.48}, {"text": "can use those without um suffering in", "start": 1231.08, "duration": 6.04}, {"text": "terms of this the accuracy that you", "start": 1234.96, "duration": 4.28}, {"text": "require um you know you can use those", "start": 1237.12, "duration": 5.16}, {"text": "also through the CU BL", "start": 1239.24, "duration": 3.04}, {"text": "Library", "start": 1244.679, "duration": 5.12}, {"text": "um now similar to CPUs where you have", "start": 1246.2, "duration": 6.0}, {"text": "different types of CPUs that you know", "start": 1249.799, "duration": 3.921}, {"text": "sort of like work in the same way but", "start": 1252.2, "duration": 4.24}, {"text": "they have different um characteristics", "start": 1253.72, "duration": 5.12}, {"text": "in terms of you know um clock frequency", "start": 1256.44, "duration": 4.76}, {"text": "and number of CPU cores that you have", "start": 1258.84, "duration": 4.319}, {"text": "available you know it's the same for", "start": 1261.2, "duration": 4.599}, {"text": "different um GPU models and generations", "start": 1263.159, "duration": 5.081}, {"text": "right um so the the floating Point", "start": 1265.799, "duration": 3.76}, {"text": "performance will change the memory", "start": 1268.24, "duration": 3.36}, {"text": "bandwidth will change the number of", "start": 1269.559, "duration": 4.6}, {"text": "compute cores and multiprocessor is", "start": 1271.6, "duration": 5.36}, {"text": "going to change now if we look at over", "start": 1274.159, "duration": 5.721}, {"text": "the last Generations what's in a single", "start": 1276.96, "duration": 5.199}, {"text": "multi process where this for instance", "start": 1279.88, "duration": 4.84}, {"text": "the the 32bit floating Point perform uh", "start": 1282.159, "duration": 3.681}, {"text": "floating", "start": 1284.72, "duration": 4.319}, {"text": "Point um course per multip process there", "start": 1285.84, "duration": 6.4}, {"text": "was always 64 so that didn't change um", "start": 1289.039, "duration": 7.201}, {"text": "it's in some sense good um to know the", "start": 1292.24, "duration": 5.799}, {"text": "number of multiprocessors that you know", "start": 1296.24, "duration": 3.64}, {"text": "were actually put onto a single chip", "start": 1298.039, "duration": 4.161}, {"text": "increase so that's similar to one CPUs", "start": 1299.88, "duration": 5.44}, {"text": "you have more compute cores um on the", "start": 1302.2, "duration": 6.76}, {"text": "v00 we have uh 80 multiprocessors and", "start": 1305.32, "duration": 6.4}, {"text": "for a total of you know 5,120 compute", "start": 1308.96, "duration": 5.56}, {"text": "cores and so you see already here", "start": 1311.72, "duration": 5.28}, {"text": "5,120 that's a lot right so that means", "start": 1314.52, "duration": 7.24}, {"text": "you need at least 5,120 threads running", "start": 1317.0, "duration": 6.24}, {"text": "at the same", "start": 1321.76, "duration": 4.72}, {"text": "time Computing basically an independent", "start": 1323.24, "duration": 6.96}, {"text": "data in order to you know um make use of", "start": 1326.48, "duration": 6.6}, {"text": "that hardware and in reality you have to", "start": 1330.2, "duration": 5.719}, {"text": "launch many many more um because I", "start": 1333.08, "duration": 6.199}, {"text": "mentioned previously this multi um um", "start": 1335.919, "duration": 6.721}, {"text": "thread issuer engine on on on the", "start": 1339.279, "duration": 6.52}, {"text": "processor is actually able to", "start": 1342.64, "duration": 6.0}, {"text": "launch and schedule many more threats", "start": 1345.799, "duration": 4.921}, {"text": "and that can hide memory", "start": 1348.64, "duration": 5.519}, {"text": "latency in you know when when some one", "start": 1350.72, "duration": 5.04}, {"text": "some threats are waiting for data to", "start": 1354.159, "duration": 4.441}, {"text": "arrive to compute other threats will be", "start": 1355.76, "duration": 4.68}, {"text": "scheduled in to work on data that is", "start": 1358.6, "duration": 5.04}, {"text": "already arrived right and so typically", "start": 1360.44, "duration": 4.8}, {"text": "applications will launch many more", "start": 1363.64, "duration": 3.08}, {"text": "threads and you have to think in you", "start": 1365.24, "duration": 3.72}, {"text": "know how you can write an", "start": 1366.72, "duration": 4.48}, {"text": "application um or how can you express", "start": 1368.96, "duration": 3.64}, {"text": "your algorithm that makes use of", "start": 1371.2, "duration": 4.079}, {"text": "hundreds of thousands of threats on a", "start": 1372.6, "duration": 4.4}, {"text": "single device right and then if you", "start": 1375.279, "duration": 3.321}, {"text": "start to parallelize across multiple", "start": 1377.0, "duration": 5.039}, {"text": "gpus which you can also do um you know", "start": 1378.6, "duration": 7.64}, {"text": "then that of course um you quickly using", "start": 1382.039, "duration": 7.161}, {"text": "millions of of threats", "start": 1386.24, "duration": 5.799}, {"text": "okay um yeah the number of registers and", "start": 1389.2, "duration": 5.92}, {"text": "cash sizes change and um that's all not", "start": 1392.039, "duration": 4.12}, {"text": "a big", "start": 1395.12, "duration": 2.96}, {"text": "issue", "start": 1396.159, "duration": 5.12}, {"text": "um I thing you have to keep why is it", "start": 1398.08, "duration": 5.44}, {"text": "not an issue because you know you'll", "start": 1401.279, "duration": 4.121}, {"text": "write code in such a way that you query", "start": 1403.52, "duration": 3.84}, {"text": "the hardware information and then you", "start": 1405.4, "duration": 3.68}, {"text": "launch a corresponding number of threats", "start": 1407.36, "duration": 5.559}, {"text": "Etc right similarly to a a", "start": 1409.08, "duration": 6.719}, {"text": "CPU if you write a multi-threaded code", "start": 1412.919, "duration": 5.401}, {"text": "you know you will pass some information", "start": 1415.799, "duration": 5.24}, {"text": "or inspect the hardware and launch a", "start": 1418.32, "duration": 5.52}, {"text": "corresponding number of threats", "start": 1421.039, "duration": 5.361}, {"text": "um um yeah and then like I mentioned", "start": 1423.84, "duration": 4.839}, {"text": "before you need to manage the memory", "start": 1426.4, "duration": 4.44}, {"text": "hierarchy and if you don't have to do it", "start": 1428.679, "duration": 4.801}, {"text": "you should at least be aware of this um", "start": 1430.84, "duration": 5.12}, {"text": "that's a little bit similar to the data", "start": 1433.48, "duration": 4.28}, {"text": "storage that Marty was talking about", "start": 1435.96, "duration": 5.199}, {"text": "before you know you need to be aware um", "start": 1437.76, "duration": 7.12}, {"text": "uh you know why it might be slow to you", "start": 1441.159, "duration": 5.361}, {"text": "know or not a good idea to store a", "start": 1444.88, "duration": 3.76}, {"text": "certain number of files or small files", "start": 1446.52, "duration": 4.759}, {"text": "or large files on different types of of", "start": 1448.64, "duration": 5.08}, {"text": "um um storage systems and it's similar", "start": 1451.279, "duration": 4.321}, {"text": "um with the data that you move to gpus", "start": 1453.72, "duration": 3.52}, {"text": "and processing", "start": 1455.6, "duration": 4.199}, {"text": "gpus and then Nvidia and AMD is somewhat", "start": 1457.24, "duration": 4.96}, {"text": "different but Intel is coming out with", "start": 1459.799, "duration": 4.521}, {"text": "GPS as well that that are going to be", "start": 1462.2, "duration": 5.8}, {"text": "used for compute um and we'll see how", "start": 1464.32, "duration": 6.2}, {"text": "this all hands out um because nobody", "start": 1468.0, "duration": 5.919}, {"text": "really wants to maintain code written", "start": 1470.52, "duration": 7.12}, {"text": "three different languages", "start": 1473.919, "duration": 3.721}, {"text": "um yeah so in a program you never write", "start": 1477.679, "duration": 5.24}, {"text": "a code with any assumption for how many", "start": 1481.24, "duration": 3.799}, {"text": "threads you're going to use", "start": 1482.919, "duration": 5.921}, {"text": "and um you know you can use cter calls", "start": 1485.039, "duration": 5.24}, {"text": "to query the hardware configuration", "start": 1488.84, "duration": 4.199}, {"text": "we'll look at this actually um with a", "start": 1490.279, "duration": 4.64}, {"text": "cuter toolkit samples that we're going", "start": 1493.039, "duration": 4.24}, {"text": "to look at you know in the Practical", "start": 1494.919, "duration": 5.521}, {"text": "piece play a little bit and then yeah", "start": 1497.279, "duration": 4.561}, {"text": "like I said you know you need to launch", "start": 1500.44, "duration": 3.32}, {"text": "many more threats than processing course", "start": 1501.84, "duration": 5.079}, {"text": "to high memory latency and you've seen", "start": 1503.76, "duration": 5.159}, {"text": "the differences uh you might have", "start": 1506.919, "duration": 3.841}, {"text": "noticed I shown that before that you", "start": 1508.919, "duration": 4.041}, {"text": "know the floating Point performance is", "start": 1510.76, "duration": 4.56}, {"text": "higher if you use data types that are", "start": 1512.96, "duration": 5.319}, {"text": "not 64-bit floating points um so if you", "start": 1515.32, "duration": 5.4}, {"text": "don't need them you'll avoid using lower", "start": 1518.279, "duration": 4.681}, {"text": "precision and you'll get quot runs much", "start": 1520.72, "duration": 4.48}, {"text": "faster we do this for instance in a", "start": 1522.96, "duration": 4.839}, {"text": "molecular Dynamics code and of course", "start": 1525.2, "duration": 4.92}, {"text": "all deep learning applications do that", "start": 1527.799, "duration": 4.801}, {"text": "where you have training that often uses", "start": 1530.12, "duration": 5.559}, {"text": "fp64 and then you have inference where", "start": 1532.6, "duration": 6.6}, {"text": "you know you can use um fp32 or you know", "start": 1535.679, "duration": 6.921}, {"text": "mixed precisions or 16 or something like", "start": 1539.2, "duration": 5.719}, {"text": "that", "start": 1542.6, "duration": 4.76}, {"text": "um so that's what I what I wanted to", "start": 1544.919, "duration": 4.48}, {"text": "tell you about about the hardware", "start": 1547.36, "duration": 5.16}, {"text": "initially um I just briefly go over a", "start": 1549.399, "duration": 5.76}, {"text": "few accelerated software examples not", "start": 1552.52, "duration": 4.44}, {"text": "too much and then show you a little bit", "start": 1555.159, "duration": 3.88}, {"text": "about how to program", "start": 1556.96, "duration": 5.36}, {"text": "duse um so by now you know it's it's", "start": 1559.039, "duration": 5.201}, {"text": "such a mature field that there's", "start": 1562.32, "duration": 4.359}, {"text": "literally any field that you go in", "start": 1564.24, "duration": 4.36}, {"text": "there's some software available that", "start": 1566.679, "duration": 3.641}, {"text": "that's going to run on gpus right I mean", "start": 1568.6, "duration": 4.04}, {"text": "again is any of the you know Natural", "start": 1570.32, "duration": 4.76}, {"text": "Sciences from chemistry to", "start": 1572.64, "duration": 4.36}, {"text": "astrophysics um you know it's also", "start": 1575.08, "duration": 4.079}, {"text": "Finance Medical Imaging of course was", "start": 1577.0, "duration": 3.84}, {"text": "also one of the first", "start": 1579.159, "duration": 4.12}, {"text": "naturally social sciences weap and", "start": 1580.84, "duration": 4.88}, {"text": "climate predictions good Dynamics and in", "start": 1583.279, "duration": 3.561}, {"text": "the last years of course machine", "start": 1585.72, "duration": 4.72}, {"text": "learning um that's you all here um in", "start": 1586.84, "duration": 5.959}, {"text": "particular deep deep learning um has has", "start": 1590.44, "duration": 5.44}, {"text": "been using a lot of of gpus and you know", "start": 1592.799, "duration": 7.321}, {"text": "a lot of GPU sales you know have been uh", "start": 1595.88, "duration": 7.159}, {"text": "because of uh a lot of hype around Ai", "start": 1600.12, "duration": 6.76}, {"text": "and machine learning", "start": 1603.039, "duration": 6.401}, {"text": "and yeah there's probably nothing I have", "start": 1606.88, "duration": 4.76}, {"text": "to tell you because you're here but I I", "start": 1609.44, "duration": 4.8}, {"text": "put that slide in here anyways", "start": 1611.64, "duration": 6.08}, {"text": "um um just just to emphasize again why", "start": 1614.24, "duration": 6.6}, {"text": "gpus are very efficient um for deep", "start": 1617.72, "duration": 4.64}, {"text": "learning applications in particular", "start": 1620.84, "duration": 2.959}, {"text": "right so if you have a machine learning", "start": 1622.36, "duration": 3.52}, {"text": "application what you do is you know you", "start": 1623.799, "duration": 4.441}, {"text": "build a a predictive model based on some", "start": 1625.88, "duration": 4.64}, {"text": "reference data so you have training data", "start": 1628.24, "duration": 3.48}, {"text": "right then you train your machine", "start": 1630.52, "duration": 3.84}, {"text": "learning algorithm you get a", "start": 1631.72, "duration": 7.319}, {"text": "model and um you know with that machine", "start": 1634.36, "duration": 6.199}, {"text": "learning algorithm that you have trained", "start": 1639.039, "duration": 5.161}, {"text": "you can now use some other input data um", "start": 1640.559, "duration": 6.6}, {"text": "that basically it's inference based on", "start": 1644.2, "duration": 4.599}, {"text": "that model gives the prediction and then", "start": 1647.159, "duration": 4.201}, {"text": "you can check whether you know you know", "start": 1648.799, "duration": 4.041}, {"text": "model is good enough or if you have to", "start": 1651.36, "duration": 3.24}, {"text": "retrain the algorithm is typically some", "start": 1652.84, "duration": 4.48}, {"text": "sort of like iterative procedure and the", "start": 1654.6, "duration": 4.92}, {"text": "gpus are particularly well suited for", "start": 1657.32, "duration": 4.8}, {"text": "So-Cal deep learning workloads um and", "start": 1659.52, "duration": 6.08}, {"text": "deep learning really um is when you use", "start": 1662.12, "duration": 5.439}, {"text": "neural networks with many hidden layers", "start": 1665.6, "duration": 3.76}, {"text": "and you know here you have a simple", "start": 1667.559, "duration": 4.72}, {"text": "neural network where you have um your", "start": 1669.36, "duration": 5.84}, {"text": "input data um and then you have a hidden", "start": 1672.279, "duration": 5.961}, {"text": "layer and an output layer right and", "start": 1675.2, "duration": 4.68}, {"text": "these neural networks neural networks", "start": 1678.24, "duration": 3.319}, {"text": "have been used a lot in the past even", "start": 1679.88, "duration": 3.12}, {"text": "also in chemistry I remember when I was", "start": 1681.559, "duration": 3.36}, {"text": "a undergraduate student we had a", "start": 1683.0, "duration": 4.399}, {"text": "research group back in Germany was a lot", "start": 1684.919, "duration": 4.081}, {"text": "involved and they you know the professor", "start": 1687.399, "duration": 4.601}, {"text": "wrote a book um neural networks in", "start": 1689.0, "duration": 5.44}, {"text": "chemistry that came out in I don't know", "start": 1692.0, "duration": 4.2}, {"text": "and end of the 90s something like that", "start": 1694.44, "duration": 4.56}, {"text": "right so 25 years ago 30 years ago", "start": 1696.2, "duration": 4.199}, {"text": "people have been doing this a lot", "start": 1699.0, "duration": 5.159}, {"text": "already and but what really changed um", "start": 1700.399, "duration": 6.081}, {"text": "you know the field is these deep neural", "start": 1704.159, "duration": 3.721}, {"text": "networks where you have many hidden", "start": 1706.48, "duration": 5.319}, {"text": "layers yes and um it's effectively you", "start": 1707.88, "duration": 6.0}, {"text": "know um some people say well it's", "start": 1711.799, "duration": 3.441}, {"text": "essentially data fitting but you have", "start": 1713.88, "duration": 3.44}, {"text": "highly flexible function that is able to", "start": 1715.24, "duration": 5.039}, {"text": "represent your data and some of these un", "start": 1717.32, "duration": 5.0}, {"text": "networks are huge as you know and they", "start": 1720.279, "duration": 5.201}, {"text": "have like millions of um um you know", "start": 1722.32, "duration": 5.52}, {"text": "weights here and if you write down the", "start": 1725.48, "duration": 4.799}, {"text": "equations how this all looks like these", "start": 1727.84, "duration": 5.04}, {"text": "are tensor operations where in this in", "start": 1730.279, "duration": 4.681}, {"text": "particular this fully connected neur", "start": 1732.88, "duration": 4.799}, {"text": "networks um they effectively Matrix", "start": 1734.96, "duration": 5.88}, {"text": "Matrix multiplications um that you need", "start": 1737.679, "duration": 4.961}, {"text": "to execute in you know going from your", "start": 1740.84, "duration": 3.24}, {"text": "input layer through the hidden layers to", "start": 1742.64, "duration": 3.96}, {"text": "your output layer a gpus are just very", "start": 1744.08, "duration": 5.76}, {"text": "efficient at these um already before", "start": 1746.6, "duration": 5.36}, {"text": "those tensor cores were implemented", "start": 1749.84, "duration": 3.88}, {"text": "simply because um they have been", "start": 1751.96, "duration": 3.88}, {"text": "optimized for these tasks and the reason", "start": 1753.72, "duration": 5.12}, {"text": "is that um you know 4x4 Matrix algebra", "start": 1755.84, "duration": 5.12}, {"text": "is used in 3D Graphics so the hardware", "start": 1758.84, "duration": 3.959}, {"text": "is actually very stupid to do these um", "start": 1760.96, "duration": 3.12}, {"text": "Matrix", "start": 1762.799, "duration": 3.36}, {"text": "multiplications and in addition now we", "start": 1764.08, "duration": 3.68}, {"text": "have this half Precision arithmetic that", "start": 1766.159, "duration": 3.36}, {"text": "I mentioned", "start": 1767.76, "duration": 6.279}, {"text": "and and or other data types like 16 that", "start": 1769.519, "duration": 6.561}, {"text": "can be used for many ml applications at", "start": 1774.039, "duration": 4.321}, {"text": "least for the inference stage um so you", "start": 1776.08, "duration": 5.959}, {"text": "can be really really fast um compared to", "start": 1778.36, "duration": 6.48}, {"text": "um a a a implementation on own", "start": 1782.039, "duration": 6.36}, {"text": "CPUs um and if you use these tensor", "start": 1784.84, "duration": 5.8}, {"text": "cores in the more modern gpus um then", "start": 1788.399, "duration": 3.801}, {"text": "you have a dedicated hardware for these", "start": 1790.64, "duration": 5.2}, {"text": "mix Precision Matrix multiplications and", "start": 1792.2, "duration": 6.599}, {"text": "accumulations and if you use something", "start": 1795.84, "duration": 5.76}, {"text": "like a machine learning framework um", "start": 1798.799, "duration": 5.921}, {"text": "pytor or tens ofo um they they directly", "start": 1801.6, "duration": 4.959}, {"text": "provide GQ support so there's actually", "start": 1804.72, "duration": 4.28}, {"text": "not much you really need to know in", "start": 1806.559, "duration": 6.041}, {"text": "terms of how to program a GP um because", "start": 1809.0, "duration": 6.76}, {"text": "you just tell the the framework to", "start": 1812.6, "duration": 5.959}, {"text": "generate instead of generating code for", "start": 1815.76, "duration": 4.799}, {"text": "the CPU to generate the code and", "start": 1818.559, "duration": 3.84}, {"text": "executes in the GPU and you know these", "start": 1820.559, "duration": 4.561}, {"text": "are highly optimized um there are of", "start": 1822.399, "duration": 4.88}, {"text": "course tips and tricks um you know you", "start": 1825.12, "duration": 4.48}, {"text": "can use profile to analyze those I'll", "start": 1827.279, "duration": 4.0}, {"text": "mention those briefly but there's not", "start": 1829.6, "duration": 4.76}, {"text": "enough time to go through any of those", "start": 1831.279, "duration": 5.561}, {"text": "um you know it's a little bit out of the", "start": 1834.36, "duration": 5.84}, {"text": "scope of uh this Workshop but um you", "start": 1836.84, "duration": 6.079}, {"text": "know you can also profile the code that", "start": 1840.2, "duration": 5.76}, {"text": "is being generated by py tensor flow and", "start": 1842.919, "duration": 4.441}, {"text": "see if there's anything that you can", "start": 1845.96, "duration": 2.88}, {"text": "change", "start": 1847.36, "duration": 4.039}, {"text": "um um in order to improve the", "start": 1848.84, "duration": 4.839}, {"text": "performance for P say um training or", "start": 1851.399, "duration": 4.721}, {"text": "inference", "start": 1853.679, "duration": 2.441}, {"text": "models um", "start": 1856.72, "duration": 3.919}, {"text": "then I have a few benchmarks people like", "start": 1858.799, "duration": 4.72}, {"text": "to see benchmarks um I I actually have", "start": 1860.639, "duration": 5.681}, {"text": "benchmarks of some classical computation", "start": 1863.519, "duration": 5.241}, {"text": "uh examples in here simply because I", "start": 1866.32, "duration": 5.239}, {"text": "didn't have time to add some machine", "start": 1868.76, "duration": 4.799}, {"text": "learning benchmarks so I apologize for", "start": 1871.559, "duration": 3.641}, {"text": "that but I hope that's still interesting", "start": 1873.559, "duration": 3.84}, {"text": "for you even though you have to be", "start": 1875.2, "duration": 4.479}, {"text": "careful about you", "start": 1877.399, "duration": 4.841}, {"text": "know how benchmarks are executed and", "start": 1879.679, "duration": 5.24}, {"text": "what they really mean um people often", "start": 1882.24, "duration": 4.399}, {"text": "cheat with benchmarks in one way or", "start": 1884.919, "duration": 5.24}, {"text": "another but um this here is a quantum", "start": 1886.639, "duration": 5.081}, {"text": "chemistry code so I told you I'm a", "start": 1890.159, "duration": 3.041}, {"text": "chemist so this is one of the works that", "start": 1891.72, "duration": 4.0}, {"text": "I Cod that I've been developing together", "start": 1893.2, "duration": 3.92}, {"text": "with a colleague it's an open source", "start": 1895.72, "duration": 3.319}, {"text": "code if some Quantum chemists are among", "start": 1897.12, "duration": 4.159}, {"text": "you you might be interested maybe to", "start": 1899.039, "duration": 4.48}, {"text": "download it have a look at this um few", "start": 1901.279, "duration": 3.801}, {"text": "years ago we wrote about electronic", "start": 1903.519, "duration": 3.721}, {"text": "structure calculations a book that's", "start": 1905.08, "duration": 5.12}, {"text": "added it also um about quantum chemistry", "start": 1907.24, "duration": 5.52}, {"text": "applications and you know um electronic", "start": 1910.2, "duration": 3.719}, {"text": "structure", "start": 1912.76, "duration": 3.2}, {"text": "calculations um and you can see that you", "start": 1913.919, "duration": 4.6}, {"text": "know we have a CPU code and our GPU", "start": 1915.96, "duration": 4.439}, {"text": "implementation is significantly faster", "start": 1918.519, "duration": 3.801}, {"text": "so that's a comparison to a single CPU", "start": 1920.399, "duration": 4.561}, {"text": "core so it's not of course 67 times", "start": 1922.32, "duration": 5.4}, {"text": "faster than running the code on a on the", "start": 1924.96, "duration": 5.8}, {"text": "on the full CPU Noe but here for", "start": 1927.72, "duration": 5.959}, {"text": "instance you know um those are two", "start": 1930.76, "duration": 4.72}, {"text": "different steps that are required during", "start": 1933.679, "duration": 5.281}, {"text": "the computation and you see the scaling", "start": 1935.48, "duration": 5.36}, {"text": "B Bob earlier mentioned something about", "start": 1938.96, "duration": 3.52}, {"text": "scaling so this is the code how it", "start": 1940.84, "duration": 4.52}, {"text": "scales um we have an ideal scaling and", "start": 1942.48, "duration": 5.0}, {"text": "then the the real scaling are the data", "start": 1945.36, "duration": 4.799}, {"text": "points here for two different um", "start": 1947.48, "duration": 4.96}, {"text": "expensive pieces in in that", "start": 1950.159, "duration": 5.24}, {"text": "computation and that's you know on on", "start": 1952.44, "duration": 5.959}, {"text": "that dual socket server that we had back", "start": 1955.399, "duration": 6.201}, {"text": "then uh into zon CPUs that's the best", "start": 1958.399, "duration": 6.12}, {"text": "time we could get and this logiic scale", "start": 1961.6, "duration": 4.36}, {"text": "and of course lower is better and you", "start": 1964.519, "duration": 4.681}, {"text": "see on a single GPU we are significantly", "start": 1965.96, "duration": 6.12}, {"text": "faster like for both of those steps um", "start": 1969.2, "duration": 6.199}, {"text": "so it's really um paid off to do this", "start": 1972.08, "duration": 5.4}, {"text": "implementation and rewrite the code for", "start": 1975.399, "duration": 3.081}, {"text": "for", "start": 1977.48, "duration": 5.079}, {"text": "use um now nowadays what you want to do", "start": 1978.48, "duration": 6.52}, {"text": "is to try to um develop machine learning", "start": 1982.559, "duration": 5.201}, {"text": "models that get around this um quantum", "start": 1985.0, "duration": 5.2}, {"text": "chemistry application and you know take", "start": 1987.76, "duration": 4.24}, {"text": "a lot of reference data people are doing", "start": 1990.2, "duration": 4.719}, {"text": "this um and try to predict the solutions", "start": 1992.0, "duration": 4.88}, {"text": "that we can get from those quantum", "start": 1994.919, "duration": 3.561}, {"text": "chemistry calculations without actually", "start": 1996.88, "duration": 2.84}, {"text": "running those quantum chemistry", "start": 1998.48, "duration": 4.559}, {"text": "appications um of course that it's not I", "start": 1999.72, "duration": 6.079}, {"text": "think generally feasible always but um", "start": 2003.039, "duration": 4.281}, {"text": "they're very good models that are able", "start": 2005.799, "duration": 3.641}, {"text": "to do this in certain cases so that's a", "start": 2007.32, "duration": 4.88}, {"text": "PR pretty cool application fields and I", "start": 2009.44, "duration": 4.239}, {"text": "don't want to talk much about that but", "start": 2012.2, "duration": 3.04}, {"text": "that's one of the pieces The Exchange", "start": 2013.679, "duration": 4.041}, {"text": "correlation quadrature where you know", "start": 2015.24, "duration": 4.439}, {"text": "you see even for a water molecule we", "start": 2017.72, "duration": 4.839}, {"text": "have like um gosh I don't know what is", "start": 2019.679, "duration": 5.36}, {"text": "it here at the end we have 8,000 grid", "start": 2022.559, "duration": 3.96}, {"text": "points and you know for each grid point", "start": 2025.039, "duration": 3.321}, {"text": "we have to do a lot of we have thousands", "start": 2026.519, "duration": 4.961}, {"text": "of basis functions and we need to do", "start": 2028.36, "duration": 5.4}, {"text": "computations for each of those and so", "start": 2031.48, "duration": 3.88}, {"text": "that's the way you can parallelize", "start": 2033.76, "duration": 3.68}, {"text": "something where we have independent data", "start": 2035.36, "duration": 4.84}, {"text": "points and you know an three algorithm", "start": 2037.44, "duration": 4.839}, {"text": "that splits the data up and then that", "start": 2040.2, "duration": 3.88}, {"text": "gets farmed out onto the different", "start": 2042.279, "duration": 3.601}, {"text": "multiprocessors and on each multi", "start": 2044.08, "duration": 3.999}, {"text": "processor you have you know many many of", "start": 2045.88, "duration": 4.92}, {"text": "those um CPU cores that can operate on", "start": 2048.079, "duration": 4.641}, {"text": "all those individual grid points uh", "start": 2050.8, "duration": 4.079}, {"text": "independently um so that's a typical way", "start": 2052.72, "duration": 3.639}, {"text": "of you know where you have a domain de", "start": 2054.879, "duration": 4.0}, {"text": "composition and then can parallelize the", "start": 2056.359, "duration": 5.72}, {"text": "code um to run efficiently in the", "start": 2058.879, "duration": 5.8}, {"text": "GQ um another example that I've been", "start": 2062.079, "duration": 4.361}, {"text": "working on is a molecular Dynamics code", "start": 2064.679, "duration": 3.841}, {"text": "that's um called Amber", "start": 2066.44, "duration": 4.76}, {"text": "and so this is used for let me see", "start": 2068.52, "duration": 4.599}, {"text": "there's a movie oh yeah that's actually", "start": 2071.2, "duration": 4.8}, {"text": "a movie um you know that this you know", "start": 2073.119, "duration": 6.361}, {"text": "is is a um nbody simulations with very", "start": 2076.0, "duration": 6.0}, {"text": "simple for fields that describe how the", "start": 2079.48, "duration": 4.24}, {"text": "the atoms you know these molecules", "start": 2082.0, "duration": 3.399}, {"text": "interact in an enzyme in this case and", "start": 2083.72, "duration": 3.24}, {"text": "you see here water molecules going", "start": 2085.399, "duration": 3.641}, {"text": "around and we found some water exit", "start": 2086.96, "duration": 4.879}, {"text": "Pathways here and some enzyme in in in a", "start": 2089.04, "duration": 4.96}, {"text": "publication that came out a few years", "start": 2091.839, "duration": 4.401}, {"text": "ago um", "start": 2094.0, "duration": 4.52}, {"text": "and you know", "start": 2096.24, "duration": 5.08}, {"text": "each time step needs to be you know we", "start": 2098.52, "duration": 4.68}, {"text": "need to compute basically how these", "start": 2101.32, "duration": 3.519}, {"text": "molecules interact all the atoms", "start": 2103.2, "duration": 3.96}, {"text": "interact and there's like hundreds of", "start": 2104.839, "duration": 5.28}, {"text": "thousands of atoms and um you know we", "start": 2107.16, "duration": 4.8}, {"text": "need millions of time steps actually to", "start": 2110.119, "duration": 3.801}, {"text": "reach time scales that are of relevance", "start": 2111.96, "duration": 6.04}, {"text": "for for for biology and biophysics so", "start": 2113.92, "duration": 5.36}, {"text": "you see there's a lot of computations", "start": 2118.0, "duration": 2.72}, {"text": "that need to be done and each time step", "start": 2119.28, "duration": 4.72}, {"text": "needs to be really really fast and um a", "start": 2120.72, "duration": 5.119}, {"text": "lot of software engineering time went", "start": 2124.0, "duration": 3.76}, {"text": "into that with collaborations also with", "start": 2125.839, "duration": 3.841}, {"text": "VI and this is already a few years back", "start": 2127.76, "duration": 3.76}, {"text": "but you know um it still looks more or", "start": 2129.68, "duration": 4.64}, {"text": "less the same um you know you can see", "start": 2131.52, "duration": 5.079}, {"text": "the MD software and you see a bunch of", "start": 2134.32, "duration": 4.279}, {"text": "different gpus um here like that's a", "start": 2136.599, "duration": 5.961}, {"text": "gaming GPU that's more modern gaming GPU", "start": 2138.599, "duration": 6.281}, {"text": "that's the a Titan V that is similar to", "start": 2142.56, "duration": 8.039}, {"text": "The V 100 um um data center", "start": 2144.88, "duration": 8.32}, {"text": "GPU and that's the", "start": 2150.599, "duration": 5.201}, {"text": "time in the life of the molecule that we", "start": 2153.2, "duration": 5.04}, {"text": "can simulate in in a day in 24 hours", "start": 2155.8, "duration": 4.88}, {"text": "right so you wait 24 hours and how much", "start": 2158.24, "duration": 4.4}, {"text": "many NCS in the life of the molecule can", "start": 2160.68, "duration": 4.32}, {"text": "you simulate on a single GPU you see", "start": 2162.64, "duration": 7.56}, {"text": "this like about 50 and these are 36 CPU", "start": 2165.0, "duration": 8.16}, {"text": "cores on on the corresponding CPU Cod so", "start": 2170.2, "duration": 4.639}, {"text": "um you see that you know we have a", "start": 2173.16, "duration": 5.439}, {"text": "massive performance um um advantage over", "start": 2174.839, "duration": 7.76}, {"text": "over gpus um but that required uh many", "start": 2178.599, "duration": 5.641}, {"text": "years of software engineering efforts", "start": 2182.599, "duration": 5.281}, {"text": "and thinking about how to use um 32 in", "start": 2184.24, "duration": 7.72}, {"text": "points um without losing losing um", "start": 2187.88, "duration": 6.88}, {"text": "accuracy in our simulations and so and", "start": 2191.96, "duration": 4.359}, {"text": "designing a lot of algorithms but if you", "start": 2194.76, "duration": 3.079}, {"text": "do it correctly you can actually get a", "start": 2196.319, "duration": 3.081}, {"text": "very high", "start": 2197.839, "duration": 3.441}, {"text": "performance um that's just something I", "start": 2199.4, "duration": 3.48}, {"text": "wanted to show you as a as a background", "start": 2201.28, "duration": 3.799}, {"text": "and of course you know um there's", "start": 2202.88, "duration": 5.0}, {"text": "machine learning applications that run", "start": 2205.079, "duration": 7.561}, {"text": "very efficiently on on uh on gpus and if", "start": 2207.88, "duration": 8.04}, {"text": "you have even just a gaming GPU you know", "start": 2212.64, "duration": 5.199}, {"text": "you can do a lot of uh interest", "start": 2215.92, "duration": 4.439}, {"text": "applications or even on your desktop GPU", "start": 2217.839, "duration": 6.641}, {"text": "right I mean um these codes like Amber", "start": 2220.359, "duration": 6.521}, {"text": "and also quick the quantum chemistry", "start": 2224.48, "duration": 4.839}, {"text": "code um you can actually run them also", "start": 2226.88, "duration": 4.0}, {"text": "on your on your laptop if you have a", "start": 2229.319, "duration": 5.441}, {"text": "corresponding Nvidia GP on", "start": 2230.88, "duration": 3.88}, {"text": "them", "start": 2235.48, "duration": 5.839}, {"text": "so that's as a background um we spent", "start": 2238.2, "duration": 5.159}, {"text": "about 40 minutes so let me think about", "start": 2241.319, "duration": 6.961}, {"text": "this we have up to 50 right and", "start": 2243.359, "duration": 8.161}, {"text": "what I want to do yes um this that you", "start": 2248.28, "duration": 5.92}, {"text": "also test out expans a little bit um but", "start": 2251.52, "duration": 5.48}, {"text": "let me talk before a little bit about um", "start": 2254.2, "duration": 4.28}, {"text": "programming gpus and give you a little", "start": 2257.0, "duration": 3.48}, {"text": "bit of an overview so so that you get", "start": 2258.48, "duration": 4.8}, {"text": "get a little bit of an idea um what is", "start": 2260.48, "duration": 6.16}, {"text": "out there and and if you were interested", "start": 2263.28, "duration": 4.96}, {"text": "in learning a little bit more so you", "start": 2266.64, "duration": 3.64}, {"text": "have um some", "start": 2268.24, "duration": 5.56}, {"text": "pointers um there's different", "start": 2270.28, "duration": 7.24}, {"text": "programming languages um if you direct", "start": 2273.8, "duration": 7.88}, {"text": "they want to write um code code for", "start": 2277.52, "duration": 8.24}, {"text": "gpus um and you know there's opencl", "start": 2281.68, "duration": 5.76}, {"text": "which is an industry", "start": 2285.76, "duration": 4.599}, {"text": "standard um I myself have never used it", "start": 2287.44, "duration": 5.24}, {"text": "so I can't tell you too much about it um", "start": 2290.359, "duration": 4.601}, {"text": "but it works you know for all sorts of", "start": 2292.68, "duration": 4.8}, {"text": "different architectures embedded systems", "start": 2294.96, "duration": 5.72}, {"text": "and so on and it works for NV and digits", "start": 2297.48, "duration": 5.92}, {"text": "and other other devices if you want the", "start": 2300.68, "duration": 4.159}, {"text": "highest performance and that's the def", "start": 2303.4, "duration": 5.719}, {"text": "facto standard um is is for NVIDIA gpus", "start": 2304.839, "duration": 6.76}, {"text": "is Cuda so that's why there most of the", "start": 2309.119, "duration": 5.2}, {"text": "codes that run on on Nvidia gpus are", "start": 2311.599, "duration": 4.121}, {"text": "actually written in", "start": 2314.319, "duration": 4.721}, {"text": "Cuda um you know has the downside that", "start": 2315.72, "duration": 5.44}, {"text": "it only works for NVIDIA gpus now you", "start": 2319.04, "duration": 4.559}, {"text": "know 10 years ago people were worried of", "start": 2321.16, "duration": 3.959}, {"text": "course you know you put effort into this", "start": 2323.599, "duration": 3.52}, {"text": "and who knows maybe it's gone in one or", "start": 2325.119, "duration": 3.2}, {"text": "two ways and then you put a lot of", "start": 2327.119, "duration": 4.0}, {"text": "effort into it but you know Nvidia was", "start": 2328.319, "duration": 3.52}, {"text": "so", "start": 2331.119, "duration": 4.2}, {"text": "successful that um I think nowadays it's", "start": 2331.839, "duration": 6.681}, {"text": "not an issue to write code in in Cuda", "start": 2335.319, "duration": 4.681}, {"text": "so it's the practice standard still for", "start": 2338.52, "duration": 3.92}, {"text": "high performance code um and and Nvidia", "start": 2340.0, "duration": 3.76}, {"text": "has a lot of tools that help you", "start": 2342.44, "duration": 3.2}, {"text": "actually optimize the codes and you know", "start": 2343.76, "duration": 4.0}, {"text": "make sure that you have debuggers", "start": 2345.64, "duration": 5.0}, {"text": "available and um profilers it really", "start": 2347.76, "duration": 6.24}, {"text": "helps a lot now AMD also has very", "start": 2350.64, "duration": 6.12}, {"text": "powerful um um gpus and they came up", "start": 2354.0, "duration": 5.72}, {"text": "with something that's called hip I keep", "start": 2356.76, "duration": 5.839}, {"text": "forgetting what it stands for it's um", "start": 2359.72, "duration": 4.639}, {"text": "heterogeneous", "start": 2362.599, "duration": 3.961}, {"text": "interoperable um the I stands for", "start": 2364.359, "duration": 3.96}, {"text": "interoperable", "start": 2366.56, "duration": 5.36}, {"text": "um that's an open source C++ runtime API", "start": 2368.319, "duration": 6.28}, {"text": "and a kernel language developed by MD it", "start": 2371.92, "duration": 5.84}, {"text": "looks almost exactly like Cuda um so you", "start": 2374.599, "duration": 5.281}, {"text": "for much you can there's actually tool", "start": 2377.76, "duration": 3.96}, {"text": "in there you can take Cuda code and you", "start": 2379.88, "duration": 4.36}, {"text": "run a a translator that basically does a", "start": 2381.72, "duration": 5.08}, {"text": "gra and replace and it works on large", "start": 2384.24, "duration": 4.16}, {"text": "portions of the code and then all you", "start": 2386.8, "duration": 4.44}, {"text": "have to do is fix the rest and um do a", "start": 2388.4, "duration": 4.719}, {"text": "little bit of profiling and performance", "start": 2391.24, "duration": 4.72}, {"text": "optimizations and of course you know you", "start": 2393.119, "duration": 4.801}, {"text": "have complex code something like", "start": 2395.96, "duration": 5.2}, {"text": "Amber that's not so easy you know Amber", "start": 2397.92, "duration": 6.76}, {"text": "have been ported to hi um that was", "start": 2401.16, "duration": 5.84}, {"text": "a about you know people started to do", "start": 2404.68, "duration": 4.76}, {"text": "that about three years ago and the last", "start": 2407.0, "duration": 4.359}, {"text": "one year with a lot of effort from AMD", "start": 2409.44, "duration": 3.72}, {"text": "Engineers so it's you know depending on", "start": 2411.359, "duration": 3.281}, {"text": "how complex the code is and how", "start": 2413.16, "duration": 2.959}, {"text": "optimized you know it can be a big", "start": 2414.64, "duration": 3.84}, {"text": "effort but for smaller pieces of code is", "start": 2416.119, "duration": 3.561}, {"text": "actually", "start": 2418.48, "duration": 4.48}, {"text": "straightforward um the downside is that", "start": 2419.68, "duration": 5.04}, {"text": "you know basically what it does under", "start": 2422.96, "duration": 3.56}, {"text": "the hood if you run it in video gpus it", "start": 2424.72, "duration": 3.639}, {"text": "translates back to cter compiles cter", "start": 2426.52, "duration": 4.599}, {"text": "code and you know for for AMD GPS it", "start": 2428.359, "duration": 5.521}, {"text": "uses rocken that's nvidia's equivalent", "start": 2431.119, "duration": 7.561}, {"text": "for Cuda and the back end and um so if", "start": 2433.88, "duration": 6.64}, {"text": "you have AMD gpus that's something you", "start": 2438.68, "duration": 4.679}, {"text": "might want to look into then there's", "start": 2440.52, "duration": 5.68}, {"text": "accelerator directives so Bob mentioned", "start": 2443.359, "duration": 5.641}, {"text": "open MP for CPUs and uh you can actually", "start": 2446.2, "duration": 6.48}, {"text": "use open MP also for gpus but it's uh I", "start": 2449.0, "duration": 6.68}, {"text": "would say not mature yet", "start": 2452.68, "duration": 5.159}, {"text": "um uh there's something else it's called", "start": 2455.68, "duration": 5.8}, {"text": "open ACC um unfortunately oh this is", "start": 2457.839, "duration": 7.041}, {"text": "wrong it's not AMD anymore sorry this", "start": 2461.48, "duration": 5.0}, {"text": "must have kept this in over the years", "start": 2464.88, "duration": 4.12}, {"text": "from different slides it used to work", "start": 2466.48, "duration": 4.56}, {"text": "for NVIDIA and AMD but then it was", "start": 2469.0, "duration": 4.44}, {"text": "developed originally by um the Portland", "start": 2471.04, "duration": 4.4}, {"text": "group um", "start": 2473.44, "duration": 4.6}, {"text": "PGI and their compilers but PGI got", "start": 2475.44, "duration": 4.48}, {"text": "bought by Nvidia and of course the AMD", "start": 2478.04, "duration": 2.84}, {"text": "support", "start": 2479.92, "duration": 3.159}, {"text": "dropped um but it's very nice because", "start": 2480.88, "duration": 3.64}, {"text": "you know it's it's directives that you", "start": 2483.079, "duration": 3.28}, {"text": "insert into your code so you have your C", "start": 2484.52, "duration": 4.12}, {"text": "or C++ or forun code and then you just", "start": 2486.359, "duration": 3.841}, {"text": "add those directives", "start": 2488.64, "duration": 5.479}, {"text": "and that open ACC will generate the the", "start": 2490.2, "duration": 7.399}, {"text": "CU code effectively for you and open a", "start": 2494.119, "duration": 5.041}, {"text": "is supposed to work similarly in the", "start": 2497.599, "duration": 4.041}, {"text": "future I mean it does already but um I", "start": 2499.16, "duration": 6.12}, {"text": "think it's not up to up up there yet", "start": 2501.64, "duration": 7.64}, {"text": "and um but something certainly to to to", "start": 2505.28, "duration": 5.76}, {"text": "to keep a look out", "start": 2509.28, "duration": 5.12}, {"text": "for um so this is something taken from", "start": 2511.04, "duration": 4.96}, {"text": "nvidia's website where you see you know", "start": 2514.4, "duration": 4.6}, {"text": "you have basically your applications", "start": 2516.0, "duration": 5.079}, {"text": "that you want to develop um here you", "start": 2519.0, "duration": 5.28}, {"text": "have your gpus and you know if you use", "start": 2521.079, "duration": 6.841}, {"text": "Cuda and the cter framework um you can", "start": 2524.28, "duration": 5.72}, {"text": "use and write code that will run on", "start": 2527.92, "duration": 3.84}, {"text": "anything on embedded devices on the", "start": 2530.0, "duration": 5.76}, {"text": "consumer uh on desktop um and laptop you", "start": 2531.76, "duration": 6.079}, {"text": "know gpus professional workstation gpus", "start": 2535.76, "duration": 3.72}, {"text": "and the data center gpus so that's", "start": 2537.839, "duration": 4.401}, {"text": "actually quite nice um there's a lot of", "start": 2539.48, "duration": 4.92}, {"text": "libraries available that you can use you", "start": 2542.24, "duration": 4.359}, {"text": "know um qnn is the Deep neural network", "start": 2544.4, "duration": 6.719}, {"text": "library RT is p run time there's all", "start": 2546.599, "duration": 6.321}, {"text": "sorts of libraries for fast for", "start": 2551.119, "duration": 4.2}, {"text": "transforms basic linear algebra systems", "start": 2552.92, "duration": 4.6}, {"text": "so linear algebra libraries and so on", "start": 2555.319, "duration": 5.961}, {"text": "solvers etc etc you can use it with", "start": 2557.52, "duration": 7.36}, {"text": "matlb um Can can use gpus directly and", "start": 2561.28, "duration": 5.039}, {"text": "then if you have programming languages", "start": 2564.88, "duration": 3.84}, {"text": "there's C and C++ qter that you", "start": 2566.319, "duration": 3.561}, {"text": "effectively", "start": 2568.72, "duration": 5.2}, {"text": "write uh parallel code in Cuda using C", "start": 2569.88, "duration": 8.04}, {"text": "C++ it's also for Fortune um and then", "start": 2573.92, "duration": 7.88}, {"text": "there's also Java and Pon wrappers that", "start": 2577.92, "duration": 5.639}, {"text": "you can use and of course also", "start": 2581.8, "duration": 4.88}, {"text": "libraries um yeah this is of course for", "start": 2583.559, "duration": 5.641}, {"text": "um yeah visualization and then", "start": 2586.68, "duration": 6.2}, {"text": "directives like open ACC um there's a", "start": 2589.2, "duration": 5.0}, {"text": "lot of information in the cuter", "start": 2592.88, "duration": 3.8}, {"text": "programming guide that you can look at", "start": 2594.2, "duration": 5.28}, {"text": "um the development tools are free", "start": 2596.68, "duration": 4.679}, {"text": "there's a cuter tool kit that you can", "start": 2599.48, "duration": 5.639}, {"text": "download contains the C and C++ well", "start": 2601.359, "duration": 7.841}, {"text": "secter compiler nbcc it works in in in", "start": 2605.119, "duration": 5.841}, {"text": "conjunction with a system compiler that", "start": 2609.2, "duration": 4.44}, {"text": "you have that can be Intel compiler or", "start": 2610.96, "duration": 6.32}, {"text": "or glue compiler or AMD compiler Etc it", "start": 2613.64, "duration": 5.56}, {"text": "contains all these libraries um it", "start": 2617.28, "duration": 5.52}, {"text": "contains debugging tools profiling tools", "start": 2619.2, "duration": 5.6}, {"text": "um and the code samples the code samples", "start": 2622.8, "duration": 4.279}, {"text": "are now um open sourc in GitHub you can", "start": 2624.8, "duration": 4.2}, {"text": "download them directly we'll have a look", "start": 2627.079, "duration": 4.52}, {"text": "at those um and there's some information", "start": 2629.0, "duration": 4.96}, {"text": "here uh Mary mentioned that before so if", "start": 2631.599, "duration": 5.801}, {"text": "you want to um activate that on on on", "start": 2633.96, "duration": 6.04}, {"text": "expand so if you are already on a GQ", "start": 2637.4, "duration": 3.679}, {"text": "compute", "start": 2640.0, "duration": 3.8}, {"text": "Noe what you have to do is module load", "start": 2641.079, "duration": 6.601}, {"text": "Fuda um in order to have that available", "start": 2643.8, "duration": 6.559}, {"text": "there must be the GPU module loaded so", "start": 2647.68, "duration": 4.6}, {"text": "often it's advisable to just you know", "start": 2650.359, "duration": 3.2}, {"text": "remove all the", "start": 2652.28, "duration": 4.2}, {"text": "modules um don't have to do that but you", "start": 2653.559, "duration": 4.681}, {"text": "know sometimes things can get messed up", "start": 2656.48, "duration": 3.839}, {"text": "and module per removes everything and", "start": 2658.24, "duration": 3.92}, {"text": "module reset will load the modules that", "start": 2660.319, "duration": 4.481}, {"text": "are appropriate for either the um CPU or", "start": 2662.16, "duration": 4.959}, {"text": "the GPU noes and then you can load the", "start": 2664.8, "duration": 4.16}, {"text": "cter uh", "start": 2667.119, "duration": 4.521}, {"text": "module um I think cuter 11 is what we", "start": 2668.96, "duration": 4.8}, {"text": "currently have available now there's", "start": 2671.64, "duration": 4.52}, {"text": "something else it's called Invidia HPC", "start": 2673.76, "duration": 5.0}, {"text": "um SDK it's also free and you can get it", "start": 2676.16, "duration": 3.56}, {"text": "from this", "start": 2678.76, "duration": 3.24}, {"text": "website that is meant as a replacement", "start": 2679.72, "duration": 5.28}, {"text": "for the cter toolkit it contains more", "start": 2682.0, "duration": 5.079}, {"text": "than the CUA toolkit um because in", "start": 2685.0, "duration": 6.68}, {"text": "addition um to the Nvidia cuter compiler", "start": 2687.079, "duration": 7.52}, {"text": "nvcc Library State bugers and profile it", "start": 2691.68, "duration": 7.52}, {"text": "contains also AC and C++ compiler a", "start": 2694.599, "duration": 7.72}, {"text": "foron compiler and those is are", "start": 2699.2, "duration": 4.96}, {"text": "basically the compilers that used to be", "start": 2702.319, "duration": 5.161}, {"text": "the PGI compilers okay and so these", "start": 2704.16, "duration": 5.52}, {"text": "compilers will understand open", "start": 2707.48, "duration": 4.96}, {"text": "ACC um and again so you load this with", "start": 2709.68, "duration": 5.28}, {"text": "module load um and vhpc and we'll try", "start": 2712.44, "duration": 3.72}, {"text": "that", "start": 2714.96, "duration": 2.92}, {"text": "out", "start": 2716.16, "duration": 5.6}, {"text": "um so there's basically three ways to", "start": 2717.88, "duration": 6.84}, {"text": "use gpus either you use libraries that", "start": 2721.76, "duration": 4.839}, {"text": "you link against your your source code", "start": 2724.72, "duration": 5.72}, {"text": "if you have source code um you use these", "start": 2726.599, "duration": 6.401}, {"text": "open ACC directives that's pretty", "start": 2730.44, "duration": 4.24}, {"text": "straightforward", "start": 2733.0, "duration": 4.92}, {"text": "um um or you use programming languages", "start": 2734.68, "duration": 5.24}, {"text": "like you know CU", "start": 2737.92, "duration": 4.12}, {"text": "C++ and then of course you know if you", "start": 2739.92, "duration": 4.399}, {"text": "have some deep learning Frameworks T of", "start": 2742.04, "duration": 6.319}, {"text": "Flor pyes come with buil-in PPU", "start": 2744.319, "duration": 5.841}, {"text": "support", "start": 2748.359, "duration": 5.48}, {"text": "um this is something I took from uh a", "start": 2750.16, "duration": 6.6}, {"text": "recent slides from to thank Nvidia they", "start": 2753.839, "duration": 5.28}, {"text": "put together this nice slide um that", "start": 2756.76, "duration": 4.04}, {"text": "that gives an overview again and also a", "start": 2759.119, "duration": 3.521}, {"text": "little bit on how the source codes look", "start": 2760.8, "duration": 5.12}, {"text": "like um one thing that I didn't mention", "start": 2762.64, "duration": 5.04}, {"text": "actually that that's also available now", "start": 2765.92, "duration": 4.439}, {"text": "are accelerated standard languages so", "start": 2767.68, "duration": 4.08}, {"text": "standard language I mean you know you", "start": 2770.359, "duration": 5.401}, {"text": "have ISO C++ and foron for instance and", "start": 2771.76, "duration": 5.68}, {"text": "there are additional language constructs", "start": 2775.76, "duration": 4.04}, {"text": "that you can use like do concurrent", "start": 2777.44, "duration": 5.399}, {"text": "right and", "start": 2779.8, "duration": 6.44}, {"text": "um or you know here you have the two", "start": 2782.839, "duration": 6.161}, {"text": "numeric but you can use in in Python in", "start": 2786.24, "duration": 5.52}, {"text": "place of numile right and anything that", "start": 2789.0, "duration": 4.359}, {"text": "you would do in numile basically is", "start": 2791.76, "duration": 5.2}, {"text": "going to work and be accelerated", "start": 2793.359, "duration": 5.96}, {"text": "automatically um so that's pretty easy", "start": 2796.96, "duration": 4.399}, {"text": "to use right and it's part of you know", "start": 2799.319, "duration": 5.24}, {"text": "the language standard um or you have", "start": 2801.359, "duration": 5.801}, {"text": "this open ACC and open Mt", "start": 2804.559, "duration": 6.56}, {"text": "pragas um where open ACC is pretty", "start": 2807.16, "duration": 5.919}, {"text": "mature right so you add just these", "start": 2811.119, "duration": 3.681}, {"text": "pragas so you already have Source coding", "start": 2813.079, "duration": 4.48}, {"text": "you just add these pragmas and it will", "start": 2814.8, "duration": 4.6}, {"text": "basically the compiler will then take", "start": 2817.559, "duration": 5.081}, {"text": "the piece of code analyze it and see how", "start": 2819.4, "duration": 7.0}, {"text": "can he execute that on the GPU how can", "start": 2822.64, "duration": 6.08}, {"text": "you move the data that is required by", "start": 2826.4, "duration": 5.719}, {"text": "this function here onto the GPU and the", "start": 2828.72, "duration": 5.76}, {"text": "data that is be basically returned back", "start": 2832.119, "duration": 5.321}, {"text": "from the GPU and does it all for you or", "start": 2834.48, "duration": 4.839}, {"text": "you have to write the cuter code", "start": 2837.44, "duration": 4.2}, {"text": "yourself and there's these examples here", "start": 2839.319, "duration": 3.881}, {"text": "you know where you write a", "start": 2841.64, "duration": 4.24}, {"text": "function um and then you have to deal", "start": 2843.2, "duration": 4.44}, {"text": "with certain things where you have to", "start": 2845.88, "duration": 4.88}, {"text": "tell that function while it's executing", "start": 2847.64, "duration": 7.24}, {"text": "which um you know IDM you know if if you", "start": 2850.76, "duration": 5.559}, {"text": "running if you launch", "start": 2854.88, "duration": 3.52}, {"text": "100,000 threads you need to know which", "start": 2856.319, "duration": 3.681}, {"text": "thread I am and so there's this buil-in", "start": 2858.4, "duration": 5.28}, {"text": "V variables um that come with a cuter", "start": 2860.0, "duration": 6.559}, {"text": "language and memory copy operations that", "start": 2863.68, "duration": 5.24}, {"text": "you have to handle yourself basically", "start": 2866.559, "duration": 3.961}, {"text": "and then these are the launch", "start": 2868.92, "duration": 3.48}, {"text": "configurations um that tell how many", "start": 2870.52, "duration": 4.319}, {"text": "threats threats you're running on when", "start": 2872.4, "duration": 5.64}, {"text": "you launch that um function", "start": 2874.839, "duration": 4.881}, {"text": "um that's now called a kernel that", "start": 2878.04, "duration": 4.44}, {"text": "basically runs on the GPU", "start": 2879.72, "duration": 6.0}, {"text": "right and well I have those", "start": 2882.48, "duration": 7.16}, {"text": "libraries so for the", "start": 2885.72, "duration": 7.399}, {"text": "people who know how to use you know who", "start": 2889.64, "duration": 6.199}, {"text": "are used to to program I I'll go just", "start": 2893.119, "duration": 4.361}, {"text": "very briefly over you know what what you", "start": 2895.839, "duration": 5.48}, {"text": "do in in or people who know how to use c", "start": 2897.48, "duration": 7.0}, {"text": "um as an example how would you use GPU", "start": 2901.319, "duration": 8.0}, {"text": "accelerated libraries okay um um", "start": 2904.48, "duration": 9.48}, {"text": "so you can you can use um that obviously", "start": 2909.319, "duration": 7.0}, {"text": "without inp knowledge of any GPU", "start": 2913.96, "duration": 4.32}, {"text": "programing so what the GPU does so it's", "start": 2916.319, "duration": 3.881}, {"text": "a nice drop in acceleration that's", "start": 2918.28, "duration": 4.079}, {"text": "pretty easy and you have high quality", "start": 2920.2, "duration": 4.08}, {"text": "implementations that have been optimized", "start": 2922.359, "duration": 5.121}, {"text": "a lot so tuned by by experts so use", "start": 2924.28, "duration": 6.079}, {"text": "those if you can um there's many", "start": 2927.48, "duration": 5.48}, {"text": "available I think I mentioned before um", "start": 2930.359, "duration": 4.72}, {"text": "you know interest to you may might be", "start": 2932.96, "duration": 4.0}, {"text": "qtn", "start": 2935.079, "duration": 6.321}, {"text": "um and um for machine learning tensor RT", "start": 2936.96, "duration": 5.8}, {"text": "is deep stream", "start": 2941.4, "duration": 3.76}, {"text": "SDK that's for video inference so if", "start": 2942.76, "duration": 5.28}, {"text": "you're doing something like that for", "start": 2945.16, "duration": 5.08}, {"text": "instance and there's a lot of different", "start": 2948.04, "duration": 3.88}, {"text": "libraries that are freely available", "start": 2950.24, "duration": 4.76}, {"text": "actually and so if you take an example", "start": 2951.92, "duration": 4.96}, {"text": "here that's that's from you know", "start": 2955.0, "duration": 4.16}, {"text": "numerical computation to linear algebra", "start": 2956.88, "duration": 5.0}, {"text": "that's an sa XY function it does a", "start": 2959.16, "duration": 6.6}, {"text": "simple um vector addition of you know", "start": 2961.88, "duration": 9.239}, {"text": "Vector a so you have a number a number a", "start": 2965.76, "duration": 8.52}, {"text": "times a vector X Plus Vector y that's", "start": 2971.119, "duration": 4.361}, {"text": "what it does and all you do is you", "start": 2974.28, "duration": 4.36}, {"text": "replace it with Q blast XP and then you", "start": 2975.48, "duration": 4.8}, {"text": "have to Bas", "start": 2978.64, "duration": 5.12}, {"text": "tell the source code to copy the data", "start": 2980.28, "duration": 7.0}, {"text": "onto the GPU um so allocate memory copy", "start": 2983.76, "duration": 6.319}, {"text": "the data to the GPU or you can use q+", "start": 2987.28, "duration": 6.16}, {"text": "functions that um allow you to you know", "start": 2990.079, "duration": 7.04}, {"text": "operate directly on on a vector and at", "start": 2993.44, "duration": 5.8}, {"text": "the end you just think everything", "start": 2997.119, "duration": 3.96}, {"text": "against the q+", "start": 2999.24, "duration": 5.839}, {"text": "value so if you had this source code", "start": 3001.079, "duration": 7.401}, {"text": "where you have uh one million elements", "start": 3005.079, "duration": 6.961}, {"text": "in uh um and then you have like arrays", "start": 3008.48, "duration": 5.119}, {"text": "and so you have an", "start": 3012.04, "duration": 6.519}, {"text": "array Y and you want to add a plus a * X", "start": 3013.599, "duration": 7.801}, {"text": "into y right that's the result so you", "start": 3018.559, "duration": 4.8}, {"text": "can call this blast function that's", "start": 3021.4, "duration": 4.439}, {"text": "exactly what this blast function does", "start": 3023.359, "duration": 6.081}, {"text": "there a single prec a * X+ y um if you", "start": 3025.839, "duration": 7.24}, {"text": "want to use a GPU with the Q Plus", "start": 3029.44, "duration": 6.48}, {"text": "Library just call the corresponding Q", "start": 3033.079, "duration": 5.441}, {"text": "Plus function you add the", "start": 3035.92, "duration": 6.52}, {"text": "prefix and you use uh device variables", "start": 3038.52, "duration": 6.64}, {"text": "so often people will prefix those with d", "start": 3042.44, "duration": 6.08}, {"text": "underscore sometimes they do that to", "start": 3045.16, "duration": 5.52}, {"text": "tell the source code or to understand", "start": 3048.52, "duration": 3.68}, {"text": "you know it's for the programmer to", "start": 3050.68, "duration": 4.24}, {"text": "understand easier see that this is now", "start": 3052.2, "duration": 4.919}, {"text": "data that's sitting on the device which", "start": 3054.92, "duration": 5.399}, {"text": "is not what typically the GPU is called", "start": 3057.119, "duration": 5.841}, {"text": "the accelerator as as opposed to the", "start": 3060.319, "duration": 5.681}, {"text": "host which is the CPU that's hosting", "start": 3062.96, "duration": 6.68}, {"text": "the um and then you have to initialize Q", "start": 3066.0, "duration": 5.599}, {"text": "blast that's the handle that you're", "start": 3069.64, "duration": 4.479}, {"text": "passing here and then um there's a q", "start": 3071.599, "duration": 4.76}, {"text": "blast destroy function at the end so", "start": 3074.119, "duration": 3.96}, {"text": "that's all documented in the", "start": 3076.359, "duration": 4.361}, {"text": "manual you have to allocate memory using", "start": 3078.079, "duration": 5.641}, {"text": "that c Mal function um you know for", "start": 3080.72, "duration": 4.68}, {"text": "those arrays on the", "start": 3083.72, "duration": 5.639}, {"text": "GPU um and then you release that that um", "start": 3085.4, "duration": 5.159}, {"text": "memory at the", "start": 3089.359, "duration": 3.96}, {"text": "end and then you have to transfer the", "start": 3090.559, "duration": 4.76}, {"text": "data to the GPU and there's a CU set", "start": 3093.319, "duration": 3.641}, {"text": "Vector function basically where you say", "start": 3095.319, "duration": 4.8}, {"text": "how many data elements um of you know", "start": 3096.96, "duration": 4.839}, {"text": "what data types so how big that data", "start": 3100.119, "duration": 4.401}, {"text": "type is that you're", "start": 3101.799, "duration": 5.28}, {"text": "transferring um and that that those are", "start": 3104.52, "duration": 5.36}, {"text": "the arrays that are on the on the CPU", "start": 3107.079, "duration": 4.641}, {"text": "right and you want to have them on the", "start": 3109.88, "duration": 4.439}, {"text": "GPU and that's what those functions do", "start": 3111.72, "duration": 5.639}, {"text": "okay and then you have to do the reverse", "start": 3114.319, "duration": 5.28}, {"text": "and you copy the data back for the", "start": 3117.359, "duration": 5.0}, {"text": "result data after you have executed this", "start": 3119.599, "duration": 5.601}, {"text": "function on the GPU and that's all so", "start": 3122.359, "duration": 4.96}, {"text": "relatively small changes and you don't", "start": 3125.2, "duration": 3.32}, {"text": "really need to know how that's", "start": 3127.319, "duration": 3.961}, {"text": "implemented on the", "start": 3128.52, "duration": 2.76}, {"text": "GPU um now if you don't use C or C++ um", "start": 3131.68, "duration": 8.919}, {"text": "but if you use say python um lot of", "start": 3137.2, "duration": 5.68}, {"text": "people in the in the data Sciences like", "start": 3140.599, "duration": 4.401}, {"text": "to use P for", "start": 3142.88, "duration": 5.0}, {"text": "instance um and you might be familiar", "start": 3145.0, "duration": 6.0}, {"text": "with napai um so it works works very", "start": 3147.88, "duration": 5.08}, {"text": "similar so there's libraries and that", "start": 3151.0, "duration": 5.48}, {"text": "that you can directly use in in Python", "start": 3152.96, "duration": 5.72}, {"text": "that have been ported and will run and", "start": 3156.48, "duration": 4.319}, {"text": "execute automatically on the gpus for", "start": 3158.68, "duration": 6.48}, {"text": "you um so napai operates on arrays of", "start": 3160.799, "duration": 7.161}, {"text": "data and it's highly tuned for for CPUs", "start": 3165.16, "duration": 4.08}, {"text": "right I mean it's been around for many", "start": 3167.96, "duration": 3.48}, {"text": "many years", "start": 3169.24, "duration": 5.16}, {"text": "um of course you know there's no way it", "start": 3171.44, "duration": 6.04}, {"text": "can compete anywhere with you know", "start": 3174.4, "duration": 7.12}, {"text": "um um C++ or Fortune code um but you", "start": 3177.48, "duration": 7.56}, {"text": "know if you have python code and E pass", "start": 3181.52, "duration": 5.64}, {"text": "right you might you know have to use", "start": 3185.04, "duration": 4.16}, {"text": "numpy", "start": 3187.16, "duration": 6.04}, {"text": "um so npy like interface is is similar", "start": 3189.2, "duration": 7.119}, {"text": "uh qy has a npy like interface and that", "start": 3193.2, "duration": 5.56}, {"text": "makes it triv report to code to the", "start": 3196.319, "duration": 4.081}, {"text": "GPU", "start": 3198.76, "duration": 5.039}, {"text": "um and so you have ND array available", "start": 3200.4, "duration": 5.56}, {"text": "you know that also holds the same data", "start": 3203.799, "duration": 5.04}, {"text": "types as as on the CPU um it also", "start": 3205.96, "duration": 4.879}, {"text": "provides data interoperability with", "start": 3208.839, "duration": 3.561}, {"text": "other deep learning Frameworks there's", "start": 3210.839, "duration": 3.641}, {"text": "de learning frame deep learning", "start": 3212.4, "duration": 4.04}, {"text": "Frameworks um called", "start": 3214.48, "duration": 6.319}, {"text": "Rapids and uh it also works with num num", "start": 3216.44, "duration": 6.639}, {"text": "and it uses under the hood highly tuned", "start": 3220.799, "duration": 5.201}, {"text": "Nvidia libraries right so um you also", "start": 3223.079, "duration": 4.561}, {"text": "have the possibility to write custom", "start": 3226.0, "duration": 3.28}, {"text": "computer functions so I won't go into", "start": 3227.64, "duration": 4.28}, {"text": "details uh of that I'm actually not a", "start": 3229.28, "duration": 5.92}, {"text": "big expert with um python code but um", "start": 3231.92, "duration": 5.399}, {"text": "it's certainly possible and and in this", "start": 3235.2, "duration": 4.04}, {"text": "simple case you", "start": 3237.319, "duration": 4.161}, {"text": "know", "start": 3239.24, "duration": 5.76}, {"text": "um you know see here you have an import", "start": 3241.48, "duration": 6.56}, {"text": "function you import NP SNP well you just", "start": 3245.0, "duration": 5.599}, {"text": "replace it with import", "start": 3248.04, "duration": 5.559}, {"text": "qnp and uh you know then you use that", "start": 3250.599, "duration": 6.281}, {"text": "function here um that that does a QR", "start": 3253.599, "duration": 5.401}, {"text": "factorization uh of you know this a", "start": 3256.88, "duration": 4.16}, {"text": "linear linear", "start": 3259.0, "duration": 4.52}, {"text": "algebra package don't know this looks", "start": 3261.04, "duration": 6.319}, {"text": "like a type probably L um QR but it's a", "start": 3263.52, "duration": 5.799}, {"text": "QR factorization of this Matrix that you", "start": 3267.359, "duration": 3.521}, {"text": "have initialized here you know if you", "start": 3269.319, "duration": 5.441}, {"text": "have got a large Matrix like 4K by 4K um", "start": 3270.88, "duration": 5.959}, {"text": "I don't know what GPU that is on but you", "start": 3274.76, "duration": 3.4}, {"text": "know you can expect the significant", "start": 3276.839, "duration": 3.561}, {"text": "speed up simply by using Q instead of", "start": 3278.16, "duration": 3.959}, {"text": "numai and it's a pretty simple change to", "start": 3280.4, "duration": 4.52}, {"text": "do right and there there are other ways", "start": 3282.119, "duration": 4.801}, {"text": "to do that and you know we tomorrow and", "start": 3284.92, "duration": 3.399}, {"text": "the day after we'll have also some", "start": 3286.92, "duration": 5.48}, {"text": "examples um using um python in you know", "start": 3288.319, "duration": 6.081}, {"text": "machine learning applications that then", "start": 3292.4, "duration": 5.04}, {"text": "will run on gpus", "start": 3294.4, "duration": 4.52}, {"text": "um with that I want to introduce a", "start": 3297.44, "duration": 5.28}, {"text": "little bit of CA C actually to give you", "start": 3298.92, "duration": 5.08}, {"text": "a little bit more of a background what", "start": 3302.72, "duration": 2.599}, {"text": "happens behind the scenes I've been", "start": 3304.0, "duration": 3.28}, {"text": "talking about these things you know how", "start": 3305.319, "duration": 3.561}, {"text": "data gets transferred you have many", "start": 3307.28, "duration": 3.16}, {"text": "threats running and so on but let's look", "start": 3308.88, "duration": 4.08}, {"text": "a little bit more in detail", "start": 3310.44, "duration": 6.0}, {"text": "um so so QA C is that solution to run C", "start": 3312.96, "duration": 6.56}, {"text": "on on gpus and I said you know like I", "start": 3316.44, "duration": 5.399}, {"text": "said it's a standard of C++ basically", "start": 3319.52, "duration": 5.799}, {"text": "most people use nowadays um and the", "start": 3321.839, "duration": 5.041}, {"text": "extensions are pretty modern so it's not", "start": 3325.319, "duration": 4.0}, {"text": "a lot to learn but it's a lot to learn", "start": 3326.88, "duration": 6.52}, {"text": "on how to use it um you know write", "start": 3329.319, "duration": 6.641}, {"text": "algorithms and deer code so it requires", "start": 3333.4, "duration": 4.399}, {"text": "major rewriting of the code actually", "start": 3335.96, "duration": 4.0}, {"text": "right um if you're fortron programmer", "start": 3337.799, "duration": 4.161}, {"text": "there's also something called cud foron", "start": 3339.96, "duration": 5.24}, {"text": "um and that works with Nvidia foron", "start": 3341.96, "duration": 6.76}, {"text": "compilers um here I listed a few books", "start": 3345.2, "duration": 5.68}, {"text": "and resources if you curious about that", "start": 3348.72, "duration": 4.24}, {"text": "where where you can can read about this", "start": 3350.88, "duration": 3.719}, {"text": "um there's newer books and you Google", "start": 3352.96, "duration": 3.04}, {"text": "you'll find a lot of information on the", "start": 3354.599, "duration": 3.561}, {"text": "web", "start": 3356.0, "duration": 4.599}, {"text": "noways um yeah and that that's how it", "start": 3358.16, "duration": 3.72}, {"text": "looks like you know you have code that", "start": 3360.599, "duration": 2.401}, {"text": "runs in the", "start": 3361.88, "duration": 5.199}, {"text": "CPU um in serial that's called Running", "start": 3363.0, "duration": 7.16}, {"text": "on the host um then you have a parallel", "start": 3367.079, "duration": 5.401}, {"text": "section and you know you've seen this", "start": 3370.16, "duration": 4.48}, {"text": "variables before that I called like", "start": 3372.48, "duration": 4.8}, {"text": "block dim and drip Di and thread ID and", "start": 3374.64, "duration": 4.64}, {"text": "you know that tells basically which of", "start": 3377.28, "duration": 3.96}, {"text": "those threads that are launched on the", "start": 3379.28, "duration": 5.2}, {"text": "GQ um each of those threats is in and", "start": 3381.24, "duration": 5.16}, {"text": "the reason for having that is that one", "start": 3384.48, "duration": 4.639}, {"text": "of those blocks is guaranteed to execute", "start": 3386.4, "duration": 5.12}, {"text": "on on on one multiprocessor or two", "start": 3389.119, "duration": 4.321}, {"text": "multiprocessors and you can use that to", "start": 3391.52, "duration": 3.96}, {"text": "internally communicate data between the", "start": 3393.44, "duration": 6.44}, {"text": "threats within a block um yeah and then", "start": 3395.48, "duration": 5.879}, {"text": "you know have more serial code and then", "start": 3399.88, "duration": 3.199}, {"text": "you have other device code that execute", "start": 3401.359, "duration": 5.24}, {"text": "something else a different kind of for", "start": 3403.079, "duration": 3.52}, {"text": "instance", "start": 3408.119, "duration": 4.44}, {"text": "and that's what I mentioned before you", "start": 3410.28, "duration": 3.759}, {"text": "know schematically you have your host", "start": 3412.559, "duration": 2.56}, {"text": "you have your", "start": 3414.039, "duration": 4.28}, {"text": "CPU um with it's memory and then there's", "start": 3415.119, "duration": 5.361}, {"text": "this PCI Express bus um there's not", "start": 3418.319, "duration": 4.881}, {"text": "always a PCI Express bus that's being", "start": 3420.48, "duration": 4.559}, {"text": "used you know there's the data center", "start": 3423.2, "duration": 4.72}, {"text": "gpus that have different architectures", "start": 3425.039, "duration": 6.52}, {"text": "but um most cases you you might", "start": 3427.92, "duration": 5.879}, {"text": "encounter you know the CPU sitting on", "start": 3431.559, "duration": 4.081}, {"text": "the PCI Express Bus in any case there's", "start": 3433.799, "duration": 3.481}, {"text": "always some sort of bus that connects", "start": 3435.64, "duration": 5.52}, {"text": "you know the CPU to the GPU and um you", "start": 3437.28, "duration": 5.68}, {"text": "have to copy the input data right from", "start": 3441.16, "duration": 4.879}, {"text": "the CPU memory to the GPU memory and", "start": 3442.96, "duration": 5.839}, {"text": "then you have to launch a kernel the CPU", "start": 3446.039, "duration": 5.961}, {"text": "basically tells the you know um device", "start": 3448.799, "duration": 6.121}, {"text": "the GPU to load the program execute it", "start": 3452.0, "duration": 5.64}, {"text": "on the on the cache data on the on the", "start": 3454.92, "duration": 4.48}, {"text": "on the GPU cach the data here on the", "start": 3457.64, "duration": 3.8}, {"text": "chip for performance and then when", "start": 3459.4, "duration": 3.8}, {"text": "you're done you copy the data back to", "start": 3461.44, "duration": 5.48}, {"text": "the CPU and then postprocess it or write", "start": 3463.2, "duration": 5.72}, {"text": "it to this whatever you need to do it", "start": 3466.92, "duration": 5.0}, {"text": "right so that's really really the", "start": 3468.92, "duration": 7.52}, {"text": "processing flow and when you", "start": 3471.92, "duration": 7.96}, {"text": "see people programming um and talk about", "start": 3476.44, "duration": 6.72}, {"text": "you know cter code you you you you", "start": 3479.88, "duration": 6.239}, {"text": "you'll see these terms you know a kernel", "start": 3483.16, "duration": 7.04}, {"text": "that is basically a code or a function", "start": 3486.119, "duration": 7.521}, {"text": "that can be executed on the GPU right so", "start": 3490.2, "duration": 5.2}, {"text": "in this kernel what it does it operates", "start": 3493.64, "duration": 3.64}, {"text": "and lock step on the multiprocessors of", "start": 3495.4, "duration": 2.6}, {"text": "the", "start": 3497.28, "duration": 4.72}, {"text": "GPU and that happens in so-called warps", "start": 3498.0, "duration": 6.28}, {"text": "that's the N clature that that", "start": 3502.0, "duration": 5.76}, {"text": "um Cuda uses um I believe open C calls", "start": 3504.28, "duration": 7.039}, {"text": "it B front um and on CA you have that's", "start": 3507.76, "duration": 6.12}, {"text": "32 threats for most of the hardware um", "start": 3511.319, "duration": 6.48}, {"text": "AMD has I believe 32 and 64 depending on", "start": 3513.88, "duration": 6.76}, {"text": "what type of Hardware you have and these", "start": 3517.799, "duration": 5.481}, {"text": "threats will you know operate with", "start": 3520.64, "duration": 3.6}, {"text": "single", "start": 3523.28, "duration": 3.24}, {"text": "instructions um for all those multiple", "start": 3524.24, "duration": 6.52}, {"text": "threats so that's called an S te um", "start": 3526.52, "duration": 7.12}, {"text": "Paradigm um and then a threat is that", "start": 3530.76, "duration": 6.96}, {"text": "execution um uh um unit of the kernel", "start": 3533.64, "duration": 6.84}, {"text": "with a given index and with each thread", "start": 3537.72, "duration": 4.44}, {"text": "you know you have this index available", "start": 3540.48, "duration": 3.52}, {"text": "with which you then can access data for", "start": 3542.16, "duration": 4.56}, {"text": "instance in an array right um so for", "start": 3544.0, "duration": 4.88}, {"text": "instance you know thread number one go", "start": 3546.72, "duration": 4.119}, {"text": "goes and operates on data element number", "start": 3548.88, "duration": 3.719}, {"text": "one thread number two operates data", "start": 3550.839, "duration": 3.72}, {"text": "element to and so", "start": 3552.599, "duration": 4.401}, {"text": "on and these threats they are grouped", "start": 3554.559, "duration": 5.76}, {"text": "into blocks I mentioned this just before", "start": 3557.0, "duration": 4.64}, {"text": "um these blocks are guaranteed to", "start": 3560.319, "duration": 3.04}, {"text": "execute on the same", "start": 3561.64, "duration": 4.12}, {"text": "multiprocessor and the threats within a", "start": 3563.359, "duration": 4.0}, {"text": "block can actually synchronize and share", "start": 3565.76, "duration": 3.079}, {"text": "data so if you were to program this", "start": 3567.359, "duration": 3.641}, {"text": "yourself you can you can use make use of", "start": 3568.839, "duration": 3.72}, {"text": "that and that's often very important to", "start": 3571.0, "duration": 3.119}, {"text": "actually get", "start": 3572.559, "duration": 3.881}, {"text": "performance um and then the grid is just", "start": 3574.119, "duration": 4.041}, {"text": "the total number of thread blocks that", "start": 3576.44, "duration": 5.119}, {"text": "you have launched and that that um total", "start": 3578.16, "duration": 5.84}, {"text": "grid you know um is larger you know the", "start": 3581.559, "duration": 4.121}, {"text": "thread blocks you you typically will", "start": 3584.0, "duration": 4.28}, {"text": "have many more than multiprocessors in", "start": 3585.68, "duration": 4.2}, {"text": "the", "start": 3588.28, "duration": 3.68}, {"text": "GPU", "start": 3589.88, "duration": 5.0}, {"text": "um yeah so that's basically an example", "start": 3591.96, "duration": 6.079}, {"text": "here um", "start": 3594.88, "duration": 3.159}, {"text": "you know the grids m to the gpus and the", "start": 3598.2, "duration": 4.44}, {"text": "Box map to the multiprocessors we have", "start": 3600.48, "duration": 4.16}, {"text": "that grid and then we have a block and", "start": 3602.64, "duration": 4.28}, {"text": "then in each block you can have threads", "start": 3604.64, "duration": 4.24}, {"text": "and they can be indexed two dimensional", "start": 3606.92, "duration": 3.56}, {"text": "or threedimensional", "start": 3608.88, "duration": 4.439}, {"text": "even which is useful for instance if you", "start": 3610.48, "duration": 4.68}, {"text": "to make it easier for the programmer if", "start": 3613.319, "duration": 3.841}, {"text": "you have a three-dimensional data like", "start": 3615.16, "duration": 3.52}, {"text": "you could have a threedimensional grid", "start": 3617.16, "duration": 3.679}, {"text": "for", "start": 3618.68, "duration": 5.84}, {"text": "instance and uh yeah so these threads on", "start": 3620.839, "duration": 5.841}, {"text": "in one of these thread box they will", "start": 3624.52, "duration": 5.279}, {"text": "execute simultaneously in loog step on a", "start": 3626.68, "duration": 5.2}, {"text": "multiple of 32 but don't rely on that", "start": 3629.799, "duration": 3.721}, {"text": "because that's not guaranteed on the", "start": 3631.88, "duration": 3.239}, {"text": "cter", "start": 3633.52, "duration": 6.0}, {"text": "um language that that remains", "start": 3635.119, "duration": 7.521}, {"text": "constant and in that code example that I", "start": 3639.52, "duration": 4.68}, {"text": "showed before in that overview you know", "start": 3642.64, "duration": 5.399}, {"text": "you saw these grit dim dox and bl ID x.x", "start": 3644.2, "duration": 6.879}, {"text": "so these are the variables that that are", "start": 3648.039, "duration": 5.841}, {"text": "part of the cter language that um you", "start": 3651.079, "duration": 5.441}, {"text": "know you can query to return the grit di", "start": 3653.88, "duration": 6.04}, {"text": "menion uh the block ID and then also the", "start": 3656.52, "duration": 7.76}, {"text": "thread IND indices via thread idx and uh", "start": 3659.92, "duration": 6.399}, {"text": "you know the dimensions of the block", "start": 3664.28, "duration": 7.319}, {"text": "block B Max and so on and um yeah so in", "start": 3666.319, "duration": 8.52}, {"text": "the example here right you'd have 3 * 2", "start": 3671.599, "duration": 8.041}, {"text": "is six blocks right 1 2 3 * two and then", "start": 3674.839, "duration": 8.28}, {"text": "each block has 1 2 4 * 3 12 threads so", "start": 3679.64, "duration": 6.52}, {"text": "you have a total of 72 threads running", "start": 3683.119, "duration": 4.92}, {"text": "of course you you would never do that", "start": 3686.16, "duration": 4.08}, {"text": "you always have to have a multiple of 32", "start": 3688.039, "duration": 6.481}, {"text": "threats in each block um because of that", "start": 3690.24, "duration": 7.079}, {"text": "that you know is um instructions being", "start": 3694.52, "duration": 6.64}, {"text": "issued in in warps multiples of 32 um", "start": 3697.319, "duration": 6.04}, {"text": "otherwise you know you you you will have", "start": 3701.16, "duration": 4.28}, {"text": "very inefficient code and a lot of um", "start": 3703.359, "duration": 4.841}, {"text": "compute course idling um this is just", "start": 3705.44, "duration": 6.159}, {"text": "for for visual illustration purposes", "start": 3708.2, "duration": 6.599}, {"text": "yeah and then there are keywords for the", "start": 3711.599, "duration": 5.601}, {"text": "language like underscore uncore Global", "start": 3714.799, "duration": 5.721}, {"text": "underscore uncore where you know now you", "start": 3717.2, "duration": 5.359}, {"text": "write so this is C it looks you know", "start": 3720.52, "duration": 3.68}, {"text": "it's like a c function but now it has", "start": 3722.559, "duration": 4.121}, {"text": "this declaration specifier here", "start": 3724.2, "duration": 5.68}, {"text": "underscore Global uncore uncore um that", "start": 3726.68, "duration": 5.08}, {"text": "basically means this is a kernel that", "start": 3729.88, "duration": 4.6}, {"text": "should execute on the GPU so nvcc when", "start": 3731.76, "duration": 5.48}, {"text": "you compile it will can generate code", "start": 3734.48, "duration": 5.72}, {"text": "for the GPU on this for this kernel and", "start": 3737.24, "duration": 5.079}, {"text": "it will also generate basically code", "start": 3740.2, "duration": 5.24}, {"text": "that is callable as a function from the", "start": 3742.319, "duration": 5.52}, {"text": "from the CPU that's why it's Global", "start": 3745.44, "duration": 5.32}, {"text": "function um so the CPU basically can", "start": 3747.839, "duration": 5.0}, {"text": "launch that function and it thinks it's", "start": 3750.76, "duration": 6.68}, {"text": "ready and you can use the special uh uh", "start": 3752.839, "duration": 8.401}, {"text": "um uh um variables cuter cuter variables", "start": 3757.44, "duration": 6.679}, {"text": "in there and uh what what this function", "start": 3761.24, "duration": 5.079}, {"text": "does is a vector ad kernel it basically", "start": 3764.119, "duration": 5.881}, {"text": "you know you have an input um array A", "start": 3766.319, "duration": 6.24}, {"text": "and B and an output array C so these are", "start": 3770.0, "duration": 4.88}, {"text": "just pointers in this case of a certain", "start": 3772.559, "duration": 3.8}, {"text": "size", "start": 3774.88, "duration": 4.919}, {"text": "and you know each thread will have a", "start": 3776.359, "duration": 5.601}, {"text": "different thread ID here and then", "start": 3779.799, "duration": 4.24}, {"text": "basically you can see that how this", "start": 3781.96, "duration": 3.68}, {"text": "works in parallel now because each", "start": 3784.039, "duration": 3.961}, {"text": "thread will operate on a different", "start": 3785.64, "duration": 4.639}, {"text": "element of that Vector", "start": 3788.0, "duration": 4.839}, {"text": "okay um and this stride is just being", "start": 3790.279, "duration": 5.161}, {"text": "used with this while", "start": 3792.839, "duration": 4.921}, {"text": "function um so that you can pass an", "start": 3795.44, "duration": 4.96}, {"text": "arbitrary sized um", "start": 3797.76, "duration": 6.599}, {"text": "um arrays here with arbitrary Dimension", "start": 3800.4, "duration": 5.959}, {"text": "um while using a fixed number of of", "start": 3804.359, "duration": 4.0}, {"text": "threats when you launch that kernel when", "start": 3806.359, "duration": 4.361}, {"text": "you run this actually executed and then", "start": 3808.359, "duration": 4.0}, {"text": "you know you have this", "start": 3810.72, "duration": 3.96}, {"text": "memory um", "start": 3812.359, "duration": 6.081}, {"text": "allocation uh um API in imputer to", "start": 3814.68, "duration": 6.359}, {"text": "allocate in free memory and copy data", "start": 3818.44, "duration": 5.159}, {"text": "between the CPU memory the GPU memory", "start": 3821.039, "duration": 5.201}, {"text": "that's the M Copy function uh sorry the", "start": 3823.599, "duration": 4.601}, {"text": "the Q M Copy function which is an", "start": 3826.24, "duration": 4.359}, {"text": "equivalent to the corresponding C", "start": 3828.2, "duration": 4.24}, {"text": "functions and when you launch that", "start": 3830.599, "duration": 4.68}, {"text": "kernel you have this funny triple angle", "start": 3832.44, "duration": 4.52}, {"text": "brackets", "start": 3835.279, "duration": 4.52}, {"text": "um so this would be in the CPU code it", "start": 3836.96, "duration": 5.159}, {"text": "would call that function which is this", "start": 3839.799, "duration": 6.361}, {"text": "function here that's defined up here uh", "start": 3842.119, "duration": 6.2}, {"text": "and this is the number of threads you", "start": 3846.16, "duration": 3.36}, {"text": "know this is the number of threads in", "start": 3848.319, "duration": 2.52}, {"text": "the block and this is the number of", "start": 3849.52, "duration": 4.799}, {"text": "blocks in the grid um no and these can", "start": 3850.839, "duration": 7.2}, {"text": "be these will theault to one z0 and one", "start": 3854.319, "duration": 7.04}, {"text": "z z you don't specify that and with that", "start": 3858.039, "duration": 5.881}, {"text": "you know You' have a a parallel vector", "start": 3861.359, "duration": 6.361}, {"text": "addition that would execute on the GPU", "start": 3863.92, "duration": 3.8}, {"text": "um and let me just mention to you again", "start": 3867.839, "duration": 6.76}, {"text": "it's important to keep in mind you know", "start": 3871.839, "duration": 4.76}, {"text": "you have the host which is the CPU in", "start": 3874.599, "duration": 4.52}, {"text": "its memory and you need to transfer the", "start": 3876.599, "duration": 4.48}, {"text": "data there's actually also something", "start": 3879.119, "duration": 4.2}, {"text": "called constant memory that you can", "start": 3881.079, "duration": 6.081}, {"text": "use typically Ed for constants like say", "start": 3883.319, "duration": 7.04}, {"text": "Pi or natural constants or for you know", "start": 3887.16, "duration": 5.04}, {"text": "simulation constants that are constant", "start": 3890.359, "duration": 4.68}, {"text": "during the runtime of each colel and", "start": 3892.2, "duration": 4.52}, {"text": "when you have the dat are there then you", "start": 3895.039, "duration": 4.841}, {"text": "know a block will execute on a single", "start": 3896.72, "duration": 5.2}, {"text": "multiprocessor with multiple threats and", "start": 3899.88, "duration": 4.04}, {"text": "has access to the registers on the multi", "start": 3901.92, "duration": 5.399}, {"text": "processor and it's shared memory okay", "start": 3903.92, "duration": 5.359}, {"text": "and keep in mind is", "start": 3907.319, "duration": 4.081}, {"text": "basically this is the slow piece you", "start": 3909.279, "duration": 3.881}, {"text": "don't want to this is the slowest piece", "start": 3911.4, "duration": 3.08}, {"text": "here you don't want to move much data", "start": 3913.16, "duration": 3.28}, {"text": "between the host and the device and once", "start": 3914.48, "duration": 3.559}, {"text": "you've done that you want to do as much", "start": 3916.44, "duration": 4.359}, {"text": "comput as possible with as little", "start": 3918.039, "duration": 4.921}, {"text": "transfer between the GPU memory and the", "start": 3920.799, "duration": 5.56}, {"text": "mul processors um yeah we want to do as", "start": 3922.96, "duration": 6.48}, {"text": "much compute as possible um to offset", "start": 3926.359, "duration": 5.92}, {"text": "basically the the cost that it took to", "start": 3929.44, "duration": 5.04}, {"text": "copy the data of the GPU and and launch", "start": 3932.279, "duration": 4.361}, {"text": "the", "start": 3934.48, "duration": 2.16}, {"text": "cels um so avoid data transfers between", "start": 3937.119, "duration": 5.641}, {"text": "CPU and GPU and that's that's important", "start": 3940.44, "duration": 3.96}, {"text": "in any", "start": 3942.76, "duration": 5.039}, {"text": "case um minimize access to global memory", "start": 3944.4, "duration": 5.719}, {"text": "that is the memory the the ram that's", "start": 3947.799, "duration": 3.961}, {"text": "really becomes only important for you to", "start": 3950.119, "duration": 4.841}, {"text": "actually write CU kernels um otherwise", "start": 3951.76, "duration": 5.64}, {"text": "you don't have have really influence on", "start": 3954.96, "duration": 4.92}, {"text": "that and the same here for taking", "start": 3957.4, "duration": 4.56}, {"text": "advantage of fast share memory by tying", "start": 3959.88, "duration": 4.239}, {"text": "data that is you know if you write your", "start": 3961.96, "duration": 4.72}, {"text": "own code computer code then then then", "start": 3964.119, "duration": 4.68}, {"text": "you need to take these things into", "start": 3966.68, "duration": 4.0}, {"text": "account that's like cach blocking on a", "start": 3968.799, "duration": 5.401}, {"text": "CPU sort of like similar in some sense", "start": 3970.68, "duration": 6.56}, {"text": "where you know you basically read a stop", "start": 3974.2, "duration": 4.72}, {"text": "block of the data to be processed", "start": 3977.24, "duration": 3.359}, {"text": "operate on that in particular if you", "start": 3978.92, "duration": 5.24}, {"text": "have to re repeatedly read the data um", "start": 3980.599, "duration": 5.52}, {"text": "you know typical example is a May", "start": 3984.16, "duration": 4.76}, {"text": "multiplication where you have to", "start": 3986.119, "duration": 6.0}, {"text": "read each data element n Square", "start": 3988.92, "duration": 5.04}, {"text": "times and then you perform the", "start": 3992.119, "duration": 3.401}, {"text": "computation on the data subset and", "start": 3993.96, "duration": 5.04}, {"text": "shared memory before moving it back into", "start": 3995.52, "duration": 5.4}, {"text": "Global", "start": 3999.0, "duration": 4.599}, {"text": "memory um so that's a lot of information", "start": 4000.92, "duration": 5.6}, {"text": "in a lot of short time um I still have", "start": 4003.599, "duration": 5.68}, {"text": "more to show to you but we're", "start": 4006.52, "duration": 5.599}, {"text": "getting not too much about you", "start": 4009.279, "duration": 5.961}, {"text": "know you know um exhausting programming", "start": 4012.119, "duration": 4.16}, {"text": "Direct", "start": 4015.24, "duration": 4.16}, {"text": "or or you know source code that's more", "start": 4016.279, "duration": 6.201}, {"text": "difficult to to to go through but I", "start": 4019.4, "duration": 4.84}, {"text": "would just very briefly you want to", "start": 4022.48, "duration": 3.2}, {"text": "touch an open", "start": 4024.24, "duration": 4.48}, {"text": "ACC um because so if you actually were", "start": 4025.68, "duration": 5.639}, {"text": "to write your own code in C or have code", "start": 4028.72, "duration": 6.319}, {"text": "in cc++ or for you can use open", "start": 4031.319, "duration": 6.441}, {"text": "ACC um as an open standard for", "start": 4035.039, "duration": 5.361}, {"text": "expressing this parallelism instead of", "start": 4037.76, "duration": 5.319}, {"text": "writing your own kernel so you let", "start": 4040.4, "duration": 4.719}, {"text": "basically the compiler do that for you", "start": 4043.079, "duration": 3.72}, {"text": "but you have to tell tell the compiler", "start": 4045.119, "duration": 4.841}, {"text": "where to do that okay it works for", "start": 4046.799, "duration": 6.081}, {"text": "fortune and c and C++ um and it's fully", "start": 4049.96, "duration": 5.319}, {"text": "supported by the Nvidia compilers um", "start": 4052.88, "duration": 4.36}, {"text": "also some other compilers partially by", "start": 4055.279, "duration": 4.601}, {"text": "the glue compilers actually um I don't", "start": 4057.24, "duration": 5.96}, {"text": "know how well that works in the mean", "start": 4059.88, "duration": 6.679}, {"text": "time um and then open MP has also", "start": 4063.2, "duration": 7.48}, {"text": "prognos um that I think they're not not", "start": 4066.559, "duration": 6.361}, {"text": "as as efficient you know they don't work", "start": 4070.68, "duration": 6.24}, {"text": "as well yet as open ACC", "start": 4072.92, "duration": 4.0}, {"text": "um there's also PGI Community Edition", "start": 4076.96, "duration": 4.52}, {"text": "but since there's Nvidia HPC SDK you", "start": 4078.96, "duration": 6.599}, {"text": "don't need that anymore I would say", "start": 4081.48, "duration": 7.119}, {"text": "um um it's installed on expon so you", "start": 4085.559, "duration": 6.601}, {"text": "want to use it play around with", "start": 4088.599, "duration": 3.561}, {"text": "it um the Nvidia HPC SDK yeah modu Lo NV", "start": 4093.0, "duration": 10.12}, {"text": "HPC um I mentioned that before um", "start": 4097.92, "duration": 8.279}, {"text": "so let's go quickly over that and so", "start": 4103.12, "duration": 6.159}, {"text": "this is an example now I mentioned this", "start": 4106.199, "duration": 5.241}, {"text": "function earlier this SXP function as a", "start": 4109.279, "duration": 3.801}, {"text": "library it's part", "start": 4111.44, "duration": 4.799}, {"text": "of right if you were to implement it", "start": 4113.08, "duration": 4.92}, {"text": "yourself this is C code and this is", "start": 4116.239, "duration": 2.761}, {"text": "fortun", "start": 4118.0, "duration": 2.64}, {"text": "code", "start": 4119.0, "duration": 4.0}, {"text": "um that's how it look would look like", "start": 4120.64, "duration": 5.199}, {"text": "you know you pass the number of the size", "start": 4123.0, "duration": 6.08}, {"text": "of your your vectors you pass the", "start": 4125.839, "duration": 7.801}, {"text": "constant a and you pass the um pointers", "start": 4129.08, "duration": 9.4}, {"text": "to the to the um arrays X and Y okay and", "start": 4133.64, "duration": 6.32}, {"text": "then you have a for Loop where you just", "start": 4138.48, "duration": 5.719}, {"text": "do this addition you know a x a * x i", "start": 4139.96, "duration": 8.239}, {"text": "plus Y and store it back into Yi", "start": 4144.199, "duration": 6.401}, {"text": "and if you want to use open", "start": 4148.199, "duration": 5.12}, {"text": "ACC in principle all you have to do is", "start": 4150.6, "duration": 6.04}, {"text": "to include some pragmas um so pragma", "start": 4153.319, "duration": 6.88}, {"text": "ACC in foron would be your um", "start": 4156.64, "duration": 5.719}, {"text": "exclamation mark dollar", "start": 4160.199, "duration": 4.201}, {"text": "ACC and you have to have an end", "start": 4162.359, "duration": 4.281}, {"text": "statement um here you don't need it", "start": 4164.4, "duration": 4.52}, {"text": "because you know it's basically where", "start": 4166.64, "duration": 3.88}, {"text": "the for Loop", "start": 4168.92, "duration": 6.319}, {"text": "ends um and tell open ACC to generate a", "start": 4170.52, "duration": 6.719}, {"text": "kernel for you for that right so you", "start": 4175.239, "duration": 5.361}, {"text": "don't have to write it yourself um and", "start": 4177.239, "duration": 5.92}, {"text": "that's how the source code looks like is", "start": 4180.6, "duration": 4.599}, {"text": "really you know this is your main", "start": 4183.159, "duration": 4.841}, {"text": "function that somewhere you you know you", "start": 4185.199, "duration": 5.721}, {"text": "prepare the input arrays and then you do", "start": 4188.0, "duration": 6.719}, {"text": "this XY function called and so", "start": 4190.92, "duration": 5.799}, {"text": "previously you know we saw well we could", "start": 4194.719, "duration": 3.48}, {"text": "use a library for that and of course we", "start": 4196.719, "duration": 2.96}, {"text": "would want to use a library because", "start": 4198.199, "duration": 3.561}, {"text": "that's highly optimized but you know", "start": 4199.679, "duration": 3.361}, {"text": "have a function that doesn't have a", "start": 4201.76, "duration": 3.36}, {"text": "library um you know you can use these", "start": 4203.04, "duration": 4.48}, {"text": "pragmas to try to generate code", "start": 4205.12, "duration": 4.559}, {"text": "automatically and in some cases if the", "start": 4207.52, "duration": 3.6}, {"text": "functions are not too complex that", "start": 4209.679, "duration": 4.641}, {"text": "actually works quite well um then you", "start": 4211.12, "duration": 5.039}, {"text": "have the this is in this case with a", "start": 4214.32, "duration": 4.16}, {"text": "Portland group compiler works the same", "start": 4216.159, "duration": 6.08}, {"text": "way now with the Invidia um cc++ and and", "start": 4218.48, "duration": 8.12}, {"text": "for compilers you just tell it minus ACC", "start": 4222.239, "duration": 8.601}, {"text": "so use open ACC and this m info equals", "start": 4226.6, "duration": 6.44}, {"text": "Exel um gives you some", "start": 4230.84, "duration": 6.08}, {"text": "information um about what what open ACC", "start": 4233.04, "duration": 6.28}, {"text": "does uh in the compiler and this is the", "start": 4236.92, "duration": 4.92}, {"text": "output that you get you", "start": 4239.32, "duration": 5.0}, {"text": "know see some information like", "start": 4241.84, "duration": 5.64}, {"text": "generating copy in generating copy so", "start": 4244.32, "duration": 5.08}, {"text": "that basically means okay it's", "start": 4247.48, "duration": 7.84}, {"text": "generating code to copy X from the CPU", "start": 4249.4, "duration": 8.279}, {"text": "into the GPU and it's kind generating", "start": 4255.32, "duration": 5.56}, {"text": "code to copy y from the CPU to the GPU", "start": 4257.679, "duration": 5.121}, {"text": "and then when it's done back because", "start": 4260.88, "duration": 3.64}, {"text": "that's where we store the results so it", "start": 4262.8, "duration": 3.879}, {"text": "correctly identified you know which data", "start": 4264.52, "duration": 3.679}, {"text": "is being needed actually in this case", "start": 4266.679, "duration": 2.841}, {"text": "and that's not always the case so", "start": 4268.199, "duration": 2.881}, {"text": "sometimes you have to tell the", "start": 4269.52, "duration": 3.56}, {"text": "compiler and they found that Loop that", "start": 4271.08, "duration": 4.68}, {"text": "is parallelizable the for Loop and it", "start": 4273.08, "duration": 5.52}, {"text": "generated the kernel for you and you", "start": 4275.76, "duration": 4.76}, {"text": "know generates Tesla code which is you", "start": 4278.6, "duration": 4.4}, {"text": "know Tesla is the data center cards for", "start": 4280.52, "duration": 5.92}, {"text": "for NVIDIA that was the code name", "start": 4283.0, "duration": 6.04}, {"text": "um and I see some information here what", "start": 4286.44, "duration": 4.88}, {"text": "open ACC calls Loop gang and vectors", "start": 4289.04, "duration": 5.159}, {"text": "which is basically you know the the the", "start": 4291.32, "duration": 6.64}, {"text": "grid size um block size and thread size", "start": 4294.199, "duration": 6.081}, {"text": "and you see you know here these two", "start": 4297.96, "duration": 4.16}, {"text": "variables gang and Vector they", "start": 4300.28, "duration": 5.879}, {"text": "correspond to block and thread ID um", "start": 4302.12, "duration": 5.72}, {"text": "that's being generated so that's", "start": 4306.159, "duration": 4.401}, {"text": "basically generates that cter code", "start": 4307.84, "duration": 5.68}, {"text": "for and there there many more um open", "start": 4310.56, "duration": 6.679}, {"text": "ACC syntax elements", "start": 4313.52, "duration": 3.719}, {"text": "um um so usually you know you have this", "start": 4318.92, "duration": 3.719}, {"text": "directive that's followed by a", "start": 4321.48, "duration": 2.92}, {"text": "structured code", "start": 4322.639, "duration": 3.961}, {"text": "block um you know there's the chonos", "start": 4324.4, "duration": 5.04}, {"text": "construct and then you have Clauses like", "start": 4326.6, "duration": 6.16}, {"text": "um with if conditions or um um async", "start": 4329.44, "duration": 6.84}, {"text": "expressions and data Clauses that are", "start": 4332.76, "duration": 5.84}, {"text": "important so the data Clauses are you", "start": 4336.28, "duration": 5.2}, {"text": "know the compiler cannot figure out and", "start": 4338.6, "duration": 7.32}, {"text": "that can happen um you you can manually", "start": 4341.48, "duration": 7.12}, {"text": "tell via you know open ACC programers to", "start": 4345.92, "duration": 6.6}, {"text": "copy a list of arrays variables pointers", "start": 4348.6, "duration": 6.96}, {"text": "um the data basically to the GPU and", "start": 4352.52, "duration": 6.119}, {"text": "back or just copy it in or copy it out", "start": 4355.56, "duration": 6.079}, {"text": "only afterwards after the know basically", "start": 4358.639, "duration": 5.681}, {"text": "allocate memory don't copy memory from", "start": 4361.639, "duration": 4.641}, {"text": "the CPU or GPU but when you're done copy", "start": 4364.32, "duration": 5.6}, {"text": "it back um just create memory that's you", "start": 4366.28, "duration": 7.16}, {"text": "know temporary memory or um tell the the", "start": 4369.92, "duration": 5.88}, {"text": "compiler that dep data already present", "start": 4373.44, "duration": 5.08}, {"text": "on the GPU perhaps because somewhere", "start": 4375.8, "duration": 5.96}, {"text": "else in your code you already copied it", "start": 4378.52, "duration": 7.719}, {"text": "um with a data Clause to the GPU okay um", "start": 4381.76, "duration": 7.12}, {"text": "Etc so we have to understand these", "start": 4386.239, "duration": 4.281}, {"text": "things and that's why it's I think a", "start": 4388.88, "duration": 3.319}, {"text": "good idea to go", "start": 4390.52, "duration": 4.08}, {"text": "through Cuda understand a little bit how", "start": 4392.199, "duration": 5.561}, {"text": "Cuda works so you understand what", "start": 4394.6, "duration": 5.24}, {"text": "happens under the hood and you know", "start": 4397.76, "duration": 4.56}, {"text": "something if you want to use open ACC it", "start": 4399.84, "duration": 6.24}, {"text": "helps but also if you use some something", "start": 4402.32, "duration": 5.04}, {"text": "else you know if there's a performance", "start": 4406.08, "duration": 3.559}, {"text": "bottleneck and or something isn't as", "start": 4407.36, "duration": 5.2}, {"text": "fast as you think that you understand", "start": 4409.639, "duration": 4.401}, {"text": "that under the hood you know how the", "start": 4412.56, "duration": 4.599}, {"text": "data has to move between the the GPU and", "start": 4414.04, "duration": 4.599}, {"text": "the", "start": 4417.159, "duration": 3.801}, {"text": "CPU and if you really want to understand", "start": 4418.639, "duration": 5.361}, {"text": "it very well what's happening actually", "start": 4420.96, "duration": 4.64}, {"text": "um with a compiled code that you're", "start": 4424.0, "duration": 4.12}, {"text": "using you know you can use", "start": 4425.6, "duration": 6.84}, {"text": "profilers um they Nvidia profiling", "start": 4428.12, "duration": 4.32}, {"text": "tools these are older", "start": 4432.8, "duration": 4.6}, {"text": "they still work I'm not sure if they", "start": 4435.6, "duration": 5.36}, {"text": "still come with the NV HPC toolkit um I", "start": 4437.4, "duration": 6.279}, {"text": "I don't I don't know but it's used to be", "start": 4440.96, "duration": 4.719}, {"text": "NV Prof the command line profiler and", "start": 4443.679, "duration": 4.761}, {"text": "nvp then has a visual", "start": 4445.679, "duration": 5.121}, {"text": "profiler but really what Nvidia", "start": 4448.44, "duration": 4.719}, {"text": "recommends to use are the inside tools", "start": 4450.8, "duration": 5.12}, {"text": "so these are uh tools now there are", "start": 4453.159, "duration": 5.241}, {"text": "three tools actually um two that I've", "start": 4455.92, "duration": 3.84}, {"text": "been using in the research that I've", "start": 4458.4, "duration": 4.0}, {"text": "been doing um inside systems inside", "start": 4459.76, "duration": 3.84}, {"text": "computer and then there's inside", "start": 4462.4, "duration": 3.12}, {"text": "Graphics if you develop graphics code", "start": 4463.6, "duration": 5.32}, {"text": "that's not something that I do um that", "start": 4465.52, "duration": 5.48}, {"text": "are very very good tools and for", "start": 4468.92, "duration": 4.64}, {"text": "profiling your source code and so inside", "start": 4471.0, "duration": 6.88}, {"text": "systems helps you to understand the", "start": 4473.56, "duration": 6.96}, {"text": "entire executable the entire code from", "start": 4477.88, "duration": 4.64}, {"text": "start to end so you run the entire code", "start": 4480.52, "duration": 3.719}, {"text": "and you see what happens under the hood", "start": 4482.52, "duration": 3.36}, {"text": "when when when are kernels called when", "start": 4484.239, "duration": 4.0}, {"text": "is data copied when does the CPU do", "start": 4485.88, "duration": 4.319}, {"text": "something when you know when is the GP", "start": 4488.239, "duration": 4.721}, {"text": "idle and so on and so that helps you", "start": 4490.199, "duration": 5.561}, {"text": "basically to identify performance Spott", "start": 4492.96, "duration": 6.92}, {"text": "and to look at you know where you might", "start": 4495.76, "duration": 6.04}, {"text": "need to change something or where where", "start": 4499.88, "duration": 4.68}, {"text": "there are opportunities to optimize your", "start": 4501.8, "duration": 4.32}, {"text": "code", "start": 4504.56, "duration": 4.92}, {"text": "um once you've identified a kernel that", "start": 4506.12, "duration": 6.48}, {"text": "is already ported to to to GPU and you", "start": 4509.48, "duration": 5.199}, {"text": "see that it's not running fast or it", "start": 4512.6, "duration": 4.76}, {"text": "occupies most of the time um you might", "start": 4514.679, "duration": 5.281}, {"text": "want to profile that with inside compute", "start": 4517.36, "duration": 4.52}, {"text": "which gives you lots of details about", "start": 4519.96, "duration": 4.12}, {"text": "you know all the GQ utilization the", "start": 4521.88, "duration": 4.0}, {"text": "registers that are being used um you", "start": 4524.08, "duration": 3.599}, {"text": "know the memory access patterns memory", "start": 4525.88, "duration": 4.52}, {"text": "transfers and so on um it's got a roof", "start": 4527.679, "duration": 4.681}, {"text": "line analysis in there that you know", "start": 4530.4, "duration": 6.48}, {"text": "tells you what is the um um um you know", "start": 4532.36, "duration": 7.04}, {"text": "floating point and memory bandwidth um", "start": 4536.88, "duration": 3.759}, {"text": "floating Point performance memory", "start": 4539.4, "duration": 3.12}, {"text": "bandwidth and how you could potentially", "start": 4540.639, "duration": 4.921}, {"text": "optimize that so um and you know if you", "start": 4542.52, "duration": 4.52}, {"text": "use those tools together that's", "start": 4545.56, "duration": 4.56}, {"text": "basically what you do um to to optimize", "start": 4547.04, "duration": 5.159}, {"text": "um your source", "start": 4550.12, "duration": 5.64}, {"text": "code um there are also", "start": 4552.199, "duration": 5.561}, {"text": "specific profiling tools for deep", "start": 4555.76, "duration": 4.12}, {"text": "learning applications", "start": 4557.76, "duration": 3.72}, {"text": "um", "start": 4559.88, "duration": 4.64}, {"text": "so um inside systems and inside compute", "start": 4561.48, "duration": 7.04}, {"text": "they have been built uh using cuter you", "start": 4564.52, "duration": 5.6}, {"text": "know the so called cuter profiling tools", "start": 4568.52, "duration": 4.679}, {"text": "interface TI and you know you can insert", "start": 4570.12, "duration": 5.8}, {"text": "that specifically into your your Source", "start": 4573.199, "duration": 4.96}, {"text": "codes", "start": 4575.92, "duration": 6.719}, {"text": "um um there's this nbtx um extension", "start": 4578.159, "duration": 6.441}, {"text": "library is a way to annotate source code", "start": 4582.639, "duration": 4.441}, {"text": "with Mar markers so that helps you um", "start": 4584.6, "duration": 4.88}, {"text": "the profiler to", "start": 4587.08, "duration": 5.48}, {"text": "understand collect the", "start": 4589.48, "duration": 5.679}, {"text": "data um so you you know you annotate", "start": 4592.56, "duration": 4.2}, {"text": "code and focus on sections of code", "start": 4595.159, "duration": 4.681}, {"text": "important to the user now tensor flow", "start": 4596.76, "duration": 3.959}, {"text": "there's versions that have been", "start": 4599.84, "duration": 4.28}, {"text": "optimized by Nvidia um contains support", "start": 4600.719, "duration": 6.44}, {"text": "for mvtx markers and um there are also", "start": 4604.12, "duration": 4.559}, {"text": "mvtx", "start": 4607.159, "duration": 4.961}, {"text": "plugins uh uh as python binders bindings", "start": 4608.679, "duration": 6.921}, {"text": "for users to add markers easily and um", "start": 4612.12, "duration": 6.32}, {"text": "so you can use deal Prof which is theep", "start": 4615.6, "duration": 4.4}, {"text": "you know profiler for deep learning", "start": 4618.44, "duration": 5.4}, {"text": "models um that works with inside systems", "start": 4620.0, "duration": 5.8}, {"text": "and under the hood uses you know mvtx", "start": 4623.84, "duration": 4.64}, {"text": "for tensorflow or these mvtx plugins or", "start": 4625.8, "duration": 4.359}, {"text": "also mvtx for", "start": 4628.48, "duration": 5.32}, {"text": "pytorch um to collect profile data and", "start": 4630.159, "duration": 6.08}, {"text": "correlate it with a deep learning model", "start": 4633.8, "duration": 4.0}, {"text": "um I have to say I've not done this", "start": 4636.239, "duration": 6.281}, {"text": "myself um but it is it is possible and", "start": 4637.8, "duration": 7.56}, {"text": "um so you get information about", "start": 4642.52, "duration": 4.76}, {"text": "where the data is moving how it's moving", "start": 4645.36, "duration": 4.2}, {"text": "where the compute happens and you know", "start": 4647.28, "duration": 5.04}, {"text": "where you spend time and why why um so", "start": 4649.56, "duration": 4.8}, {"text": "that that can be very", "start": 4652.32, "duration": 4.6}, {"text": "insightful", "start": 4654.36, "duration": 5.64}, {"text": "um yeah so that's basically yeah tens of", "start": 4656.92, "duration": 5.719}, {"text": "flow High toor supported and so you get", "start": 4660.0, "duration": 5.4}, {"text": "an idea about are my gpus being utilized", "start": 4662.639, "duration": 5.201}, {"text": "right um am I using the tensor course or", "start": 4665.4, "duration": 6.0}, {"text": "not and why would I not be using um how", "start": 4667.84, "duration": 6.839}, {"text": "how can I improve performance and so you", "start": 4671.4, "duration": 6.799}, {"text": "can can you can um visualize you know", "start": 4674.679, "duration": 6.881}, {"text": "the the analysis and there", "start": 4678.199, "duration": 5.48}, {"text": "recommendations that come", "start": 4681.56, "duration": 7.24}, {"text": "up and um can help you to optimize um", "start": 4683.679, "duration": 6.96}, {"text": "your deep learning code as", "start": 4688.8, "duration": 4.839}, {"text": "well", "start": 4690.639, "duration": 3.0}, {"text": "um so tensor Flor and tensor RT they", "start": 4694.0, "duration": 4.92}, {"text": "they don't require any additional code", "start": 4697.0, "duration": 2.92}, {"text": "modifications", "start": 4698.92, "duration": 2.44}, {"text": "[Music]", "start": 4699.92, "duration": 5.319}, {"text": "um so the the DL Prof command line", "start": 4701.36, "duration": 6.279}, {"text": "interface would just prepend with um", "start": 4705.239, "duration": 4.681}, {"text": "dlpr command and then you visualize the", "start": 4707.639, "duration": 5.0}, {"text": "results with a DPR", "start": 4709.92, "duration": 5.68}, {"text": "viewer and for pyge you need to add a", "start": 4712.639, "duration": 4.441}, {"text": "few lines of code to your training", "start": 4715.6, "duration": 4.76}, {"text": "script to enable this Nvidia deal Prof", "start": 4717.08, "duration": 6.2}, {"text": "py andx module and then you can profile", "start": 4720.36, "duration": 6.68}, {"text": "using again the the Prof command line", "start": 4723.28, "duration": 6.68}, {"text": "interface and the visual year", "start": 4727.04, "duration": 5.92}, {"text": "profie so that's something that that", "start": 4729.96, "duration": 5.32}, {"text": "would be of interest for if you have", "start": 4732.96, "duration": 4.92}, {"text": "deep learning", "start": 4735.28, "duration": 5.76}, {"text": "workloads and with", "start": 4737.88, "duration": 7.24}, {"text": "that I actually want to stop here I", "start": 4741.04, "duration": 6.4}, {"text": "think we have about like 20 minutes and", "start": 4745.12, "duration": 4.2}, {"text": "I will go through a few slides", "start": 4747.44, "duration": 3.04}, {"text": "[Music]", "start": 4749.32, "duration": 4.839}, {"text": "um and then I let you work through", "start": 4750.48, "duration": 5.4}, {"text": "yourself but let me go through those", "start": 4754.159, "duration": 3.321}, {"text": "slides first to give you a little bit of", "start": 4755.88, "duration": 4.24}, {"text": "an idea about um how to use the expan", "start": 4757.48, "duration": 3.88}, {"text": "stre", "start": 4760.12, "duration": 3.599}, {"text": "notes", "start": 4761.36, "duration": 5.52}, {"text": "um this we've seen before so I don't", "start": 4763.719, "duration": 6.041}, {"text": "really have to talk much about that um", "start": 4766.88, "duration": 5.4}, {"text": "we have many GPU notes so we interested", "start": 4769.76, "duration": 4.439}, {"text": "in those GPU notes there", "start": 4772.28, "duration": 6.6}, {"text": "are um a total of 280 100 gpus I believe", "start": 4774.199, "duration": 7.921}, {"text": "that data are still correct um at least", "start": 4778.88, "duration": 6.839}, {"text": "accessible for the um research Community", "start": 4782.12, "duration": 6.119}, {"text": "open research Community there are also", "start": 4785.719, "duration": 4.361}, {"text": "notes that that are accessible for", "start": 4788.239, "duration": 4.081}, {"text": "industry Partners", "start": 4790.08, "duration": 5.32}, {"text": "specifically and um", "start": 4792.32, "duration": 5.8}, {"text": "this is how GPU no sort of looks like", "start": 4795.4, "duration": 4.12}, {"text": "you know", "start": 4798.12, "duration": 4.4}, {"text": "um", "start": 4799.52, "duration": 3.0}, {"text": "um we actually have the V100 sxm2 gpus", "start": 4802.6, "duration": 6.84}, {"text": "so um it's it doesn't look like a you", "start": 4806.32, "duration": 5.28}, {"text": "know PCI card that Ed that you know you", "start": 4809.44, "duration": 5.12}, {"text": "buy for for desktop workstations but", "start": 4811.6, "duration": 5.24}, {"text": "that's how the GPU actually looks like", "start": 4814.56, "duration": 4.4}, {"text": "and similar to a CPU in some sense um", "start": 4816.84, "duration": 5.2}, {"text": "but this is the memory here right and", "start": 4818.96, "duration": 5.96}, {"text": "the these are the cooling elements um", "start": 4822.04, "duration": 4.4}, {"text": "for the passive cooling so there's no", "start": 4824.92, "duration": 3.04}, {"text": "fan on it instead of you know you have a", "start": 4826.44, "duration": 4.279}, {"text": "lot of fans on here and they blow air no", "start": 4827.96, "duration": 4.4}, {"text": "cool air in there and the hot air comes", "start": 4830.719, "duration": 5.121}, {"text": "out there and um so in the data center", "start": 4832.36, "duration": 5.16}, {"text": "basically we have the hot aisles and the", "start": 4835.84, "duration": 4.08}, {"text": "cold aisles so you know the the air", "start": 4837.52, "duration": 3.639}, {"text": "conditioned air comes into the cold", "start": 4839.92, "duration": 3.68}, {"text": "aisles get sucked into the you know", "start": 4841.159, "duration": 4.601}, {"text": "cooling through the fence and then cools", "start": 4843.6, "duration": 4.559}, {"text": "the both the gpus and the CPUs in the", "start": 4845.76, "duration": 5.52}, {"text": "system so um and the memory of course", "start": 4848.159, "duration": 6.56}, {"text": "and and the local discs and so there", "start": 4851.28, "duration": 5.919}, {"text": "basically two CPUs and then over the PCI", "start": 4854.719, "duration": 6.361}, {"text": "Express pluss switch um the gpus are", "start": 4857.199, "duration": 6.281}, {"text": "connected and so those GPS they actually", "start": 4861.08, "duration": 5.4}, {"text": "talk to each other via NV link", "start": 4863.48, "duration": 4.88}, {"text": "interfaces", "start": 4866.48, "duration": 5.36}, {"text": "um that's faster than than PCI Express", "start": 4868.36, "duration": 6.359}, {"text": "bus but they do talk to the CPU by PCI", "start": 4871.84, "duration": 6.52}, {"text": "Express bus um if I recall correctly um", "start": 4874.719, "duration": 7.681}, {"text": "so that's that's how it looks like um", "start": 4878.36, "duration": 5.08}, {"text": "that's the", "start": 4882.4, "duration": 4.239}, {"text": "topology um um the note typology that's", "start": 4883.44, "duration": 6.16}, {"text": "an information that you can get um I", "start": 4886.639, "duration": 5.161}, {"text": "think that's also printed with Nvidia", "start": 4889.6, "duration": 4.8}, {"text": "SMI um you know there are four CPUs on", "start": 4891.8, "duration": 4.919}, {"text": "each each note and um this is the", "start": 4894.4, "duration": 3.56}, {"text": "network", "start": 4896.719, "duration": 6.241}, {"text": "interface um and the CPU Affinity Numa", "start": 4897.96, "duration": 6.8}, {"text": "Affinity is just simply because you know", "start": 4902.96, "duration": 5.64}, {"text": "you have two gpus that are sitting on uh", "start": 4904.76, "duration": 6.36}, {"text": "um and connected to a single uh CPU and", "start": 4908.6, "duration": 4.52}, {"text": "two other gpus that are connected to", "start": 4911.12, "duration": 3.88}, {"text": "another CPU", "start": 4913.12, "duration": 5.0}, {"text": "um I'm very sorry there's an alarm um", "start": 4915.0, "duration": 4.56}, {"text": "it's not an alarm it's just a phone I", "start": 4918.12, "duration": 2.84}, {"text": "have to switch it off otherwise it keeps", "start": 4919.56, "duration": 3.82}, {"text": "peing I'm sorry I'll be back in one", "start": 4920.96, "duration": 5.539}, {"text": "[Music]", "start": 4923.38, "duration": 3.119}, {"text": "sec okay um and it tells you which gpus", "start": 4928.6, "duration": 8.4}, {"text": "can talk to each other um via MV link", "start": 4934.199, "duration": 6.161}, {"text": "and how they connected with different", "start": 4937.0, "duration": 6.36}, {"text": "CPUs um that's a bigger picture on how", "start": 4940.36, "duration": 6.0}, {"text": "you know one of the CPUs actually looks", "start": 4943.36, "duration": 5.6}, {"text": "like um that's one of those diagrams and", "start": 4946.36, "duration": 4.0}, {"text": "you know you've seen earlier I showed", "start": 4948.96, "duration": 6.36}, {"text": "you that the the T10 from 2009 and now", "start": 4950.36, "duration": 6.2}, {"text": "of course you know you have many many", "start": 4955.32, "duration": 3.839}, {"text": "many many many many more U", "start": 4956.56, "duration": 5.599}, {"text": "multiprocessors and in a single um GPU", "start": 4959.159, "duration": 6.321}, {"text": "and they actually have larger L2 cache", "start": 4962.159, "duration": 5.161}, {"text": "um and then they have these EnV link", "start": 4965.48, "duration": 4.28}, {"text": "interconnects that talk to each other to", "start": 4967.32, "duration": 5.2}, {"text": "other gpus um high high bandwidth", "start": 4969.76, "duration": 5.76}, {"text": "interconnect", "start": 4972.52, "duration": 3.0}, {"text": "um yeah so each GPU has 32 gab of ram 80", "start": 4975.719, "duration": 8.561}, {"text": "SMS um and it has", "start": 4980.92, "duration": 7.2}, {"text": "64 uh fp32 cores 32 fp64 cores and an", "start": 4984.28, "duration": 7.2}, {"text": "81er course and draws approximately um", "start": 4988.12, "duration": 6.48}, {"text": "300 watts um", "start": 4991.48, "duration": 6.56}, {"text": "if if um it's under full load right so", "start": 4994.6, "duration": 5.52}, {"text": "if it's idle actually doesn't draw much", "start": 4998.04, "duration": 4.52}, {"text": "power and that's that's the floting", "start": 5000.12, "duration": 5.24}, {"text": "point performance that you can get", "start": 5002.56, "duration": 5.24}, {"text": "now if you log into expands", "start": 5005.36, "duration": 5.799}, {"text": "so you you know you can just SS AG into", "start": 5007.8, "duration": 5.76}, {"text": "expans or you can just use um you know", "start": 5011.159, "duration": 5.761}, {"text": "the the um the portal for", "start": 5013.56, "duration": 6.52}, {"text": "instance um once you're in expans so we", "start": 5016.92, "duration": 5.48}, {"text": "don't need this I left this in here for", "start": 5020.08, "duration": 5.159}, {"text": "you if you want if you go home and then", "start": 5022.4, "duration": 6.64}, {"text": "you know you want to actually run uh um", "start": 5025.239, "duration": 7.641}, {"text": "jobs bya s sash command or srun um these", "start": 5029.04, "duration": 6.32}, {"text": "are examples for you to use use um we", "start": 5032.88, "duration": 3.96}, {"text": "have an allias for that so we don't have", "start": 5035.36, "duration": 5.48}, {"text": "to take care about that um then the GPU", "start": 5036.84, "duration": 5.68}, {"text": "related modules as I said you know it's", "start": 5040.84, "duration": 3.839}, {"text": "often safe to say module Purge so once", "start": 5042.52, "duration": 4.4}, {"text": "you're on the GPU Noe we'll do this", "start": 5044.679, "duration": 4.761}, {"text": "interactively um and then say module", "start": 5046.92, "duration": 5.719}, {"text": "reset um s module is not required but", "start": 5049.44, "duration": 5.12}, {"text": "you can do that and then you can load um", "start": 5052.639, "duration": 4.56}, {"text": "I would say we will need the NV HPC", "start": 5054.56, "duration": 4.24}, {"text": "module", "start": 5057.199, "duration": 3.881}, {"text": "um when you have that loaded you can", "start": 5058.8, "duration": 4.879}, {"text": "check for the Nvidia cuter compiler and", "start": 5061.08, "duration": 4.159}, {"text": "don't worry that going fast through this", "start": 5063.679, "duration": 3.52}, {"text": "I just want to go fast through this and", "start": 5065.239, "duration": 3.241}, {"text": "I have all of this with input and", "start": 5067.199, "duration": 3.721}, {"text": "outputs and you know how to proceed on", "start": 5068.48, "duration": 4.52}, {"text": "the readme file in the GitHub repository", "start": 5070.92, "duration": 4.04}, {"text": "so that's what you can use now then then", "start": 5073.0, "duration": 3.6}, {"text": "to go through this but I'll just walk", "start": 5074.96, "duration": 5.719}, {"text": "you very briefly through this um you you", "start": 5076.6, "duration": 7.0}, {"text": "will see you should have the NV viia", "start": 5080.679, "duration": 5.241}, {"text": "compter compiler loaded nvcc D version", "start": 5083.6, "duration": 5.079}, {"text": "shows you the compiler version um if you", "start": 5085.92, "duration": 5.36}, {"text": "were to load also the Portland group um", "start": 5088.679, "duration": 5.761}, {"text": "module you'd have tgcc compiler but we", "start": 5091.28, "duration": 5.919}, {"text": "not going to use that now um that's the", "start": 5094.44, "duration": 4.799}, {"text": "way to get interactive", "start": 5097.199, "duration": 5.641}, {"text": "access um when you are a GPU node and", "start": 5099.239, "duration": 5.48}, {"text": "you have the GPU mod loaded you can use", "start": 5102.84, "duration": 5.44}, {"text": "the Nvidia SMI command um system", "start": 5104.719, "duration": 5.44}, {"text": "management interface and it will give", "start": 5108.28, "duration": 3.68}, {"text": "you information about the GPU and you'll", "start": 5110.159, "duration": 6.0}, {"text": "see um well we have a single V100 sxm2", "start": 5111.96, "duration": 7.159}, {"text": "GPU right and it's idle it draw only", "start": 5116.159, "duration": 5.361}, {"text": "little power no no memory is", "start": 5119.119, "duration": 6.361}, {"text": "used um nothing is running on it so it's", "start": 5121.52, "duration": 7.04}, {"text": "my GPU I can use it now for compute", "start": 5125.48, "duration": 4.56}, {"text": "stuff", "start": 5128.56, "duration": 3.32}, {"text": "okay", "start": 5130.04, "duration": 4.48}, {"text": "um then we'll be using cter toolkit", "start": 5131.88, "duration": 4.52}, {"text": "samples so this is an older version", "start": 5134.52, "duration": 3.92}, {"text": "there's a new version that's actually in", "start": 5136.4, "duration": 5.68}, {"text": "the in the um data repository for the", "start": 5138.44, "duration": 6.04}, {"text": "simil summer Institute and we'll be", "start": 5142.08, "duration": 4.28}, {"text": "using that and then we'll look into", "start": 5144.48, "duration": 5.0}, {"text": "those compter samples um we'll copy only", "start": 5146.36, "duration": 6.359}, {"text": "subset of those um so we don't compile", "start": 5149.48, "duration": 5.719}, {"text": "all of them we'll just compile two of", "start": 5152.719, "duration": 6.44}, {"text": "them and um one of them is device query", "start": 5155.199, "duration": 8.121}, {"text": "which will um you know source code um", "start": 5159.159, "duration": 7.96}, {"text": "that that checks the the the you know", "start": 5163.32, "duration": 7.399}, {"text": "uses the ca API function calls to check", "start": 5167.119, "duration": 6.921}, {"text": "um Hardware information about the the", "start": 5170.719, "duration": 6.4}, {"text": "Cuda capable um GPU that's installed so", "start": 5174.04, "duration": 5.04}, {"text": "it will tell you a lot about the GPU", "start": 5177.119, "duration": 3.761}, {"text": "that is installed and that you have", "start": 5179.08, "duration": 4.92}, {"text": "access to and the nice thing about these", "start": 5180.88, "duration": 5.279}, {"text": "um samples is you can look at the source", "start": 5184.0, "duration": 5.119}, {"text": "code and you know um look at how things", "start": 5186.159, "duration": 4.241}, {"text": "are written so it's actually quite", "start": 5189.119, "duration": 2.881}, {"text": "instructive and other things like device", "start": 5190.4, "duration": 3.64}, {"text": "per actually quite useful I use it", "start": 5192.0, "duration": 4.04}, {"text": "myself often just to check what G What", "start": 5194.04, "duration": 3.76}, {"text": "GPU I currently have on the machine that", "start": 5196.04, "duration": 4.4}, {"text": "I'm currently logged in", "start": 5197.8, "duration": 5.52}, {"text": "um and then there's two examples that", "start": 5200.44, "duration": 5.12}, {"text": "you know you should just test out one is", "start": 5203.32, "duration": 5.44}, {"text": "um there's a zero simple directory in a", "start": 5205.56, "duration": 6.159}, {"text": "matrix multiplication example Matrix", "start": 5208.76, "duration": 5.479}, {"text": "mode that is a handwritten Matrix multi", "start": 5211.719, "duration": 4.4}, {"text": "application that is optimized with all", "start": 5214.239, "duration": 3.721}, {"text": "sorts of like cash blocking and so on so", "start": 5216.119, "duration": 4.401}, {"text": "a lot of you know it's not non-trivial", "start": 5217.96, "duration": 5.56}, {"text": "code takes some time to write and you", "start": 5220.52, "duration": 4.32}, {"text": "know you'll see what performance you", "start": 5223.52, "duration": 3.32}, {"text": "create with your runit and then there's", "start": 5224.84, "duration": 3.68}, {"text": "a matrix multiplication example that", "start": 5226.84, "duration": 4.399}, {"text": "uses the qast library and we'll compile", "start": 5228.52, "duration": 4.24}, {"text": "that as well and you run it and then you", "start": 5231.239, "duration": 3.681}, {"text": "can see um what is the performance", "start": 5232.76, "duration": 5.879}, {"text": "basically that you get out of that um", "start": 5234.92, "duration": 6.96}, {"text": "I'll just show you the GitHub repository", "start": 5238.639, "duration": 5.161}, {"text": "and then you can try and work through", "start": 5241.88, "duration": 4.759}, {"text": "that and so that helps you know get onto", "start": 5243.8, "duration": 6.439}, {"text": "the GPU nodes and um play around with us", "start": 5246.639, "duration": 7.641}, {"text": "a little bit so let me show you the uh", "start": 5250.239, "duration": 7.321}, {"text": "what I mean with this so you should see", "start": 5254.28, "duration": 6.6}, {"text": "the screen I believe", "start": 5257.56, "duration": 3.32}, {"text": "and I'm not sure how I can increase the", "start": 5261.0, "duration": 4.8}, {"text": "font size", "start": 5263.96, "duration": 6.719}, {"text": "here so this should be probably good", "start": 5265.8, "duration": 8.64}, {"text": "enough so if you go to this you know S", "start": 5270.679, "duration": 7.641}, {"text": "Summer Institute website and then", "start": 5274.44, "duration": 6.52}, {"text": "2.5 GPU", "start": 5278.32, "duration": 4.72}, {"text": "Computing", "start": 5280.96, "duration": 4.56}, {"text": "um there is some information here where", "start": 5283.04, "duration": 5.36}, {"text": "it's well basically tasks you know it", "start": 5285.52, "duration": 4.84}, {"text": "walks you through logging inter", "start": 5288.4, "duration": 5.839}, {"text": "expounds um by SSH um and then using", "start": 5290.36, "duration": 6.56}, {"text": "that srun GPU shared command to get an", "start": 5294.239, "duration": 6.121}, {"text": "interactive node um you'd load the GPU", "start": 5296.92, "duration": 6.319}, {"text": "module um you can do module Pur and", "start": 5300.36, "duration": 5.0}, {"text": "module reset before or it's not required", "start": 5303.239, "duration": 8.041}, {"text": "um this case um you load n HPC compiler", "start": 5305.36, "duration": 8.319}, {"text": "uh check which which modules we have", "start": 5311.28, "duration": 6.72}, {"text": "loaded and run the NV SMI command go", "start": 5313.679, "duration": 6.241}, {"text": "further down there is an example you", "start": 5318.0, "duration": 3.8}, {"text": "know we'll copy the Nidia cuter samples", "start": 5319.92, "duration": 4.56}, {"text": "into our home directory so you can use", "start": 5321.8, "duration": 5.96}, {"text": "this this command here um so we", "start": 5324.48, "duration": 5.28}, {"text": "laterally copy it", "start": 5327.76, "duration": 4.959}, {"text": "from the simil data directory there", "start": 5329.76, "duration": 5.16}, {"text": "cuter samples directory", "start": 5332.719, "duration": 4.92}, {"text": "okay and that's just a a clone of", "start": 5334.92, "duration": 4.44}, {"text": "nvidia's GitHub repository and we", "start": 5337.639, "duration": 3.441}, {"text": "exclude some of those because there's a", "start": 5339.36, "duration": 3.2}, {"text": "lot of files and if you copy them it", "start": 5341.08, "duration": 3.4}, {"text": "will take a few minutes probably because", "start": 5342.56, "duration": 4.36}, {"text": "there's lots of people copying", "start": 5344.48, "duration": 5.12}, {"text": "things and then we'll compile and run", "start": 5346.92, "duration": 5.279}, {"text": "the device query example so that will", "start": 5349.6, "duration": 4.639}, {"text": "execute on the GPU you can look at you", "start": 5352.199, "duration": 4.201}, {"text": "know what what is the output that you", "start": 5354.239, "duration": 4.321}, {"text": "get", "start": 5356.4, "duration": 5.04}, {"text": "um yeah that's the that's the output", "start": 5358.56, "duration": 5.079}, {"text": "here and then then there's the examples", "start": 5361.44, "duration": 4.32}, {"text": "for compiling and running the matrix", "start": 5363.639, "duration": 4.121}, {"text": "multiplication example the handwritten", "start": 5365.76, "duration": 3.919}, {"text": "matrix multiplication and the matrix", "start": 5367.76, "duration": 5.359}, {"text": "multiplication with a Q Plus F okay so", "start": 5369.679, "duration": 4.881}, {"text": "I'll I'll I'll let", "start": 5373.119, "duration": 5.161}, {"text": "you look at this work through this um", "start": 5374.56, "duration": 6.4}, {"text": "and you know if there are questions um", "start": 5378.28, "duration": 4.12}, {"text": "raise your", "start": 5380.96, "duration": 6.719}, {"text": "hand um and and let me know and you", "start": 5382.4, "duration": 7.64}, {"text": "know we'll we'll try to fix this if", "start": 5387.679, "duration": 3.881}, {"text": "there are any problems or you know if", "start": 5390.04, "duration": 2.96}, {"text": "there are any questions i' be happy to", "start": 5391.56, "duration": 4.48}, {"text": "answer them", "start": 5393.0, "duration": 3.04}]