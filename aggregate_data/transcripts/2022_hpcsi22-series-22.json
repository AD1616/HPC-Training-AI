[{"text": "all right thanks um all right welcome", "start": 1.319, "duration": 3.921}, {"text": "back to deep learning this is the second", "start": 3.12, "duration": 4.04}, {"text": "part of deep learning so deep learning", "start": 5.24, "duration": 6.08}, {"text": "part two um so here's the agenda uh", "start": 7.16, "duration": 5.68}, {"text": "we're gonna I'll talk about deep", "start": 11.32, "duration": 3.519}, {"text": "learning layers and architectures and", "start": 12.84, "duration": 4.08}, {"text": "then uh we'll talk about transfer", "start": 14.839, "duration": 3.44}, {"text": "learning what that means in the Deep", "start": 16.92, "duration": 3.4}, {"text": "learning context then do some", "start": 18.279, "duration": 4.281}, {"text": "exercises um that's going to be followed", "start": 20.32, "duration": 3.959}, {"text": "by a break and then Paul's going to talk", "start": 22.56, "duration": 3.52}, {"text": "about um other deep learning topics and", "start": 24.279, "duration": 3.08}, {"text": "then hopefully we'll have a few minutes", "start": 26.08, "duration": 2.88}, {"text": "at the end to wrap", "start": 27.359, "duration": 3.961}, {"text": "up", "start": 28.96, "duration": 5.759}, {"text": "okay um so let's get started here so um", "start": 31.32, "duration": 4.88}, {"text": "here are the topics I'm going to be", "start": 34.719, "duration": 4.481}, {"text": "covering the next uh 45 minutes I think", "start": 36.2, "duration": 6.359}, {"text": "um so we'll start with um neural network", "start": 39.2, "duration": 6.199}, {"text": "Basics so I kind of want to start out", "start": 42.559, "duration": 5.081}, {"text": "with this", "start": 45.399, "duration": 5.761}, {"text": "um uh start out with this uh talk about", "start": 47.64, "duration": 6.88}, {"text": "this diagram here um so as the diagram", "start": 51.16, "duration": 5.68}, {"text": "shows deep learning is a subfield of", "start": 54.52, "duration": 4.559}, {"text": "machine learning which in is in turn a", "start": 56.84, "duration": 4.559}, {"text": "subfield of artif icial intelligence", "start": 59.079, "duration": 5.48}, {"text": "right so if you I think if you talk to", "start": 61.399, "duration": 4.241}, {"text": "you know different people you're going", "start": 64.559, "duration": 3.161}, {"text": "to get different definitions of of these", "start": 65.64, "duration": 3.76}, {"text": "terms depending on their background", "start": 67.72, "duration": 2.92}, {"text": "because lots of people come from", "start": 69.4, "duration": 3.24}, {"text": "different backgrounds who are working in", "start": 70.64, "duration": 3.92}, {"text": "deep learning now um but I think that", "start": 72.64, "duration": 4.4}, {"text": "most people would agree that um the goal", "start": 74.56, "duration": 5.36}, {"text": "of artificial intelligence is to build", "start": 77.04, "duration": 4.68}, {"text": "uh Systems computer systems that can", "start": 79.92, "duration": 4.64}, {"text": "perform tasks that are kind of commonly", "start": 81.72, "duration": 5.24}, {"text": "associated with what we refer to we", "start": 84.56, "duration": 4.36}, {"text": "would think of as intelligent thought", "start": 86.96, "duration": 3.24}, {"text": "right or that exhibits sort of", "start": 88.92, "duration": 3.96}, {"text": "intelligent Behavior like um", "start": 90.2, "duration": 4.599}, {"text": "understanding spoken words uh", "start": 92.88, "duration": 4.4}, {"text": "recognizing what's in an image um", "start": 94.799, "duration": 4.921}, {"text": "playing a game of strategy like Chester", "start": 97.28, "duration": 4.839}, {"text": "go right so that's artificial", "start": 99.72, "duration": 4.88}, {"text": "intelligence machine learning is a subal", "start": 102.119, "duration": 4.68}, {"text": "of that and that focuses on systems that", "start": 104.6, "duration": 4.479}, {"text": "can learn from data and if you were in", "start": 106.799, "duration": 4.92}, {"text": "the scalable machine learning session", "start": 109.079, "duration": 5.201}, {"text": "yesterday we talked about uh you know", "start": 111.719, "duration": 5.521}, {"text": "the fact that it's um one of the main", "start": 114.28, "duration": 4.56}, {"text": "characteristics of machine learning is", "start": 117.24, "duration": 3.799}, {"text": "that you don't have to to explicitly", "start": 118.84, "duration": 4.52}, {"text": "program the model you know you don't", "start": 121.039, "duration": 4.12}, {"text": "have to give it explicit step-by-step", "start": 123.36, "duration": 3.679}, {"text": "instructions on how to do a certain task", "start": 125.159, "duration": 6.241}, {"text": "um it it learns from data um so uh the", "start": 127.039, "duration": 6.321}, {"text": "idea is that the machine learning model", "start": 131.4, "duration": 5.479}, {"text": "can um are data driven and they can", "start": 133.36, "duration": 5.08}, {"text": "discover hidden patterns and Trends in", "start": 136.879, "duration": 5.321}, {"text": "the data without uh given explicit", "start": 138.44, "duration": 6.28}, {"text": "step-by-step instructions um deep", "start": 142.2, "duration": 5.64}, {"text": "learning also focuses on systems that", "start": 144.72, "duration": 6.32}, {"text": "can learn from data um and the defining", "start": 147.84, "duration": 5.039}, {"text": "characteristics of uh deep learning", "start": 151.04, "duration": 3.919}, {"text": "models is that they have lots and lots", "start": 152.879, "duration": 5.241}, {"text": "of layers of processing", "start": 154.959, "duration": 6.041}, {"text": "units okay", "start": 158.12, "duration": 5.52}, {"text": "so so in general deep learning models", "start": 161.0, "duration": 4.92}, {"text": "are based on neural networks um which", "start": 163.64, "duration": 5.44}, {"text": "are a type of uh machine learning model", "start": 165.92, "duration": 6.2}, {"text": "um and a neural network consists of many", "start": 169.08, "duration": 6.68}, {"text": "processing units um so what Paul went", "start": 172.12, "duration": 7.96}, {"text": "over um in the previous session is um", "start": 175.76, "duration": 6.96}, {"text": "you know the um this is on the what's", "start": 180.08, "duration": 5.12}, {"text": "shown on the left here is a conventional", "start": 182.72, "duration": 5.079}, {"text": "noal Network right so typically in a", "start": 185.2, "duration": 4.679}, {"text": "conventional Nal Network you you have an", "start": 187.799, "duration": 4.201}, {"text": "input layer and then one or two hidden", "start": 189.879, "duration": 5.08}, {"text": "layers and then an output layer um so", "start": 192.0, "duration": 6.0}, {"text": "it's um considered a shallow Nal Network", "start": 194.959, "duration": 5.84}, {"text": "right so now that's kind of the term", "start": 198.0, "duration": 5.2}, {"text": "that is used to kind of distinguish", "start": 200.799, "duration": 4.36}, {"text": "conventional neural networks from Deep", "start": 203.2, "duration": 3.399}, {"text": "uh neural", "start": 205.159, "duration": 5.201}, {"text": "networks so a deep uh neural network or", "start": 206.599, "duration": 5.92}, {"text": "a deep learning model um on the other", "start": 210.36, "duration": 4.36}, {"text": "hand can have lots and lots of layers", "start": 212.519, "duration": 4.161}, {"text": "right you can have dozens even hundreds", "start": 214.72, "duration": 4.599}, {"text": "of layers and these", "start": 216.68, "duration": 5.759}, {"text": "layers give the Deep learning model the", "start": 219.319, "duration": 6.241}, {"text": "power to learn very complex mappings", "start": 222.439, "duration": 6.121}, {"text": "between the input and the output um so", "start": 225.56, "duration": 4.759}, {"text": "these layers allow for the model to", "start": 228.56, "duration": 4.56}, {"text": "learn representations of the data at", "start": 230.319, "duration": 3.76}, {"text": "different", "start": 233.12, "duration": 3.479}, {"text": "layers um and different levels of", "start": 234.079, "duration": 5.281}, {"text": "abstraction right and so this is what", "start": 236.599, "duration": 6.081}, {"text": "gives deep learning models um such a", "start": 239.36, "duration": 5.159}, {"text": "great performance and also leads to", "start": 242.68, "duration": 3.919}, {"text": "automatic feature learning which um Paul", "start": 244.519, "duration": 4.401}, {"text": "also talked about earlier right so you", "start": 246.599, "duration": 5.48}, {"text": "don't have to manually specify what", "start": 248.92, "duration": 6.08}, {"text": "features a deep learning model um has to", "start": 252.079, "duration": 5.641}, {"text": "look for it automatically figures out", "start": 255.0, "duration": 5.479}, {"text": "what features are Salient um to the task", "start": 257.72, "duration": 6.12}, {"text": "at hand okay", "start": 260.479, "duration": 5.801}, {"text": "um and also because a deep learning", "start": 263.84, "duration": 5.32}, {"text": "model has so many layers this is why um", "start": 266.28, "duration": 4.84}, {"text": "deep loaring models require so much", "start": 269.16, "duration": 3.68}, {"text": "training data because there's so many", "start": 271.12, "duration": 4.4}, {"text": "parameters that need to be", "start": 272.84, "duration": 5.919}, {"text": "adjusted okay um all right so that's", "start": 275.52, "duration": 6.48}, {"text": "kind of background on deep learning and", "start": 278.759, "duration": 5.72}, {"text": "um many many applications in deep", "start": 282.0, "duration": 4.52}, {"text": "learning right they uh de learning", "start": 284.479, "duration": 3.72}, {"text": "models have been applied to a lot of", "start": 286.52, "duration": 5.2}, {"text": "different tasks so most notably uh image", "start": 288.199, "duration": 5.84}, {"text": "processing image analysis uh type of", "start": 291.72, "duration": 4.319}, {"text": "task and natural language processing", "start": 294.039, "duration": 3.761}, {"text": "type of task like speech recognition", "start": 296.039, "duration": 5.561}, {"text": "text summarization um uh name dentity", "start": 297.8, "duration": 6.76}, {"text": "recognition things like that um but uh", "start": 301.6, "duration": 4.64}, {"text": "deep learning models have been applied", "start": 304.56, "duration": 3.76}, {"text": "to lots of other applications as well", "start": 306.24, "duration": 4.28}, {"text": "and they have uh delivered really good", "start": 308.32, "duration": 5.28}, {"text": "performance uh especially uh compared to", "start": 310.52, "duration": 5.64}, {"text": "you know your conventional", "start": 313.6, "duration": 4.719}, {"text": "methods okay", "start": 316.16, "duration": 5.159}, {"text": "so let's talk um a little bit more about", "start": 318.319, "duration": 4.72}, {"text": "what a noal network is so this is a", "start": 321.319, "duration": 3.761}, {"text": "little bit of a review but a different", "start": 323.039, "duration": 5.841}, {"text": "uh kind of a different um take on uh a", "start": 325.08, "duration": 5.16}, {"text": "noral network", "start": 328.88, "duration": 3.64}, {"text": "um that Paul talked about earlier so a", "start": 330.24, "duration": 4.799}, {"text": "old network is a machine learning model", "start": 332.52, "duration": 5.32}, {"text": "right and it consists of processing", "start": 335.039, "duration": 5.761}, {"text": "units that are interconnected by", "start": 337.84, "duration": 5.12}, {"text": "parameters and in a n network parameters", "start": 340.8, "duration": 4.28}, {"text": "are also referred to as", "start": 342.96, "duration": 5.88}, {"text": "weights um so the noal network is", "start": 345.08, "duration": 6.04}, {"text": "trained to learn the mapping from the", "start": 348.84, "duration": 4.12}, {"text": "input to the output based on the", "start": 351.12, "duration": 5.72}, {"text": "training data that it receives right um", "start": 352.96, "duration": 6.88}, {"text": "and the neural network this neural", "start": 356.84, "duration": 6.24}, {"text": "network model is inspired by biological", "start": 359.84, "duration": 5.88}, {"text": "neural systems like like our brain right", "start": 363.08, "duration": 5.399}, {"text": "so in our brain we have lots and lots of", "start": 365.72, "duration": 4.68}, {"text": "processing units called neurons right", "start": 368.479, "duration": 4.481}, {"text": "and these neurons are connected by lots", "start": 370.4, "duration": 6.919}, {"text": "of connections by dendrites and axons um", "start": 372.96, "duration": 7.0}, {"text": "and information is transmitted between", "start": 377.319, "duration": 4.761}, {"text": "these neurons you know um using these", "start": 379.96, "duration": 6.16}, {"text": "connections using the ddes and axons um", "start": 382.08, "duration": 9.839}, {"text": "and so um there's also a a large um", "start": 386.12, "duration": 8.84}, {"text": "research area that uses neural networks", "start": 391.919, "duration": 5.641}, {"text": "and these are these are um at the", "start": 394.96, "duration": 4.76}, {"text": "beginning um these neural network models", "start": 397.56, "duration": 3.84}, {"text": "are referred to as artificial neural", "start": 399.72, "duration": 4.199}, {"text": "networks or a&n for short right to kind", "start": 401.4, "duration": 4.72}, {"text": "of um differentiate them for biological", "start": 403.919, "duration": 4.041}, {"text": "neural networks and there's a large", "start": 406.12, "duration": 5.28}, {"text": "research area that uses these um Ann", "start": 407.96, "duration": 5.48}, {"text": "these neural network models to study the", "start": 411.4, "duration": 4.519}, {"text": "processing of the human brain right so", "start": 413.44, "duration": 4.159}, {"text": "uh the inspiration for neural networks", "start": 415.919, "duration": 4.641}, {"text": "comes from the brain um and and in fact", "start": 417.599, "duration": 4.44}, {"text": "a lot of the pioneering work was done", "start": 420.56, "duration": 7.44}, {"text": "here at UCSD so um that's an interesting", "start": 422.039, "duration": 9.0}, {"text": "background okay so if you take a deeper", "start": 428.0, "duration": 5.12}, {"text": "dive into you know each one of these", "start": 431.039, "duration": 3.961}, {"text": "processing units right if you if you", "start": 433.12, "duration": 4.4}, {"text": "look at what happens in this um", "start": 435.0, "duration": 6.16}, {"text": "Processing Unit um you have each", "start": 437.52, "duration": 6.2}, {"text": "processing unit gets inputs right so the", "start": 441.16, "duration": 5.52}, {"text": "X's here are the inputs and then the W's", "start": 443.72, "duration": 4.44}, {"text": "are the weights these are the parameters", "start": 446.68, "duration": 4.12}, {"text": "of that processing of that goes into a", "start": 448.16, "duration": 5.8}, {"text": "processing unit so each unit computes", "start": 450.8, "duration": 4.88}, {"text": "the dot product of the inputs and the", "start": 453.96, "duration": 4.959}, {"text": "weights right the dot product and then", "start": 455.68, "duration": 4.919}, {"text": "it adds a bias and a bias is just", "start": 458.919, "duration": 4.4}, {"text": "another weight another parameter and", "start": 460.599, "duration": 4.88}, {"text": "then it applies an activation in order", "start": 463.319, "duration": 5.361}, {"text": "to get the output right so um computes a", "start": 465.479, "duration": 6.641}, {"text": "DOT product has a bias and applies an", "start": 468.68, "duration": 5.4}, {"text": "activation function to get the output", "start": 472.12, "duration": 4.039}, {"text": "and then the output of each unit then is", "start": 474.08, "duration": 5.2}, {"text": "fed to units in the next layer and", "start": 476.159, "duration": 7.0}, {"text": "normally this activation is a nonlinear", "start": 479.28, "duration": 7.24}, {"text": "activation all right", "start": 483.159, "duration": 5.04}, {"text": "um", "start": 486.52, "duration": 5.0}, {"text": "so training a neural network uh consists", "start": 488.199, "duration": 6.081}, {"text": "of two phases so this is uh what Paul", "start": 491.52, "duration": 5.48}, {"text": "had gone over this this uh earlier", "start": 494.28, "duration": 6.16}, {"text": "today uh so in the forward phase the", "start": 497.0, "duration": 5.919}, {"text": "input is fed to the network uh the", "start": 500.44, "duration": 4.599}, {"text": "network is multiplied by the weights", "start": 502.919, "duration": 3.72}, {"text": "right so each processing unit will", "start": 505.039, "duration": 4.321}, {"text": "compute the dot product add the bias", "start": 506.639, "duration": 5.12}, {"text": "apply a an activation function to get", "start": 509.36, "duration": 3.88}, {"text": "the output and then the output of one", "start": 511.759, "duration": 4.601}, {"text": "layer then is fed to the units of in the", "start": 513.24, "duration": 5.679}, {"text": "other layer in the next layers until you", "start": 516.36, "duration": 5.64}, {"text": "get to the output layer that's how", "start": 518.919, "duration": 4.8}, {"text": "that's what happens in the forward pass", "start": 522.0, "duration": 4.32}, {"text": "in the backward pass then some error is", "start": 523.719, "duration": 4.721}, {"text": "calculated at the output layer right so", "start": 526.32, "duration": 5.32}, {"text": "this is based on some loss function that", "start": 528.44, "duration": 4.8}, {"text": "Quant uh", "start": 531.64, "duration": 3.879}, {"text": "quantifies the discrepancies between", "start": 533.24, "duration": 4.0}, {"text": "what the model is outputting and what it", "start": 535.519, "duration": 2.88}, {"text": "should be outputting right so the", "start": 537.24, "duration": 3.719}, {"text": "model's predictions versus the targets", "start": 538.399, "duration": 4.481}, {"text": "and then that error then is back", "start": 540.959, "duration": 3.961}, {"text": "propagated in order to adjust all of", "start": 542.88, "duration": 3.92}, {"text": "these weights in the neural network", "start": 544.92, "duration": 4.359}, {"text": "model okay so that's kind of in a", "start": 546.8, "duration": 4.64}, {"text": "nutshell um what happens during neural", "start": 549.279, "duration": 5.0}, {"text": "network training so it's an optimization", "start": 551.44, "duration": 4.68}, {"text": "problem you're trying to adjust these", "start": 554.279, "duration": 4.281}, {"text": "weights which are the model parameters", "start": 556.12, "duration": 6.68}, {"text": "in order to minimize some loss", "start": 558.56, "duration": 7.24}, {"text": "function", "start": 562.8, "duration": 3.0}, {"text": "okay any questions so far let me", "start": 566.0, "duration": 5.12}, {"text": "check all right so um so let's talk", "start": 571.44, "duration": 9.76}, {"text": "about deep networks now", "start": 576.56, "duration": 4.64}, {"text": "um so this is a general architecture for", "start": 582.0, "duration": 6.48}, {"text": "a deep neural network so you have a", "start": 585.76, "duration": 4.16}, {"text": "sequence of layers just like in a", "start": 588.48, "duration": 2.76}, {"text": "conventional neural", "start": 589.92, "duration": 4.919}, {"text": "network um and each layer transforms its", "start": 591.24, "duration": 5.56}, {"text": "input to generate an output that gets", "start": 594.839, "duration": 4.481}, {"text": "fed to the next layer just in a con just", "start": 596.8, "duration": 4.52}, {"text": "like um in a conventional noal", "start": 599.32, "duration": 5.4}, {"text": "Network um but in a deep learning model", "start": 601.32, "duration": 5.0}, {"text": "uh you can have different types of", "start": 604.72, "duration": 3.48}, {"text": "layers and in a conventional no network", "start": 606.32, "duration": 4.16}, {"text": "so let's talk about um some of the most", "start": 608.2, "duration": 5.0}, {"text": "commonly used layers in a deep learning", "start": 610.48, "duration": 6.64}, {"text": "model um so the convol convolutional", "start": 613.2, "duration": 6.4}, {"text": "layer is what um Paul talked about", "start": 617.12, "duration": 4.48}, {"text": "earlier today so this is the core", "start": 619.6, "duration": 4.6}, {"text": "building block for a convolutional", "start": 621.6, "duration": 5.799}, {"text": "neural network or CNN right so performs", "start": 624.2, "duration": 6.24}, {"text": "convolution operations of input using", "start": 627.399, "duration": 5.201}, {"text": "these filters convolutional", "start": 630.44, "duration": 5.32}, {"text": "filters um and the filter operates on", "start": 632.6, "duration": 5.08}, {"text": "just a local region right so it doesn't", "start": 635.76, "duration": 3.92}, {"text": "take the entire input at once it", "start": 637.68, "duration": 3.92}, {"text": "operates on the local region and then it", "start": 639.68, "duration": 5.88}, {"text": "slides over and and um convolves on the", "start": 641.6, "duration": 5.6}, {"text": "next uh part of the", "start": 645.56, "duration": 4.56}, {"text": "input the filters have weights have", "start": 647.2, "duration": 5.68}, {"text": "parameters that can be learned during", "start": 650.12, "duration": 5.48}, {"text": "training and each filter learns to", "start": 652.88, "duration": 5.8}, {"text": "detect a feature in the input that is", "start": 655.6, "duration": 5.2}, {"text": "important for whatever task the model", "start": 658.68, "duration": 4.68}, {"text": "has to perform right and the output of", "start": 660.8, "duration": 5.4}, {"text": "this convolution is a feature valap", "start": 663.36, "duration": 6.36}, {"text": "right so this animation shows the", "start": 666.2, "duration": 6.84}, {"text": "operation of the convolutional filter so", "start": 669.72, "duration": 5.84}, {"text": "again the filter operates in a local", "start": 673.04, "duration": 5.359}, {"text": "region right and it just slides over so", "start": 675.56, "duration": 5.279}, {"text": "this is what happens in step two so the", "start": 678.399, "duration": 6.88}, {"text": "filter now has um slid over one cell and", "start": 680.839, "duration": 6.56}, {"text": "it does a convolution operation and then", "start": 685.279, "duration": 4.201}, {"text": "it outputs this output here in the", "start": 687.399, "duration": 3.081}, {"text": "feature", "start": 689.48, "duration": 6.159}, {"text": "map right and there are parameters um in", "start": 690.48, "duration": 7.12}, {"text": "the filter so there's a filter size", "start": 695.639, "duration": 3.801}, {"text": "which is the receptive field of a filter", "start": 697.6, "duration": 4.76}, {"text": "so this filter is 3x3 and as Paul talked", "start": 699.44, "duration": 5.639}, {"text": "about before usually people use a small", "start": 702.36, "duration": 5.08}, {"text": "um filter like 3x3 or 5 by five", "start": 705.079, "duration": 5.081}, {"text": "sometimes 7 by seven The Stride is a", "start": 707.44, "duration": 4.48}, {"text": "sliding amount right so the number of", "start": 710.16, "duration": 5.239}, {"text": "pixels that the filter moves um over the", "start": 711.92, "duration": 4.599}, {"text": "the input", "start": 715.399, "duration": 3.641}, {"text": "image U padding is a padding around the", "start": 716.519, "duration": 5.201}, {"text": "input volume so remember when Paul", "start": 719.04, "duration": 4.039}, {"text": "talked about this the feature map is", "start": 721.72, "duration": 2.84}, {"text": "going to be smaller because of this", "start": 723.079, "duration": 4.161}, {"text": "convolution operation so you can add", "start": 724.56, "duration": 4.76}, {"text": "padding around the input volume so that", "start": 727.24, "duration": 4.32}, {"text": "your um output can be the same size as", "start": 729.32, "duration": 2.92}, {"text": "your", "start": 731.56, "duration": 3.2}, {"text": "input uh and the depth is a number of", "start": 732.24, "duration": 4.64}, {"text": "filters right so each", "start": 734.76, "duration": 5.16}, {"text": "filter um ex detects a particular", "start": 736.88, "duration": 6.16}, {"text": "feature um so you usually want to have", "start": 739.92, "duration": 4.719}, {"text": "multiple filters so that you can detect", "start": 743.04, "duration": 4.52}, {"text": "multiple features in the input", "start": 744.639, "duration": 5.801}, {"text": "data um so here's another kind of a", "start": 747.56, "duration": 5.32}, {"text": "deeper dive into how the convolution", "start": 750.44, "duration": 5.56}, {"text": "operation works so let me see so in step", "start": 752.88, "duration": 6.079}, {"text": "two here right so the", "start": 756.0, "duration": 6.56}, {"text": "convolu the filter has is is operating", "start": 758.959, "duration": 5.961}, {"text": "on this part of the image right so if", "start": 762.56, "duration": 4.399}, {"text": "these are the the weights of the filter", "start": 764.92, "duration": 5.12}, {"text": "and this is what is in the input you do", "start": 766.959, "duration": 5.081}, {"text": "um a dotproduct of this right so you", "start": 770.04, "duration": 3.76}, {"text": "multiply everything together and then", "start": 772.04, "duration": 4.0}, {"text": "you get um and and sum them up and you", "start": 773.8, "duration": 5.8}, {"text": "get a a three here um", "start": 776.04, "duration": 5.4}, {"text": "so then this then it also gets pass", "start": 779.6, "duration": 3.4}, {"text": "through an activation function it's not", "start": 781.44, "duration": 3.399}, {"text": "shown here just to make things you know", "start": 783.0, "duration": 4.24}, {"text": "kind of keep things simple but this um", "start": 784.839, "duration": 4.12}, {"text": "dot product then will be passed through", "start": 787.24, "duration": 3.64}, {"text": "a an activation function to actually", "start": 788.959, "duration": 3.401}, {"text": "come up with the the output of the", "start": 790.88, "duration": 5.16}, {"text": "feature map so that's step two right and", "start": 792.36, "duration": 6.159}, {"text": "then the filter will move across the", "start": 796.04, "duration": 5.599}, {"text": "input and then in Step nine it operates", "start": 798.519, "duration": 6.12}, {"text": "on this part of the input and then uh it", "start": 801.639, "duration": 4.681}, {"text": "uh you know fills out the last part of", "start": 804.639, "duration": 3.121}, {"text": "the feature", "start": 806.32, "duration": 2.959}, {"text": "map", "start": 807.76, "duration": 5.199}, {"text": "okay um so that's processing of a single", "start": 809.279, "duration": 6.721}, {"text": "filter a convolutional layer can consist", "start": 812.959, "duration": 4.921}, {"text": "of several of these", "start": 816.0, "duration": 6.24}, {"text": "filters right um and it performs", "start": 817.88, "duration": 7.28}, {"text": "convolution on the input volume so when", "start": 822.24, "duration": 4.32}, {"text": "you think about convolutional Neal", "start": 825.16, "duration": 3.52}, {"text": "networks it's easiest to think about the", "start": 826.56, "duration": 5.04}, {"text": "input being an image so an image you", "start": 828.68, "duration": 5.719}, {"text": "would have you know it's a 2d grid right", "start": 831.6, "duration": 4.44}, {"text": "so you have the height and width of the", "start": 834.399, "duration": 4.36}, {"text": "image and then you also have channels so", "start": 836.04, "duration": 5.479}, {"text": "for a regular image you would have U RGB", "start": 838.759, "duration": 4.801}, {"text": "red green and blue so you would have", "start": 841.519, "duration": 5.041}, {"text": "three channels here okay so it uh", "start": 843.56, "duration": 4.36}, {"text": "convolutional layer performs a", "start": 846.56, "duration": 4.36}, {"text": "convolution on the input volume uh each", "start": 847.92, "duration": 4.44}, {"text": "filter in the convolutional layer is", "start": 850.92, "duration": 3.919}, {"text": "connected to a local region right and", "start": 852.36, "duration": 4.08}, {"text": "the result of the convolution is passed", "start": 854.839, "duration": 4.601}, {"text": "through a nonlinear activation function", "start": 856.44, "duration": 5.959}, {"text": "um and uh you can have multiple filters", "start": 859.44, "duration": 5.48}, {"text": "in convolutional layer and again the", "start": 862.399, "duration": 4.481}, {"text": "depth is a number of filters the number", "start": 864.92, "duration": 5.2}, {"text": "of feature Maps um that get that will be", "start": 866.88, "duration": 6.84}, {"text": "output by the convolutional", "start": 870.12, "duration": 6.6}, {"text": "layer", "start": 873.72, "duration": 3.0}, {"text": "okay okay", "start": 877.12, "duration": 7.24}, {"text": "um another commonly used layer in a um", "start": 879.279, "duration": 7.281}, {"text": "deep learning model is the pooling layer", "start": 884.36, "duration": 4.0}, {"text": "um Paul also talked a little bit about", "start": 886.56, "duration": 5.719}, {"text": "this earlier um so a pooling layer", "start": 888.36, "duration": 6.8}, {"text": "reduces the spatial size of the input", "start": 892.279, "duration": 6.521}, {"text": "right so um and you can have Max pulling", "start": 895.16, "duration": 4.799}, {"text": "you can have average pooling you can", "start": 898.8, "duration": 2.88}, {"text": "have other operations as well but most", "start": 899.959, "duration": 3.961}, {"text": "commonly um the max operation is used in", "start": 901.68, "duration": 5.64}, {"text": "the pooling layer so um if you applying", "start": 903.92, "duration": 6.56}, {"text": "a pooling uh layer with a filter that is", "start": 907.32, "duration": 6.199}, {"text": "2 by two if you apply the filter the", "start": 910.48, "duration": 5.279}, {"text": "pooling filter to this uh region of the", "start": 913.519, "duration": 5.041}, {"text": "input the pink region and you apply the", "start": 915.759, "duration": 5.361}, {"text": "max operation on that then the max the", "start": 918.56, "duration": 4.44}, {"text": "result will be six right so that is", "start": 921.12, "duration": 4.2}, {"text": "going to be the result of um the pooling", "start": 923.0, "duration": 4.56}, {"text": "operation there and then similarly on", "start": 925.32, "duration": 4.879}, {"text": "the green area the max there is eight", "start": 927.56, "duration": 5.639}, {"text": "and the yellow area the max is three um", "start": 930.199, "duration": 6.2}, {"text": "Blue Area the max is four so the pooling", "start": 933.199, "duration": 6.281}, {"text": "reduces the spatial size of the input um", "start": 936.399, "duration": 4.92}, {"text": "and pulling is performed independently", "start": 939.48, "duration": 4.4}, {"text": "on every size of the input so if you", "start": 941.319, "duration": 6.481}, {"text": "have this slice here um you would apply", "start": 943.88, "duration": 6.639}, {"text": "the max pooling here to get uh this", "start": 947.8, "duration": 4.399}, {"text": "output right and then you do this for", "start": 950.519, "duration": 5.12}, {"text": "every slice in your", "start": 952.199, "duration": 3.44}, {"text": "input okay um another commonly used um", "start": 955.8, "duration": 8.08}, {"text": "layer is the fully connected layer and", "start": 961.68, "duration": 4.04}, {"text": "these the fully connected layer is", "start": 963.88, "duration": 5.24}, {"text": "what's uh is used in the con in the", "start": 965.72, "duration": 6.64}, {"text": "conventional uh noal Network right so as", "start": 969.12, "duration": 5.199}, {"text": "the name implies fully connected means", "start": 972.36, "duration": 5.839}, {"text": "every unit is connected to every other", "start": 974.319, "duration": 6.76}, {"text": "to every unit in from the previous", "start": 978.199, "duration": 6.961}, {"text": "layer um and so the output of the fully", "start": 981.079, "duration": 6.44}, {"text": "connected layer is is typically a vector", "start": 985.16, "duration": 4.64}, {"text": "with probabilities for categories when", "start": 987.519, "duration": 4.8}, {"text": "you do classification so usually it's", "start": 989.8, "duration": 5.56}, {"text": "the the last layer in a convolutional", "start": 992.319, "duration": 6.481}, {"text": "network um and often times you'll have", "start": 995.36, "duration": 5.159}, {"text": "the input to the fully connected layer", "start": 998.8, "duration": 3.839}, {"text": "is either the output of a convolutional", "start": 1000.519, "duration": 4.161}, {"text": "layer or a Max pulling layer right and", "start": 1002.639, "duration": 4.281}, {"text": "the output of those layers it would be a", "start": 1004.68, "duration": 4.44}, {"text": "a a grid like this so you would need to", "start": 1006.92, "duration": 5.039}, {"text": "flatten it in order to um have it input", "start": 1009.12, "duration": 6.24}, {"text": "into a fully connected", "start": 1011.959, "duration": 3.401}, {"text": "layer okay um another layer that is used", "start": 1015.839, "duration": 7.56}, {"text": "is a Dropout layer so what happens in a", "start": 1019.759, "duration": 7.521}, {"text": "Dropout layer is um that units", "start": 1023.399, "duration": 5.68}, {"text": "processing units are randomly dropped", "start": 1027.28, "duration": 2.759}, {"text": "during", "start": 1029.079, "duration": 3.281}, {"text": "training and the reason that this is", "start": 1030.039, "duration": 5.0}, {"text": "done is to prevent units from co-", "start": 1032.36, "duration": 6.199}, {"text": "adapting and co- adapting means that um", "start": 1035.039, "duration": 5.441}, {"text": "the units are working together right", "start": 1038.559, "duration": 3.041}, {"text": "they're working in a tandem so they're", "start": 1040.48, "duration": 2.719}, {"text": "kind of codependent you want to break", "start": 1041.6, "duration": 5.199}, {"text": "that cycle um so this by breaking that", "start": 1043.199, "duration": 6.121}, {"text": "cycle you can come your your model can", "start": 1046.799, "duration": 3.401}, {"text": "be more", "start": 1049.32, "duration": 5.4}, {"text": "robust um and because units are um also", "start": 1050.2, "duration": 6.88}, {"text": "dropped randomly this adds noise to the", "start": 1054.72, "duration": 4.839}, {"text": "training process and this so this is a", "start": 1057.08, "duration": 5.04}, {"text": "regularization process right so it's a", "start": 1059.559, "duration": 4.961}, {"text": "it's a form of regularization and and it", "start": 1062.12, "duration": 5.52}, {"text": "can help to address um overfitting in a", "start": 1064.52, "duration": 6.12}, {"text": "model in a deep learning model um and so", "start": 1067.64, "duration": 5.64}, {"text": "uh overfitting prevents a model from", "start": 1070.64, "duration": 6.56}, {"text": "generalizing to um new data so uh you", "start": 1073.28, "duration": 5.519}, {"text": "want you want a model that does not", "start": 1077.2, "duration": 3.599}, {"text": "overfit you want a model that generaliz", "start": 1078.799, "duration": 5.441}, {"text": "as well all right so that's a drop", "start": 1080.799, "duration": 7.721}, {"text": "out um the another layer is um batch", "start": 1084.24, "duration": 7.28}, {"text": "normalization um and this is you can", "start": 1088.52, "duration": 5.36}, {"text": "think of it as um you know kind of", "start": 1091.52, "duration": 5.279}, {"text": "similar to how we do zero normalization", "start": 1093.88, "duration": 5.56}, {"text": "or you know standard standardization of", "start": 1096.799, "duration": 4.601}, {"text": "the input right so you subtract the mean", "start": 1099.44, "duration": 4.68}, {"text": "divide by the standard deviation um for", "start": 1101.4, "duration": 5.0}, {"text": "each batch of data that you give to the", "start": 1104.12, "duration": 6.88}, {"text": "to the to the model um and this", "start": 1106.4, "duration": 7.56}, {"text": "increases stability in training um", "start": 1111.0, "duration": 6.44}, {"text": "because you know each layer can learn", "start": 1113.96, "duration": 5.079}, {"text": "kind of independently of the previous", "start": 1117.44, "duration": 3.68}, {"text": "layer because it normalizes its uh the", "start": 1119.039, "duration": 4.921}, {"text": "input that it gets uh and in practice it", "start": 1121.12, "duration": 4.559}, {"text": "has people have found that this leads to", "start": 1123.96, "duration": 4.52}, {"text": "faster conversion so training is uh", "start": 1125.679, "duration": 6.401}, {"text": "faster um and it also is less sensitive", "start": 1128.48, "duration": 6.48}, {"text": "to the initial values of the weights and", "start": 1132.08, "duration": 5.24}, {"text": "also because it um adds Some Noise it", "start": 1134.96, "duration": 4.719}, {"text": "also reduces over fitting and leads to", "start": 1137.32, "duration": 4.64}, {"text": "better", "start": 1139.679, "duration": 2.281}, {"text": "generalization okay any questions so far", "start": 1142.72, "duration": 5.56}, {"text": "about the", "start": 1145.159, "duration": 3.121}, {"text": "layers okay", "start": 1153.24, "duration": 7.28}, {"text": "um all right so then let's go on to", "start": 1156.84, "duration": 5.88}, {"text": "architectures um there are many many", "start": 1160.52, "duration": 3.6}, {"text": "architectures right I'm just going to", "start": 1162.72, "duration": 3.88}, {"text": "cover some of the most commonly used", "start": 1164.12, "duration": 6.2}, {"text": "ones um so so we've talked about CNN's", "start": 1166.6, "duration": 7.72}, {"text": "right convolutional oil networks so a", "start": 1170.32, "duration": 7.56}, {"text": "CNN consists of several repeating sets", "start": 1174.32, "duration": 5.2}, {"text": "of layers called", "start": 1177.88, "duration": 6.52}, {"text": "blocks um and this is a what we're", "start": 1179.52, "duration": 7.159}, {"text": "looking at is a bg16 network so this is", "start": 1184.4, "duration": 5.639}, {"text": "one of the earlier um CNN", "start": 1186.679, "duration": 8.521}, {"text": "models um and it's it's a very um clean", "start": 1190.039, "duration": 8.681}, {"text": "model um so it has um several", "start": 1195.2, "duration": 5.76}, {"text": "convolutional blocks right so each", "start": 1198.72, "duration": 5.0}, {"text": "convolutional block is made up of two", "start": 1200.96, "duration": 4.64}, {"text": "convolutional layers right so these are", "start": 1203.72, "duration": 4.4}, {"text": "two convolutional layers followed by a", "start": 1205.6, "duration": 4.76}, {"text": "Max pulling layer right so remember that", "start": 1208.12, "duration": 4.6}, {"text": "a Max pulling layer reduces the spatial", "start": 1210.36, "duration": 4.84}, {"text": "Dimensions so um you know when you have", "start": 1212.72, "duration": 5.76}, {"text": "a spa a Max pooling then the input uh", "start": 1215.2, "duration": 6.52}, {"text": "size gets smaller right so that's one", "start": 1218.48, "duration": 5.72}, {"text": "convolutional block there's another", "start": 1221.72, "duration": 4.839}, {"text": "convolutional block here and then that's", "start": 1224.2, "duration": 5.2}, {"text": "followed by um another convolutional", "start": 1226.559, "duration": 4.841}, {"text": "block that has three convolutional", "start": 1229.4, "duration": 4.44}, {"text": "layers right and that's another", "start": 1231.4, "duration": 4.88}, {"text": "convolutional block and another", "start": 1233.84, "duration": 5.0}, {"text": "convolutional block and then that then", "start": 1236.28, "duration": 5.8}, {"text": "is followed by a Foy connected layer and", "start": 1238.84, "duration": 5.88}, {"text": "then that's um at the end here you just", "start": 1242.08, "duration": 4.64}, {"text": "have a softmax which is an activation", "start": 1244.72, "duration": 3.92}, {"text": "function that gives you", "start": 1246.72, "duration": 5.6}, {"text": "probabilities right so it has the CNN", "start": 1248.64, "duration": 4.68}, {"text": "has", "start": 1252.32, "duration": 5.16}, {"text": "repeating um blocks uh and the input", "start": 1253.32, "duration": 7.12}, {"text": "volume uh is a tensor size of width time", "start": 1257.48, "duration": 5.319}, {"text": "height times number of channels and then", "start": 1260.44, "duration": 5.08}, {"text": "the output is a vector of numbers that", "start": 1262.799, "duration": 4.441}, {"text": "represent class", "start": 1265.52, "duration": 5.759}, {"text": "probabilities okay", "start": 1267.24, "duration": 7.559}, {"text": "um let's see so uh a general CNN", "start": 1271.279, "duration": 5.721}, {"text": "architecture has a sequence of layers", "start": 1274.799, "duration": 4.0}, {"text": "each layer will transform its input to", "start": 1277.0, "duration": 4.4}, {"text": "generate an output um through a", "start": 1278.799, "duration": 4.721}, {"text": "nonlinear function and usually you have", "start": 1281.4, "duration": 3.44}, {"text": "you the input image you have", "start": 1283.52, "duration": 5.2}, {"text": "convolutional blocks you have pooling um", "start": 1284.84, "duration": 5.64}, {"text": "you have several of these blocks", "start": 1288.72, "duration": 3.64}, {"text": "repeated and then that's followed by a", "start": 1290.48, "duration": 4.48}, {"text": "fully connected layer and in between you", "start": 1292.36, "duration": 6.36}, {"text": "could also have Dropout layers um batch", "start": 1294.96, "duration": 8.36}, {"text": "normalization layers um and uh you know", "start": 1298.72, "duration": 6.52}, {"text": "kind of in between these these blocks", "start": 1303.32, "duration": 3.2}, {"text": "and then that's followed by a fully", "start": 1305.24, "duration": 3.559}, {"text": "connected", "start": 1306.52, "duration": 7.32}, {"text": "layer okay um here are some common or I", "start": 1308.799, "duration": 9.401}, {"text": "guess uh popular uh CNN models and all", "start": 1313.84, "duration": 8.16}, {"text": "of these have um done very well very", "start": 1318.2, "duration": 6.28}, {"text": "very well on the image net Challenge and", "start": 1322.0, "duration": 4.24}, {"text": "I'll talk a little bit more about that", "start": 1324.48, "duration": 4.079}, {"text": "when I talk about transfer learning um", "start": 1326.24, "duration": 3.84}, {"text": "but these are some of the CNN models", "start": 1328.559, "duration": 4.521}, {"text": "that are um uh you know have done well", "start": 1330.08, "duration": 4.64}, {"text": "and you probably have heard about some", "start": 1333.08, "duration": 3.479}, {"text": "of", "start": 1334.72, "duration": 4.36}, {"text": "these okay", "start": 1336.559, "duration": 7.801}, {"text": "um and CNN applications um so the their", "start": 1339.08, "duration": 6.959}, {"text": "success the early success have all been", "start": 1344.36, "duration": 5.319}, {"text": "around image uh applications so objects", "start": 1346.039, "duration": 7.0}, {"text": "classification localization detection um", "start": 1349.679, "duration": 4.761}, {"text": "but they have also been applied to", "start": 1353.039, "duration": 3.201}, {"text": "Natural processing and natural language", "start": 1354.44, "duration": 4.599}, {"text": "processing and and other uh areas as", "start": 1356.24, "duration": 7.76}, {"text": "well okay so that's CNN um another uh", "start": 1359.039, "duration": 7.161}, {"text": "type of deep learning model is uh called", "start": 1364.0, "duration": 3.039}, {"text": "an", "start": 1366.2, "duration": 4.16}, {"text": "autoencoder um so in an autoencoder the", "start": 1367.039, "duration": 5.161}, {"text": "input is fed into a hidden layer and", "start": 1370.36, "duration": 3.4}, {"text": "then the output is Recon is a", "start": 1372.2, "duration": 4.16}, {"text": "reconstructed version of the input right", "start": 1373.76, "duration": 7.159}, {"text": "so the output should match the input so", "start": 1376.36, "duration": 8.199}, {"text": "the model learns to to represent the", "start": 1380.919, "duration": 6.841}, {"text": "input um using a", "start": 1384.559, "duration": 6.281}, {"text": "um a latent representation it learns a", "start": 1387.76, "duration": 4.96}, {"text": "latent representation of the input and", "start": 1390.84, "duration": 3.52}, {"text": "then it learns to reconstruct the input", "start": 1392.72, "duration": 4.0}, {"text": "data from this latent", "start": 1394.36, "duration": 5.48}, {"text": "representation um yeah so if you put in", "start": 1396.72, "duration": 5.24}, {"text": "the input the original input here the", "start": 1399.84, "duration": 4.959}, {"text": "auto encoder will come up with a latent", "start": 1401.96, "duration": 4.599}, {"text": "representation which is you know kind of", "start": 1404.799, "duration": 5.0}, {"text": "a a kind of an internal representation", "start": 1406.559, "duration": 5.881}, {"text": "of the input and then it uh learns to", "start": 1409.799, "duration": 6.721}, {"text": "reconstruct the input from that latent", "start": 1412.44, "duration": 6.4}, {"text": "representation um and this layer is is", "start": 1416.52, "duration": 4.08}, {"text": "refer as a bottleneck", "start": 1418.84, "duration": 6.12}, {"text": "layer okay um so the auto encoder is", "start": 1420.6, "duration": 6.64}, {"text": "used for feature learning right because", "start": 1424.96, "duration": 6.52}, {"text": "it it um it it learns um a different", "start": 1427.24, "duration": 6.96}, {"text": "representation of the input and that", "start": 1431.48, "duration": 5.64}, {"text": "latent representation um can be used for", "start": 1434.2, "duration": 6.0}, {"text": "other Downstream task right so that uh", "start": 1437.12, "duration": 6.64}, {"text": "hidden representation can be input into", "start": 1440.2, "duration": 5.2}, {"text": "uh you know another classifier another", "start": 1443.76, "duration": 3.6}, {"text": "classification model or it can be used", "start": 1445.4, "duration": 3.879}, {"text": "for clustering or anomaly", "start": 1447.36, "duration": 4.96}, {"text": "detection um so oftentimes it can be", "start": 1449.279, "duration": 5.841}, {"text": "part of a larger deeper a larger deep", "start": 1452.32, "duration": 4.56}, {"text": "learning model and there are many", "start": 1455.12, "duration": 5.2}, {"text": "different variations um uh you know for", "start": 1456.88, "duration": 5.44}, {"text": "different purposes there Spar Den", "start": 1460.32, "duration": 4.92}, {"text": "noising contractive variational you can", "start": 1462.32, "duration": 5.52}, {"text": "find lots of information about these um", "start": 1465.24, "duration": 7.24}, {"text": "so for example D noising is um used to", "start": 1467.84, "duration": 7.76}, {"text": "you know if you have input that is", "start": 1472.48, "duration": 5.28}, {"text": "corrupted by noise um you can use an", "start": 1475.6, "duration": 6.88}, {"text": "auto encoder to denoise the input", "start": 1477.76, "duration": 4.72}, {"text": "image okay um another type of uh model", "start": 1483.24, "duration": 7.2}, {"text": "is a unit um so this is commonly used", "start": 1487.679, "duration": 4.921}, {"text": "for semantic segmentation so this is", "start": 1490.44, "duration": 5.76}, {"text": "used to divide the image input the uh", "start": 1492.6, "duration": 5.84}, {"text": "input into", "start": 1496.2, "duration": 5.719}, {"text": "multiple image regions right so as what", "start": 1498.44, "duration": 7.2}, {"text": "as we see here um the pixels are grouped", "start": 1501.919, "duration": 6.76}, {"text": "together into you know what they what", "start": 1505.64, "duration": 7.8}, {"text": "each represent so the um pixels that are", "start": 1508.679, "duration": 7.72}, {"text": "colored red represent people right the", "start": 1513.44, "duration": 6.719}, {"text": "ones that are colored green um represent", "start": 1516.399, "duration": 7.081}, {"text": "uh trees vegetation uh the purple ones", "start": 1520.159, "duration": 5.481}, {"text": "represent uh vehicles and then this kind", "start": 1523.48, "duration": 5.439}, {"text": "of uh off purple color is there", "start": 1525.64, "duration": 7.279}, {"text": "roads um okay so it's that's the unit is", "start": 1528.919, "duration": 6.521}, {"text": "often used for", "start": 1532.919, "duration": 4.521}, {"text": "segmentation and the reason that this", "start": 1535.44, "duration": 4.92}, {"text": "model is called a unit as you can guess", "start": 1537.44, "duration": 5.04}, {"text": "is because of its architecture right so", "start": 1540.36, "duration": 5.319}, {"text": "it has an encoding", "start": 1542.48, "duration": 7.96}, {"text": "path um encoding path and then decoding", "start": 1545.679, "duration": 8.561}, {"text": "path so the encoding path is used for", "start": 1550.44, "duration": 5.839}, {"text": "feature extraction it goes through this", "start": 1554.24, "duration": 4.0}, {"text": "bottleneck layer which again is an", "start": 1556.279, "duration": 4.52}, {"text": "internal representation of the input and", "start": 1558.24, "duration": 6.039}, {"text": "then in the decoder path this internal", "start": 1560.799, "duration": 6.6}, {"text": "representation is decoded um into the", "start": 1564.279, "duration": 5.0}, {"text": "output segmentation", "start": 1567.399, "duration": 4.801}, {"text": "map um and if you notice the the", "start": 1569.279, "duration": 6.161}, {"text": "encoding part of the unit is similar to", "start": 1572.2, "duration": 6.92}, {"text": "a CNN right so it's uh consists of", "start": 1575.44, "duration": 6.88}, {"text": "several um convolutional blocks right so", "start": 1579.12, "duration": 4.88}, {"text": "you have several convolutional layers", "start": 1582.32, "duration": 4.44}, {"text": "followed by a pooling layer and you have", "start": 1584.0, "duration": 7.799}, {"text": "repeated uh um convolutional blocks here", "start": 1586.76, "duration": 11.24}, {"text": "okay and unit um the unet model was", "start": 1591.799, "duration": 8.6}, {"text": "first uh used for biomedical", "start": 1598.0, "duration": 3.76}, {"text": "segmentation so if you look at a", "start": 1600.399, "duration": 3.321}, {"text": "biomedical image you want to see you", "start": 1601.76, "duration": 4.68}, {"text": "know what types of cells are in that", "start": 1603.72, "duration": 5.0}, {"text": "image um that was kind of the first", "start": 1606.44, "duration": 4.68}, {"text": "application of units um but it has been", "start": 1608.72, "duration": 4.88}, {"text": "used for lots of different uh other", "start": 1611.12, "duration": 6.159}, {"text": "different um applications as well um so", "start": 1613.6, "duration": 4.64}, {"text": "in", "start": 1617.279, "duration": 3.041}, {"text": "I've used them for medical image", "start": 1618.24, "duration": 5.2}, {"text": "analysis so uh this is looking", "start": 1620.32, "duration": 5.16}, {"text": "at a cardiac", "start": 1623.44, "duration": 4.68}, {"text": "MRI and this is a cross-section of the", "start": 1625.48, "duration": 5.24}, {"text": "heart and this part is the left", "start": 1628.12, "duration": 4.48}, {"text": "ventricle which is the largest chamber", "start": 1630.72, "duration": 4.079}, {"text": "of the heart and that pumps blood out of", "start": 1632.6, "duration": 4.72}, {"text": "the heart into the rest of the body um", "start": 1634.799, "duration": 5.6}, {"text": "and so you know the the shape and the", "start": 1637.32, "duration": 6.92}, {"text": "function of um the LV is a good", "start": 1640.399, "duration": 6.28}, {"text": "indicator of heart health so um a lot of", "start": 1644.24, "duration": 4.439}, {"text": "times um people the first thing that", "start": 1646.679, "duration": 5.041}, {"text": "people will do um is is to identify", "start": 1648.679, "duration": 5.761}, {"text": "where the the left ventricle is in a", "start": 1651.72, "duration": 6.8}, {"text": "cardiac MRI and so um unit I've used a", "start": 1654.44, "duration": 6.52}, {"text": "unit to do this um I've also used a unit", "start": 1658.52, "duration": 5.24}, {"text": "to um analyze salent imagery right", "start": 1660.96, "duration": 4.959}, {"text": "because uh this is also a segmentation", "start": 1663.76, "duration": 5.159}, {"text": "so for example um you know you want to", "start": 1665.919, "duration": 4.841}, {"text": "figure out where buildings are versus", "start": 1668.919, "duration": 4.36}, {"text": "where vegetation is versus where um", "start": 1670.76, "duration": 5.759}, {"text": "water is for example right um You can", "start": 1673.279, "duration": 5.4}, {"text": "also use a unit for object detection for", "start": 1676.519, "duration": 5.321}, {"text": "scene analysis or scene", "start": 1678.679, "duration": 10.801}, {"text": "understanding okay um another type of um", "start": 1681.84, "duration": 9.439}, {"text": "deep learning model that is commonly", "start": 1689.48, "duration": 4.799}, {"text": "used is an lstm uh that stands for long", "start": 1691.279, "duration": 5.0}, {"text": "short-term memory and this is used for", "start": 1694.279, "duration": 4.0}, {"text": "sequence learning right and it's a type", "start": 1696.279, "duration": 5.201}, {"text": "of no network called a recurrent Network", "start": 1698.279, "duration": 5.12}, {"text": "so sequence learning is learning a", "start": 1701.48, "duration": 4.36}, {"text": "signal that has some sort of ordering to", "start": 1703.399, "duration": 4.721}, {"text": "it or some sort of time comp component", "start": 1705.84, "duration": 5.76}, {"text": "right like speech signals um you know it", "start": 1708.12, "duration": 6.52}, {"text": "has a it's a Time component um or stock", "start": 1711.6, "duration": 6.559}, {"text": "price right so how um the price of a", "start": 1714.64, "duration": 6.0}, {"text": "stock changes over the course of a day", "start": 1718.159, "duration": 5.88}, {"text": "over the course of um a month um video", "start": 1720.64, "duration": 6.639}, {"text": "analysis is also another common uh", "start": 1724.039, "duration": 5.721}, {"text": "application for sequence", "start": 1727.279, "duration": 7.161}, {"text": "learning um so a recurrent NL Network um", "start": 1729.76, "duration": 7.039}, {"text": "Can model sequences and time dependent", "start": 1734.44, "duration": 3.719}, {"text": "signals and the the way they do that is", "start": 1736.799, "duration": 4.641}, {"text": "to have a cyclic connection that pre", "start": 1738.159, "duration": 5.12}, {"text": "that feed previous", "start": 1741.44, "duration": 4.92}, {"text": "activations um back um to be part of the", "start": 1743.279, "duration": 6.12}, {"text": "input U for the next time step right so", "start": 1746.36, "duration": 6.12}, {"text": "that allows for temporal context context", "start": 1749.399, "duration": 6.0}, {"text": "um information to be stored um and", "start": 1752.48, "duration": 5.919}, {"text": "learned by by the", "start": 1755.399, "duration": 7.12}, {"text": "network okay so this is", "start": 1758.399, "duration": 9.12}, {"text": "um a diagram of the lstm architecture so", "start": 1762.519, "duration": 8.241}, {"text": "data flows through these blocks called", "start": 1767.519, "duration": 6.64}, {"text": "cells um the structure of the cell", "start": 1770.76, "duration": 6.56}, {"text": "allows for the model to kind of", "start": 1774.159, "duration": 5.321}, {"text": "determine what is important to remember", "start": 1777.32, "duration": 4.719}, {"text": "and what can be um", "start": 1779.48, "duration": 5.0}, {"text": "discarded um and this each cell", "start": 1782.039, "duration": 5.401}, {"text": "manipulates U memory through um these", "start": 1784.48, "duration": 6.48}, {"text": "things called Gates um and it's uh you", "start": 1787.44, "duration": 7.959}, {"text": "know just a series of um Matrix", "start": 1790.96, "duration": 7.0}, {"text": "operations to kind of", "start": 1795.399, "duration": 6.16}, {"text": "regulate um the input to a", "start": 1797.96, "duration": 6.199}, {"text": "cell and uh I think Paul's going to talk", "start": 1801.559, "duration": 5.801}, {"text": "a little bit more about this later um in", "start": 1804.159, "duration": 4.561}, {"text": "in the", "start": 1807.36, "duration": 4.48}, {"text": "session um okay and lstm applications", "start": 1808.72, "duration": 5.959}, {"text": "have been used for you know uh sequences", "start": 1811.84, "duration": 5.16}, {"text": "or where the where the input is U made", "start": 1814.679, "duration": 5.081}, {"text": "up of sequences so speech recognition", "start": 1817.0, "duration": 4.88}, {"text": "excuse me machine translation", "start": 1819.76, "duration": 4.039}, {"text": "handwriting recognition right where you", "start": 1821.88, "duration": 6.039}, {"text": "have to actually follow um the um the", "start": 1823.799, "duration": 7.201}, {"text": "motion when somebody writes um a letter", "start": 1827.919, "duration": 7.521}, {"text": "or a number video analysis um stock priz", "start": 1831.0, "duration": 7.6}, {"text": "prediction too excuse", "start": 1835.44, "duration": 7.92}, {"text": "me okay um and then there's also um", "start": 1838.6, "duration": 7.52}, {"text": "sequence to sequence so this is another", "start": 1843.36, "duration": 4.4}, {"text": "type of deep learning model that is used", "start": 1846.12, "duration": 4.72}, {"text": "for sequence learning um it's actually", "start": 1847.76, "duration": 6.639}, {"text": "more of a class of uh Network or a", "start": 1850.84, "duration": 6.28}, {"text": "general approach to to sequence learning", "start": 1854.399, "duration": 7.64}, {"text": "um um so the idea is um it converts an", "start": 1857.12, "duration": 6.76}, {"text": "input sequence into an output sequence", "start": 1862.039, "duration": 3.6}, {"text": "and this has been used a lot for things", "start": 1863.88, "duration": 3.279}, {"text": "like machine translation or question", "start": 1865.639, "duration": 2.721}, {"text": "answering", "start": 1867.159, "duration": 4.161}, {"text": "applications so the idea is that if you", "start": 1868.36, "duration": 6.4}, {"text": "have to um translate a sentence in", "start": 1871.32, "duration": 5.959}, {"text": "English into", "start": 1874.76, "duration": 6.2}, {"text": "German um this you can use a sequence to", "start": 1877.279, "duration": 4.841}, {"text": "sequence", "start": 1880.96, "duration": 4.439}, {"text": "model uh so the this this is called an", "start": 1882.12, "duration": 5.799}, {"text": "encoder right because this takes the in", "start": 1885.399, "duration": 4.52}, {"text": "and it comes up with some internal", "start": 1887.919, "duration": 4.681}, {"text": "representation of the input sentence and", "start": 1889.919, "duration": 4.441}, {"text": "then from that internal representation", "start": 1892.6, "duration": 4.439}, {"text": "the decoder part this is a decoder will", "start": 1894.36, "duration": 5.64}, {"text": "take that and and um performs the", "start": 1897.039, "duration": 5.52}, {"text": "translation into you know kind of uh", "start": 1900.0, "duration": 5.72}, {"text": "essentially performs a different mapping", "start": 1902.559, "duration": 5.921}, {"text": "um to get the uh translation to a", "start": 1905.72, "duration": 3.76}, {"text": "different", "start": 1908.48, "duration": 4.319}, {"text": "language um the encoder and and decoder", "start": 1909.48, "duration": 6.679}, {"text": "are often uh recurrent noal networks", "start": 1912.799, "duration": 5.24}, {"text": "like an Alm", "start": 1916.159, "duration": 3.561}, {"text": "right so people use this a lot for", "start": 1918.039, "duration": 3.24}, {"text": "machine translation and question", "start": 1919.72, "duration": 3.959}, {"text": "question answering applications the", "start": 1921.279, "duration": 5.64}, {"text": "issue with this is that um it is really", "start": 1923.679, "duration": 4.6}, {"text": "difficult to capture long range", "start": 1926.919, "duration": 4.841}, {"text": "dependencies because everything that is", "start": 1928.279, "duration": 5.561}, {"text": "important about the input sentence has", "start": 1931.76, "duration": 6.279}, {"text": "to be captured in the state um and so", "start": 1933.84, "duration": 7.839}, {"text": "you know for if you have a long sentence", "start": 1938.039, "duration": 6.161}, {"text": "um or if you have you know something", "start": 1941.679, "duration": 5.201}, {"text": "that is um that you have to keep track", "start": 1944.2, "duration": 3.52}, {"text": "of", "start": 1946.88, "duration": 2.799}, {"text": "um that happened at the beginning of the", "start": 1947.72, "duration": 3.6}, {"text": "sentence it's really difficult to", "start": 1949.679, "duration": 3.88}, {"text": "capture those longrange dependencies", "start": 1951.32, "duration": 3.959}, {"text": "with a sequence to sequence", "start": 1953.559, "duration": 5.321}, {"text": "model and so to address this difficulty", "start": 1955.279, "duration": 5.441}, {"text": "in capturing the long", "start": 1958.88, "duration": 5.279}, {"text": "sequences um the attention mechanism was", "start": 1960.72, "duration": 6.839}, {"text": "invented so at a high level what this", "start": 1964.159, "duration": 5.4}, {"text": "attention mechanism does is that for", "start": 1967.559, "duration": 4.72}, {"text": "each word it determines the relationship", "start": 1969.559, "duration": 6.401}, {"text": "between that word and every other word", "start": 1972.279, "duration": 6.201}, {"text": "right um so for each word the attention", "start": 1975.96, "duration": 4.199}, {"text": "is used to determine which other words", "start": 1978.48, "duration": 4.36}, {"text": "in the sequence are important so for", "start": 1980.159, "duration": 4.961}, {"text": "example in this sentence right the cat", "start": 1982.84, "duration": 4.28}, {"text": "drank the milk because it was hungry so", "start": 1985.12, "duration": 6.12}, {"text": "does it refer to the cat or the milk", "start": 1987.12, "duration": 6.12}, {"text": "right and so the attention mechanism", "start": 1991.24, "duration": 5.6}, {"text": "allows you to do to figure out um you", "start": 1993.24, "duration": 6.399}, {"text": "know what it refers to depending on the", "start": 1996.84, "duration": 6.04}, {"text": "context right so in this sentence it", "start": 1999.639, "duration": 5.92}, {"text": "refers to to the cat but in this", "start": 2002.88, "duration": 4.56}, {"text": "sentence the cat drank the no because it", "start": 2005.559, "duration": 6.161}, {"text": "was sweet um it refers to to milk right", "start": 2007.44, "duration": 7.32}, {"text": "so the attention mechanism allows you to", "start": 2011.72, "duration": 7.16}, {"text": "uh determine the importance of the", "start": 2014.76, "duration": 7.12}, {"text": "surrounding words um for each uh word", "start": 2018.88, "duration": 5.799}, {"text": "that you're that in your", "start": 2021.88, "duration": 6.44}, {"text": "symptoms okay um so the attention", "start": 2024.679, "duration": 5.161}, {"text": "mechanism improved performance of the", "start": 2028.32, "duration": 4.319}, {"text": "sequence to sequence models um but then", "start": 2029.84, "duration": 4.48}, {"text": "there was a paper a very influential", "start": 2032.639, "duration": 3.961}, {"text": "paper that came out and the title of it", "start": 2034.32, "duration": 4.52}, {"text": "was a attention is all you need and what", "start": 2036.6, "duration": 4.679}, {"text": "they showed was that a model with the", "start": 2038.84, "duration": 4.48}, {"text": "attention mechanism can outperform", "start": 2041.279, "duration": 6.28}, {"text": "models with uh recurrent recurrence so", "start": 2043.32, "duration": 6.0}, {"text": "essentially that's you know attention is", "start": 2047.559, "duration": 3.401}, {"text": "all you need the attention mechanism is", "start": 2049.32, "duration": 4.72}, {"text": "all you need to capture these long-term", "start": 2050.96, "duration": 6.6}, {"text": "dependencies um and it only so it only", "start": 2054.04, "duration": 5.319}, {"text": "uses the attention mechanism there's no", "start": 2057.56, "duration": 3.68}, {"text": "recurrence and there's no convolution at", "start": 2059.359, "duration": 6.201}, {"text": "all um and that uh model is uh called a", "start": 2061.24, "duration": 6.96}, {"text": "Transformer model is a very complex", "start": 2065.56, "duration": 5.16}, {"text": "model it has encoders and decoders as", "start": 2068.2, "duration": 4.52}, {"text": "well but it has no recurrence there's no", "start": 2070.72, "duration": 4.959}, {"text": "convolution it just has um a very", "start": 2072.72, "duration": 6.32}, {"text": "complex uh way to capture", "start": 2075.679, "duration": 7.24}, {"text": "attention and the advantages of a", "start": 2079.04, "duration": 6.039}, {"text": "transformer over you know a recurrent", "start": 2082.919, "duration": 4.76}, {"text": "neural network like an LTM is that these", "start": 2085.079, "duration": 4.56}, {"text": "long agage dependencies can be captured", "start": 2087.679, "duration": 3.96}, {"text": "more easily using the attention", "start": 2089.639, "duration": 4.28}, {"text": "mechanism and also because of the way", "start": 2091.639, "duration": 6.041}, {"text": "that the Transformer is um designed", "start": 2093.919, "duration": 5.241}, {"text": "you can process all the words in the", "start": 2097.68, "duration": 3.6}, {"text": "sequence in parallel right whereas with", "start": 2099.16, "duration": 3.919}, {"text": "the LTM you have to process one at a", "start": 2101.28, "duration": 4.96}, {"text": "times you process one word that the the", "start": 2103.079, "duration": 4.681}, {"text": "representation of that word gets fed", "start": 2106.24, "duration": 4.52}, {"text": "into the next time step and so you have", "start": 2107.76, "duration": 3.96}, {"text": "to do this", "start": 2110.76, "duration": 3.4}, {"text": "sequentially um so there are a couple", "start": 2111.72, "duration": 4.119}, {"text": "very important advantages of the", "start": 2114.16, "duration": 5.8}, {"text": "Transformer over um RNN and so uh people", "start": 2115.839, "duration": 6.401}, {"text": "now are mostly using transformer for you", "start": 2119.96, "duration": 4.28}, {"text": "know things like um natural language", "start": 2122.24, "duration": 4.64}, {"text": "processing and and even um image", "start": 2124.24, "duration": 3.72}, {"text": "processing", "start": 2126.88, "duration": 4.68}, {"text": "now um another type of uh deep learning", "start": 2127.96, "duration": 7.72}, {"text": "model is called a birch so this is a um", "start": 2131.56, "duration": 5.799}, {"text": "it stands for bidirectional encoder", "start": 2135.68, "duration": 4.159}, {"text": "representations for Transformers so it", "start": 2137.359, "duration": 5.281}, {"text": "is a Transformer but only uh uses the", "start": 2139.839, "duration": 6.081}, {"text": "encoding part only um and bird is used", "start": 2142.64, "duration": 5.76}, {"text": "as a language model so it was trained on", "start": 2145.92, "duration": 4.28}, {"text": "lots and lots of data like data from", "start": 2148.4, "duration": 4.36}, {"text": "Wikipedia and also a corpus called Books", "start": 2150.2, "duration": 4.96}, {"text": "Corpus so it's it's a language model", "start": 2152.76, "duration": 4.8}, {"text": "it's just um you know generic language", "start": 2155.16, "duration": 4.84}, {"text": "model but it can be fine-tuned it can be", "start": 2157.56, "duration": 5.0}, {"text": "used for a lot of different um natural", "start": 2160.0, "duration": 4.24}, {"text": "language processing tasks like name", "start": 2162.56, "duration": 3.64}, {"text": "entity recognition um relation", "start": 2164.24, "duration": 3.839}, {"text": "extraction question answering and things", "start": 2166.2, "duration": 3.639}, {"text": "like", "start": 2168.079, "duration": 5.52}, {"text": "that okay um", "start": 2169.839, "duration": 8.681}, {"text": "so the a Transformer um GPT is a type of", "start": 2173.599, "duration": 7.48}, {"text": "Transformer it is a uh so it's a", "start": 2178.52, "duration": 5.52}, {"text": "language model um", "start": 2181.079, "duration": 6.28}, {"text": "and so um it can", "start": 2184.04, "duration": 8.96}, {"text": "be used for um what's referred to as um", "start": 2187.359, "duration": 8.48}, {"text": "uh it can it can generate text um so", "start": 2193.0, "duration": 4.52}, {"text": "given some promps it can generate some", "start": 2195.839, "duration": 4.881}, {"text": "text um and it has it's it's a really", "start": 2197.52, "duration": 6.24}, {"text": "huge model with a lot of uh parameters", "start": 2200.72, "duration": 5.32}, {"text": "like I don't know 100 billion weights or", "start": 2203.76, "duration": 5.92}, {"text": "something like that um and it has been", "start": 2206.04, "duration": 7.319}, {"text": "used for a lot of different um NLP tasks", "start": 2209.68, "duration": 6.48}, {"text": "um and its performance has been really", "start": 2213.359, "duration": 4.281}, {"text": "really fantastic fantastic and so this", "start": 2216.16, "duration": 3.8}, {"text": "is um an article that someone wrote", "start": 2217.64, "duration": 4.88}, {"text": "about uh the performance of GPT so I'll", "start": 2219.96, "duration": 3.76}, {"text": "give you a couple minutes to read", "start": 2222.52, "duration": 3.48}, {"text": "through", "start": 2223.72, "duration": 2.28}, {"text": "this", "start": 2245.599, "duration": 3.0}, {"text": "okay so hopefully you've read through", "start": 2276.359, "duration": 3.801}, {"text": "that so this is kind of a you know a", "start": 2277.68, "duration": 6.399}, {"text": "review of gpt3 and they say that gpt3", "start": 2280.16, "duration": 5.919}, {"text": "you know has done a really good job of", "start": 2284.079, "duration": 4.481}, {"text": "uh generating text right and things like", "start": 2286.079, "duration": 6.401}, {"text": "that okay so now what if I tell told you", "start": 2288.56, "duration": 6.519}, {"text": "that this was actually written by gpt3", "start": 2292.48, "duration": 5.359}, {"text": "right this was not something that was it", "start": 2295.079, "duration": 5.681}, {"text": "was not only written about gpt3 but it", "start": 2297.839, "duration": 5.561}, {"text": "was written by gpt3 so this text was", "start": 2300.76, "duration": 4.079}, {"text": "generated by this", "start": 2303.4, "duration": 5.8}, {"text": "model and um um it was the prompt was uh", "start": 2304.839, "duration": 6.041}, {"text": "you know it was given the author some", "start": 2309.2, "duration": 4.04}, {"text": "information about the author the title", "start": 2310.88, "duration": 5.959}, {"text": "some tags and a summary I share my early", "start": 2313.24, "duration": 5.96}, {"text": "experiments with open ai's new language", "start": 2316.839, "duration": 5.48}, {"text": "prediction model gpt3 beta I explain why", "start": 2319.2, "duration": 5.8}, {"text": "I think gpt3 has disruptive potential", "start": 2322.319, "duration": 4.881}, {"text": "comparable to that of blockchain", "start": 2325.0, "duration": 6.48}, {"text": "technology so from that summary gpt3 was", "start": 2327.2, "duration": 6.68}, {"text": "able to generate this text right these", "start": 2331.48, "duration": 6.119}, {"text": "two paragraphs about um this topic and", "start": 2333.88, "duration": 5.64}, {"text": "so that's pretty", "start": 2337.599, "duration": 4.401}, {"text": "amazing um okay so some common", "start": 2339.52, "duration": 5.24}, {"text": "Transformer applications a lot of NLP", "start": 2342.0, "duration": 6.319}, {"text": "tasks um but also uh Vision tasks as", "start": 2344.76, "duration": 6.68}, {"text": "well um and also image captioning so", "start": 2348.319, "duration": 5.52}, {"text": "image caption captioning is uh you know", "start": 2351.44, "duration": 4.159}, {"text": "the input is the image and then the", "start": 2353.839, "duration": 4.121}, {"text": "output is a caption that explains the", "start": 2355.599, "duration": 4.961}, {"text": "contents of the", "start": 2357.96, "duration": 5.72}, {"text": "image okay um another type of deep", "start": 2360.56, "duration": 6.2}, {"text": "learning model that is um uh very", "start": 2363.68, "duration": 4.96}, {"text": "popular or commonly used for lots of", "start": 2366.76, "duration": 4.2}, {"text": "different applications is the generative", "start": 2368.64, "duration": 7.04}, {"text": "adversarial networks or Gams um so this", "start": 2370.96, "duration": 8.04}, {"text": "is a an approach for generative modeling", "start": 2375.68, "duration": 6.679}, {"text": "so the model actually generates data um", "start": 2379.0, "duration": 5.319}, {"text": "so it learns a structure of the input", "start": 2382.359, "duration": 4.081}, {"text": "data and it generates new data that is", "start": 2384.319, "duration": 4.401}, {"text": "similar to um you know what what it was", "start": 2386.44, "duration": 5.6}, {"text": "given as the input so it consists of two", "start": 2388.72, "duration": 5.8}, {"text": "models there a generator and a", "start": 2392.04, "duration": 4.92}, {"text": "determinator right so", "start": 2394.52, "duration": 4.599}, {"text": "uh so it has two models the gener", "start": 2396.96, "duration": 4.6}, {"text": "generator and the discriminator so the", "start": 2399.119, "duration": 5.2}, {"text": "generator generates data that comes from", "start": 2401.56, "duration": 6.039}, {"text": "uh some distribution of the input data", "start": 2404.319, "duration": 6.721}, {"text": "so in the case here of um images of", "start": 2407.599, "duration": 7.881}, {"text": "faces the generator is trained to", "start": 2411.04, "duration": 6.4}, {"text": "generate images with", "start": 2415.48, "duration": 4.359}, {"text": "faces the", "start": 2417.44, "duration": 6.8}, {"text": "discriminator is trained to um determine", "start": 2419.839, "duration": 8.401}, {"text": "if the image of the case was generated", "start": 2424.24, "duration": 7.52}, {"text": "by the generator or an actual image okay", "start": 2428.24, "duration": 5.079}, {"text": "so it determines that the input comes", "start": 2431.76, "duration": 4.52}, {"text": "from the generator which is a synthetic", "start": 2433.319, "duration": 7.081}, {"text": "right generated data or actual data so", "start": 2436.28, "duration": 6.6}, {"text": "um that's why that's where the name Aid", "start": 2440.4, "duration": 4.56}, {"text": "stereo comes from because a generator is", "start": 2442.88, "duration": 5.479}, {"text": "trained to come up with more and more", "start": 2444.96, "duration": 5.6}, {"text": "realistic um images to fool the", "start": 2448.359, "duration": 3.921}, {"text": "discriminator and the discriminator is", "start": 2450.56, "duration": 4.2}, {"text": "trained to um make sure that it doesn't", "start": 2452.28, "duration": 4.28}, {"text": "get fooled by the generator so there", "start": 2454.76, "duration": 4.52}, {"text": "trained in an ADV serial", "start": 2456.56, "duration": 5.279}, {"text": "way um", "start": 2459.28, "duration": 6.4}, {"text": "and the Gan has been used for a lot of", "start": 2461.839, "duration": 6.201}, {"text": "really interesting applications so one", "start": 2465.68, "duration": 4.52}, {"text": "of the first applications it was trained", "start": 2468.04, "duration": 4.319}, {"text": "to generate realistic photographs of", "start": 2470.2, "duration": 5.56}, {"text": "human faces um so you know given some", "start": 2472.359, "duration": 6.321}, {"text": "sort of um distribution of the data it", "start": 2475.76, "duration": 6.319}, {"text": "it learns to generate these images so", "start": 2478.68, "duration": 4.76}, {"text": "these are you know these are the actual", "start": 2482.079, "duration": 4.24}, {"text": "outputs from that model and on the", "start": 2483.44, "duration": 5.08}, {"text": "training data was of celebrity faces", "start": 2486.319, "duration": 4.52}, {"text": "which is why you see such beautiful um", "start": 2488.52, "duration": 5.04}, {"text": "people here in the in the generated", "start": 2490.839, "duration": 5.441}, {"text": "images another application is image to", "start": 2493.56, "duration": 5.759}, {"text": "image translation so um the task is to", "start": 2496.28, "duration": 5.0}, {"text": "transform the image from one domain to", "start": 2499.319, "duration": 4.601}, {"text": "another domain so for example you can", "start": 2501.28, "duration": 7.319}, {"text": "take the model can take a a picture um", "start": 2503.92, "duration": 7.439}, {"text": "and turn it into a Monae like painting", "start": 2508.599, "duration": 5.52}, {"text": "or take a picture of a horse and turn it", "start": 2511.359, "duration": 6.321}, {"text": "into a zebra or or you know take a", "start": 2514.119, "duration": 5.921}, {"text": "picture from a winter scene and turn it", "start": 2517.68, "duration": 5.0}, {"text": "to a summer", "start": 2520.04, "duration": 2.64}, {"text": "scene um it has also been used um to", "start": 2523.319, "duration": 6.961}, {"text": "create high resolution images from low", "start": 2527.52, "duration": 4.799}, {"text": "resolution images and that's referred to", "start": 2530.28, "duration": 3.799}, {"text": "as a super resolution", "start": 2532.319, "duration": 6.04}, {"text": "Gan um so this is let's see so this is", "start": 2534.079, "duration": 6.601}, {"text": "the original image so they down sample", "start": 2538.359, "duration": 4.401}, {"text": "the image and then they use different", "start": 2540.68, "duration": 5.639}, {"text": "methods to um increase the resolution of", "start": 2542.76, "duration": 6.12}, {"text": "down sampled image so this is using a", "start": 2546.319, "duration": 5.161}, {"text": "conventional approach using bcbic", "start": 2548.88, "duration": 7.239}, {"text": "interpolation um this is using um reset", "start": 2551.48, "duration": 6.599}, {"text": "which is another type of noal network", "start": 2556.119, "duration": 4.44}, {"text": "convolutional network um and then this", "start": 2558.079, "duration": 4.561}, {"text": "is using the super resolution Gan and", "start": 2560.559, "duration": 5.601}, {"text": "you can see it's the quality is is uh", "start": 2562.64, "duration": 5.4}, {"text": "very very good right it's very close to", "start": 2566.16, "duration": 5.199}, {"text": "the original um image uh there's a", "start": 2568.04, "duration": 5.2}, {"text": "little bit of detail that is lacking", "start": 2571.359, "duration": 5.24}, {"text": "here but um and here as well but you", "start": 2573.24, "duration": 5.76}, {"text": "know overall it's a very good", "start": 2576.599, "duration": 5.72}, {"text": "replication of the original", "start": 2579.0, "duration": 3.319}, {"text": "image um other Gan applications text to", "start": 2582.359, "duration": 4.401}, {"text": "image", "start": 2585.68, "duration": 3.56}, {"text": "translation uh face aging is really an", "start": 2586.76, "duration": 5.559}, {"text": "interesting application of that as", "start": 2589.24, "duration": 7.48}, {"text": "well okay um any questions about what we", "start": 2592.319, "duration": 7.52}, {"text": "about the um deep learning architectures", "start": 2596.72, "duration": 5.8}, {"text": "that we just went", "start": 2599.839, "duration": 2.681}, {"text": "over", "start": 2605.079, "duration": 4.721}, {"text": "okay all right", "start": 2607.52, "duration": 5.44}, {"text": "so let's go on to deep learning", "start": 2609.8, "duration": 7.319}, {"text": "libraries um so here are some commonly", "start": 2612.96, "duration": 6.56}, {"text": "uh used deep learning libraries uh these", "start": 2617.119, "duration": 4.72}, {"text": "are python based deep learning libraries", "start": 2619.52, "duration": 3.88}, {"text": "um tensor", "start": 2621.839, "duration": 5.28}, {"text": "flow um is a framework that was", "start": 2623.4, "duration": 9.28}, {"text": "developed by Google um and Caris uh was", "start": 2627.119, "duration": 8.641}, {"text": "what Paul had used in his demos so Caris", "start": 2632.68, "duration": 5.159}, {"text": "used to to be kind of a standalone", "start": 2635.76, "duration": 6.2}, {"text": "package it's a highlevel API that worked", "start": 2637.839, "duration": 7.121}, {"text": "on top of tensorflow as well as other um", "start": 2641.96, "duration": 5.44}, {"text": "deep learning libraries as well but now", "start": 2644.96, "duration": 5.28}, {"text": "Caris is now part of tensorflow as of I", "start": 2647.4, "duration": 4.8}, {"text": "think 20 or I don't remember which", "start": 2650.24, "duration": 5.68}, {"text": "version Caris is now part of tensor flow", "start": 2652.2, "duration": 5.639}, {"text": "um", "start": 2655.92, "duration": 5.32}, {"text": "and uh there's also pytorch uh and this", "start": 2657.839, "duration": 6.561}, {"text": "is a framework that is developed by um", "start": 2661.24, "duration": 5.76}, {"text": "Facebook um there's also a pie torch", "start": 2664.4, "duration": 6.24}, {"text": "lightning library that uh is um kind of", "start": 2667.0, "duration": 6.52}, {"text": "equivalent to Caris um so it's a higher", "start": 2670.64, "duration": 6.8}, {"text": "level um API that works on top of py", "start": 2673.52, "duration": 7.2}, {"text": "torch um and then there's also Apache", "start": 2677.44, "duration": 7.2}, {"text": "mxnet uh this is a framework used by", "start": 2680.72, "duration": 8.72}, {"text": "AWS um and then for Java there's de forj", "start": 2684.64, "duration": 7.479}, {"text": "um for R there's tensor flow and", "start": 2689.44, "duration": 5.919}, {"text": "mxnet and lots of lots of cloud", "start": 2692.119, "duration": 4.521}, {"text": "libraries", "start": 2695.359, "duration": 5.24}, {"text": "um as well so Google Cloud ml aw AWS", "start": 2696.64, "duration": 6.919}, {"text": "sagemaker and", "start": 2700.599, "duration": 2.96}, {"text": "others okay and then there's lots and", "start": 2704.0, "duration": 4.119}, {"text": "lots of resources here that I put here", "start": 2706.24, "duration": 5.2}, {"text": "this is a very good um this is a course", "start": 2708.119, "duration": 6.24}, {"text": "uh taught at Stanford um so it has they", "start": 2711.44, "duration": 4.84}, {"text": "made their class notes available so it", "start": 2714.359, "duration": 4.161}, {"text": "has a lot of um really useful", "start": 2716.28, "duration": 5.079}, {"text": "information here um tensorflow there's a", "start": 2718.52, "duration": 4.92}, {"text": "tensorflow noal network background where", "start": 2721.359, "duration": 3.24}, {"text": "you can kind of play around with the", "start": 2723.44, "duration": 3.36}, {"text": "hyper parameters to see how things", "start": 2724.599, "duration": 4.801}, {"text": "change and then P TCH tutorials so", "start": 2726.8, "duration": 4.36}, {"text": "tensorflow and P torch have a lot of", "start": 2729.4, "duration": 5.12}, {"text": "tutorials that you can um uh kind of", "start": 2731.16, "duration": 4.919}, {"text": "look", "start": 2734.52, "duration": 4.839}, {"text": "through okay I think that is what I have", "start": 2736.079, "duration": 8.561}, {"text": "for this part um any", "start": 2739.359, "duration": 5.281}, {"text": "questions", "start": 2744.68, "duration": 3.0}, {"text": "comments okay um so let's talk about", "start": 2751.16, "duration": 10.0}, {"text": "transfer learning in the context of deep", "start": 2756.4, "duration": 9.439}, {"text": "learning okay so transfer learning is a", "start": 2761.16, "duration": 6.8}, {"text": "method to overcome the challenges of", "start": 2765.839, "duration": 4.76}, {"text": "training the a model from scratch so", "start": 2767.96, "duration": 5.0}, {"text": "remember um and I said that a deep", "start": 2770.599, "duration": 3.801}, {"text": "learning model has lots and lots of", "start": 2772.96, "duration": 3.76}, {"text": "layers meaning that it has lots and lots", "start": 2774.4, "duration": 4.719}, {"text": "of parameters uh and so that means that", "start": 2776.72, "duration": 6.52}, {"text": "you need a lot of data in order to um", "start": 2779.119, "duration": 7.2}, {"text": "adjust those parameters right so in a", "start": 2783.24, "duration": 5.319}, {"text": "lot of applications you may not have", "start": 2786.319, "duration": 5.401}, {"text": "enough data or it takes it would take a", "start": 2788.559, "duration": 4.961}, {"text": "very very long time it take would take a", "start": 2791.72, "duration": 4.76}, {"text": "lot of GPU Cycles to train your model", "start": 2793.52, "duration": 4.76}, {"text": "and so the idea is that you can use a", "start": 2796.48, "duration": 4.72}, {"text": "pre-trained model with that is it's a", "start": 2798.28, "duration": 4.799}, {"text": "model that was trained on another data", "start": 2801.2, "duration": 4.44}, {"text": "set and that will serve as a starting", "start": 2803.079, "duration": 4.24}, {"text": "point for your model and then you can", "start": 2805.64, "duration": 5.199}, {"text": "train your model on your data set for", "start": 2807.319, "duration": 5.481}, {"text": "your particular", "start": 2810.839, "duration": 5.441}, {"text": "task um so a couple of approach is do", "start": 2812.8, "duration": 4.88}, {"text": "transfer learning so there's feature", "start": 2816.28, "duration": 4.16}, {"text": "extraction and fine tuning so in feature", "start": 2817.68, "duration": 5.0}, {"text": "extraction you remove the classification", "start": 2820.44, "duration": 4.32}, {"text": "layer so kind of you know the the the", "start": 2822.68, "duration": 4.879}, {"text": "last layer in your model uh from the", "start": 2824.76, "duration": 5.2}, {"text": "pre-trained model you treat the rest as", "start": 2827.559, "duration": 6.56}, {"text": "a feature extractor and then you um feed", "start": 2829.96, "duration": 7.32}, {"text": "those features into a new classifier", "start": 2834.119, "duration": 4.841}, {"text": "right so this is referred to as a top", "start": 2837.28, "duration": 3.72}, {"text": "model or a classification", "start": 2838.96, "duration": 6.92}, {"text": "head um there's also fine-tuning um so", "start": 2841.0, "duration": 7.4}, {"text": "this is uh you", "start": 2845.88, "duration": 5.92}, {"text": "also add your uh classification head or", "start": 2848.4, "duration": 7.4}, {"text": "your Top Model but you you also tune uh", "start": 2851.8, "duration": 6.12}, {"text": "some of the layers of the original", "start": 2855.8, "duration": 6.24}, {"text": "pre-trained model as well um so those", "start": 2857.92, "duration": 5.8}, {"text": "are two different approaches and we'll", "start": 2862.04, "duration": 4.079}, {"text": "we'll in our exercises we'll do", "start": 2863.72, "duration": 6.24}, {"text": "both um some popular architectures that", "start": 2866.119, "duration": 7.041}, {"text": "have been used for transfer learning or", "start": 2869.96, "duration": 6.08}, {"text": "um the CNN that uh I had listed Ed", "start": 2873.16, "duration": 5.04}, {"text": "before so Alex net Google net vget and", "start": 2876.04, "duration": 4.76}, {"text": "reset so these are all winners of this", "start": 2878.2, "duration": 6.24}, {"text": "uh image analysis competition that is", "start": 2880.8, "duration": 5.48}, {"text": "referred to as", "start": 2884.44, "duration": 5.159}, {"text": "ilss VRC which stands for imag net large", "start": 2886.28, "duration": 5.92}, {"text": "scale visual recognition challenge so", "start": 2889.599, "duration": 5.161}, {"text": "this is in competition on a lot of image", "start": 2892.2, "duration": 7.04}, {"text": "tasks um on this this um data that we", "start": 2894.76, "duration": 7.92}, {"text": "refer to as a imag net data so imag net", "start": 2899.24, "duration": 5.599}, {"text": "is a database that was developed for", "start": 2902.68, "duration": 4.48}, {"text": "computer vision research Arch um it has", "start": 2904.839, "duration": 5.321}, {"text": "about 14 million images that are hand", "start": 2907.16, "duration": 6.28}, {"text": "annotated um it has about 22,000", "start": 2910.16, "duration": 9.12}, {"text": "categories um so the um the history of", "start": 2913.44, "duration": 9.08}, {"text": "this uh competition is started back in", "start": 2919.28, "duration": 6.12}, {"text": "2010 um and we're going to be focusing", "start": 2922.52, "duration": 4.839}, {"text": "mostly on IM the image classification", "start": 2925.4, "duration": 6.0}, {"text": "task um and that has a thousand object", "start": 2927.359, "duration": 7.121}, {"text": "categories and if you take a look at the", "start": 2931.4, "duration": 6.0}, {"text": "error rate over the years um back in", "start": 2934.48, "duration": 5.879}, {"text": "2010 when this competition started the", "start": 2937.4, "duration": 5.08}, {"text": "error rate was about 28% and this was", "start": 2940.359, "duration": 4.0}, {"text": "using conventional image processing", "start": 2942.48, "duration": 3.8}, {"text": "techniques right you know Huff transform", "start": 2944.359, "duration": 4.681}, {"text": "Edge detectors things like that then in", "start": 2946.28, "duration": 5.88}, {"text": "2012 alexnet was the first CNN that that", "start": 2949.04, "duration": 6.279}, {"text": "entered this competition and that nearly", "start": 2952.16, "duration": 5.28}, {"text": "haved the error rate right so it brought", "start": 2955.319, "duration": 4.24}, {"text": "it from 28% down to", "start": 2957.44, "duration": 5.639}, {"text": "15% and then ever since then um the", "start": 2959.559, "duration": 6.081}, {"text": "error rate has been you know going lower", "start": 2963.079, "duration": 5.841}, {"text": "lower and decreasing uh more and more so", "start": 2965.64, "duration": 4.04}, {"text": "in", "start": 2968.92, "duration": 5.04}, {"text": "2015 uh resnet achieved a an error rate", "start": 2969.68, "duration": 5.72}, {"text": "of about three and a half and this was", "start": 2973.96, "duration": 3.8}, {"text": "better than human performance they so", "start": 2975.4, "duration": 5.679}, {"text": "they trained somebody a human uh to you", "start": 2977.76, "duration": 5.559}, {"text": "know do this image classification task", "start": 2981.079, "duration": 4.28}, {"text": "and that person or resent did better", "start": 2983.319, "duration": 3.48}, {"text": "than than that", "start": 2985.359, "duration": 3.801}, {"text": "person uh and then now you know it's", "start": 2986.799, "duration": 5.28}, {"text": "getting down to you know kind of the 2%", "start": 2989.16, "duration": 4.52}, {"text": "uh error here and this might be just", "start": 2992.079, "duration": 4.04}, {"text": "down to the noise level um", "start": 2993.68, "duration": 6.6}, {"text": "and uh you know so uh it's it's just", "start": 2996.119, "duration": 6.2}, {"text": "been getting better and better and ever", "start": 3000.28, "duration": 5.279}, {"text": "since Alex net um you know all the", "start": 3002.319, "duration": 5.721}, {"text": "entries are now deep learning", "start": 3005.559, "duration": 5.721}, {"text": "models um so here's another look at that", "start": 3008.04, "duration": 5.68}, {"text": "um classification results um you know", "start": 3011.28, "duration": 5.92}, {"text": "you can see that the error goes down and", "start": 3013.72, "duration": 5.879}, {"text": "down okay", "start": 3017.2, "duration": 7.919}, {"text": "so the idea behind transfer learning is", "start": 3019.599, "duration": 7.24}, {"text": "um remember that a deep learning model", "start": 3025.119, "duration": 4.921}, {"text": "has lots and lots of layers right um and", "start": 3026.839, "duration": 5.0}, {"text": "the higher up you go so sorry this is", "start": 3030.04, "duration": 6.88}, {"text": "kind of um the opposite so um the the", "start": 3031.839, "duration": 8.76}, {"text": "the higher up you go the more abstract", "start": 3036.92, "duration": 6.04}, {"text": "um the the layers become the features", "start": 3040.599, "duration": 4.76}, {"text": "become the features that are learned", "start": 3042.96, "duration": 6.119}, {"text": "become and so the idea is that the lower", "start": 3045.359, "duration": 5.72}, {"text": "layers of the model detect kind of", "start": 3049.079, "duration": 5.48}, {"text": "generic features in an image so you know", "start": 3051.079, "duration": 5.04}, {"text": "edges", "start": 3054.559, "duration": 5.24}, {"text": "curves um you know different colors and", "start": 3056.119, "duration": 5.161}, {"text": "things like that so those are things", "start": 3059.799, "duration": 3.441}, {"text": "that are common in all images right that", "start": 3061.28, "duration": 5.799}, {"text": "you need to extract in order to um", "start": 3063.24, "duration": 7.119}, {"text": "understand higher level U features and", "start": 3067.079, "duration": 5.52}, {"text": "so what you can do the idea then is that", "start": 3070.359, "duration": 5.96}, {"text": "you can um use the lower layers as is", "start": 3072.599, "duration": 6.52}, {"text": "right so on a a Network that has been", "start": 3076.319, "duration": 6.121}, {"text": "trained on image net you can keep these", "start": 3079.119, "duration": 6.96}, {"text": "lower layers as is because these layers", "start": 3082.44, "duration": 7.52}, {"text": "um detect features are important in uh", "start": 3086.079, "duration": 6.681}, {"text": "any image um and then fine-tune the rest", "start": 3089.96, "duration": 6.24}, {"text": "of the layers to customize to your own", "start": 3092.76, "duration": 5.96}, {"text": "data set okay so that's the idea behind", "start": 3096.2, "duration": 3.44}, {"text": "transfer", "start": 3098.72, "duration": 3.68}, {"text": "learning so we take this pre- train", "start": 3099.64, "duration": 4.719}, {"text": "model this is a", "start": 3102.4, "duration": 6.12}, {"text": "vgg um future extraction then means that", "start": 3104.359, "duration": 7.081}, {"text": "you would extract the feature here right", "start": 3108.52, "duration": 4.88}, {"text": "so you don't change any of this the only", "start": 3111.44, "duration": 2.96}, {"text": "thing that you're doing is you're", "start": 3113.4, "duration": 3.64}, {"text": "replacing this with your own", "start": 3114.4, "duration": 5.679}, {"text": "classifier so this is used as a feature", "start": 3117.04, "duration": 4.799}, {"text": "extractor you're extracting features", "start": 3120.079, "duration": 3.601}, {"text": "here you take these features and feed it", "start": 3121.839, "duration": 4.401}, {"text": "into your own classifier trained on your", "start": 3123.68, "duration": 6.159}, {"text": "data set um U for your particular", "start": 3126.24, "duration": 7.599}, {"text": "task fine tuning is you replace this", "start": 3129.839, "duration": 5.881}, {"text": "classification head or the Top Model", "start": 3133.839, "duration": 6.441}, {"text": "here um for your particular task and you", "start": 3135.72, "duration": 7.2}, {"text": "adjust those parameters as well as some", "start": 3140.28, "duration": 6.16}, {"text": "of the layers usually the higher layers", "start": 3142.92, "duration": 5.24}, {"text": "in the pre-trained", "start": 3146.44, "duration": 3.84}, {"text": "model", "start": 3148.16, "duration": 5.6}, {"text": "okay um so a couple of tips on when and", "start": 3150.28, "duration": 5.839}, {"text": "how to fine tune so if the new data set", "start": 3153.76, "duration": 4.12}, {"text": "is small and similar to your original", "start": 3156.119, "duration": 4.2}, {"text": "data set then you can just do feature", "start": 3157.88, "duration": 4.04}, {"text": "extraction right extractive features", "start": 3160.319, "duration": 3.161}, {"text": "from the higher layer and feed it to a", "start": 3161.92, "duration": 4.28}, {"text": "separate classifier if the new data set", "start": 3163.48, "duration": 4.839}, {"text": "is large and similar to the original", "start": 3166.2, "duration": 5.48}, {"text": "data set then you can fine tune or uh", "start": 3168.319, "duration": 5.081}, {"text": "the top part of all layers because now", "start": 3171.68, "duration": 4.36}, {"text": "you have more data new data if the new", "start": 3173.4, "duration": 4.719}, {"text": "data set is small and different from the", "start": 3176.04, "duration": 4.36}, {"text": "original data set then you might want to", "start": 3178.119, "duration": 4.041}, {"text": "go a little bit lower because then you", "start": 3180.4, "duration": 6.08}, {"text": "have to kind of you know train um um", "start": 3182.16, "duration": 7.48}, {"text": "lower layers as well if the new data set", "start": 3186.48, "duration": 4.639}, {"text": "is large and different from the original", "start": 3189.64, "duration": 4.919}, {"text": "data set then you can again fine-tune um", "start": 3191.119, "duration": 7.0}, {"text": "just either the top layer or um all", "start": 3194.559, "duration": 8.681}, {"text": "layers um some other tips um when you do", "start": 3198.119, "duration": 7.881}, {"text": "transfer learning you want to use a very", "start": 3203.24, "duration": 4.44}, {"text": "small learning rate for the fine tuning", "start": 3206.0, "duration": 3.2}, {"text": "part because you don't want to destroy", "start": 3207.68, "duration": 4.159}, {"text": "what was already learned um the other is", "start": 3209.2, "duration": 5.8}, {"text": "that you want to train your top level", "start": 3211.839, "duration": 5.201}, {"text": "classifier first right so that's the one", "start": 3215.0, "duration": 4.64}, {"text": "that is um customized for your", "start": 3217.04, "duration": 5.16}, {"text": "particular task um to your data so you", "start": 3219.64, "duration": 4.12}, {"text": "want to train that first and then you", "start": 3222.2, "duration": 4.119}, {"text": "find two in the lower layers otherwise", "start": 3223.76, "duration": 4.24}, {"text": "um you can mess up what was already", "start": 3226.319, "duration": 4.76}, {"text": "learned by the cre trained model you", "start": 3228.0, "duration": 5.079}, {"text": "might also want to do data augmentation", "start": 3231.079, "duration": 3.681}, {"text": "and we'll talk a more about that when we", "start": 3233.079, "duration": 6.881}, {"text": "do the exercise so this is um a way to", "start": 3234.76, "duration": 8.079}, {"text": "uh add variation and also increase the", "start": 3239.96, "duration": 4.92}, {"text": "size of your training set so you can add", "start": 3242.839, "duration": 3.96}, {"text": "things like horizontal flips vertical", "start": 3244.88, "duration": 4.52}, {"text": "flips random crops translation rotation", "start": 3246.799, "duration": 5.121}, {"text": "you know kind of simple image processing", "start": 3249.4, "duration": 5.28}, {"text": "um operations to slightly alter your", "start": 3251.92, "duration": 5.32}, {"text": "image um and so that will add variation", "start": 3254.68, "duration": 4.76}, {"text": "to your data and it will also also", "start": 3257.24, "duration": 5.64}, {"text": "increase the size of your data", "start": 3259.44, "duration": 3.44}, {"text": "set okay so now we're going to do a", "start": 3263.64, "duration": 3.8}, {"text": "couple of", "start": 3266.52, "duration": 4.52}, {"text": "Hands-On um so the data that we're using", "start": 3267.44, "duration": 6.919}, {"text": "is a subset of the cats and dogs images", "start": 3271.04, "duration": 6.12}, {"text": "from a CLE competition um and we'll do", "start": 3274.359, "duration": 4.561}, {"text": "both feature extraction and", "start": 3277.16, "duration": 5.6}, {"text": "fine-tuning all right so the data uh we", "start": 3278.92, "duration": 6.679}, {"text": "have a thousand uh images of cats and a", "start": 3282.76, "duration": 5.039}, {"text": "thousand images of dogs and then a", "start": 3285.599, "duration": 3.801}, {"text": "couple hundred for validation and a", "start": 3287.799, "duration": 5.081}, {"text": "couple for um a test so these are just", "start": 3289.4, "duration": 6.28}, {"text": "images of cats and dogs right so kind of", "start": 3292.88, "duration": 4.959}, {"text": "images that people will take of their", "start": 3295.68, "duration": 5.96}, {"text": "pets um so the feuture extraction uh for", "start": 3297.839, "duration": 5.24}, {"text": "feature extraction we're going to set", "start": 3301.64, "duration": 5.0}, {"text": "the image Dimensions um and location and", "start": 3303.079, "duration": 6.161}, {"text": "then we're going to do uh use what's", "start": 3306.64, "duration": 4.84}, {"text": "called a image data generator to read", "start": 3309.24, "duration": 5.28}, {"text": "images from a folder right so when you", "start": 3311.48, "duration": 4.72}, {"text": "dealing with a lot of data you don't", "start": 3314.52, "duration": 3.839}, {"text": "want to read everything all in at once a", "start": 3316.2, "duration": 3.76}, {"text": "lot of times you can't so you want to", "start": 3318.359, "duration": 5.121}, {"text": "read just a batch at a time um from uh", "start": 3319.96, "duration": 6.28}, {"text": "your file your file system", "start": 3323.48, "duration": 5.8}, {"text": "um and then for the model building we're", "start": 3326.24, "duration": 4.44}, {"text": "going to load the", "start": 3329.28, "duration": 4.0}, {"text": "model uh we're going to load the the the", "start": 3330.68, "duration": 5.76}, {"text": "pre-rain weights we're going to freeze", "start": 3333.28, "duration": 5.559}, {"text": "the weights in the pre-train model right", "start": 3336.44, "duration": 4.0}, {"text": "because we're only using this as a", "start": 3338.839, "duration": 3.641}, {"text": "feature extractor then we're going to to", "start": 3340.44, "duration": 4.04}, {"text": "add the Top Model to classify cats", "start": 3342.48, "duration": 4.4}, {"text": "versus dogs and so and then we're going", "start": 3344.48, "duration": 5.44}, {"text": "to compile the model so that the we're", "start": 3346.88, "duration": 5.28}, {"text": "combining the pre-trained base model", "start": 3349.92, "duration": 4.08}, {"text": "plus our Top Model", "start": 3352.16, "duration": 4.32}, {"text": "classifier when we train the model we're", "start": 3354.0, "duration": 5.88}, {"text": "only um training the Top Model weights", "start": 3356.48, "duration": 5.04}, {"text": "and then we'll do you know your normal", "start": 3359.88, "duration": 3.719}, {"text": "evaluation calculate accuracy Etc and", "start": 3361.52, "duration": 4.12}, {"text": "then performance infuence on some test", "start": 3363.599, "duration": 6.081}, {"text": "images okay for fine tuning um kind of", "start": 3365.64, "duration": 6.04}, {"text": "the same thing the difference here is", "start": 3369.68, "duration": 4.2}, {"text": "that when we're training the model we", "start": 3371.68, "duration": 5.28}, {"text": "are we want to um use the model weights", "start": 3373.88, "duration": 6.04}, {"text": "that we got from feature extraction and", "start": 3376.96, "duration": 6.399}, {"text": "then um we are going to to adjust some", "start": 3379.92, "duration": 5.56}, {"text": "of the layers in the pre-train model as", "start": 3383.359, "duration": 5.081}, {"text": "well and we're going to use a validation", "start": 3385.48, "duration": 4.839}, {"text": "data to determine when to stop training", "start": 3388.44, "duration": 2.96}, {"text": "right so we're going to use early", "start": 3390.319, "duration": 2.881}, {"text": "stopping to determine when to stop", "start": 3391.4, "duration": 6.0}, {"text": "training and then evaluation the same", "start": 3393.2, "duration": 8.28}, {"text": "way um so this kind of show uh kind of", "start": 3397.4, "duration": 6.159}, {"text": "explains what um how early stopping", "start": 3401.48, "duration": 4.319}, {"text": "works so the idea is that we're going to", "start": 3403.559, "duration": 4.201}, {"text": "use a validation data to determine when", "start": 3405.799, "duration": 3.921}, {"text": "to stop the training in order to avoid", "start": 3407.76, "duration": 3.88}, {"text": "overfitting so remember that when a", "start": 3409.72, "duration": 3.96}, {"text": "model overfits it doesn't generalize", "start": 3411.64, "duration": 5.36}, {"text": "well to new data so we want to prevent", "start": 3413.68, "duration": 5.52}, {"text": "overfitting um so the idea is that we", "start": 3417.0, "duration": 7.28}, {"text": "are going to um monitor the Val the the", "start": 3419.2, "duration": 8.04}, {"text": "um the error on the validation set and", "start": 3424.28, "duration": 5.799}, {"text": "when the model when the validation error", "start": 3427.24, "duration": 4.48}, {"text": "starts to increase this is when the", "start": 3430.079, "duration": 3.401}, {"text": "model is overfitting and so we want to", "start": 3431.72, "duration": 4.399}, {"text": "stop training right here and save these", "start": 3433.48, "duration": 4.24}, {"text": "weights and these are the weights that", "start": 3436.119, "duration": 4.68}, {"text": "we want to use for the final", "start": 3437.72, "duration": 6.2}, {"text": "model um okay and this is um this", "start": 3440.799, "duration": 6.52}, {"text": "explains data a ation right so it's", "start": 3443.92, "duration": 9.84}, {"text": "adding random image um uh operations", "start": 3447.319, "duration": 9.72}, {"text": "image manipulation operations to your um", "start": 3453.76, "duration": 6.44}, {"text": "image so this is your original image um", "start": 3457.039, "duration": 6.28}, {"text": "you can add random uh rotation you can", "start": 3460.2, "duration": 7.0}, {"text": "add random uh Zoom uh you can also add", "start": 3463.319, "duration": 6.681}, {"text": "this is flipping this is um horizontal", "start": 3467.2, "duration": 5.599}, {"text": "flipping okay this adds variability to", "start": 3470.0, "duration": 6.48}, {"text": "your data set it it also um uh increases", "start": 3472.799, "duration": 6.481}, {"text": "the size of your data", "start": 3476.48, "duration": 6.639}, {"text": "set okay um okay so the model the pre-", "start": 3479.28, "duration": 5.68}, {"text": "train model that we are going to be use", "start": 3483.119, "duration": 5.0}, {"text": "is uh is called the mobile net mobile", "start": 3484.96, "duration": 6.32}, {"text": "net version two um so it also has", "start": 3488.119, "duration": 5.401}, {"text": "convolutional blocks um they're much", "start": 3491.28, "duration": 4.48}, {"text": "more complicated than the", "start": 3493.52, "duration": 3.92}, {"text": "vgd", "start": 3495.76, "duration": 4.92}, {"text": "um but uh essentially this is kind of", "start": 3497.44, "duration": 4.76}, {"text": "what it looks like is it has an", "start": 3500.68, "duration": 6.679}, {"text": "expansion layer um depth wise layer um", "start": 3502.2, "duration": 8.04}, {"text": "so it has you know different types of", "start": 3507.359, "duration": 6.121}, {"text": "layers as well it's it is a CNN um it is", "start": 3510.24, "duration": 5.559}, {"text": "a lightweight architecture and it was", "start": 3513.48, "duration": 4.24}, {"text": "designed for mobile devices which is why", "start": 3515.799, "duration": 5.481}, {"text": "it's called a mobile net okay all right", "start": 3517.72, "duration": 7.839}, {"text": "so let's get going on this", "start": 3521.28, "duration": 7.88}, {"text": "so um yeah so you should have a terminal", "start": 3525.559, "duration": 6.121}, {"text": "on um your local machine so that you can", "start": 3529.16, "duration": 5.919}, {"text": "log into expanse and then um do a git", "start": 3531.68, "duration": 7.639}, {"text": "poll so you can get the latest um", "start": 3535.079, "duration": 7.201}, {"text": "material all right and", "start": 3539.319, "duration": 4.011}, {"text": "then", "start": 3542.28, "duration": 3.559}, {"text": "[Music]", "start": 3543.33, "duration": 5.31}, {"text": "um in your terminal", "start": 3545.839, "duration": 5.48}, {"text": "window okay so that should be yes in", "start": 3548.64, "duration": 4.84}, {"text": "your terminal window type in Jupiter GPU", "start": 3551.319, "duration": 5.24}, {"text": "Shar tensor flow so um the PDF for this", "start": 3553.48, "duration": 5.48}, {"text": "slide is also available in the repost so", "start": 3556.559, "duration": 5.56}, {"text": "you can go ahead and um download this", "start": 3558.96, "duration": 6.32}, {"text": "and um copy and paste this if you'd like", "start": 3562.119, "duration": 6.2}, {"text": "um I can also put this in here", "start": 3565.28, "duration": 4.839}, {"text": "so", "start": 3568.319, "duration": 4.441}, {"text": "GPU share", "start": 3570.119, "duration": 6.801}, {"text": "10 flow so if you type that in that is", "start": 3572.76, "duration": 5.92}, {"text": "an alias with this very very long", "start": 3576.92, "duration": 4.48}, {"text": "command here um when you type that in", "start": 3578.68, "duration": 4.639}, {"text": "you should get a URL so you can copy and", "start": 3581.4, "duration": 6.0}, {"text": "paste that um into your", "start": 3583.319, "duration": 4.081}, {"text": "browser okay", "start": 3588.64, "duration": 4.32}, {"text": "um", "start": 3593.64, "duration": 3.0}, {"text": "let me know when you have done that and", "start": 3597.119, "duration": 6.72}, {"text": "we can continue on and I'm going to", "start": 3599.76, "duration": 8.039}, {"text": "also see if I can share", "start": 3603.839, "duration": 3.96}, {"text": "my", "start": 3609.839, "duration": 3.0}, {"text": "um jupit", "start": 3614.64, "duration": 5.6}, {"text": "lab as", "start": 3617.039, "duration": 3.201}, {"text": "well I'm going to stop sharing I think", "start": 3623.2, "duration": 5.0}, {"text": "and so I", "start": 3625.839, "duration": 6.0}, {"text": "can share both", "start": 3628.2, "duration": 3.639}, {"text": "windows stop", "start": 3632.0, "duration": 3.24}, {"text": "sharing", "start": 3638.72, "duration": 3.0}, {"text": "um okay so you should see now", "start": 3653.319, "duration": 5.561}, {"text": "both", "start": 3659.92, "duration": 3.0}, {"text": "windows okay", "start": 3664.599, "duration": 6.121}, {"text": "um all right so once you have your juper", "start": 3667.559, "duration": 4.401}, {"text": "lab up and", "start": 3670.72, "duration": 4.0}, {"text": "running um in the terminal window in", "start": 3671.96, "duration": 4.399}, {"text": "Jupiter lab so you want to open up a", "start": 3674.72, "duration": 4.56}, {"text": "terminal window here and you want to do", "start": 3676.359, "duration": 7.081}, {"text": "go to your local scratch right so CD", "start": 3679.28, "duration": 8.48}, {"text": "scratch slash user oh there's there's a", "start": 3683.44, "duration": 6.24}, {"text": "missing slash here so it should be", "start": 3687.76, "duration": 5.319}, {"text": "scratch slash", "start": 3689.68, "duration": 3.399}, {"text": "user all right so you should be in your", "start": 3695.92, "duration": 5.159}, {"text": "scratch local scratch so it should look", "start": 3699.16, "duration": 4.08}, {"text": "something like", "start": 3701.079, "duration": 5.561}, {"text": "this okay is", "start": 3703.24, "duration": 6.799}, {"text": "anybody not", "start": 3706.64, "duration": 3.399}, {"text": "there okay let me um give me a thumbs up", "start": 3713.44, "duration": 6.96}, {"text": "if you are here at this", "start": 3716.68, "duration": 3.72}, {"text": "point awesome thank", "start": 3723.68, "duration": 4.599}, {"text": "you all right", "start": 3729.799, "duration": 4.0}, {"text": "um okay so then we're going to copy the", "start": 3734.24, "duration": 5.559}, {"text": "data over the cats and dogs data um and", "start": 3736.88, "duration": 5.76}, {"text": "again you can copy and paste this um and", "start": 3739.799, "duration": 5.681}, {"text": "I can also", "start": 3742.64, "duration": 6.56}, {"text": "in the chat", "start": 3745.48, "duration": 3.72}, {"text": "black so do", "start": 3750.119, "duration": 8.841}, {"text": "that and you can do copy SI", "start": 3753.279, "duration": 9.961}, {"text": "2022 data dur", "start": 3758.96, "duration": 8.68}, {"text": "cats versus dogs. zip and period don't", "start": 3763.24, "duration": 6.319}, {"text": "forget this", "start": 3767.64, "duration": 5.719}, {"text": "period so it's this", "start": 3769.559, "duration": 6.081}, {"text": "command", "start": 3773.359, "duration": 4.081}, {"text": "and", "start": 3775.64, "duration": 4.08}, {"text": "then we do an", "start": 3777.44, "duration": 4.919}, {"text": "mzip uh you want to do a dash Q", "start": 3779.72, "duration": 3.879}, {"text": "otherwise it's going to speed out a lot", "start": 3782.359, "duration": 3.44}, {"text": "of", "start": 3783.599, "duration": 2.2}, {"text": "stuff okay and then you unzip that", "start": 3788.279, "duration": 4.76}, {"text": "file and then you can do an LS cats and", "start": 3793.599, "duration": 6.96}, {"text": "dogs and you should see test train and", "start": 3797.039, "duration": 6.24}, {"text": "validation", "start": 3800.559, "duration": 4.8}, {"text": "okay", "start": 3803.279, "duration": 6.28}, {"text": "anybody need help anybody", "start": 3805.359, "duration": 4.2}, {"text": "stuck okay hopefully everybody's", "start": 3818.4, "duration": 5.36}, {"text": "there okay so the", "start": 3826.599, "duration": 5.641}, {"text": "code so if you go", "start": 3829.319, "duration": 6.96}, {"text": "to um", "start": 3832.24, "duration": 4.039}, {"text": "your home directory go into wherever you", "start": 3837.359, "duration": 7.24}, {"text": "know the the sdsc uh clone the the repo", "start": 3839.92, "duration": 9.119}, {"text": "clone and then go to", "start": 3844.599, "duration": 7.68}, {"text": "5.2b deep learning and then go under", "start": 3849.039, "duration": 5.681}, {"text": "transfer", "start": 3852.279, "duration": 2.441}, {"text": "learning", "start": 3855.119, "duration": 6.44}, {"text": "and yeah we have time we can", "start": 3857.079, "duration": 4.48}, {"text": "um open up feature extract", "start": 3861.68, "duration": 7.159}, {"text": "not the solution one the", "start": 3865.2, "duration": 3.639}, {"text": "um I think I don't need to yeah so I'm", "start": 3871.079, "duration": 8.04}, {"text": "gonna get rid of", "start": 3875.839, "duration": 3.28}, {"text": "this I think I do", "start": 3879.72, "duration": 4.119}, {"text": "that do you see just one window", "start": 3884.599, "duration": 7.041}, {"text": "now just my Jupiter lab yes okay", "start": 3887.52, "duration": 6.759}, {"text": "fantastic thanks so that gives you a", "start": 3891.64, "duration": 5.84}, {"text": "little bit more room to kind of", "start": 3894.279, "duration": 7.721}, {"text": "um move things around a little bit", "start": 3897.48, "duration": 4.52}, {"text": "here all right um so hopefully", "start": 3904.44, "duration": 4.359}, {"text": "everybody's there and we're gonna kind", "start": 3907.559, "duration": 4.361}, {"text": "of go through this together I think it's", "start": 3908.799, "duration": 5.921}, {"text": "probably um better to do it", "start": 3911.92, "duration": 6.48}, {"text": "together okay", "start": 3914.72, "duration": 3.68}, {"text": "um Zoom Windows keep", "start": 3922.839, "duration": 3.881}, {"text": "moving all", "start": 3928.2, "duration": 3.2}, {"text": "right okay hopefully everybody's got", "start": 3931.72, "duration": 7.48}, {"text": "this", "start": 3936.2, "duration": 3.0}, {"text": "up all right", "start": 3939.96, "duration": 4.2}, {"text": "um where are we here okay so um so again", "start": 3945.4, "duration": 7.52}, {"text": "this is going to be uh we're going to be", "start": 3950.599, "duration": 3.52}, {"text": "doing transfer learning we're going to", "start": 3952.92, "duration": 3.76}, {"text": "use a pre-trained model which is the", "start": 3954.119, "duration": 3.761}, {"text": "mobet", "start": 3956.68, "duration": 4.04}, {"text": "V2 uh and this is using it as a feature", "start": 3957.88, "duration": 4.399}, {"text": "extractor so we're going to freeze the", "start": 3960.72, "duration": 4.079}, {"text": "weights in the pre-trained model add our", "start": 3962.279, "duration": 4.76}, {"text": "Top Model and then train it on the cats", "start": 3964.799, "duration": 6.201}, {"text": "and dogs data okay so we can just go", "start": 3967.039, "duration": 5.601}, {"text": "through here so this is just importing a", "start": 3971.0, "duration": 3.359}, {"text": "bunch of", "start": 3972.64, "duration": 4.36}, {"text": "libraries this is looking at what", "start": 3974.359, "duration": 4.48}, {"text": "version of tensor flow we're using and", "start": 3977.0, "duration": 5.64}, {"text": "also python version we're using this is", "start": 3978.839, "duration": 6.801}, {"text": "looking at um you know what is the", "start": 3982.64, "duration": 5.0}, {"text": "device that we're using so we are using", "start": 3985.64, "duration": 5.0}, {"text": "a GPU and by default it's going to use a", "start": 3987.64, "duration": 4.04}, {"text": "first", "start": 3990.64, "duration": 4.439}, {"text": "GPU um and then this is the uh Nvidia", "start": 3991.68, "duration": 8.72}, {"text": "SMI command so um this will tell you", "start": 3995.079, "duration": 7.401}, {"text": "what is running on the", "start": 4000.4, "duration": 4.399}, {"text": "GPU um So currently nothing is running", "start": 4002.48, "duration": 4.28}, {"text": "on there right now um as it's running we", "start": 4004.799, "duration": 4.28}, {"text": "can also go to um the terminal window", "start": 4006.76, "duration": 4.44}, {"text": "and and issue this command to see how", "start": 4009.079, "duration": 5.601}, {"text": "much memory um is being used", "start": 4011.2, "duration": 6.52}, {"text": "okay um this is just to set the logging", "start": 4014.68, "duration": 6.359}, {"text": "level so that we don't get a bunch of uh", "start": 4017.72, "duration": 6.879}, {"text": "messages this is um setting some random", "start": 4021.039, "duration": 6.161}, {"text": "generator seeds so that um we can get", "start": 4024.599, "duration": 4.841}, {"text": "somewhat reproducible results um the", "start": 4027.2, "duration": 4.28}, {"text": "thing to note about GPU is that it's", "start": 4029.44, "duration": 3.76}, {"text": "really difficult to get exactly the same", "start": 4031.48, "duration": 3.44}, {"text": "results because of all the optimization", "start": 4033.2, "duration": 3.879}, {"text": "that happens within the GPU every time", "start": 4034.92, "duration": 5.359}, {"text": "it runs something but we're trying to um", "start": 4037.079, "duration": 4.881}, {"text": "you know set it so that we can reproduce", "start": 4040.279, "duration": 4.401}, {"text": "the results as much as possible", "start": 4041.96, "duration": 6.359}, {"text": "okay so here is where we are um setting", "start": 4044.68, "duration": 5.359}, {"text": "the image location and dimension so if", "start": 4048.319, "duration": 3.0}, {"text": "you're following", "start": 4050.039, "duration": 4.24}, {"text": "along um hopeful you", "start": 4051.319, "duration": 7.201}, {"text": "are uh this is", "start": 4054.279, "duration": 8.681}, {"text": "uh um where okay", "start": 4058.52, "duration": 7.16}, {"text": "so so we're sending some um we're", "start": 4062.96, "duration": 4.399}, {"text": "getting some Environ environmental", "start": 4065.68, "duration": 4.399}, {"text": "variables right so that we can get to um", "start": 4067.359, "duration": 5.041}, {"text": "where that uh the data is that we just", "start": 4070.079, "duration": 5.441}, {"text": "copied Okay so now we want to set the P", "start": 4072.4, "duration": 6.879}, {"text": "data path here so if you are following", "start": 4075.52, "duration": 8.599}, {"text": "along uh you can put in data path equals", "start": 4079.279, "duration": 7.04}, {"text": "um what did we say so it's scratch user", "start": 4084.119, "duration": 5.601}, {"text": "right so have to put in", "start": 4086.319, "duration": 5.8}, {"text": "scratch", "start": 4089.72, "duration": 4.48}, {"text": "slash so", "start": 4092.119, "duration": 6.761}, {"text": "user we have um set that up", "start": 4094.2, "duration": 11.639}, {"text": "here and then it is job underscore", "start": 4098.88, "duration": 6.959}, {"text": "uh and then slurm job ID we set it up", "start": 4106.88, "duration": 4.839}, {"text": "here and then it's going to be cats and", "start": 4114.92, "duration": 8.04}, {"text": "dogs right slash cats versus", "start": 4117.64, "duration": 8.84}, {"text": "Dos all right so hopefully that", "start": 4122.96, "duration": 6.239}, {"text": "works okay so this is", "start": 4126.48, "duration": 4.48}, {"text": "our", "start": 4129.199, "duration": 5.96}, {"text": "um location of our data so under there", "start": 4130.96, "duration": 6.92}, {"text": "so remember when we did this um when we", "start": 4135.159, "duration": 5.04}, {"text": "did an LS here we have three", "start": 4137.88, "duration": 4.319}, {"text": "subdirectories there's one for test", "start": 4140.199, "duration": 3.241}, {"text": "there's one for train and there's one", "start": 4142.199, "duration": 4.401}, {"text": "for validation right so we've set the", "start": 4143.44, "duration": 5.44}, {"text": "path to each one of", "start": 4146.6, "duration": 4.0}, {"text": "those", "start": 4148.88, "duration": 4.399}, {"text": "okay uh is this okay am I going too fast", "start": 4150.6, "duration": 6.079}, {"text": "or everything's", "start": 4153.279, "duration": 3.4}, {"text": "okay kind hard to", "start": 4157.199, "duration": 5.6}, {"text": "tell thumbs up if everybody if", "start": 4159.96, "duration": 5.759}, {"text": "everybody's okay", "start": 4162.799, "duration": 2.92}, {"text": "okay I think my the job uh the path", "start": 4173.12, "duration": 9.559}, {"text": "setup has some error like the your path", "start": 4177.04, "duration": 7.319}, {"text": "are you getting an", "start": 4182.679, "duration": 5.241}, {"text": "ear no I'm looking at your path is it", "start": 4184.359, "duration": 5.88}, {"text": "right the train path I", "start": 4187.92, "duration": 5.96}, {"text": "think the forward slash is missing and", "start": 4190.239, "duration": 7.521}, {"text": "then in my slide yeah yeah it is missing", "start": 4193.88, "duration": 6.52}, {"text": "sorry yes it is missing in in the slide", "start": 4197.76, "duration": 4.12}, {"text": "it is missing", "start": 4200.4, "duration": 4.08}, {"text": "so", "start": 4201.88, "duration": 4.839}, {"text": "uh yeah here it's missing there should", "start": 4204.48, "duration": 5.52}, {"text": "be a slash after", "start": 4206.719, "duration": 3.281}, {"text": "scratch", "start": 4219.32, "duration": 6.24}, {"text": "um Okay so", "start": 4221.6, "duration": 7.119}, {"text": "let's see where are we now so", "start": 4225.56, "duration": 5.24}, {"text": "um okay so now we're down here so we", "start": 4228.719, "duration": 3.641}, {"text": "need to set the image", "start": 4230.8, "duration": 5.32}, {"text": "Dimension um you want to set image width", "start": 4232.36, "duration": 6.52}, {"text": "and image height", "start": 4236.12, "duration": 6.44}, {"text": "so image width equals", "start": 4238.88, "duration": 7.88}, {"text": "224 and image height is", "start": 4242.56, "duration": 4.2}, {"text": "also", "start": 4247.4, "duration": 3.0}, {"text": "224", "start": 4250.679, "duration": 3.961}, {"text": "okay", "start": 4252.64, "duration": 4.599}, {"text": "just scroll up a little bit here all", "start": 4254.64, "duration": 4.76}, {"text": "right so here's where we are um looking", "start": 4257.239, "duration": 5.801}, {"text": "at the the uh preparing the data so we", "start": 4259.4, "duration": 7.0}, {"text": "want to set the batch size um the batch", "start": 4263.04, "duration": 6.76}, {"text": "size is how many images do we use at a", "start": 4266.4, "duration": 5.839}, {"text": "time to do that forward and backward", "start": 4269.8, "duration": 4.12}, {"text": "pass to train the", "start": 4272.239, "duration": 4.161}, {"text": "model so in our case let's use batch", "start": 4273.92, "duration": 4.0}, {"text": "size", "start": 4276.4, "duration": 4.2}, {"text": "um uh for 16 let me try to make this a", "start": 4277.92, "duration": 3.799}, {"text": "little", "start": 4280.6, "duration": 4.96}, {"text": "bit biger", "start": 4281.719, "duration": 3.841}, {"text": "is the font okay on the Jupiter lab or", "start": 4286.08, "duration": 3.96}, {"text": "do I need to make", "start": 4288.6, "duration": 4.44}, {"text": "it", "start": 4290.04, "duration": 3.0}, {"text": "bigger it looks fine to me okay thank", "start": 4295.84, "duration": 7.44}, {"text": "you let try to make", "start": 4299.56, "duration": 3.72}, {"text": "it um okay so set the batch size so this", "start": 4304.8, "duration": 5.16}, {"text": "is where the batch size com comes in", "start": 4307.88, "duration": 4.88}, {"text": "right so this is saying okay so we're", "start": 4309.96, "duration": 7.64}, {"text": "just uh setting the um we setting up the", "start": 4312.76, "duration": 5.72}, {"text": "image", "start": 4317.6, "duration": 3.2}, {"text": "generators and so what you notice here", "start": 4318.48, "duration": 6.239}, {"text": "is that in the for the train um data", "start": 4320.8, "duration": 5.76}, {"text": "generator we're going to", "start": 4324.719, "duration": 4.841}, {"text": "add data augmentation all right we're", "start": 4326.56, "duration": 8.639}, {"text": "going to do add Shear Zoom horizontal", "start": 4329.56, "duration": 8.28}, {"text": "flip um and then there's also this", "start": 4335.199, "duration": 5.681}, {"text": "pre-processing so this", "start": 4337.84, "duration": 6.12}, {"text": "pre-processing um is set to pre PR proc", "start": 4340.88, "duration": 6.04}, {"text": "the data the same way that it was", "start": 4343.96, "duration": 5.239}, {"text": "pre-processed for the mobile net", "start": 4346.92, "duration": 4.84}, {"text": "V2 okay so we need to do that same", "start": 4349.199, "duration": 5.881}, {"text": "processing for train validation and", "start": 4351.76, "duration": 7.24}, {"text": "test only for the train do we do the", "start": 4355.08, "duration": 6.0}, {"text": "data augmentation right because you", "start": 4359.0, "duration": 4.96}, {"text": "don't I mean the the that that is only", "start": 4361.08, "duration": 4.559}, {"text": "um relevant for", "start": 4363.96, "duration": 3.52}, {"text": "training um", "start": 4365.639, "duration": 5.201}, {"text": "usually so um and", "start": 4367.48, "duration": 5.96}, {"text": "then uh so that's setting up the data", "start": 4370.84, "duration": 5.879}, {"text": "generators and then this is setting up", "start": 4373.44, "duration": 6.4}, {"text": "um where to read the data right so we're", "start": 4376.719, "duration": 5.161}, {"text": "using a flow from directory that me that", "start": 4379.84, "duration": 4.92}, {"text": "means that it's going to read a batch uh", "start": 4381.88, "duration": 6.6}, {"text": "of images at a time so we're giving it", "start": 4384.76, "duration": 6.399}, {"text": "the training data directory which we set", "start": 4388.48, "duration": 5.08}, {"text": "up", "start": 4391.159, "duration": 4.241}, {"text": "here", "start": 4393.56, "duration": 5.599}, {"text": "okay and we are also setting the target", "start": 4395.4, "duration": 6.6}, {"text": "size which we set", "start": 4399.159, "duration": 6.281}, {"text": "here we are setting the batch size which", "start": 4402.0, "duration": 6.44}, {"text": "now we have to set here so where you see", "start": 4405.44, "duration": 5.56}, {"text": "your code here put in batch size and", "start": 4408.44, "duration": 5.64}, {"text": "batch size is going to be all", "start": 4411.0, "duration": 3.08}, {"text": "caps all", "start": 4414.96, "duration": 3.32}, {"text": "caps batch underscore size and we're", "start": 4418.52, "duration": 5.639}, {"text": "going to use a 16 batch of", "start": 4421.36, "duration": 5.64}, {"text": "16 um and class mode is binary because", "start": 4424.159, "duration": 4.601}, {"text": "we only have two categories right cats", "start": 4427.0, "duration": 7.4}, {"text": "and dogs um Shuffle is just are the", "start": 4428.76, "duration": 9.28}, {"text": "images shuffled um so you know you want", "start": 4434.4, "duration": 5.4}, {"text": "to shuffle them or do you do you just", "start": 4438.04, "duration": 3.76}, {"text": "want to use the same order that you read", "start": 4439.8, "duration": 3.72}, {"text": "them in so for training usually it's a", "start": 4441.8, "duration": 4.2}, {"text": "good idea to shuffle them um and then", "start": 4443.52, "duration": 5.24}, {"text": "we're also setting a random seed uh here", "start": 4446.0, "duration": 4.56}, {"text": "so that we can reproduce results as much", "start": 4448.76, "duration": 3.04}, {"text": "as", "start": 4450.56, "duration": 4.92}, {"text": "possible um okay", "start": 4451.8, "duration": 6.68}, {"text": "then", "start": 4455.48, "duration": 3.0}, {"text": "um all right so then we also have um a", "start": 4459.44, "duration": 8.36}, {"text": "validation generator which is", "start": 4463.719, "duration": 7.241}, {"text": "similar um the only difference is again", "start": 4467.8, "duration": 5.879}, {"text": "there's no uh data augmentation right", "start": 4470.96, "duration": 4.92}, {"text": "for the validation", "start": 4473.679, "duration": 5.96}, {"text": "generator okay so now we also need to", "start": 4475.88, "duration": 7.4}, {"text": "set up the um test data generator so", "start": 4479.639, "duration": 5.0}, {"text": "it's going to be very similar to the", "start": 4483.28, "duration": 4.04}, {"text": "validation generator so you can kind of", "start": 4484.639, "duration": 4.641}, {"text": "copy and paste that and then make the", "start": 4487.32, "duration": 3.68}, {"text": "necessary", "start": 4489.28, "duration": 6.24}, {"text": "changes Okay so now we want to call this", "start": 4491.0, "duration": 6.96}, {"text": "test", "start": 4495.52, "duration": 2.44}, {"text": "generator and we are going to use the", "start": 4498.6, "duration": 5.84}, {"text": "test data", "start": 4501.719, "duration": 2.721}, {"text": "gen um we are reading from the test data", "start": 4504.8, "duration": 6.12}, {"text": "directory Target size is the", "start": 4511.239, "duration": 5.601}, {"text": "same batch size is the", "start": 4514.159, "duration": 6.161}, {"text": "same class mode is the same we're also", "start": 4516.84, "duration": 7.76}, {"text": "doing Shuffle is false and um we", "start": 4520.32, "duration": 7.28}, {"text": "actually don't really need this seed but", "start": 4524.6, "duration": 6.0}, {"text": "um we can just leave it there", "start": 4527.6, "duration": 6.44}, {"text": "okay all right", "start": 4530.6, "duration": 7.76}, {"text": "so if we run this we should get um if", "start": 4534.04, "duration": 5.72}, {"text": "everything's set up correctly we should", "start": 4538.36, "duration": 5.44}, {"text": "get the number of images in each class", "start": 4539.76, "duration": 7.16}, {"text": "and there's something", "start": 4543.8, "duration": 3.12}, {"text": "wrong did I spell something now", "start": 4550.76, "duration": 4.439}, {"text": "oh I see uh oh okay I spelled this", "start": 4557.239, "duration": 5.721}, {"text": "wrong", "start": 4570.28, "duration": 3.0}, {"text": "job I'm missing a", "start": 4573.32, "duration": 3.72}, {"text": "slash okay so if you've set up", "start": 4581.4, "duration": 5.44}, {"text": "everything correctly you should get this", "start": 4584.44, "duration": 4.799}, {"text": "two found 2,000 images belonging to two", "start": 4586.84, "duration": 5.6}, {"text": "classes found 400 images belonging to", "start": 4589.239, "duration": 5.96}, {"text": "two classes this is validation and then", "start": 4592.44, "duration": 4.44}, {"text": "uh this is", "start": 4595.199, "duration": 4.681}, {"text": "test", "start": 4596.88, "duration": 3.0}, {"text": "okay okay all right", "start": 4601.199, "duration": 8.281}, {"text": "um load pre-change model", "start": 4604.719, "duration": 4.761}, {"text": "so so here we are loading the the the", "start": 4610.36, "duration": 6.4}, {"text": "base model right so we are using we're", "start": 4614.84, "duration": 5.68}, {"text": "loading the mobile net V2 uh the weights", "start": 4616.76, "duration": 6.36}, {"text": "that were um trained on the image net", "start": 4620.52, "duration": 5.48}, {"text": "data include top is false because we", "start": 4623.12, "duration": 4.24}, {"text": "don't want that", "start": 4626.0, "duration": 4.48}, {"text": "classification um layer because aish net", "start": 4627.36, "duration": 5.08}, {"text": "has a thousand categories we're just", "start": 4630.48, "duration": 3.56}, {"text": "going to we're going to add our own Top", "start": 4632.44, "duration": 3.719}, {"text": "Model for our cats and dogs", "start": 4634.04, "duration": 4.48}, {"text": "data this is freezing the weights of the", "start": 4636.159, "duration": 5.04}, {"text": "pre-trained model right so trainable is", "start": 4638.52, "duration": 5.56}, {"text": "false this we also need to set because", "start": 4641.199, "duration": 4.801}, {"text": "of the batch normalization layer and it", "start": 4644.08, "duration": 3.559}, {"text": "gets a little bit complicated but it's", "start": 4646.0, "duration": 2.88}, {"text": "just the way that the batch", "start": 4647.639, "duration": 5.921}, {"text": "normalization layer um behaves during", "start": 4648.88, "duration": 6.279}, {"text": "inference mode and you can read more", "start": 4653.56, "duration": 3.4}, {"text": "about that", "start": 4655.159, "duration": 5.321}, {"text": "here okay so now we want to look at the", "start": 4656.96, "duration": 10.36}, {"text": "architecture so we can do base model.", "start": 4660.48, "duration": 6.84}, {"text": "summary Okay so this is the model it's a", "start": 4671.0, "duration": 6.6}, {"text": "a pretty complicated model lots and lots", "start": 4675.28, "duration": 3.04}, {"text": "of", "start": 4677.6, "duration": 4.039}, {"text": "layers um but you can see you know it", "start": 4678.32, "duration": 5.879}, {"text": "has different blocks and within each", "start": 4681.639, "duration": 4.481}, {"text": "block there are different", "start": 4684.199, "duration": 5.401}, {"text": "layers okay so at the end here you're", "start": 4686.12, "duration": 5.2}, {"text": "going to see the total number of", "start": 4689.6, "duration": 4.24}, {"text": "parameters the total number of trainable", "start": 4691.32, "duration": 5.08}, {"text": "parameters so we're not training any of", "start": 4693.84, "duration": 5.399}, {"text": "the models in the base in the base model", "start": 4696.4, "duration": 4.64}, {"text": "so we're not adjusting any of those so", "start": 4699.239, "duration": 5.44}, {"text": "those are all Frozen right right okay so", "start": 4701.04, "duration": 5.52}, {"text": "now here is where we create our Top", "start": 4704.679, "duration": 4.401}, {"text": "Model so we're going to put this on top", "start": 4706.56, "duration": 5.32}, {"text": "of the pre-trained model and this is", "start": 4709.08, "duration": 4.8}, {"text": "going to be customized for our dogs and", "start": 4711.88, "duration": 3.48}, {"text": "cats", "start": 4713.88, "duration": 6.4}, {"text": "data um so this is setting the input", "start": 4715.36, "duration": 8.359}, {"text": "layer right so we're adding that on top", "start": 4720.28, "duration": 7.959}, {"text": "of the base model we are adding a a", "start": 4723.719, "duration": 6.92}, {"text": "layer called a global average pooling so", "start": 4728.239, "duration": 5.761}, {"text": "it's kind of like pooling um except that", "start": 4730.639, "duration": 8.121}, {"text": "it's it's not it it it um operates on", "start": 4734.0, "duration": 7.199}, {"text": "the entire input instead of just a patch", "start": 4738.76, "duration": 6.64}, {"text": "at a time we're adding a Dropout layer", "start": 4741.199, "duration": 6.561}, {"text": "with the probability of dropping units", "start": 4745.4, "duration": 3.64}, {"text": "at", "start": 4747.76, "duration": 5.479}, {"text": "20% we're adding um a fully connected", "start": 4749.04, "duration": 7.36}, {"text": "layer um with the sigmoid", "start": 4753.239, "duration": 7.96}, {"text": "activation and that's going to be our um", "start": 4756.4, "duration": 7.2}, {"text": "model all right so now let's take a look", "start": 4761.199, "duration": 4.48}, {"text": "at what the model looks like now after", "start": 4763.6, "duration": 3.48}, {"text": "we have", "start": 4765.679, "duration": 3.721}, {"text": "um added our", "start": 4767.08, "duration": 5.72}, {"text": "model so here's the input layer here's", "start": 4769.4, "duration": 6.52}, {"text": "the pre-train model here's our average", "start": 4772.8, "duration": 6.439}, {"text": "pooling model uh layer here's Dropout", "start": 4775.92, "duration": 6.36}, {"text": "here's a fully connected layer so now we", "start": 4779.239, "duration": 5.721}, {"text": "have this many parameters and these are", "start": 4782.28, "duration": 4.8}, {"text": "the ones that are in the top", "start": 4784.96, "duration": 4.88}, {"text": "layer um so this from it comes from the", "start": 4787.08, "duration": 4.559}, {"text": "fully connected layer so these are the", "start": 4789.84, "duration": 4.96}, {"text": "only ones that we're adjusting during", "start": 4791.639, "duration": 8.281}, {"text": "training okay all right now let's train", "start": 4794.8, "duration": 8.56}, {"text": "the model so um this is compiling the", "start": 4799.92, "duration": 6.6}, {"text": "model so this is just um creating that", "start": 4803.36, "duration": 5.56}, {"text": "the the the graph computation graph um", "start": 4806.52, "duration": 3.84}, {"text": "the graph", "start": 4808.92, "duration": 5.799}, {"text": "computation um at the end or in in the", "start": 4810.36, "duration": 8.0}, {"text": "background um so we are using the atom", "start": 4814.719, "duration": 7.561}, {"text": "Optimizer with this learning rate and we", "start": 4818.36, "duration": 6.56}, {"text": "are us using uh the loss function that", "start": 4822.28, "duration": 5.04}, {"text": "we're using is binary cross", "start": 4824.92, "duration": 5.84}, {"text": "entropy um and the metric that we are", "start": 4827.32, "duration": 5.04}, {"text": "monitoring is", "start": 4830.76, "duration": 3.76}, {"text": "accuracy okay", "start": 4832.36, "duration": 5.879}, {"text": "so compile that so now let's", "start": 4834.52, "duration": 6.56}, {"text": "train uh let's train it", "start": 4838.239, "duration": 4.96}, {"text": "for um we need to set the number of", "start": 4841.08, "duration": 4.4}, {"text": "epochs so let's just train it for five", "start": 4843.199, "duration": 6.241}, {"text": "epochs here so here let's just train it", "start": 4845.48, "duration": 7.08}, {"text": "for up five Epoch and then we'll see the", "start": 4849.44, "duration": 4.0}, {"text": "um", "start": 4852.56, "duration": 4.56}, {"text": "loss and the accuracy will get output as", "start": 4853.44, "duration": 5.84}, {"text": "we", "start": 4857.12, "duration": 2.16}, {"text": "train okay", "start": 4860.44, "duration": 5.68}, {"text": "so this is the loss and the accuracy on", "start": 4863.36, "duration": 4.799}, {"text": "the training data and then at the end of", "start": 4866.12, "duration": 4.119}, {"text": "the epoch it's going to also output the", "start": 4868.159, "duration": 6.04}, {"text": "loss and accuracy for the validation", "start": 4870.239, "duration": 3.96}, {"text": "data okay so that's the end of the first", "start": 4875.719, "duration": 4.801}, {"text": "epox this is the loss accuracy on the", "start": 4877.96, "duration": 5.32}, {"text": "training data validation loss and", "start": 4880.52, "duration": 3.96}, {"text": "validation", "start": 4883.28, "duration": 4.48}, {"text": "accuracy and we're doing this for 5 e PS", "start": 4884.48, "duration": 5.759}, {"text": "so this is it's going pretty fast", "start": 4887.76, "duration": 4.2}, {"text": "because we're only training about a", "start": 4890.239, "duration": 5.121}, {"text": "thousand weights", "start": 4891.96, "duration": 3.4}, {"text": "here", "start": 4896.8, "duration": 5.399}, {"text": "okay I guess I need to kind of hurry", "start": 4899.639, "duration": 5.04}, {"text": "along", "start": 4902.199, "duration": 2.48}, {"text": "here is going to go so you can see that", "start": 4909.44, "duration": 6.48}, {"text": "the loss is is decreasing accuracy is", "start": 4911.719, "duration": 7.721}, {"text": "increasing um accuracy on the validation", "start": 4915.92, "duration": 6.319}, {"text": "data is also", "start": 4919.44, "duration": 2.799}, {"text": "increasing okay so this is the end of", "start": 4923.8, "duration": 5.12}, {"text": "the fourth Epoch we're going to go for", "start": 4926.36, "duration": 4.92}, {"text": "another Epoch here this will probably", "start": 4928.92, "duration": 5.56}, {"text": "take about a couple minutes to train so", "start": 4931.28, "duration": 6.6}, {"text": "maybe another H", "start": 4934.48, "duration": 7.08}, {"text": "it's um finishing up", "start": 4937.88, "duration": 6.68}, {"text": "here", "start": 4941.56, "duration": 3.0}, {"text": "okay so that took about a minute and a", "start": 4949.44, "duration": 7.0}, {"text": "half um accuracy went up which is good", "start": 4952.88, "duration": 5.72}, {"text": "which is what we want okay so now we", "start": 4956.44, "duration": 4.719}, {"text": "want to save the weights and you can do", "start": 4958.6, "duration": 7.119}, {"text": "that using model. saave so model Dove", "start": 4961.159, "duration": 6.201}, {"text": "and then you can give it a name so I", "start": 4965.719, "duration": 3.92}, {"text": "like to keep my models in a separate", "start": 4967.36, "duration": 3.92}, {"text": "directory from my code so I'm going to", "start": 4969.639, "duration": 3.921}, {"text": "put it in a separate directory and then", "start": 4971.28, "duration": 5.04}, {"text": "I'll call this model features", "start": 4973.56, "duration": 4.28}, {"text": "model", "start": 4976.32, "duration": 6.2}, {"text": "okay and it's going to save the models", "start": 4977.84, "duration": 7.76}, {"text": "there and then I'm going", "start": 4982.52, "duration": 7.44}, {"text": "to um plot the L", "start": 4985.6, "duration": 4.36}, {"text": "curves um this warning error is because", "start": 4990.44, "duration": 6.88}, {"text": "uh", "start": 4994.639, "duration": 6.52}, {"text": "config yeah I'm actually not certain oh", "start": 4997.32, "duration": 6.44}, {"text": "I think it's because it has to do with", "start": 5001.159, "duration": 3.52}, {"text": "the", "start": 5003.76, "duration": 4.08}, {"text": "um actually the mobile net V2 there's", "start": 5004.679, "duration": 6.721}, {"text": "some uh configuration that I think is is", "start": 5007.84, "duration": 6.68}, {"text": "uh kind of old um so I think this is", "start": 5011.4, "duration": 5.2}, {"text": "what this warning is okay so now we're", "start": 5014.52, "duration": 6.24}, {"text": "plotting the U validation and", "start": 5016.6, "duration": 7.84}, {"text": "um train of validation so this is loss", "start": 5020.76, "duration": 5.919}, {"text": "and this is", "start": 5024.44, "duration": 4.92}, {"text": "um accuracy so you can see that the", "start": 5026.679, "duration": 7.601}, {"text": "accuracy is is going up here um okay so", "start": 5029.36, "duration": 8.08}, {"text": "then let's do evaluation and inference", "start": 5034.28, "duration": 7.2}, {"text": "so this is getting the train um data", "start": 5037.44, "duration": 6.6}, {"text": "accuracy you can do that using model", "start": 5041.48, "duration": 5.759}, {"text": "evaluate so this is getting the train", "start": 5044.04, "duration": 6.159}, {"text": "data accuracy now we can U we also want", "start": 5047.239, "duration": 4.041}, {"text": "to get the", "start": 5050.199, "duration": 4.601}, {"text": "test accuracy here so you want to copy", "start": 5051.28, "duration": 5.64}, {"text": "and paste that and just tra um ta U", "start": 5054.8, "duration": 3.839}, {"text": "change everything to", "start": 5056.92, "duration": 7.44}, {"text": "test um train generator", "start": 5058.639, "duration": 5.721}, {"text": "P data", "start": 5065.04, "duration": 3.639}, {"text": "accuracy all right let's see what we're", "start": 5066.76, "duration": 4.56}, {"text": "getting here right so now it's passing", "start": 5068.679, "duration": 4.0}, {"text": "all of the trained data through the", "start": 5071.32, "duration": 4.08}, {"text": "trained model and similarly with the", "start": 5072.679, "duration": 4.401}, {"text": "test", "start": 5075.4, "duration": 4.16}, {"text": "data", "start": 5077.08, "duration": 6.32}, {"text": "and see what we get in", "start": 5079.56, "duration": 3.84}, {"text": "here train a accuracy is 9 9", "start": 5084.88, "duration": 8.44}, {"text": "967 and test accuracy is", "start": 5090.0, "duration": 5.88}, {"text": "977 so we're actually doing better on", "start": 5093.32, "duration": 4.52}, {"text": "the test data than we are doing on the", "start": 5095.88, "duration": 5.08}, {"text": "train data um which does happen", "start": 5097.84, "duration": 4.92}, {"text": "sometimes usually it's the other way", "start": 5100.96, "duration": 4.6}, {"text": "around but it does happen and so with", "start": 5102.76, "duration": 6.76}, {"text": "this part here um what the model outputs", "start": 5105.56, "duration": 7.559}, {"text": "is um a probability so in order", "start": 5109.52, "duration": 6.24}, {"text": "to uh you know compute things like", "start": 5113.119, "duration": 4.08}, {"text": "precision and accuracy and things like", "start": 5115.76, "duration": 4.04}, {"text": "that we need to threshold the bottle", "start": 5117.199, "duration": 5.321}, {"text": "predictions um to make it into a binary", "start": 5119.8, "duration": 4.839}, {"text": "quantity to compare it to the labels and", "start": 5122.52, "duration": 4.76}, {"text": "this is what is happening here and then", "start": 5124.639, "duration": 5.761}, {"text": "we can um use the classification report", "start": 5127.28, "duration": 6.76}, {"text": "which is a psych learn method um to get", "start": 5130.4, "duration": 6.64}, {"text": "our results so what we're getting here", "start": 5134.04, "duration": 6.56}, {"text": "is this is on the test data right say on", "start": 5137.04, "duration": 5.52}, {"text": "the test data so we're getting an", "start": 5140.6, "duration": 3.8}, {"text": "accuracy of", "start": 5142.56, "duration": 3.84}, {"text": "9775", "start": 5144.4, "duration": 5.16}, {"text": "okay um what", "start": 5146.4, "duration": 5.6}, {"text": "does uh oh you're talking about this", "start": 5149.56, "duration": 3.24}, {"text": "here", "start": 5152.0, "duration": 6.04}, {"text": "so this is um this returns both loss and", "start": 5152.8, "duration": 7.919}, {"text": "um accuracy and we're since we're only", "start": 5158.04, "duration": 4.079}, {"text": "concerned about the accuracy we don't", "start": 5160.719, "duration": 4.801}, {"text": "need to save the the loss so this is", "start": 5162.119, "duration": 4.961}, {"text": "just you know kind of a throwaway", "start": 5165.52, "duration": 3.36}, {"text": "variable because we don't we're not", "start": 5167.08, "duration": 4.0}, {"text": "storing", "start": 5168.88, "duration": 6.6}, {"text": "it you know in a in a separate", "start": 5171.08, "duration": 4.4}, {"text": "variable okay okay great okay so now", "start": 5176.28, "duration": 6.959}, {"text": "let's perform some um", "start": 5180.159, "duration": 6.52}, {"text": "inference on some test images so this is", "start": 5183.239, "duration": 7.361}, {"text": "a method that we're defining to load an", "start": 5186.679, "duration": 9.52}, {"text": "image um to do some scaling at the image", "start": 5190.6, "duration": 7.68}, {"text": "and um this is just some data", "start": 5196.199, "duration": 4.321}, {"text": "manipulation to make it um the", "start": 5198.28, "duration": 4.56}, {"text": "dimensions right so this is a method", "start": 5200.52, "duration": 5.92}, {"text": "we're going to look at this cat image so", "start": 5202.84, "duration": 8.48}, {"text": "the model outputs a probability of 0.12", "start": 5206.44, "duration": 8.36}, {"text": "for this image so zero is cat and one is", "start": 5211.32, "duration": 6.0}, {"text": "dog right so the smaller the number the", "start": 5214.8, "duration": 5.08}, {"text": "more certain the model is it's a cat the", "start": 5217.32, "duration": 4.839}, {"text": "larger in the number um the more certain", "start": 5219.88, "duration": 4.359}, {"text": "that it is a dog right so in this image", "start": 5222.159, "duration": 4.361}, {"text": "it's it's relatively it's pretty certain", "start": 5224.239, "duration": 5.4}, {"text": "that it is a cat right so let's look at", "start": 5226.52, "duration": 6.32}, {"text": "a dog image so in this one um the", "start": 5229.639, "duration": 4.281}, {"text": "probability is", "start": 5232.84, "duration": 3.399}, {"text": "0.95 so it's pretty certain that this is", "start": 5233.92, "duration": 6.48}, {"text": "a dog all right so let's look at other", "start": 5236.239, "duration": 7.0}, {"text": "um test images so I think we can just", "start": 5240.4, "duration": 6.48}, {"text": "copy and paste so this is loading yeah", "start": 5243.239, "duration": 6.121}, {"text": "so this is", "start": 5246.88, "duration": 2.48}, {"text": "loading um let's see what this image is", "start": 5250.679, "duration": 4.761}, {"text": "so this is a cat and this one is", "start": 5252.84, "duration": 4.44}, {"text": "actually misclassified right because the", "start": 5255.44, "duration": 4.52}, {"text": "threshold is 0.5 so it thinks that this", "start": 5257.28, "duration": 7.56}, {"text": "is a dog um so this is has a probability", "start": 5259.96, "duration": 8.159}, {"text": "of of about 0.6 so this actually thinks", "start": 5264.84, "duration": 9.879}, {"text": "it's a dog um and then let's do this one", "start": 5268.119, "duration": 6.6}, {"text": "here all right this is a dog oh and this", "start": 5278.04, "duration": 4.84}, {"text": "one is actually misclassified right this", "start": 5281.28, "duration": 2.76}, {"text": "is a", "start": 5282.88, "duration": 4.56}, {"text": "dog um but it's misclassified but note", "start": 5284.04, "duration": 5.4}, {"text": "that these two that is misclassified is", "start": 5287.44, "duration": 3.56}, {"text": "kind of borderline right it's very close", "start": 5289.44, "duration": 2.64}, {"text": "to", "start": 5291.0, "duration": 3.719}, {"text": "0.5 and this I guess kind of looks like", "start": 5292.08, "duration": 6.52}, {"text": "a c because you know of the um kind of", "start": 5294.719, "duration": 7.361}, {"text": "the face is uh really kind of uh what", "start": 5298.6, "duration": 6.88}, {"text": "look more like a cat um okay and then", "start": 5302.08, "duration": 5.87}, {"text": "perform inference on here", "start": 5305.48, "duration": 4.36}, {"text": "[Music]", "start": 5307.95, "duration": 6.13}, {"text": "so let's do this one let's see what this", "start": 5309.84, "duration": 5.879}, {"text": "one does and then we have to change this", "start": 5314.08, "duration": 3.599}, {"text": "to", "start": 5315.719, "duration": 7.361}, {"text": "1311 and this is a dog um but it Al it", "start": 5317.679, "duration": 7.361}, {"text": "also is not very certain about this this", "start": 5323.08, "duration": 4.2}, {"text": "is a dog it does correctly classify it", "start": 5325.04, "duration": 4.679}, {"text": "but it's very close to 0.5 as well and", "start": 5327.28, "duration": 3.64}, {"text": "as you can see you know it's kind of", "start": 5329.719, "duration": 3.281}, {"text": "blurry right the dog is is behind the", "start": 5330.92, "duration": 4.239}, {"text": "fence um and so it's a little bit", "start": 5333.0, "duration": 4.639}, {"text": "difficult to see okay so anyway so this", "start": 5335.159, "duration": 3.921}, {"text": "is for feature", "start": 5337.639, "duration": 5.281}, {"text": "extraction so", "start": 5339.08, "duration": 3.84}, {"text": "um let's try to look at fine tuning as", "start": 5342.96, "duration": 4.8}, {"text": "well given the amount of time that we", "start": 5345.96, "duration": 5.32}, {"text": "have left so it's important to restart", "start": 5347.76, "duration": 8.68}, {"text": "the kernel here um before and that will", "start": 5351.28, "duration": 8.32}, {"text": "um kind of free up uh it kind of cleans", "start": 5356.44, "duration": 6.16}, {"text": "the the GPU cache and you know kind of", "start": 5359.6, "duration": 5.119}, {"text": "purges everything on the on the GPU", "start": 5362.6, "duration": 4.72}, {"text": "memory um if you don't do that and you", "start": 5364.719, "duration": 5.041}, {"text": "try to run another notebook like the", "start": 5367.32, "duration": 4.12}, {"text": "fine T notebook you're going to get an", "start": 5369.76, "duration": 3.879}, {"text": "out of memory error or you could get an", "start": 5371.44, "duration": 4.719}, {"text": "out of memory error so let's look at the", "start": 5373.639, "duration": 7.641}, {"text": "fine-tuning um so given the um amount of", "start": 5376.159, "duration": 7.04}, {"text": "time I think I'm", "start": 5381.28, "duration": 5.24}, {"text": "gonna I'm going to look at the solution", "start": 5383.199, "duration": 6.761}, {"text": "and just kind of walk you through", "start": 5386.52, "duration": 3.44}, {"text": "that all right so for fine-tuning what", "start": 5390.32, "duration": 4.799}, {"text": "we're doing here so we're going to just", "start": 5393.96, "duration": 4.32}, {"text": "run through the setup", "start": 5395.119, "duration": 3.161}, {"text": "part I'm", "start": 5401.719, "duration": 3.081}, {"text": "GNA clear all outputs", "start": 5406.08, "duration": 6.52}, {"text": "first all", "start": 5409.4, "duration": 3.2}, {"text": "right all right so all this is kind of", "start": 5412.96, "duration": 3.679}, {"text": "the setup that is the same as the", "start": 5415.08, "duration": 4.599}, {"text": "feature extraction um setting the image", "start": 5416.639, "duration": 5.401}, {"text": "locations everything is the same", "start": 5419.679, "duration": 4.04}, {"text": "preparing data is the", "start": 5422.04, "duration": 4.4}, {"text": "same um so here's where it's different", "start": 5423.719, "duration": 5.0}, {"text": "so now we are loading the model that we", "start": 5426.44, "duration": 4.279}, {"text": "trained from feature extraction right so", "start": 5428.719, "duration": 4.321}, {"text": "remember that we saved it here so we're", "start": 5430.719, "duration": 4.081}, {"text": "going to load that", "start": 5433.04, "duration": 4.96}, {"text": "model um this is if you're running this", "start": 5434.8, "duration": 5.12}, {"text": "notebook on your own time you can", "start": 5438.0, "duration": 5.44}, {"text": "uncomment this to see all the layers um", "start": 5439.92, "duration": 5.48}, {"text": "so it it's it prints out a lot of", "start": 5443.44, "duration": 3.44}, {"text": "information because this is a pretty", "start": 5445.4, "duration": 4.0}, {"text": "complicated model um but if you're", "start": 5446.88, "duration": 4.56}, {"text": "interested in that you can do that okay", "start": 5449.4, "duration": 5.08}, {"text": "so here here's where we are freezing", "start": 5451.44, "duration": 6.32}, {"text": "some of the weights but leaving the ones", "start": 5454.48, "duration": 6.639}, {"text": "in the higher layers um unfrozen so that", "start": 5457.76, "duration": 8.959}, {"text": "we can uh train those right so now um we", "start": 5461.119, "duration": 8.56}, {"text": "have a lot more parameters to train so", "start": 5466.719, "duration": 6.4}, {"text": "before with feature extraction we had", "start": 5469.679, "duration": 6.121}, {"text": "let's see what was it at the end", "start": 5473.119, "duration": 5.281}, {"text": "here before we were training just the", "start": 5475.8, "duration": 6.359}, {"text": "Top Model feature uh model um sorry the", "start": 5478.4, "duration": 7.279}, {"text": "Top Model weight so we only had about a", "start": 5482.159, "duration": 6.641}, {"text": "thousand um parameters to train here we", "start": 5485.679, "duration": 5.96}, {"text": "are also fin tuning some of the weights", "start": 5488.8, "duration": 4.76}, {"text": "in the pre-train model so we now we have", "start": 5491.639, "duration": 7.04}, {"text": "a million and a half um uh parameters to", "start": 5493.56, "duration": 7.88}, {"text": "train right okay so now we're going to", "start": 5498.679, "duration": 4.641}, {"text": "fine tune and this is going to take", "start": 5501.44, "duration": 3.199}, {"text": "longer", "start": 5503.32, "duration": 5.08}, {"text": "because um we are tuning a lot more", "start": 5504.639, "duration": 8.201}, {"text": "parameter right um and also we are doing", "start": 5508.4, "duration": 5.759}, {"text": "early stopping", "start": 5512.84, "duration": 4.359}, {"text": "here right so we are monitoring the loss", "start": 5514.159, "duration": 6.841}, {"text": "on the validation data set um and we are", "start": 5517.199, "duration": 6.361}, {"text": "setting uh these are parameters for", "start": 5521.0, "duration": 4.88}, {"text": "early stopping so patients of three and", "start": 5523.56, "duration": 5.72}, {"text": "minimum Delta of 0.01 meaning that if", "start": 5525.88, "duration": 5.72}, {"text": "the validation loss has not changed by", "start": 5529.28, "duration": 5.32}, {"text": "this much for three epochs then stop", "start": 5531.6, "duration": 8.0}, {"text": "training okay so we are training this", "start": 5534.6, "duration": 7.96}, {"text": "we're giving it 20 epods but", "start": 5539.6, "duration": 5.28}, {"text": "um we're doing early stopping so it", "start": 5542.56, "duration": 4.079}, {"text": "could stop before", "start": 5544.88, "duration": 4.6}, {"text": "then all right uh so this is going to", "start": 5546.639, "duration": 7.0}, {"text": "take a little while to run", "start": 5549.48, "duration": 8.0}, {"text": "um let me see anything else I", "start": 5553.639, "duration": 8.241}, {"text": "can walk you through um so after that we", "start": 5557.48, "duration": 9.32}, {"text": "are going to load the best", "start": 5561.88, "duration": 4.92}, {"text": "weights um from early stopping we're", "start": 5566.92, "duration": 6.44}, {"text": "going to save the weights", "start": 5569.92, "duration": 7.319}, {"text": "and we're going to plot the loss and the", "start": 5573.36, "duration": 5.839}, {"text": "accuracy curves as", "start": 5577.239, "duration": 5.121}, {"text": "before and we're also going to do uh you", "start": 5579.199, "duration": 6.081}, {"text": "know evaluate on the train data the test", "start": 5582.36, "duration": 5.4}, {"text": "data um and also get the classification", "start": 5585.28, "duration": 4.8}, {"text": "report and then do inference on some", "start": 5587.76, "duration": 3.359}, {"text": "test", "start": 5590.08, "duration": 5.72}, {"text": "images Okay so let's see", "start": 5591.119, "duration": 4.681}, {"text": "um how this", "start": 5596.56, "duration": 4.0}, {"text": "is", "start": 5598.84, "duration": 4.72}, {"text": "doing", "start": 5600.56, "duration": 3.0}, {"text": "okay um any", "start": 5608.36, "duration": 4.68}, {"text": "questions that I can answer while we're", "start": 5610.92, "duration": 3.48}, {"text": "waiting for this I think this takes", "start": 5613.04, "duration": 3.88}, {"text": "about 10 OTS to run", "start": 5614.4, "duration": 5.52}, {"text": "through", "start": 5616.92, "duration": 3.0}, {"text": "um", "start": 5619.96, "duration": 6.8}, {"text": "so got a few minutes here um and if you", "start": 5621.48, "duration": 7.239}, {"text": "you can also test this on a CPU and you", "start": 5626.76, "duration": 3.8}, {"text": "can see that it's much much slower on a", "start": 5628.719, "duration": 4.841}, {"text": "CPU", "start": 5630.56, "duration": 3.0}, {"text": "so just for fun you can do that you know", "start": 5634.08, "duration": 6.2}, {"text": "later on your own", "start": 5637.36, "duration": 2.92}, {"text": "time okay so I think it's getting close", "start": 5642.08, "duration": 7.24}, {"text": "to the end here and you can see that", "start": 5645.48, "duration": 7.88}, {"text": "um see the loss the loss on the train", "start": 5649.32, "duration": 5.6}, {"text": "data is", "start": 5653.36, "duration": 4.48}, {"text": "decreasing but the loss on the", "start": 5654.92, "duration": 6.08}, {"text": "validation set so it decreases decreases", "start": 5657.84, "duration": 5.24}, {"text": "decreases okay it still decreases but", "start": 5661.0, "duration": 4.32}, {"text": "it's kind of leveling off here now so", "start": 5663.08, "duration": 4.36}, {"text": "it's kind of fluctuating at this point", "start": 5665.32, "duration": 3.48}, {"text": "now so I think it's going to stop pretty", "start": 5667.44, "duration": 3.52}, {"text": "soon", "start": 5668.8, "duration": 4.359}, {"text": "here because remember early stopping", "start": 5670.96, "duration": 6.36}, {"text": "we're monitoring the validation loss", "start": 5673.159, "duration": 9.401}, {"text": "right um okay where did 116 for fine tun", "start": 5677.32, "duration": 10.64}, {"text": "okay so 116 we are um we are", "start": 5682.56, "duration": 10.04}, {"text": "freezing all the weights up until layer", "start": 5687.96, "duration": 8.8}, {"text": "um I think there are 17 convolution um", "start": 5692.6, "duration": 8.4}, {"text": "blocks in the mobet V2 and we are", "start": 5696.76, "duration": 8.399}, {"text": "stopping at um convolution of 14 so", "start": 5701.0, "duration": 5.92}, {"text": "that's kind of you know where the top", "start": 5705.159, "duration": 4.0}, {"text": "layers", "start": 5706.92, "duration": 4.92}, {"text": "start so that's another hyperparameter", "start": 5709.159, "duration": 4.761}, {"text": "right so there not a a hard and fast", "start": 5711.84, "duration": 5.319}, {"text": "rule to say when you should stop when", "start": 5713.92, "duration": 6.6}, {"text": "you should start um fine-tuning okay so", "start": 5717.159, "duration": 5.161}, {"text": "it stopped", "start": 5720.52, "duration": 4.639}, {"text": "uh training right that took about three", "start": 5722.32, "duration": 4.6}, {"text": "minutes so let's run the rest of this", "start": 5725.159, "duration": 6.08}, {"text": "and see what happens here so this", "start": 5726.92, "duration": 7.44}, {"text": "is loading the model or loading the", "start": 5731.239, "duration": 5.161}, {"text": "weights from the uh loading the weights", "start": 5734.36, "duration": 4.24}, {"text": "at the best model from early stopping", "start": 5736.4, "duration": 4.04}, {"text": "saving the", "start": 5738.6, "duration": 4.68}, {"text": "weights and then we are going to plot", "start": 5740.44, "duration": 6.44}, {"text": "the L curves L and accuracy", "start": 5743.28, "duration": 3.6}, {"text": "curves", "start": 5748.4, "duration": 5.0}, {"text": "and", "start": 5750.4, "duration": 3.0}, {"text": "accuracy curve so we can see that um", "start": 5755.44, "duration": 7.08}, {"text": "let's see the loss goes down and then it", "start": 5759.88, "duration": 4.64}, {"text": "kind of flattens out and kind of", "start": 5762.52, "duration": 3.719}, {"text": "fluctuates around here and so that's", "start": 5764.52, "duration": 5.4}, {"text": "when early stopping uh kicks in because", "start": 5766.239, "duration": 5.92}, {"text": "we actually set it for 20 epochs but it", "start": 5769.92, "duration": 6.56}, {"text": "only trained up until Epoch 8 here the 9", "start": 5772.159, "duration": 5.841}, {"text": "part because it starts at", "start": 5776.48, "duration": 6.159}, {"text": "zero okay um so this is the uh train and", "start": 5778.0, "duration": 8.32}, {"text": "validation accuracy and classification", "start": 5782.639, "duration": 7.52}, {"text": "report so let's see how we do after", "start": 5786.32, "duration": 7.2}, {"text": "training so feature extraction we did", "start": 5790.159, "duration": 7.161}, {"text": "what did we do so we got uh on the test", "start": 5793.52, "duration": 6.48}, {"text": "data we got", "start": 5797.32, "duration": 2.68}, {"text": "9775 and here we are actually doing a", "start": 5800.639, "duration": 6.201}, {"text": "little bit worse so", "start": 5804.6, "duration": 5.72}, {"text": "9875 um so in this case fine tuning did", "start": 5806.84, "duration": 6.799}, {"text": "not help um but this is a very small", "start": 5810.32, "duration": 5.96}, {"text": "data set um if we use a larger data set", "start": 5813.639, "duration": 4.321}, {"text": "we could get um slightly different", "start": 5816.28, "duration": 4.56}, {"text": "results okay so now let's do performance", "start": 5817.96, "duration": 6.719}, {"text": "on U test data on individual test data", "start": 5820.84, "duration": 7.0}, {"text": "so this is um the cat image that we saw", "start": 5824.679, "duration": 5.801}, {"text": "before so the model now is very very", "start": 5827.84, "duration": 4.64}, {"text": "confident that this is a cat right so", "start": 5830.48, "duration": 4.84}, {"text": "compared to so this is", "start": 5832.48, "duration": 7.28}, {"text": "0.025 compared to", "start": 5835.32, "duration": 10.16}, {"text": "0.122 um this dog was 9 or 0.958 so", "start": 5839.76, "duration": 8.08}, {"text": "let's see how it does", "start": 5845.48, "duration": 5.199}, {"text": "here so this also did better right so", "start": 5847.84, "duration": 5.12}, {"text": "the it's very confident this is a cat", "start": 5850.679, "duration": 4.321}, {"text": "very confident this is a dog all right", "start": 5852.96, "duration": 3.279}, {"text": "let me just kind of go through these", "start": 5855.0, "duration": 3.4}, {"text": "quickly because we out of time", "start": 5856.239, "duration": 5.92}, {"text": "here um so I thought some of these are", "start": 5858.4, "duration": 7.239}, {"text": "really interesting so this one um", "start": 5862.159, "duration": 6.721}, {"text": "actually got worse right because now it", "start": 5865.639, "duration": 5.56}, {"text": "misclassifies this one uh it corre", "start": 5868.88, "duration": 4.64}, {"text": "directly classifies this one it still", "start": 5871.199, "duration": 5.0}, {"text": "misclassifies this one this one I", "start": 5873.52, "duration": 3.76}, {"text": "thought was really interesting because", "start": 5876.199, "duration": 3.4}, {"text": "it's upside down and you know maybe the", "start": 5877.28, "duration": 5.08}, {"text": "data augmentation um helped here this", "start": 5879.599, "duration": 4.321}, {"text": "one I thought was really difficult even", "start": 5882.36, "duration": 3.72}, {"text": "for me to figure out right but it did a", "start": 5883.92, "duration": 4.88}, {"text": "pretty good job um this one it's able to", "start": 5886.08, "duration": 4.159}, {"text": "do a really good job even though you", "start": 5888.8, "duration": 5.2}, {"text": "don't see the the face at all um this", "start": 5890.239, "duration": 7.681}, {"text": "one um is kind of iffy so it thinks that", "start": 5894.0, "duration": 7.92}, {"text": "it is a dog um", "start": 5897.92, "duration": 6.6}, {"text": "and I think this is a dog to me that", "start": 5901.92, "duration": 5.36}, {"text": "looks like a dog so that might be okay", "start": 5904.52, "duration": 4.32}, {"text": "there and then this one is really", "start": 5907.28, "duration": 3.08}, {"text": "interesting as well because this is a", "start": 5908.84, "duration": 3.96}, {"text": "picture this is a drawing of a dog and", "start": 5910.36, "duration": 5.319}, {"text": "it does a really good job of classifying", "start": 5912.8, "duration": 6.64}, {"text": "that okay so I think we are at the end", "start": 5915.679, "duration": 6.0}, {"text": "here I'm going to stop sharing and see", "start": 5919.44, "duration": 4.08}, {"text": "if there are any questions in the last", "start": 5921.679, "duration": 4.601}, {"text": "couple minutes", "start": 5923.52, "duration": 2.76}, {"text": "here and all of this um these notebooks", "start": 5926.36, "duration": 5.839}, {"text": "are in the repo so um you can download", "start": 5929.36, "duration": 6.239}, {"text": "them and look at them more closely um", "start": 5932.199, "duration": 5.801}, {"text": "later if you'd", "start": 5935.599, "duration": 5.961}, {"text": "like okay any", "start": 5938.0, "duration": 5.48}, {"text": "questions all right well if you don't", "start": 5941.56, "duration": 4.119}, {"text": "have any questions so thanks for um", "start": 5943.48, "duration": 3.96}, {"text": "attending this session and I hope you", "start": 5945.679, "duration": 4.361}, {"text": "found it to be", "start": 5947.44, "duration": 2.6}, {"text": "useful okay so for this last session um", "start": 5951.8, "duration": 7.56}, {"text": "I wanted to to get to something to try", "start": 5956.52, "duration": 5.719}, {"text": "to build some intuition about", "start": 5959.36, "duration": 5.2}, {"text": "that about what happens with more", "start": 5962.239, "duration": 3.681}, {"text": "complicated", "start": 5964.56, "duration": 3.44}, {"text": "models so I'm to look at this idea of", "start": 5965.92, "duration": 5.719}, {"text": "skip connections and the Caris uh model", "start": 5968.0, "duration": 6.119}, {"text": "API", "start": 5971.639, "duration": 2.48}, {"text": "functions my so here's my outline I'm", "start": 5974.44, "duration": 4.08}, {"text": "going to I'm going to talk a little bit", "start": 5976.52, "duration": 3.159}, {"text": "about gate connection the gate", "start": 5978.52, "duration": 3.24}, {"text": "connection idea and Skip in residual", "start": 5979.679, "duration": 3.841}, {"text": "connections and then we'll look at the", "start": 5981.76, "duration": 3.32}, {"text": "car's model API which is different than", "start": 5983.52, "duration": 2.199}, {"text": "the", "start": 5985.08, "duration": 2.599}, {"text": "sequential function that we were using", "start": 5985.719, "duration": 4.0}, {"text": "before so for more complicated", "start": 5987.679, "duration": 4.681}, {"text": "models uh there's a there's another way", "start": 5989.719, "duration": 4.48}, {"text": "to program it and that's what we'll do", "start": 5992.36, "duration": 3.879}, {"text": "in the exercise and we'll look at an", "start": 5994.199, "duration": 4.561}, {"text": "autoencoding example with uh with mnist", "start": 5996.239, "duration": 5.281}, {"text": "and we'll add Skip", "start": 5998.76, "duration": 2.76}, {"text": "connections all right so let's start", "start": 6003.36, "duration": 5.64}, {"text": "with this this was a slide I had before", "start": 6005.32, "duration": 6.2}, {"text": "the logistic unit remember I said um you", "start": 6009.0, "duration": 5.04}, {"text": "know this is a function that defines our", "start": 6011.52, "duration": 4.079}, {"text": "activation we can draw it out as a", "start": 6014.04, "duration": 4.119}, {"text": "little bit as a kind of graph we have", "start": 6015.599, "duration": 4.361}, {"text": "these parameters that shift around this", "start": 6018.159, "duration": 3.881}, {"text": "function", "start": 6019.96, "duration": 5.0}, {"text": "and I gave you an example before where I", "start": 6022.04, "duration": 5.88}, {"text": "said imagine you have one input this", "start": 6024.96, "duration": 5.84}, {"text": "input feeds into two different uh units", "start": 6027.92, "duration": 4.64}, {"text": "and these units have some parameters in", "start": 6030.8, "duration": 3.399}, {"text": "their activation function it's using a", "start": 6032.56, "duration": 3.36}, {"text": "sigmoid and they have this kind of shape", "start": 6034.199, "duration": 3.201}, {"text": "and we can add it together we get this", "start": 6035.92, "duration": 3.84}, {"text": "bump function as the output so we can", "start": 6037.4, "duration": 3.92}, {"text": "build this nonlinear transformation of", "start": 6039.76, "duration": 2.479}, {"text": "the", "start": 6041.32, "duration": 4.04}, {"text": "input now imagine I have this", "start": 6042.239, "duration": 6.641}, {"text": "situation I have two inputs I call them", "start": 6045.36, "duration": 7.12}, {"text": "x1x2 two units they each have some", "start": 6048.88, "duration": 4.759}, {"text": "different parameters so they have", "start": 6052.48, "duration": 4.84}, {"text": "different activation shapes it's the say", "start": 6053.639, "duration": 6.281}, {"text": "again these are logistic functions and", "start": 6057.32, "duration": 4.64}, {"text": "instead of adding these together what if", "start": 6059.92, "duration": 4.04}, {"text": "I do this what if I say I'm going to", "start": 6061.96, "duration": 4.04}, {"text": "multiply them", "start": 6063.96, "duration": 4.48}, {"text": "together what is the output function", "start": 6066.0, "duration": 4.48}, {"text": "doing in this", "start": 6068.44, "duration": 4.44}, {"text": "case all right so just look at that for", "start": 6070.48, "duration": 4.119}, {"text": "a second and in your head see if you can", "start": 6072.88, "duration": 3.0}, {"text": "come up with a", "start": 6074.599, "duration": 4.801}, {"text": "description formal or informal of what", "start": 6075.88, "duration": 5.6}, {"text": "that of what that function output", "start": 6079.4, "duration": 3.92}, {"text": "function is going to", "start": 6081.48, "duration": 4.6}, {"text": "represent and if you if you're if you've", "start": 6083.32, "duration": 4.16}, {"text": "seen this kind of stuff before if you", "start": 6086.08, "duration": 3.079}, {"text": "have maybe the uh you know an", "start": 6087.48, "duration": 3.4}, {"text": "engineering background you you are", "start": 6089.159, "duration": 3.121}, {"text": "familiar with what step functions are", "start": 6090.88, "duration": 4.239}, {"text": "and you can see that the X1 activation", "start": 6092.28, "duration": 5.08}, {"text": "is almost like a step function and that", "start": 6095.119, "duration": 4.56}, {"text": "step function in a sense can act like a", "start": 6097.36, "duration": 7.12}, {"text": "gate because if X1 is less than zero", "start": 6099.679, "duration": 6.321}, {"text": "it's going to be zero when you multiply", "start": 6104.48, "duration": 3.36}, {"text": "it out with X2 is just going to zero", "start": 6106.0, "duration": 3.0}, {"text": "everything", "start": 6107.84, "duration": 4.96}, {"text": "out uh and", "start": 6109.0, "duration": 7.44}, {"text": "um if X1 is greater than zero it's going", "start": 6112.8, "duration": 6.2}, {"text": "to be one and so then the activation is", "start": 6116.44, "duration": 7.12}, {"text": "just going to be um based on just X2 so", "start": 6119.0, "duration": 6.599}, {"text": "here X1 acts kind of like a", "start": 6123.56, "duration": 5.2}, {"text": "gate uh and so we can take this", "start": 6125.599, "duration": 6.441}, {"text": "idea and apply it and this was applied", "start": 6128.76, "duration": 6.919}, {"text": "in recurrent neural networks so I'll", "start": 6132.04, "duration": 5.36}, {"text": "I'll remind you what something my said", "start": 6135.679, "duration": 3.801}, {"text": "before with the recurrent real neural", "start": 6137.4, "duration": 4.04}, {"text": "network we create we create this cyclic", "start": 6139.48, "duration": 4.159}, {"text": "connection so you have an", "start": 6141.44, "duration": 5.52}, {"text": "input and you store the previous", "start": 6143.639, "duration": 6.441}, {"text": "output uh and that becomes in becomes", "start": 6146.96, "duration": 5.96}, {"text": "another input to the hidden", "start": 6150.08, "duration": 5.159}, {"text": "unit and then you multiply those", "start": 6152.92, "duration": 3.319}, {"text": "together you pass them through your", "start": 6155.239, "duration": 2.44}, {"text": "activation function I'm sorry you don't", "start": 6156.239, "duration": 2.761}, {"text": "multiply them together you add them", "start": 6157.679, "duration": 3.0}, {"text": "together you pass it through your", "start": 6159.0, "duration": 2.8}, {"text": "whatever activation function you're", "start": 6160.679, "duration": 3.0}, {"text": "using and you could get another", "start": 6161.8, "duration": 6.76}, {"text": "output well we can re rework this in the", "start": 6163.679, "duration": 6.48}, {"text": "following way we could take our previous", "start": 6168.56, "duration": 3.48}, {"text": "output our current", "start": 6170.159, "duration": 5.361}, {"text": "input feed it into a logistic unit take", "start": 6172.04, "duration": 5.76}, {"text": "the output of that logistic unit as a", "start": 6175.52, "duration": 5.0}, {"text": "gate as a gate value we have multiply it", "start": 6177.8, "duration": 5.319}, {"text": "by the previous output and now we're", "start": 6180.52, "duration": 5.639}, {"text": "we're using our our information about", "start": 6183.119, "duration": 4.441}, {"text": "the state of the network and the current", "start": 6186.159, "duration": 4.361}, {"text": "input as a gate uh we're going to apply", "start": 6187.56, "duration": 4.36}, {"text": "that gate to the previous output we're", "start": 6190.52, "duration": 3.32}, {"text": "going to take one minus the gate apply", "start": 6191.92, "duration": 4.679}, {"text": "it to the current input so now you have", "start": 6193.84, "duration": 4.52}, {"text": "this this you know this weighted", "start": 6196.599, "duration": 3.921}, {"text": "probability right it's either W or EXC", "start": 6198.36, "duration": 4.799}, {"text": "or our weight applied to the previous", "start": 6200.52, "duration": 5.0}, {"text": "output one minus our weight applied to", "start": 6203.159, "duration": 5.721}, {"text": "the uh current input and so we're", "start": 6205.52, "duration": 5.199}, {"text": "creating a gating", "start": 6208.88, "duration": 4.52}, {"text": "mechanism and this is what what", "start": 6210.719, "duration": 5.161}, {"text": "comprises um the main part of a gated", "start": 6213.4, "duration": 4.319}, {"text": "recurrent unit it's a little simpler", "start": 6215.88, "duration": 4.88}, {"text": "version of the long short-term memory", "start": 6217.719, "duration": 5.801}, {"text": "gated unit that Mai was showing uh it", "start": 6220.76, "duration": 4.76}, {"text": "comes out of this paper and there's a", "start": 6223.52, "duration": 4.159}, {"text": "couple more parts to it but uh which I", "start": 6225.52, "duration": 4.52}, {"text": "don't really need to get into but", "start": 6227.679, "duration": 4.161}, {"text": "hopefully that just you know gives you a", "start": 6230.04, "duration": 4.559}, {"text": "sense of like what what motivated the", "start": 6231.84, "duration": 5.44}, {"text": "gate but once you have an idea that oh I", "start": 6234.599, "duration": 5.201}, {"text": "can gate things you know you can apply", "start": 6237.28, "duration": 4.68}, {"text": "it anywhere so here's an example where I", "start": 6239.8, "duration": 5.839}, {"text": "have some input and I'm gonna run it", "start": 6241.96, "duration": 5.44}, {"text": "through a hidden layer and I have some", "start": 6245.639, "duration": 3.921}, {"text": "maybe the same input or maybe different", "start": 6247.4, "duration": 4.04}, {"text": "input I'm going to also run it through", "start": 6249.56, "duration": 4.0}, {"text": "another hidden layer so I have a hidden", "start": 6251.44, "duration": 6.04}, {"text": "layer h a hidden layer G and instead of", "start": 6253.56, "duration": 5.28}, {"text": "just taking these further to another", "start": 6257.48, "duration": 3.0}, {"text": "layer I can actually make a gate out of", "start": 6258.84, "duration": 2.68}, {"text": "this", "start": 6260.48, "duration": 5.08}, {"text": "this so imagine I take my G layer I'm", "start": 6261.52, "duration": 7.679}, {"text": "going to multiply it element Wise by H", "start": 6265.56, "duration": 6.48}, {"text": "by the H layer but before I do that I'm", "start": 6269.199, "duration": 5.121}, {"text": "going to take a softmax", "start": 6272.04, "duration": 4.44}, {"text": "activation at the G", "start": 6274.32, "duration": 5.799}, {"text": "layer um and remember when we're doing", "start": 6276.48, "duration": 5.84}, {"text": "categorization we use softmax because", "start": 6280.119, "duration": 4.921}, {"text": "softmax normalizes your outputs into", "start": 6282.32, "duration": 4.2}, {"text": "basically probability weights or", "start": 6285.04, "duration": 3.8}, {"text": "probability values so this is what we", "start": 6286.52, "duration": 5.28}, {"text": "used when we were doing classification", "start": 6288.84, "duration": 4.839}, {"text": "but here I'm doing it just to make a", "start": 6291.8, "duration": 4.04}, {"text": "weight a probability weights and I'm", "start": 6293.679, "duration": 4.0}, {"text": "going to actually apply it inside the", "start": 6295.84, "duration": 3.839}, {"text": "layer so I could do this and then have", "start": 6297.679, "duration": 3.761}, {"text": "more layers further on down so I could", "start": 6299.679, "duration": 4.761}, {"text": "stick this anywhere in my", "start": 6301.44, "duration": 3.0}, {"text": "network and in fact in the attention", "start": 6305.04, "duration": 6.48}, {"text": "mechanism that Mai was talking about", "start": 6308.88, "duration": 5.839}, {"text": "there is a a a layer in there that is", "start": 6311.52, "duration": 5.44}, {"text": "doing just that it's actually using a", "start": 6314.719, "duration": 4.281}, {"text": "softmax to produce what is essentially a", "start": 6316.96, "duration": 4.08}, {"text": "kind of probability", "start": 6319.0, "duration": 7.199}, {"text": "waiting or a kind of a gate uh against", "start": 6321.04, "duration": 8.48}, {"text": "the um against some other set of input", "start": 6326.199, "duration": 5.121}, {"text": "so in the I'm not going to go through", "start": 6329.52, "duration": 3.4}, {"text": "the details of this I'm just giving you", "start": 6331.32, "duration": 4.799}, {"text": "a quick hopefully some intuition that in", "start": 6332.92, "duration": 4.799}, {"text": "the attention mechanism if you're doing", "start": 6336.119, "duration": 3.281}, {"text": "something like language translation you", "start": 6337.719, "duration": 3.121}, {"text": "might have English words French words", "start": 6339.4, "duration": 4.6}, {"text": "you're trying to do these long distance", "start": 6340.84, "duration": 4.96}, {"text": "or potentially long distance matching", "start": 6344.0, "duration": 4.44}, {"text": "between your one sequence and another", "start": 6345.8, "duration": 5.96}, {"text": "sequence um so if you remember the", "start": 6348.44, "duration": 5.159}, {"text": "example my was showing every word kind", "start": 6351.76, "duration": 3.479}, {"text": "of gets matched against every other", "start": 6353.599, "duration": 3.361}, {"text": "possible word in your in your", "start": 6355.239, "duration": 4.161}, {"text": "sequences there and in the attention", "start": 6356.96, "duration": 5.08}, {"text": "mechanism there's a softmax to", "start": 6359.4, "duration": 5.92}, {"text": "helpfully choose or gate which you", "start": 6362.04, "duration": 4.96}, {"text": "should which thing you should be paying", "start": 6365.32, "duration": 3.0}, {"text": "attention", "start": 6367.0, "duration": 4.0}, {"text": "to and that's the hopefully that's the", "start": 6368.32, "duration": 4.52}, {"text": "you know that's the terminology people", "start": 6371.0, "duration": 3.04}, {"text": "use that's kind", "start": 6372.84, "duration": 3.92}, {"text": "of hopefully build some intuition about", "start": 6374.04, "duration": 4.199}, {"text": "what these things are doing what that", "start": 6376.76, "duration": 2.64}, {"text": "kind of thing is", "start": 6378.239, "duration": 3.121}, {"text": "doing", "start": 6379.4, "duration": 4.08}, {"text": "all right so that's a", "start": 6381.36, "duration": 3.68}, {"text": "gating", "start": 6383.48, "duration": 4.6}, {"text": "idea um let's look at skip connections", "start": 6385.04, "duration": 5.079}, {"text": "and rual connections here's other other", "start": 6388.08, "duration": 3.96}, {"text": "kinds of", "start": 6390.119, "duration": 4.12}, {"text": "connections so let's start for this", "start": 6392.04, "duration": 3.88}, {"text": "let's think again about the re uh", "start": 6394.239, "duration": 3.641}, {"text": "multi-layer perceptron we take our input", "start": 6395.92, "duration": 3.88}, {"text": "pass it through a hidden layer and pass", "start": 6397.88, "duration": 5.4}, {"text": "it to an output layer but what if what", "start": 6399.8, "duration": 5.64}, {"text": "if we say you know what the input has a", "start": 6403.28, "duration": 4.399}, {"text": "lot of information that it would I would", "start": 6405.44, "duration": 3.96}, {"text": "like to present to the output layer", "start": 6407.679, "duration": 3.321}, {"text": "directly", "start": 6409.4, "duration": 4.56}, {"text": "what how can I carry that input forward", "start": 6411.0, "duration": 6.679}, {"text": "well a simple way is to just make this", "start": 6413.96, "duration": 6.36}, {"text": "extra connection uh where I'm taking the", "start": 6417.679, "duration": 5.321}, {"text": "input layer I'm going to carry it", "start": 6420.32, "duration": 5.96}, {"text": "Forward um directly to the output layer", "start": 6423.0, "duration": 6.04}, {"text": "and be and so these are not this is not", "start": 6426.28, "duration": 7.359}, {"text": "a hidden layer this is just uh a", "start": 6429.04, "duration": 6.88}, {"text": "copy and in order to present it to the", "start": 6433.639, "duration": 4.441}, {"text": "output layer I'm going to make a do a", "start": 6435.92, "duration": 4.0}, {"text": "concatenation I'm going to concatenate", "start": 6438.08, "duration": 5.48}, {"text": "the hi layer and the input so now I have", "start": 6439.92, "duration": 5.199}, {"text": "a bigger", "start": 6443.56, "duration": 3.639}, {"text": "Vector um and I'm going to pass that to", "start": 6445.119, "duration": 5.04}, {"text": "the output layer and if I do this the", "start": 6447.199, "duration": 6.241}, {"text": "output layer now has um in some sense", "start": 6450.159, "duration": 5.201}, {"text": "there direct access to the input layer", "start": 6453.44, "duration": 4.199}, {"text": "so whatever features are in the input", "start": 6455.36, "duration": 4.56}, {"text": "layer are pres are used more", "start": 6457.639, "duration": 4.441}, {"text": "efficiently and presented directly to", "start": 6459.92, "duration": 3.16}, {"text": "the output", "start": 6462.08, "duration": 3.36}, {"text": "layer so the one of the ideas behind", "start": 6463.08, "duration": 5.559}, {"text": "this skip connection is that uh we can", "start": 6465.44, "duration": 5.08}, {"text": "reuse features or make the feature Fe", "start": 6468.639, "duration": 3.04}, {"text": "use more efficiently because we're going", "start": 6470.52, "duration": 3.32}, {"text": "to present them directly to you know", "start": 6471.679, "duration": 6.881}, {"text": "whatever next part of the network is is", "start": 6473.84, "duration": 4.72}, {"text": "there and in fact this doesn't actually", "start": 6478.76, "duration": 6.12}, {"text": "have to happen for just input to Output", "start": 6481.76, "duration": 7.24}, {"text": "it could happen at any layer and you", "start": 6484.88, "duration": 6.12}, {"text": "could skip ahead any other number of", "start": 6489.0, "duration": 5.52}, {"text": "layers and and present and and you know", "start": 6491.0, "duration": 7.56}, {"text": "Skip um or present that that output so", "start": 6494.52, "duration": 6.76}, {"text": "in this picture I could take the output", "start": 6498.56, "duration": 4.44}, {"text": "from my first hidden layer and just you", "start": 6501.28, "duration": 4.439}, {"text": "know Skip it forward a couple layers why", "start": 6503.0, "duration": 5.08}, {"text": "not there's nothing stopping you from", "start": 6505.719, "duration": 4.121}, {"text": "doing that", "start": 6508.08, "duration": 3.8}, {"text": "presumably if you do this kind of thing", "start": 6509.84, "duration": 3.759}, {"text": "you would have some intuition for doing", "start": 6511.88, "duration": 4.16}, {"text": "that kind of", "start": 6513.599, "duration": 2.441}, {"text": "thing", "start": 6516.679, "duration": 4.48}, {"text": "okay uh and in", "start": 6518.719, "duration": 7.081}, {"text": "fact the unit architecture that um my", "start": 6521.159, "duration": 6.52}, {"text": "mention does use this kind of", "start": 6525.8, "duration": 4.08}, {"text": "connections so let's talk a little bit", "start": 6527.679, "duration": 4.52}, {"text": "about this this uh situation remember", "start": 6529.88, "duration": 4.52}, {"text": "when we were doing mes classification we", "start": 6532.199, "duration": 5.04}, {"text": "had this um you know we had these", "start": 6534.4, "duration": 4.04}, {"text": "convolution", "start": 6537.239, "duration": 5.201}, {"text": "layers and we were as we processed the", "start": 6538.44, "duration": 7.04}, {"text": "input we were U using convolution and", "start": 6542.44, "duration": 4.719}, {"text": "Max ping we were", "start": 6545.48, "duration": 4.88}, {"text": "downsampling the input output", "start": 6547.159, "duration": 5.641}, {"text": "maps and we were increasing the number", "start": 6550.36, "duration": 4.2}, {"text": "of features and that's a kind of", "start": 6552.8, "duration": 2.76}, {"text": "standard thing you might do with", "start": 6554.56, "duration": 4.32}, {"text": "classification so you're going to", "start": 6555.56, "duration": 6.679}, {"text": "um uh so in this example we had a 28x 28", "start": 6558.88, "duration": 6.04}, {"text": "image we're down sampling 14 X 14 but", "start": 6562.239, "duration": 4.601}, {"text": "we're increasing the number of filters", "start": 6564.92, "duration": 2.84}, {"text": "and at some point you get a little", "start": 6566.84, "duration": 2.12}, {"text": "bottleneck at some point you don't want", "start": 6567.76, "duration": 3.64}, {"text": "to go down to anything lower than let's", "start": 6568.96, "duration": 5.44}, {"text": "say 7 by seven so in this bottleneck", "start": 6571.4, "duration": 5.96}, {"text": "layer I have 7 by seven Maps but I have", "start": 6574.4, "duration": 6.239}, {"text": "256 of them so this is kind of an", "start": 6577.36, "duration": 6.359}, {"text": "encoding uh part of your network and", "start": 6580.639, "duration": 4.281}, {"text": "when we did", "start": 6583.719, "duration": 2.96}, {"text": "classification we just added some", "start": 6584.92, "duration": 3.279}, {"text": "classification layers but what if", "start": 6586.679, "duration": 3.881}, {"text": "instead of classification we want to do", "start": 6588.199, "duration": 4.281}, {"text": "something like reconstruction we want to", "start": 6590.56, "duration": 5.599}, {"text": "reconstruct the input um what could we", "start": 6592.48, "duration": 6.32}, {"text": "do so it turns out a good way to do this", "start": 6596.159, "duration": 6.96}, {"text": "is to reverse the encoding into some", "start": 6598.8, "duration": 7.28}, {"text": "decoding and that requires some", "start": 6603.119, "duration": 4.921}, {"text": "upsampling so in other words from the", "start": 6606.08, "duration": 4.24}, {"text": "bottleneck that was 7 by seven which", "start": 6608.04, "duration": 3.88}, {"text": "presumably you know the good thing about", "start": 6610.32, "duration": 4.24}, {"text": "a bottleneck is you've you've process", "start": 6611.92, "duration": 5.279}, {"text": "the input and you're only saving the", "start": 6614.56, "duration": 3.88}, {"text": "most pertinent", "start": 6617.199, "duration": 3.641}, {"text": "information uh so the B like forces you", "start": 6618.44, "duration": 4.4}, {"text": "to do that it creates kind of a latent", "start": 6620.84, "duration": 5.759}, {"text": "representation which is what Ma talked", "start": 6622.84, "duration": 3.759}, {"text": "about and when we upsample but if we", "start": 6627.199, "duration": 4.601}, {"text": "want to reconstruct the the original", "start": 6629.8, "duration": 5.48}, {"text": "input then when we upsample we need to", "start": 6631.8, "duration": 5.359}, {"text": "um you know increase the size of these", "start": 6635.28, "duration": 6.0}, {"text": "Maps so in this example uh our 7 by7", "start": 6637.159, "duration": 7.801}, {"text": "bottleneck maps are up sampled into 14", "start": 6641.28, "duration": 7.52}, {"text": "by 14 I change the number of filters", "start": 6644.96, "duration": 6.639}, {"text": "from 256 to two to 128 and then I do", "start": 6648.8, "duration": 4.68}, {"text": "another upsampling and another change in", "start": 6651.599, "duration": 4.64}, {"text": "the number of filters to 64 and finally", "start": 6653.48, "duration": 5.719}, {"text": "I have a last convolution", "start": 6656.239, "duration": 6.92}, {"text": "layer uh that's basically taking my last", "start": 6659.199, "duration": 6.321}, {"text": "uh convolution my upsampling block here", "start": 6663.159, "duration": 7.92}, {"text": "and producing a 28 by 28 um", "start": 6665.52, "duration": 5.559}, {"text": "image okay we'll see how that works so", "start": 6672.36, "duration": 3.4}, {"text": "that's what we're going to look at in", "start": 6674.48, "duration": 3.759}, {"text": "the", "start": 6675.76, "duration": 2.479}, {"text": "exercise but one thing that people have", "start": 6678.96, "duration": 3.719}, {"text": "found is if you want to do something", "start": 6681.28, "duration": 2.48}, {"text": "like", "start": 6682.679, "duration": 3.161}, {"text": "reconstruction it's really helpful to", "start": 6683.76, "duration": 4.76}, {"text": "have skip connections so in a skip", "start": 6685.84, "duration": 4.6}, {"text": "connection I'm going I'm taking my", "start": 6688.52, "duration": 5.199}, {"text": "convolution output from my first", "start": 6690.44, "duration": 4.799}, {"text": "convolution block and maybe my second", "start": 6693.719, "duration": 3.561}, {"text": "convolution block and I'm just directly", "start": 6695.239, "duration": 5.201}, {"text": "passing it ahead to the you know to the", "start": 6697.28, "duration": 6.28}, {"text": "blocks um on the decoding", "start": 6700.44, "duration": 5.36}, {"text": "side and you have to be careful because", "start": 6703.56, "duration": 4.039}, {"text": "you want to make sure that you're if", "start": 6705.8, "duration": 3.0}, {"text": "you're going to do a", "start": 6707.599, "duration": 5.161}, {"text": "concatenation that your input matches", "start": 6708.8, "duration": 6.799}, {"text": "the size the shape the image height and", "start": 6712.76, "duration": 5.439}, {"text": "width on your on to where you're", "start": 6715.599, "duration": 4.841}, {"text": "skipping", "start": 6718.199, "duration": 6.601}, {"text": "ahead okay so your 28 x 28 encoded maps", "start": 6720.44, "duration": 5.639}, {"text": "have to be skipped ahead to where the", "start": 6724.8, "duration": 3.919}, {"text": "28x 28 decoding maps", "start": 6726.079, "duration": 4.841}, {"text": "are and you got to make sure you're", "start": 6728.719, "duration": 4.36}, {"text": "concatenating on the right Axis right so", "start": 6730.92, "duration": 4.92}, {"text": "in this example I have 28x 28 by", "start": 6733.079, "duration": 5.801}, {"text": "64 I want to concatenate that to 28x 28", "start": 6735.84, "duration": 6.04}, {"text": "x 64", "start": 6738.88, "duration": 3.0}, {"text": "and you want to end up with basically 28", "start": 6742.159, "duration": 4.48}, {"text": "x 28 by", "start": 6744.0, "duration": 2.639}, {"text": "128 all right so hopefully that gives", "start": 6747.56, "duration": 4.72}, {"text": "you an idea of what kind of things skip", "start": 6749.48, "duration": 4.44}, {"text": "connections are good for again this is", "start": 6752.28, "duration": 4.399}, {"text": "what the unit architecture looks like um", "start": 6753.92, "duration": 4.199}, {"text": "there's these convolution blocks and", "start": 6756.679, "duration": 4.321}, {"text": "Skip connections that help process you", "start": 6758.119, "duration": 5.801}, {"text": "know some of the help help reuse some of", "start": 6761.0, "duration": 5.159}, {"text": "those features that were um represented", "start": 6763.92, "duration": 4.92}, {"text": "in the in the convolution encoding", "start": 6766.159, "duration": 5.681}, {"text": "blocks", "start": 6768.84, "duration": 3.0}, {"text": "all right skip connections so they come", "start": 6772.159, "duration": 5.401}, {"text": "up what about residual connections this", "start": 6774.28, "duration": 7.2}, {"text": "is a more I think a slightly unintuitive", "start": 6777.56, "duration": 4.84}, {"text": "kind of", "start": 6781.48, "duration": 2.8}, {"text": "idea all right so I'm gonna but I'm", "start": 6782.4, "duration": 4.52}, {"text": "going to try it so imagine I give you", "start": 6784.28, "duration": 4.0}, {"text": "this situation where I have an input", "start": 6786.92, "duration": 2.88}, {"text": "layer some number of hidden layers and", "start": 6788.28, "duration": 3.959}, {"text": "an output", "start": 6789.8, "duration": 2.439}, {"text": "layer all right so I got some deep", "start": 6792.28, "duration": 4.12}, {"text": "Network and it learns you know a certain", "start": 6794.48, "duration": 3.32}, {"text": "amount I think gee maybe I should add", "start": 6796.4, "duration": 3.08}, {"text": "more hidden layers if I add more hidden", "start": 6797.8, "duration": 5.08}, {"text": "layers to a deep Network I'm I'm", "start": 6799.48, "duration": 4.96}, {"text": "creating a little bit harder situation", "start": 6802.88, "duration": 2.92}, {"text": "for the network to learn right we talked", "start": 6804.44, "duration": 2.759}, {"text": "about the vanishing gradient problem you", "start": 6805.8, "duration": 2.68}, {"text": "have now you have information that you", "start": 6807.199, "duration": 3.641}, {"text": "need to propagate all the way back", "start": 6808.48, "duration": 3.8}, {"text": "should I add another layer I mean this", "start": 6810.84, "duration": 3.6}, {"text": "more expensive but maybe another layer", "start": 6812.28, "duration": 3.879}, {"text": "can give you another you know", "start": 6814.44, "duration": 3.48}, {"text": "transformation another deep learning", "start": 6816.159, "duration": 4.881}, {"text": "feature Discovery kind of thing um so", "start": 6817.92, "duration": 5.44}, {"text": "it's a it's a slightly you know we have", "start": 6821.04, "duration": 4.28}, {"text": "this we have this goal that it's that we", "start": 6823.36, "duration": 4.239}, {"text": "think intuitively it's good to have more", "start": 6825.32, "duration": 4.759}, {"text": "layers but the more layers you have you", "start": 6827.599, "duration": 4.241}, {"text": "know the harder more computation it is", "start": 6830.079, "duration": 3.881}, {"text": "harder maybe it is to learn uh um to", "start": 6831.84, "duration": 4.16}, {"text": "find good representations maybe you're", "start": 6833.96, "duration": 4.719}, {"text": "overfitting for", "start": 6836.0, "duration": 2.679}, {"text": "example okay so you don't really know if", "start": 6839.199, "duration": 4.281}, {"text": "the next layer let's say the next layer", "start": 6842.0, "duration": 2.56}, {"text": "might be", "start": 6843.48, "duration": 3.92}, {"text": "unnecessary uh well if it turns out that", "start": 6844.56, "duration": 4.96}, {"text": "the next layer is", "start": 6847.4, "duration": 5.4}, {"text": "unnecessary then you might be nice if", "start": 6849.52, "duration": 6.639}, {"text": "the network um just kind of ignored it", "start": 6852.8, "duration": 4.879}, {"text": "didn't really perform any nonlinear", "start": 6856.159, "duration": 3.321}, {"text": "transformation if it just created an", "start": 6857.679, "duration": 4.641}, {"text": "idea identity function from H1 to H2 so", "start": 6859.48, "duration": 5.36}, {"text": "if H2 was the same as H1 then you're not", "start": 6862.32, "duration": 3.56}, {"text": "going to do any", "start": 6864.84, "duration": 3.319}, {"text": "worse so hopefully I get that's kind of", "start": 6865.88, "duration": 4.799}, {"text": "the intuition", "start": 6868.159, "duration": 5.121}, {"text": "um behind what what is the residual", "start": 6870.679, "duration": 6.321}, {"text": "Network residual connection I should say", "start": 6873.28, "duration": 6.24}, {"text": "um it goes something like this you take", "start": 6877.0, "duration": 4.8}, {"text": "your H1 output and you're going to skip", "start": 6879.52, "duration": 4.119}, {"text": "it", "start": 6881.8, "duration": 4.879}, {"text": "ahead to the next layer but instead of", "start": 6883.639, "duration": 5.04}, {"text": "presenting it as a", "start": 6886.679, "duration": 5.161}, {"text": "concatenation or presenting it um as a", "start": 6888.679, "duration": 4.52}, {"text": "multiplication you're just going to add", "start": 6891.84, "duration": 5.92}, {"text": "it into the output from the next", "start": 6893.199, "duration": 9.201}, {"text": "layer so my my my f ofx that is going to", "start": 6897.76, "duration": 7.919}, {"text": "be presented to the next layer is equal", "start": 6902.4, "duration": 6.4}, {"text": "to H2 plus", "start": 6905.679, "duration": 7.081}, {"text": "H1 and that means that the H2 is really", "start": 6908.8, "duration": 7.24}, {"text": "the same as F minus", "start": 6912.76, "duration": 6.6}, {"text": "H1 uh and so in this sense H2 if H2 is", "start": 6916.04, "duration": 6.48}, {"text": "going to do anything useful it's kind of", "start": 6919.36, "duration": 5.6}, {"text": "like a residual it's a residual of what", "start": 6922.52, "duration": 4.159}, {"text": "got presented to you know it's learning", "start": 6924.96, "duration": 5.0}, {"text": "the residual of what got presented to", "start": 6926.679, "duration": 7.121}, {"text": "the next layer um when you take out the", "start": 6929.96, "duration": 6.84}, {"text": "previous layer so this is a skip ahead", "start": 6933.8, "duration": 6.0}, {"text": "connection with an elementwise", "start": 6936.8, "duration": 5.879}, {"text": "addition uh and it works when you know", "start": 6939.8, "duration": 4.279}, {"text": "it works most easily when you have the", "start": 6942.679, "duration": 2.321}, {"text": "same", "start": 6944.079, "duration": 4.52}, {"text": "size um same size output for your hidden", "start": 6945.0, "duration": 6.0}, {"text": "layers", "start": 6948.599, "duration": 3.52}, {"text": "all right so this is a residual", "start": 6951.0, "duration": 2.639}, {"text": "connection this came", "start": 6952.119, "duration": 5.96}, {"text": "up in What's called the resnet the reset", "start": 6953.639, "duration": 6.401}, {"text": "um you know did really well in in the", "start": 6958.079, "duration": 4.08}, {"text": "image one of the more recent image I", "start": 6960.04, "duration": 6.36}, {"text": "guess it's 2019 I want to say uh image", "start": 6962.159, "duration": 6.92}, {"text": "competitions they the the authors show", "start": 6966.4, "duration": 5.48}, {"text": "that you know having this kind of", "start": 6969.079, "duration": 5.401}, {"text": "connection really helps you add more", "start": 6971.88, "duration": 4.799}, {"text": "deep", "start": 6974.48, "duration": 5.679}, {"text": "layers and so the intuition behind it", "start": 6976.679, "duration": 5.721}, {"text": "is that it makes it easy for a network", "start": 6980.159, "duration": 5.281}, {"text": "to carry forward you know to carry", "start": 6982.4, "duration": 5.839}, {"text": "forward representations that are", "start": 6985.44, "duration": 7.48}, {"text": "useful uh and and to and to have to add", "start": 6988.239, "duration": 6.201}, {"text": "more layers without making anything", "start": 6992.92, "duration": 3.08}, {"text": "worse and so if you're going to learn", "start": 6994.44, "duration": 2.679}, {"text": "something it's going to learn something", "start": 6996.0, "duration": 2.92}, {"text": "you know", "start": 6997.119, "duration": 4.241}, {"text": "useful", "start": 6998.92, "duration": 5.44}, {"text": "um", "start": 7001.36, "duration": 3.0}, {"text": "okay all right so here's a summary of", "start": 7005.36, "duration": 4.4}, {"text": "what these what these con connections", "start": 7008.44, "duration": 3.6}, {"text": "were so I have the softmax for gating", "start": 7009.76, "duration": 4.0}, {"text": "comes up in like recurrent networks", "start": 7012.04, "duration": 4.76}, {"text": "these Transformer Nets uh and and you", "start": 7013.76, "duration": 6.76}, {"text": "know the idea of a gate um you can you", "start": 7016.8, "duration": 5.16}, {"text": "can really use that in a lot of places", "start": 7020.52, "duration": 2.639}, {"text": "in", "start": 7021.96, "duration": 3.719}, {"text": "principle uh skip", "start": 7023.159, "duration": 4.601}, {"text": "connections uh you know the intuition", "start": 7025.679, "duration": 4.321}, {"text": "behind it that is good for feature reuse", "start": 7027.76, "duration": 3.64}, {"text": "comes up in units you can use it in", "start": 7030.0, "duration": 4.239}, {"text": "feedforward networks um it doesn't have", "start": 7031.4, "duration": 5.239}, {"text": "to just be you know image processing", "start": 7034.239, "duration": 5.041}, {"text": "problems residual connections the idea", "start": 7036.639, "duration": 5.0}, {"text": "that it's going to help deeper learning", "start": 7039.28, "duration": 5.839}, {"text": "uh and so this comes into the reset", "start": 7041.639, "duration": 6.0}, {"text": "models and so in that example it's you", "start": 7045.119, "duration": 4.881}, {"text": "know it's important for large image", "start": 7047.639, "duration": 3.921}, {"text": "classification all right so these are", "start": 7050.0, "duration": 3.599}, {"text": "three different kinds of uh connections", "start": 7051.56, "duration": 4.679}, {"text": "and the intuitions behind", "start": 7053.599, "duration": 5.241}, {"text": "them and now let's look at the Caris", "start": 7056.239, "duration": 4.521}, {"text": "model API because we need to think about", "start": 7058.84, "duration": 3.2}, {"text": "if we're going to implement these kinds", "start": 7060.76, "duration": 4.319}, {"text": "of things we need to use this more", "start": 7062.04, "duration": 6.36}, {"text": "flexible um um", "start": 7065.079, "duration": 5.441}, {"text": "functions", "start": 7068.4, "duration": 4.56}, {"text": "all right so you might", "start": 7070.52, "duration": 5.599}, {"text": "remember that when we first did the Mist", "start": 7072.96, "duration": 6.08}, {"text": "earlier we presented a simple example it", "start": 7076.119, "duration": 4.321}, {"text": "looks something like this that using the", "start": 7079.04, "duration": 4.679}, {"text": "sequential function in Caris there's a", "start": 7080.44, "duration": 7.0}, {"text": "Caris uh module the module the models", "start": 7083.719, "duration": 5.681}, {"text": "functions and one of those model", "start": 7087.44, "duration": 4.08}, {"text": "functions is the sequential", "start": 7089.4, "duration": 4.759}, {"text": "function and my simple example of mnus", "start": 7091.52, "duration": 4.44}, {"text": "was to flatten the input and have some", "start": 7094.159, "duration": 3.241}, {"text": "dense", "start": 7095.96, "duration": 6.6}, {"text": "layers okay and in this example um you", "start": 7097.4, "duration": 6.6}, {"text": "you know everything is presented in", "start": 7102.56, "duration": 5.039}, {"text": "sequence and Caris can figure out what", "start": 7104.0, "duration": 5.04}, {"text": "the inputs and outputs are just by the", "start": 7107.599, "duration": 3.08}, {"text": "fact that it's presented in", "start": 7109.04, "duration": 3.88}, {"text": "sequence but there's another way to do", "start": 7110.679, "duration": 5.56}, {"text": "this you can set up instead of having a", "start": 7112.92, "duration": 6.319}, {"text": "sequence a sequential model you have", "start": 7116.239, "duration": 5.041}, {"text": "just a sequence of", "start": 7119.239, "duration": 4.761}, {"text": "functions and here okay I'm going to go", "start": 7121.28, "duration": 4.08}, {"text": "through these one at a time my first", "start": 7124.0, "duration": 2.84}, {"text": "function is an input function I say", "start": 7125.36, "duration": 4.2}, {"text": "here's my input uh it's it's all part of", "start": 7126.84, "duration": 5.92}, {"text": "the layers uh", "start": 7129.56, "duration": 5.639}, {"text": "API so if I have an input function and I", "start": 7132.76, "duration": 3.68}, {"text": "give it a shape and then I say I'm going", "start": 7135.199, "duration": 3.601}, {"text": "to have a flatten function and I have a", "start": 7136.44, "duration": 4.32}, {"text": "flatten function and then you tell it", "start": 7138.8, "duration": 4.76}, {"text": "what the inputs are uh in separate", "start": 7140.76, "duration": 8.76}, {"text": "parentheses here um so inputs feeds the", "start": 7143.56, "duration": 8.519}, {"text": "flatten function then I have a hidden", "start": 7149.52, "duration": 4.639}, {"text": "layer the hidden layer you know just the", "start": 7152.079, "duration": 5.441}, {"text": "dense activation uh is relu and I tell", "start": 7154.159, "duration": 4.681}, {"text": "it what the inputs are going to be the", "start": 7157.52, "duration": 3.679}, {"text": "inputs going to be inputs flattened the", "start": 7158.84, "duration": 4.16}, {"text": "output layer is going to use inputs from", "start": 7161.199, "duration": 2.761}, {"text": "the hidden", "start": 7163.0, "duration": 5.32}, {"text": "layer so you you create these", "start": 7163.96, "duration": 4.36}, {"text": "functions and then you have a model", "start": 7168.84, "duration": 4.839}, {"text": "statement the model statement says okay", "start": 7170.84, "duration": 5.48}, {"text": "Caris build a model start with these", "start": 7173.679, "duration": 5.641}, {"text": "inputs end with this output layer and", "start": 7176.32, "duration": 5.24}, {"text": "then Caris will go figure out what's", "start": 7179.32, "duration": 6.24}, {"text": "connected to what by working backwards", "start": 7181.56, "duration": 6.32}, {"text": "and figuring out for each function where", "start": 7185.56, "duration": 4.88}, {"text": "its input is going to come from", "start": 7187.88, "duration": 4.6}, {"text": "I hope that makes sense it's kind of the", "start": 7190.44, "duration": 4.719}, {"text": "kind it's a little bit I think um if you", "start": 7192.48, "duration": 4.04}, {"text": "you know depending on how much P python", "start": 7195.159, "duration": 4.841}, {"text": "you've done uh maybe it's not intuitive", "start": 7196.52, "duration": 4.92}, {"text": "but if you see it enough times I think I", "start": 7200.0, "duration": 3.36}, {"text": "think it'll make", "start": 7201.44, "duration": 4.44}, {"text": "sense okay but the nice thing about this", "start": 7203.36, "duration": 4.56}, {"text": "is when you have let's say two different", "start": 7205.88, "duration": 4.319}, {"text": "paths or maybe you have skip connections", "start": 7207.92, "duration": 4.48}, {"text": "or you have you know other kinds of", "start": 7210.199, "duration": 4.681}, {"text": "architectural things you want to do uh", "start": 7212.4, "duration": 5.279}, {"text": "you can program that through you know", "start": 7214.88, "duration": 5.279}, {"text": "this these kinds of uh this kind of", "start": 7217.679, "duration": 5.92}, {"text": "functions so the model API the model API", "start": 7220.159, "duration": 5.201}, {"text": "with a capital", "start": 7223.599, "duration": 3.681}, {"text": "M uh sometimes it's called the", "start": 7225.36, "duration": 4.16}, {"text": "functional", "start": 7227.28, "duration": 4.879}, {"text": "API", "start": 7229.52, "duration": 6.96}, {"text": "okay all right so let's go to an mest", "start": 7232.159, "duration": 6.801}, {"text": "autoencoding exercise and we're going to", "start": 7236.48, "duration": 4.4}, {"text": "look at mest autoencoding and then add", "start": 7238.96, "duration": 4.96}, {"text": "Skip connections so hopefully you are", "start": 7240.88, "duration": 6.279}, {"text": "still logged", "start": 7243.92, "duration": 3.239}, {"text": "into a", "start": 7247.719, "duration": 3.4}, {"text": "um a notebook or Jupiter lab whoops hang", "start": 7252.079, "duration": 6.201}, {"text": "on okay so if you were logged into the", "start": 7261.48, "duration": 8.4}, {"text": "Jupiter lab that you were using with my", "start": 7265.92, "duration": 6.08}, {"text": "um you want to make sure you I I believe", "start": 7269.88, "duration": 3.759}, {"text": "you have to restart shut down our", "start": 7272.0, "duration": 4.239}, {"text": "kernels or restart the kernel maybe you", "start": 7273.639, "duration": 3.721}, {"text": "want to close", "start": 7276.239, "duration": 3.48}, {"text": "off uh what was it", "start": 7277.36, "duration": 7.12}, {"text": "there close those particular um", "start": 7279.719, "duration": 4.761}, {"text": "notebooks I also opened up a", "start": 7284.56, "duration": 8.48}, {"text": "new um Jupiter notebook or Jupiter lab I", "start": 7288.56, "duration": 6.2}, {"text": "should", "start": 7293.04, "duration": 7.599}, {"text": "say uh and I did this with", "start": 7294.76, "duration": 5.879}, {"text": "the the there's an alas called Jupiter", "start": 7304.4, "duration": 5.679}, {"text": "compute tensor flow which opens opens up", "start": 7306.92, "duration": 6.279}, {"text": "a um just a compute node so you could", "start": 7310.079, "duration": 4.441}, {"text": "either use a compute node for this", "start": 7313.199, "duration": 3.48}, {"text": "exercise or a GPU node for this exercise", "start": 7314.52, "duration": 4.24}, {"text": "if you're using the GPU node that you", "start": 7316.679, "duration": 4.241}, {"text": "had before make sure you shut down the", "start": 7318.76, "duration": 5.399}, {"text": "kernels um I'm going to go", "start": 7320.92, "duration": 6.759}, {"text": "into the uh compute node version or the", "start": 7324.159, "duration": 6.841}, {"text": "compute node um session that I have and", "start": 7327.679, "duration": 5.48}, {"text": "I'm going to go", "start": 7331.0, "duration": 4.92}, {"text": "into if you if you hopefully have pulled", "start": 7333.159, "duration": 7.321}, {"text": "down a repo um", "start": 7335.92, "duration": 6.4}, {"text": "today or probably yesterday I don't", "start": 7340.48, "duration": 3.44}, {"text": "think I updated it so I think it was", "start": 7342.32, "duration": 4.799}, {"text": "there yesterday you can go into the", "start": 7343.92, "duration": 5.56}, {"text": "again go into your the summer Institute", "start": 7347.119, "duration": 5.361}, {"text": "find the folder", "start": 7349.48, "duration": 6.56}, {"text": "5.2b deep learning part two look for DL", "start": 7352.48, "duration": 7.199}, {"text": "topics connections subfolder and I have", "start": 7356.04, "duration": 4.84}, {"text": "an auto", "start": 7359.679, "duration": 5.04}, {"text": "encoder an autoencoder with solution and", "start": 7360.88, "duration": 6.88}, {"text": "just as an example I have the the mnist", "start": 7364.719, "duration": 4.96}, {"text": "with sequential and", "start": 7367.76, "duration": 6.479}, {"text": "functional um API model statement so", "start": 7369.679, "duration": 6.121}, {"text": "that's not something I'm going to", "start": 7374.239, "duration": 2.92}, {"text": "present but I just wanted to have it in", "start": 7375.8, "duration": 2.72}, {"text": "the in the folder in case you want to", "start": 7377.159, "duration": 3.801}, {"text": "look at that", "start": 7378.52, "duration": 5.199}, {"text": "code", "start": 7380.96, "duration": 7.36}, {"text": "um okay so I'm going to open up the auto", "start": 7383.719, "duration": 4.601}, {"text": "encoder so go ahead and take a look at", "start": 7390.239, "duration": 4.96}, {"text": "the get uh you know open up the auto", "start": 7392.36, "duration": 5.16}, {"text": "encoder I'm just going to review it real", "start": 7395.199, "duration": 4.361}, {"text": "quickly and then", "start": 7397.52, "duration": 4.719}, {"text": "and and then let you guys work on the uh", "start": 7399.56, "duration": 5.24}, {"text": "the exercise so again this is an auto", "start": 7402.239, "duration": 4.48}, {"text": "coder for mnist what I've done here is", "start": 7404.8, "duration": 4.64}, {"text": "I've added noise so I've made it a", "start": 7406.719, "duration": 5.92}, {"text": "harder problem and the goal of this is", "start": 7409.44, "duration": 6.84}, {"text": "to reconstruct the input images from", "start": 7412.639, "duration": 4.761}, {"text": "noisy", "start": 7416.28, "duration": 3.08}, {"text": "input", "start": 7417.4, "duration": 4.44}, {"text": "um okay so my first set you know my", "start": 7419.36, "duration": 4.96}, {"text": "first I have some import", "start": 7421.84, "duration": 5.12}, {"text": "statements I prepare a data set this is", "start": 7424.32, "duration": 4.839}, {"text": "the same thing I did before here I have", "start": 7426.96, "duration": 5.639}, {"text": "an add noise function it's basically", "start": 7429.159, "duration": 5.121}, {"text": "adding uniform noise and you'll see what", "start": 7432.599, "duration": 3.441}, {"text": "that looks", "start": 7434.28, "duration": 4.439}, {"text": "like the model that we're making is", "start": 7436.04, "duration": 4.24}, {"text": "going to be again it's going to be a", "start": 7438.719, "duration": 5.641}, {"text": "unet model it does encoding a bottleneck", "start": 7440.28, "duration": 6.279}, {"text": "and then a decoding with", "start": 7444.36, "duration": 3.96}, {"text": "upsampling uh and we're going to start", "start": 7446.559, "duration": 3.68}, {"text": "with some input it's the input's going", "start": 7448.32, "duration": 3.12}, {"text": "to be noisy so it's not going to look", "start": 7450.239, "duration": 4.32}, {"text": "like this it's going to be", "start": 7451.44, "duration": 5.6}, {"text": "reconstructed and let's look at this", "start": 7454.559, "duration": 5.0}, {"text": "encoder block so I've split up my coding", "start": 7457.04, "duration": 6.559}, {"text": "functions a little bit um so my encoder", "start": 7459.559, "duration": 5.881}, {"text": "block is a convolution it's a little", "start": 7463.599, "duration": 4.321}, {"text": "block convolution followed by Max", "start": 7465.44, "duration": 4.88}, {"text": "pooling another convolution followed by", "start": 7467.92, "duration": 3.799}, {"text": "another Max", "start": 7470.32, "duration": 3.839}, {"text": "pooling um so this is the", "start": 7471.719, "duration": 6.801}, {"text": "encoding but what's uh relevant for us", "start": 7474.159, "duration": 6.201}, {"text": "or what's maybe a little bit different", "start": 7478.52, "duration": 4.119}, {"text": "is I'm returning not just the last layer", "start": 7480.36, "duration": 4.64}, {"text": "of Max pooling I'm returning the", "start": 7482.639, "duration": 5.121}, {"text": "previous convolution", "start": 7485.0, "duration": 5.76}, {"text": "layers so take a look at that code", "start": 7487.76, "duration": 4.919}, {"text": "there's a bottleneck function to create", "start": 7490.76, "duration": 4.28}, {"text": "the bottleneck", "start": 7492.679, "duration": 9.121}, {"text": "layer um I have a decoder without", "start": 7495.04, "duration": 8.84}, {"text": "concatenation so what you want to do is", "start": 7501.8, "duration": 3.319}, {"text": "you'll be able to run this I think", "start": 7503.88, "duration": 2.96}, {"text": "without changing anything and the", "start": 7505.119, "duration": 4.12}, {"text": "decoder has blocks of a convolution then", "start": 7506.84, "duration": 4.44}, {"text": "an upsample followed by another", "start": 7509.239, "duration": 4.4}, {"text": "convolution and another up", "start": 7511.28, "duration": 4.799}, {"text": "sample and then a third", "start": 7513.639, "duration": 5.801}, {"text": "convolution where I just have one filter", "start": 7516.079, "duration": 5.321}, {"text": "with the kernel size the activation is a", "start": 7519.44, "duration": 4.04}, {"text": "sigmoid so this last convolution layer", "start": 7521.4, "duration": 5.199}, {"text": "is actually transforming everything into", "start": 7523.48, "duration": 4.079}, {"text": "a", "start": 7526.599, "duration": 7.241}, {"text": "28 by 28 by 1", "start": 7527.559, "duration": 6.281}, {"text": "output okay so the training actually be", "start": 7534.92, "duration": 5.84}, {"text": "applied to that to that final", "start": 7537.32, "duration": 6.52}, {"text": "map so I have those subfunctions", "start": 7540.76, "duration": 5.12}, {"text": "convolution Auto encoder is going to put", "start": 7543.84, "duration": 5.56}, {"text": "those together and notice that", "start": 7545.88, "duration": 6.88}, {"text": "um here let's see uh okay so there's my", "start": 7549.4, "duration": 6.159}, {"text": "model statement and the model statement", "start": 7552.76, "duration": 4.72}, {"text": "says you know put together these inputs", "start": 7555.559, "duration": 3.721}, {"text": "and those outputs and make a model out", "start": 7557.48, "duration": 4.599}, {"text": "of it and the model statement can go and", "start": 7559.28, "duration": 8.319}, {"text": "just uh you know build up um from the", "start": 7562.079, "duration": 5.52}, {"text": "subfunctions okay so take a look that", "start": 7568.719, "duration": 4.44}, {"text": "you can actually go ahead and run this", "start": 7571.48, "duration": 3.8}, {"text": "without changing anything and", "start": 7573.159, "duration": 5.04}, {"text": "then before you before you start though", "start": 7575.28, "duration": 5.2}, {"text": "uh I have these statements here what", "start": 7578.199, "duration": 4.561}, {"text": "you're going to want to do is go to look", "start": 7580.48, "duration": 4.679}, {"text": "at look up the documentation for", "start": 7582.76, "duration": 4.12}, {"text": "concatenate and you're going to add a", "start": 7585.159, "duration": 4.4}, {"text": "concatenate statement here and we're", "start": 7586.88, "duration": 4.719}, {"text": "going to use a skip concatenate I called", "start": 7589.559, "duration": 4.921}, {"text": "it skip concatenate", "start": 7591.599, "duration": 5.881}, {"text": "one uh it's going to build a", "start": 7594.48, "duration": 6.119}, {"text": "concatenation and", "start": 7597.48, "duration": 5.239}, {"text": "uh that's going to feed into the next", "start": 7600.599, "duration": 4.201}, {"text": "layer so you're going to want to concat", "start": 7602.719, "duration": 4.0}, {"text": "got to make sure you so now notice in", "start": 7604.8, "duration": 5.2}, {"text": "the decoder you have in", "start": 7606.719, "duration": 5.721}, {"text": "inputs and you also are going to pass", "start": 7610.0, "duration": 6.079}, {"text": "into it the con the convolutional output", "start": 7612.44, "duration": 5.239}, {"text": "from the encoder so that's what these", "start": 7616.079, "duration": 4.361}, {"text": "two parameters are into this argument so", "start": 7617.679, "duration": 3.641}, {"text": "those are the things you're going to", "start": 7620.44, "duration": 3.4}, {"text": "want to use when you build up this skit", "start": 7621.32, "duration": 5.12}, {"text": "concatenation so take a few minutes I'm", "start": 7623.84, "duration": 5.16}, {"text": "going to give you uh just a one more one", "start": 7626.44, "duration": 4.56}, {"text": "more little bit of uh", "start": 7629.0, "duration": 4.04}, {"text": "information it turns out when you go", "start": 7631.0, "duration": 5.239}, {"text": "into Caris and look at concatenation", "start": 7633.04, "duration": 6.039}, {"text": "there's two concatenation functions one", "start": 7636.239, "duration": 5.4}, {"text": "of them is a Capital C and one of them", "start": 7639.079, "duration": 3.761}, {"text": "is a small", "start": 7641.639, "duration": 4.361}, {"text": "C okay so just be clear if you if you go", "start": 7642.84, "duration": 6.0}, {"text": "and do a search on concatenate you'll", "start": 7646.0, "duration": 4.52}, {"text": "come across the ones with a small c as", "start": 7648.84, "duration": 3.6}, {"text": "well so you just want to be clear about", "start": 7650.52, "duration": 4.559}, {"text": "that it's it's a little bit confusing uh", "start": 7652.44, "duration": 4.119}, {"text": "it's one of those quirks of carot I", "start": 7655.079, "duration": 3.6}, {"text": "think like they have a Capital C", "start": 7656.559, "duration": 4.6}, {"text": "concatenate where it's like a functional", "start": 7658.679, "duration": 3.761}, {"text": "definition and then a small C", "start": 7661.159, "duration": 3.841}, {"text": "concatenate where uh you actually put", "start": 7662.44, "duration": 4.96}, {"text": "the parameters inside the first", "start": 7665.0, "duration": 5.04}, {"text": "parentheses so", "start": 7667.4, "duration": 4.199}, {"text": "why that's I'm not quite sure why that's", "start": 7670.04, "duration": 4.28}, {"text": "there but it's", "start": 7671.599, "duration": 2.721}, {"text": "there all right but as I said before you", "start": 7677.639, "duration": 4.08}, {"text": "do that go ahead and run everything I'm", "start": 7679.76, "duration": 3.24}, {"text": "going to go ahead", "start": 7681.719, "duration": 5.081}, {"text": "and run it as it", "start": 7683.0, "duration": 3.8}, {"text": "is", "start": 7697.44, "duration": 3.0}, {"text": "okay so I got some warning here", "start": 7715.36, "duration": 5.68}, {"text": "but um oh because it's because it's not", "start": 7718.52, "duration": 5.0}, {"text": "on a GPU", "start": 7721.04, "duration": 6.24}, {"text": "device but as you can see it's", "start": 7723.52, "duration": 3.76}, {"text": "running the problem is small again the", "start": 7727.4, "duration": 5.64}, {"text": "problem is small enough to run on a CPU", "start": 7729.88, "duration": 5.4}, {"text": "no", "start": 7733.04, "duration": 2.24}, {"text": "problem", "start": 7757.32, "duration": 3.0}, {"text": "okay so I just ran this for 20", "start": 7765.52, "duration": 4.639}, {"text": "epics", "start": 7767.92, "duration": 4.96}, {"text": "um the validation loss looks like it was", "start": 7770.159, "duration": 3.881}, {"text": "still going down so it probably could", "start": 7772.88, "duration": 3.64}, {"text": "have ran for", "start": 7774.04, "duration": 5.0}, {"text": "more I have I have some functions to", "start": 7776.52, "duration": 3.84}, {"text": "help me", "start": 7779.04, "duration": 5.039}, {"text": "display the the input and the output", "start": 7780.36, "duration": 5.56}, {"text": "predictions that's what these are that's", "start": 7784.079, "duration": 3.241}, {"text": "what's going on in", "start": 7785.92, "duration": 4.319}, {"text": "here and it looks something like this so", "start": 7787.32, "duration": 6.2}, {"text": "this is an example of my input images", "start": 7790.239, "duration": 5.641}, {"text": "they're pretty noisy you could probably", "start": 7793.52, "duration": 5.84}, {"text": "look at these and take a guess what they", "start": 7795.88, "duration": 6.319}, {"text": "what the original images look like and", "start": 7799.36, "duration": 6.16}, {"text": "these are the predicted images I'm sorry", "start": 7802.199, "duration": 5.561}, {"text": "the reconstructed images down here so", "start": 7805.52, "duration": 4.48}, {"text": "from the reconstructed", "start": 7807.76, "duration": 4.68}, {"text": "images hopefully you you you know you're", "start": 7810.0, "duration": 4.28}, {"text": "getting close to this point uh you can", "start": 7812.44, "duration": 3.199}, {"text": "see that some of them do pretty well", "start": 7814.28, "duration": 2.959}, {"text": "some of them are not so", "start": 7815.639, "duration": 4.6}, {"text": "well", "start": 7817.239, "duration": 3.0}, {"text": "okay and if you get to run it you look", "start": 7829.96, "duration": 4.639}, {"text": "at the performance and then go back and", "start": 7832.119, "duration": 4.08}, {"text": "add the skip connections I'm going to", "start": 7834.599, "duration": 2.96}, {"text": "give everyone a few minutes we'll give", "start": 7836.199, "duration": 3.161}, {"text": "everyone five minutes and then I'll do", "start": 7837.559, "duration": 4.401}, {"text": "then we'll do it", "start": 7839.36, "duration": 2.6}, {"text": "together", "start": 7847.239, "duration": 5.241}, {"text": "okay I'm going to go ahead and uh see if", "start": 7849.44, "duration": 3.84}, {"text": "I", "start": 7852.48, "duration": 3.599}, {"text": "can fill in", "start": 7853.28, "duration": 6.959}, {"text": "the statements to add Skip", "start": 7856.079, "duration": 4.16}, {"text": "connections okay so I'm going to use", "start": 7873.48, "duration": 7.639}, {"text": "my this concatenate", "start": 7877.159, "duration": 7.721}, {"text": "function and let's", "start": 7881.119, "duration": 6.921}, {"text": "see I think I'm concatenating along axis", "start": 7884.88, "duration": 5.48}, {"text": "two because the height and width are", "start": 7888.04, "duration": 4.599}, {"text": "going to be the same but I'm just", "start": 7890.36, "duration": 4.719}, {"text": "essentially bringing along the features", "start": 7892.639, "duration": 5.761}, {"text": "from the previous some previous", "start": 7895.079, "duration": 6.401}, {"text": "layer so I'm going to concatenate the up", "start": 7898.4, "duration": 6.08}, {"text": "sample", "start": 7901.48, "duration": 3.0}, {"text": "one convolution with the", "start": 7905.96, "duration": 8.0}, {"text": "encoding convolution one layer or output", "start": 7910.28, "duration": 8.6}, {"text": "that was given into this decoder", "start": 7913.96, "duration": 4.92}, {"text": "function and then my convolution two", "start": 7922.679, "duration": 5.321}, {"text": "statement instead of using up sample one", "start": 7925.44, "duration": 4.6}, {"text": "it has to", "start": 7928.0, "duration": 4.48}, {"text": "use Skip", "start": 7930.04, "duration": 5.44}, {"text": "concatenation", "start": 7932.48, "duration": 3.0}, {"text": "One there's an underscore there", "start": 7935.639, "duration": 6.641}, {"text": "now one thing you have to keep in", "start": 7939.04, "duration": 3.24}, {"text": "mind", "start": 7942.32, "duration": 3.0}, {"text": "is", "start": 7946.52, "duration": 4.84}, {"text": "um matching up the right sizes so this I", "start": 7948.119, "duration": 4.44}, {"text": "think this is going to give me an error", "start": 7951.36, "duration": 3.12}, {"text": "but I'm going to go ahead and use it I'm", "start": 7952.559, "duration": 3.481}, {"text": "not going to add the other convol the", "start": 7954.48, "duration": 4.079}, {"text": "other concatenation yet what I'm going", "start": 7956.04, "duration": 4.28}, {"text": "to do just to", "start": 7958.559, "duration": 5.361}, {"text": "get a", "start": 7960.32, "duration": 3.6}, {"text": "um let's", "start": 7964.159, "duration": 5.881}, {"text": "see", "start": 7967.04, "duration": 3.0}, {"text": "just for debugging", "start": 7977.079, "duration": 3.0}, {"text": "purposes I'm going to", "start": 7980.32, "duration": 6.2}, {"text": "add a couple print statements on the", "start": 7983.84, "duration": 7.6}, {"text": "shape let see I do this right", "start": 7986.52, "duration": 4.92}, {"text": "okay okay I got an error because the", "start": 7992.84, "duration": 7.0}, {"text": "shapes are not quite right I think so", "start": 7995.92, "duration": 6.88}, {"text": "first shape is 14 by 14 the second shape", "start": 7999.84, "duration": 5.64}, {"text": "was 28 by", "start": 8002.8, "duration": 2.68}, {"text": "28 what happened well let me find those", "start": 8007.32, "duration": 5.839}, {"text": "code that code", "start": 8011.76, "duration": 3.52}, {"text": "again in the picture remember", "start": 8013.159, "duration": 3.721}, {"text": "convolution one was 28 X2 it's", "start": 8015.28, "duration": 2.919}, {"text": "convolution", "start": 8016.88, "duration": 5.199}, {"text": "two that down samples to a 14 by 14 so", "start": 8018.199, "duration": 6.04}, {"text": "when I go to my decoding function and I", "start": 8022.079, "duration": 3.52}, {"text": "say I want to do a", "start": 8024.239, "duration": 3.4}, {"text": "concatenation the first concatenation", "start": 8025.599, "duration": 4.201}, {"text": "has to to be the first upsampling and", "start": 8027.639, "duration": 6.241}, {"text": "the second convolution layer so it's in", "start": 8029.8, "duration": 4.08}, {"text": "Reverse hopefully that makes", "start": 8034.159, "duration": 4.761}, {"text": "sense uh it can be a little bit", "start": 8036.679, "duration": 5.201}, {"text": "confusing but if you work through the", "start": 8038.92, "duration": 6.319}, {"text": "the shapes in the model", "start": 8041.88, "duration": 3.359}, {"text": "summary you will see that it makes sense", "start": 8045.599, "duration": 5.321}, {"text": "and then this has to be the second", "start": 8047.679, "duration": 5.601}, {"text": "concatenation has to use the second", "start": 8050.92, "duration": 5.44}, {"text": "upsampling with the first convolution", "start": 8053.28, "duration": 6.08}, {"text": "layer and now that has to be the input", "start": 8056.36, "duration": 4.52}, {"text": "into my", "start": 8059.36, "duration": 5.16}, {"text": "last convolution", "start": 8060.88, "duration": 3.64}, {"text": "layer yep there it is", "start": 8065.84, "duration": 4.319}, {"text": "okay now it build a model I have the", "start": 8073.88, "duration": 4.759}, {"text": "model summary again the model summary is", "start": 8076.48, "duration": 3.679}, {"text": "very useful to go and look at these", "start": 8078.639, "duration": 4.681}, {"text": "shapes see how big and small your your", "start": 8080.159, "duration": 6.04}, {"text": "bottlenecks are your downsizing your max", "start": 8083.32, "duration": 5.44}, {"text": "pooling um if we look at the", "start": 8086.199, "duration": 6.601}, {"text": "concatenation so here is the second", "start": 8088.76, "duration": 6.799}, {"text": "concatenation notice oh look what it did", "start": 8092.8, "duration": 4.96}, {"text": "did that doesn't look right does", "start": 8095.559, "duration": 5.441}, {"text": "it you see what happened is any see I", "start": 8097.76, "duration": 8.08}, {"text": "hope hopefully this is um a little bit", "start": 8101.0, "duration": 9.48}, {"text": "clear so my second concatenation took my", "start": 8105.84, "duration": 6.16}, {"text": "let's go to the first concatenation this", "start": 8110.48, "duration": 3.0}, {"text": "is where it first messed up so my first", "start": 8112.0, "duration": 5.44}, {"text": "concatenation I have 14x 14 by 128 is", "start": 8113.48, "duration": 7.96}, {"text": "the upper sampling that was there and I", "start": 8117.44, "duration": 8.4}, {"text": "was combining that with the 14x 14", "start": 8121.44, "duration": 7.96}, {"text": "images from the encoding layers so I", "start": 8125.84, "duration": 6.12}, {"text": "should end up with 14 by", "start": 8129.4, "duration": 7.12}, {"text": "14 height and width by instead of to 128", "start": 8131.96, "duration": 6.4}, {"text": "that should be 256 so look so it", "start": 8136.52, "duration": 4.48}, {"text": "concatenated it into the wrong", "start": 8138.36, "duration": 6.239}, {"text": "spot what did I do", "start": 8141.0, "duration": 3.599}, {"text": "wrong what did I do wrong let's see", "start": 8145.199, "duration": 4.601}, {"text": "I used axis equals", "start": 8151.4, "duration": 6.36}, {"text": "2 I think I want axis equals", "start": 8153.48, "duration": 4.28}, {"text": "three uh so let's run that", "start": 8161.36, "duration": 4.4}, {"text": "that", "start": 8166.84, "duration": 5.359}, {"text": "now ah now my", "start": 8168.8, "duration": 5.799}, {"text": "concatenation so there's the", "start": 8172.199, "duration": 4.841}, {"text": "bottleneck this first concatenation is", "start": 8174.599, "duration": 4.321}, {"text": "now 14x 14x", "start": 8177.04, "duration": 5.679}, {"text": "256 and I have 14 X 14 64 a convolution", "start": 8178.92, "duration": 7.36}, {"text": "layer there's an upsampling and the", "start": 8182.719, "duration": 7.36}, {"text": "concatenation and boom my final output", "start": 8186.28, "duration": 6.119}, {"text": "layer all right so now we can go ahead", "start": 8190.079, "duration": 5.64}, {"text": "and test it", "start": 8192.399, "duration": 3.32}, {"text": "out all right so this is going to take a", "start": 8196.8, "duration": 5.679}, {"text": "few minutes to run and display results", "start": 8198.76, "duration": 5.4}, {"text": "I'm just going to wait right here", "start": 8202.479, "duration": 3.521}, {"text": "hopefully you guys see you know you get", "start": 8204.16, "duration": 3.64}, {"text": "a feel for what it's like when you're", "start": 8206.0, "duration": 4.08}, {"text": "coding with Caris you're looking at the", "start": 8207.8, "duration": 3.839}, {"text": "apis you're saying oh I need these", "start": 8210.08, "duration": 3.399}, {"text": "options here these options here getting", "start": 8211.639, "duration": 3.481}, {"text": "those shapes are probably getting those", "start": 8213.479, "duration": 3.641}, {"text": "shapes right", "start": 8215.12, "duration": 4.16}, {"text": "um uh I don't want to say It's Tricky", "start": 8217.12, "duration": 4.0}, {"text": "but that's the that to me is like the", "start": 8219.28, "duration": 3.359}, {"text": "one thing where it's so easy to make a", "start": 8221.12, "duration": 3.88}, {"text": "mistake and and not realize", "start": 8222.639, "duration": 6.241}, {"text": "it um I was I was recently doing a", "start": 8225.0, "duration": 5.519}, {"text": "project where I I was building a custom", "start": 8228.88, "duration": 3.88}, {"text": "loss function so Caris has a loss", "start": 8230.519, "duration": 3.96}, {"text": "function that you know a set of set loss", "start": 8232.76, "duration": 3.52}, {"text": "function that are standard and you can", "start": 8234.479, "duration": 3.641}, {"text": "build your own loss function", "start": 8236.28, "duration": 4.399}, {"text": "and pass it into the as part of the", "start": 8238.12, "duration": 3.88}, {"text": "model compile", "start": 8240.679, "duration": 4.241}, {"text": "step and I was taking tensor flow", "start": 8242.0, "duration": 6.0}, {"text": "tensors the T variables and multiplying", "start": 8244.92, "duration": 5.84}, {"text": "them together and it kept give it kept", "start": 8248.0, "duration": 6.719}, {"text": "producing instead of I had a n by one", "start": 8250.76, "duration": 6.0}, {"text": "times a 1 by", "start": 8254.719, "duration": 5.6}, {"text": "n and because it wasn't fully specified", "start": 8256.76, "duration": 5.12}, {"text": "it was like a n comma you know python", "start": 8260.319, "duration": 3.881}, {"text": "has this these kinds of shapes where it", "start": 8261.88, "duration": 4.24}, {"text": "doesn't have the the last Dimension so", "start": 8264.2, "duration": 5.08}, {"text": "was n by one it was treated at n comma", "start": 8266.12, "duration": 7.319}, {"text": "shape as n by one basically I'm sorry I", "start": 8269.28, "duration": 5.64}, {"text": "think I think I have it backwards I had", "start": 8273.439, "duration": 6.841}, {"text": "a 1 byn and a and a a one comma or just", "start": 8274.92, "duration": 8.639}, {"text": "an N vector and made it a 1 byn and it", "start": 8280.28, "duration": 5.48}, {"text": "was giving me an outer product instead", "start": 8283.559, "duration": 3.521}, {"text": "of an element", "start": 8285.76, "duration": 5.559}, {"text": "wise U product between two vectors so I", "start": 8287.08, "duration": 6.84}, {"text": "ended up having these results that were", "start": 8291.319, "duration": 4.12}, {"text": "almost", "start": 8293.92, "duration": 5.32}, {"text": "sensible um and and luckily you know", "start": 8295.439, "duration": 5.04}, {"text": "there was one thing that was quirky", "start": 8299.24, "duration": 3.119}, {"text": "about my results and and I was able to", "start": 8300.479, "duration": 3.801}, {"text": "track down that oh I just had to add a", "start": 8302.359, "duration": 4.761}, {"text": "dimension to this tensor so that it", "start": 8304.28, "duration": 5.119}, {"text": "would treat an N by one times an N by", "start": 8307.12, "duration": 5.279}, {"text": "one with an element wise multiplication", "start": 8309.399, "duration": 6.681}, {"text": "anyway that's a long way of saying uh", "start": 8312.399, "duration": 6.12}, {"text": "you know some of these T it's the shapes", "start": 8316.08, "duration": 5.479}, {"text": "you have to sometimes be careful", "start": 8318.519, "duration": 6.401}, {"text": "of okay so this is still running I think", "start": 8321.559, "duration": 4.96}, {"text": "let's see where's it", "start": 8324.92, "duration": 4.399}, {"text": "at oh okay here we", "start": 8326.519, "duration": 5.2}, {"text": "go all right so this is the", "start": 8329.319, "duration": 4.2}, {"text": "Reconstruction I think you'll see that", "start": 8331.719, "duration": 4.201}, {"text": "the Reconstruction looks better than it", "start": 8333.519, "duration": 4.401}, {"text": "did before without the skip", "start": 8335.92, "duration": 4.0}, {"text": "connections uh let's see what is the", "start": 8337.92, "duration": 4.0}, {"text": "error here the validation", "start": 8339.92, "duration": 4.479}, {"text": "loss is I you know what I didn't", "start": 8341.92, "duration": 3.96}, {"text": "remember what it was in the previous", "start": 8344.399, "duration": 3.92}, {"text": "execution but here it's uh I think it's", "start": 8345.88, "duration": 5.0}, {"text": "lower than it was", "start": 8348.319, "duration": 5.561}, {"text": "before", "start": 8350.88, "duration": 3.0}, {"text": "um and I would say t definitely this", "start": 8355.08, "duration": 5.279}, {"text": "this one is better than it was", "start": 8358.359, "duration": 4.96}, {"text": "before I'm pretty sure this is a", "start": 8360.359, "duration": 5.36}, {"text": "one and there's a little dot there that", "start": 8363.319, "duration": 4.601}, {"text": "suggests it's a funny maybe a funny", "start": 8365.719, "duration": 5.401}, {"text": "seven uh a couple of these were very", "start": 8367.92, "duration": 4.08}, {"text": "hard", "start": 8371.12, "duration": 4.399}, {"text": "to to guess what they were before", "start": 8372.0, "duration": 5.519}, {"text": "without the skip", "start": 8375.519, "duration": 3.641}, {"text": "connections hopefully you're getting", "start": 8377.519, "duration": 3.96}, {"text": "that same kind of result so adding the", "start": 8379.16, "duration": 4.76}, {"text": "skip connections the again the intuition", "start": 8381.479, "duration": 4.92}, {"text": "is that you're able to reuse some of", "start": 8383.92, "duration": 5.0}, {"text": "these lower level features Fe to", "start": 8386.399, "duration": 5.761}, {"text": "properly reconstruct this output and", "start": 8388.92, "duration": 6.519}, {"text": "again uh as my mentioned this unet is", "start": 8392.16, "duration": 4.96}, {"text": "used not for just reconstruction but", "start": 8395.439, "duration": 2.681}, {"text": "image", "start": 8397.12, "duration": 3.52}, {"text": "segmentation", "start": 8398.12, "duration": 5.08}, {"text": "um uh and I don't remember the other", "start": 8400.64, "duration": 5.32}, {"text": "ones it's used in different kinds", "start": 8403.2, "duration": 6.119}, {"text": "of uh situations where you're", "start": 8405.96, "duration": 5.08}, {"text": "reproducing an", "start": 8409.319, "duration": 4.12}, {"text": "image okay so your last convolution", "start": 8411.04, "duration": 5.08}, {"text": "layer your last layer is actually like", "start": 8413.439, "duration": 5.281}, {"text": "you know it's going to have it's", "start": 8416.12, "duration": 5.6}, {"text": "basically it has in this example 28 by", "start": 8418.72, "duration": 4.719}, {"text": "28 output", "start": 8421.72, "duration": 5.32}, {"text": "units and each output unit is producing", "start": 8423.439, "duration": 5.88}, {"text": "some", "start": 8427.04, "duration": 2.279}, {"text": "error", "start": 8431.6, "duration": 3.0}, {"text": "okay any questions on", "start": 8434.64, "duration": 5.16}, {"text": "that", "start": 8444.439, "duration": 3.641}, {"text": "um", "start": 8446.319, "duration": 3.561}, {"text": "let me let me give a second for", "start": 8448.08, "duration": 4.399}, {"text": "questions to come back in I think I'm", "start": 8449.88, "duration": 4.36}, {"text": "done with the slides let me make sure", "start": 8452.479, "duration": 4.121}, {"text": "that's the", "start": 8454.24, "duration": 2.36}, {"text": "case oh okay see I I had did this before", "start": 8458.319, "duration": 6.201}, {"text": "I I kept track of the", "start": 8461.2, "duration": 6.32}, {"text": "loss", "start": 8464.52, "duration": 3.0}, {"text": "um all right are there any", "start": 8469.16, "duration": 6.279}, {"text": "other any other", "start": 8471.88, "duration": 3.559}, {"text": "questions um", "start": 8475.88, "duration": 3.36}, {"text": "let's see oh I know what I wanted to say", "start": 8484.68, "duration": 4.6}, {"text": "I wanted I wanted I did want", "start": 8486.12, "duration": 6.72}, {"text": "to so earlier there was a", "start": 8489.28, "duration": 7.079}, {"text": "slide that Ma talked about this", "start": 8492.84, "duration": 7.0}, {"text": "Transformer and um oops ah sorry about", "start": 8496.359, "duration": 7.281}, {"text": "that hang on there we", "start": 8499.84, "duration": 3.8}, {"text": "go so in the Transformer you remember we", "start": 8504.08, "duration": 3.76}, {"text": "were talking about the this this", "start": 8506.76, "duration": 2.36}, {"text": "attention mechanism and I was telling", "start": 8507.84, "duration": 3.0}, {"text": "you about how the attention mechanism", "start": 8509.12, "duration": 5.52}, {"text": "was in fact doing a soft Max but in the", "start": 8510.84, "duration": 5.88}, {"text": "Transformer not only are they doing a", "start": 8514.64, "duration": 4.12}, {"text": "soft Max but they're also doing these", "start": 8516.72, "duration": 3.36}, {"text": "skip", "start": 8518.76, "duration": 3.639}, {"text": "connections so you'll see this I mean", "start": 8520.08, "duration": 5.399}, {"text": "this is this is what you know it makes", "start": 8522.399, "duration": 5.441}, {"text": "the model is kind of complicated when", "start": 8525.479, "duration": 5.561}, {"text": "you look at it this way if you break it", "start": 8527.84, "duration": 6.04}, {"text": "down uh then it becomes more", "start": 8531.04, "duration": 4.0}, {"text": "understandable you see there's this", "start": 8533.88, "duration": 2.599}, {"text": "attention mechanism inside that", "start": 8535.04, "duration": 2.96}, {"text": "attention mechanism is this you know", "start": 8536.479, "duration": 4.401}, {"text": "there's this gating going on to see", "start": 8538.0, "duration": 5.76}, {"text": "what's relevant and and then beyond that", "start": 8540.88, "duration": 6.559}, {"text": "there is this uh skip connection and in", "start": 8543.76, "duration": 6.0}, {"text": "this case they're doing an skip with an", "start": 8547.439, "duration": 4.121}, {"text": "ad and there's doing some normalization", "start": 8549.76, "duration": 3.28}, {"text": "as", "start": 8551.56, "duration": 4.56}, {"text": "well uh so you know these these", "start": 8553.04, "duration": 5.0}, {"text": "complicated networks are kind of taking", "start": 8556.12, "duration": 4.64}, {"text": "some of these these you know I think", "start": 8558.04, "duration": 6.48}, {"text": "ideas that are that uh by themselves are", "start": 8560.76, "duration": 5.4}, {"text": "not too bad but they're combining them", "start": 8564.52, "duration": 3.2}, {"text": "because they just keep adding", "start": 8566.16, "duration": 4.92}, {"text": "you know layers and and more uh uh kinds", "start": 8567.72, "duration": 4.679}, {"text": "of Transformations that they're looking", "start": 8571.08, "duration": 3.6}, {"text": "for so they're guiding they're really", "start": 8572.399, "duration": 3.681}, {"text": "guiding this architecture is like", "start": 8574.68, "duration": 3.12}, {"text": "guiding the network into solving this", "start": 8576.08, "duration": 3.12}, {"text": "kind of", "start": 8577.8, "duration": 3.48}, {"text": "problem so that's that's how I think", "start": 8579.2, "duration": 3.4}, {"text": "these things get built up I think", "start": 8581.28, "duration": 2.64}, {"text": "whoever you know there's probably some", "start": 8582.6, "duration": 3.719}, {"text": "trial and error going on uh in fact I'm", "start": 8583.92, "duration": 6.439}, {"text": "sure there is um when people working out", "start": 8586.319, "duration": 6.801}, {"text": "these these bigger", "start": 8590.359, "duration": 2.761}, {"text": "models okay so that is the last thing I", "start": 8594.04, "duration": 4.04}, {"text": "wanted to say", "start": 8596.72, "duration": 5.88}, {"text": "uh again um you know we could go down a", "start": 8598.08, "duration": 6.72}, {"text": "path of a lot more different kinds of", "start": 8602.6, "duration": 4.719}, {"text": "architectural things people do uh but", "start": 8604.8, "duration": 5.2}, {"text": "hopefully this gives you a flavor for uh", "start": 8607.319, "duration": 4.481}, {"text": "you know some of those", "start": 8610.0, "duration": 4.8}, {"text": "elements", "start": 8611.8, "duration": 3.0}]